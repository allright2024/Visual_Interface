[
  {
    "feature_id": 0,
    "explanation_index": 0,
    "text": "Phrases or words that introduce a question or explanation about a process, situation, or method, often beginning with \\\"how\\\".",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8876654505729675,
    "similarity_var": 0.0009401434167296922,
    "score_fuzz": 0.75,
    "score_detection": 0.71,
    "score_embedding": 0.5664,
    "total_score": 0.6754666666666665,
    "x": 11.194704055786133,
    "y": 1.8127447366714478,
    "cluster_id": 73
  },
  {
    "feature_id": 0,
    "explanation_index": 1,
    "text": "The pattern involves the use of \\\"how\\\" followed by a clause or phrase that introduces a question or explanation about a process, method, or effect, often involving modal verbs like \\\"to,\\\" \\\"can,\\\" \\\"will,\\\" or \\\"might,\\\" and frequently associated with instructional, analytical, or speculative content.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8876654505729675,
    "similarity_var": 0.0009401434167296922,
    "score_fuzz": 0.71,
    "score_detection": 0.71,
    "score_embedding": 0.5356249999999999,
    "total_score": 0.651875,
    "x": 10.483792304992676,
    "y": 6.6082844734191895,
    "cluster_id": -1
  },
  {
    "feature_id": 0,
    "explanation_index": 2,
    "text": "The highlighted tokens are almost always the first word of a clause or phrase that introduces a question, a subordinate clause, or a directive, and they are typically function words such as \u201chow\u201d, \u201cto\u201d, \u201cis\u201d, \u201cwill\u201d, \u201cand\u201d, \u201cbut\u201d, or \u201cthe\u201d.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8876654505729675,
    "similarity_var": 0.0009401434167296922,
    "score_fuzz": 0.575,
    "score_detection": 0.8,
    "score_embedding": 0.25375000000000003,
    "total_score": 0.5429166666666667,
    "x": 14.049654960632324,
    "y": 3.583242893218994,
    "cluster_id": 0
  },
  {
    "feature_id": 1,
    "explanation_index": 0,
    "text": "The token \\\"define\\\" or its variants, often used in formal or technical contexts, such as mathematics, programming, or legal documents, to introduce or specify a concept, term, or entity.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9113221963246664,
    "similarity_var": 3.802802052237869e-05,
    "score_fuzz": 0.71,
    "score_detection": 0.68,
    "score_embedding": 0.5703999999999999,
    "total_score": 0.6534666666666666,
    "x": 10.674412727355957,
    "y": 3.0461959838867188,
    "cluster_id": -1
  },
  {
    "feature_id": 1,
    "explanation_index": 1,
    "text": "The word \\\"defined\\\" and its variants (e.g., \\\"defining\\\", \\\"undefined\\\", \\\"deficient\\\", \\\"defensive\\\") frequently appear in contexts involving formal definitions, technical specifications, or logical conditions, often in academic, programming, or legal texts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9113221963246664,
    "similarity_var": 3.802802052237869e-05,
    "score_fuzz": 0.7,
    "score_detection": 0.66,
    "score_embedding": 0.6031250000000001,
    "total_score": 0.654375,
    "x": 10.646286964416504,
    "y": 2.8347322940826416,
    "cluster_id": -1
  },
  {
    "feature_id": 1,
    "explanation_index": 2,
    "text": "Tokens that signal a definition or a definition\u2011related context\u2014most commonly words beginning with \u201cdef\u201d or \u201cdefine\u201d (e.g., define, defined, defining, defendant, defensive, defenses, deficient) and code\u2011style macros or variable names that start with \u201cdf\u201d or \u201cdefine\u201d.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9113221963246664,
    "similarity_var": 3.802802052237869e-05,
    "score_fuzz": 0.8,
    "score_detection": 0.8,
    "score_embedding": 0.618125,
    "total_score": 0.739375,
    "x": 10.316665649414062,
    "y": 4.050498962402344,
    "cluster_id": -1
  },
  {
    "feature_id": 2,
    "explanation_index": 0,
    "text": "Tokens that are part of proper nouns, names of places, people, or organizations, or words that have a specific time-related meaning, such as \\\"hour\\\" or \\\"hours\\\".",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8536616166432699,
    "similarity_var": 0.00038522593601994824,
    "score_fuzz": 0.67,
    "score_detection": 0.8,
    "score_embedding": 0.19520000000000004,
    "total_score": 0.5550666666666667,
    "x": 10.062834739685059,
    "y": 4.439327239990234,
    "cluster_id": 1
  },
  {
    "feature_id": 2,
    "explanation_index": 1,
    "text": "Fragments of words or proper nouns, often part of compound terms or names, that are split across tokens and activated individually, particularly in contexts involving technical, biological, geographical, or branded terminology.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8536616166432699,
    "similarity_var": 0.00038522593601994824,
    "score_fuzz": 0.59,
    "score_detection": 0.56,
    "score_embedding": 0.14375,
    "total_score": 0.43124999999999997,
    "x": 7.0448079109191895,
    "y": 2.630777359008789,
    "cluster_id": 2
  },
  {
    "feature_id": 2,
    "explanation_index": 2,
    "text": "The highlighted tokens all share the common prefix \u201chor\u201d, appearing in words such as horse, horseradish, horizontal, horrors, hour, etc. This prefix is the latent feature that the model is detecting as important.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8536616166432699,
    "similarity_var": 0.00038522593601994824,
    "score_fuzz": 0.675,
    "score_detection": 0.7,
    "score_embedding": 0.1775,
    "total_score": 0.5175,
    "x": 14.811698913574219,
    "y": 5.003051280975342,
    "cluster_id": -1
  },
  {
    "feature_id": 3,
    "explanation_index": 0,
    "text": "Various tokens including numbers, mathematical symbols, and common function words, often used in formal or technical writing, such as academic or scientific texts, and sometimes in news articles or other informative content.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8764209747314453,
    "similarity_var": 0.0003416715133634322,
    "score_fuzz": 0.56,
    "score_detection": 0.46,
    "score_embedding": 0.518,
    "total_score": 0.5126666666666667,
    "x": 10.360152244567871,
    "y": 5.816988945007324,
    "cluster_id": -1
  },
  {
    "feature_id": 3,
    "explanation_index": 1,
    "text": "The token sequences often represent grammatical or syntactic elements, numerical values, or parts of compound terms, with activations frequently occurring at morphological suffixes, punctuation, or boundary markers in structured or technical text.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8764209747314453,
    "similarity_var": 0.0003416715133634322,
    "score_fuzz": 0.51,
    "score_detection": 0.6,
    "score_embedding": 0.535625,
    "total_score": 0.5485416666666666,
    "x": 10.976734161376953,
    "y": 5.398227214813232,
    "cluster_id": 51
  },
  {
    "feature_id": 3,
    "explanation_index": 2,
    "text": "The pattern? The tokens are often words or fragments that appear in the text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8764209747314453,
    "similarity_var": 0.0003416715133634322,
    "score_fuzz": 0.35,
    "score_detection": 0.45,
    "score_embedding": 0.43437499999999996,
    "total_score": 0.4114583333333333,
    "x": 11.270477294921875,
    "y": 4.414097785949707,
    "cluster_id": 3
  },
  {
    "feature_id": 4,
    "explanation_index": 0,
    "text": "Punctuation marks and special characters used in various contexts, including mathematical and programming notation, citations, and abbreviations.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8898617823918661,
    "similarity_var": 0.0012050741927356827,
    "score_fuzz": 0.55,
    "score_detection": 0.5,
    "score_embedding": 0.5220000000000001,
    "total_score": 0.524,
    "x": 8.601375579833984,
    "y": 7.372129917144775,
    "cluster_id": 4
  },
  {
    "feature_id": 4,
    "explanation_index": 1,
    "text": "Punctuation and special symbols such as parentheses, brackets, and delimiters are frequently used to denote technical or structural elements in text, including citations, code syntax, mathematical notation, and formatting markers.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8898617823918661,
    "similarity_var": 0.0012050741927356827,
    "score_fuzz": 0.58,
    "score_detection": 0.53,
    "score_embedding": 0.588125,
    "total_score": 0.5660416666666667,
    "x": 9.41232681274414,
    "y": 6.929836750030518,
    "cluster_id": -1
  },
  {
    "feature_id": 4,
    "explanation_index": 2,
    "text": "Tokens that act as structural delimiters\u2014parentheses, brackets, braces, commas, quotation marks, and other punctuation\u2014are consistently highlighted, indicating that the model focuses on the boundaries and formatting cues that separate or annotate the surrounding content.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8898617823918661,
    "similarity_var": 0.0012050741927356827,
    "score_fuzz": 0.575,
    "score_detection": 0.575,
    "score_embedding": 0.568125,
    "total_score": 0.5727083333333333,
    "x": 13.555500984191895,
    "y": 5.425673484802246,
    "cluster_id": -1
  },
  {
    "feature_id": 5,
    "explanation_index": 0,
    "text": "Punctuation marks, particularly commas, periods, and occasionally other symbols, often used to separate items in lists, set off clauses, or indicate the end of a sentence, and sometimes linking clauses or phrases.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.869495670000712,
    "similarity_var": 0.0009924265570578287,
    "score_fuzz": 0.74,
    "score_detection": 0.47,
    "score_embedding": 0.5496,
    "total_score": 0.5865333333333332,
    "x": 7.980985164642334,
    "y": 6.538263320922852,
    "cluster_id": 5
  },
  {
    "feature_id": 5,
    "explanation_index": 1,
    "text": "Common function words and punctuation marks (such as \\\"is\\\", \\\"was\\\", \\\",\\\", \\\".\\\", \\\"er\\\", \\\"especially\\\") that serve grammatical or syntactic roles in sentences, often appearing in contexts involving description, evaluation, or structural formatting.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.869495670000712,
    "similarity_var": 0.0009924265570578287,
    "score_fuzz": 0.74,
    "score_detection": 0.4,
    "score_embedding": 0.6362500000000001,
    "total_score": 0.5920833333333334,
    "x": 10.680213928222656,
    "y": 2.4399659633636475,
    "cluster_id": -1
  },
  {
    "feature_id": 5,
    "explanation_index": 2,
    "text": "The highlighted tokens are mainly short, high\u2011frequency function words or components of common idiomatic collocations that carry grammatical or semantic weight in the sentence.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.869495670000712,
    "similarity_var": 0.0009924265570578287,
    "score_fuzz": 0.525,
    "score_detection": 0.475,
    "score_embedding": 0.6531250000000001,
    "total_score": 0.5510416666666668,
    "x": 13.961591720581055,
    "y": 3.702458620071411,
    "cluster_id": -1
  },
  {
    "feature_id": 6,
    "explanation_index": 0,
    "text": "Special characters and symbols used in programming languages, such as operators, brackets, and semicolons, as well as keywords and identifiers in various programming contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8795420328776041,
    "similarity_var": 0.00014695102794427662,
    "score_fuzz": 0.45,
    "score_detection": 0.46,
    "score_embedding": 0.19480000000000003,
    "total_score": 0.3682666666666667,
    "x": 9.542817115783691,
    "y": 7.844647407531738,
    "cluster_id": 6
  },
  {
    "feature_id": 6,
    "explanation_index": 1,
    "text": "Specialized syntax and identifiers in code, often using uppercase tokens, underscores, and angle brackets to denote macros, templates, or preprocessor directives.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8795420328776041,
    "similarity_var": 0.00014695102794427662,
    "score_fuzz": 0.46,
    "score_detection": 0.45,
    "score_embedding": 0.286875,
    "total_score": 0.3989583333333333,
    "x": 10.60146427154541,
    "y": 7.359591007232666,
    "cluster_id": 7
  },
  {
    "feature_id": 6,
    "explanation_index": 2,
    "text": "The markers identify key code tokens\u2014identifiers, keywords, operators, and literals\u2014that are crucial for understanding the program\u2019s structure and behavior.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8795420328776041,
    "similarity_var": 0.00014695102794427662,
    "score_fuzz": 0.475,
    "score_detection": 0.425,
    "score_embedding": 0.21000000000000002,
    "total_score": 0.36999999999999994,
    "x": 13.674680709838867,
    "y": 6.729929447174072,
    "cluster_id": 8
  },
  {
    "feature_id": 7,
    "explanation_index": 0,
    "text": "Prepositions and conjunctions, often used to introduce or connect phrases, clauses, or ideas, and sometimes comparative or transitional words or phrases.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8517171343167623,
    "similarity_var": 0.004515468479213149,
    "score_fuzz": 0.79,
    "score_detection": 0.53,
    "score_embedding": 0.6236,
    "total_score": 0.6478666666666667,
    "x": 12.13435173034668,
    "y": -0.044013798236846924,
    "cluster_id": 9
  },
  {
    "feature_id": 7,
    "explanation_index": 1,
    "text": "Common prepositions and conjunctions used in comparative or contextual phrases, often preceding or following specific nouns or clauses.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8517171343167623,
    "similarity_var": 0.004515468479213149,
    "score_fuzz": 0.79,
    "score_detection": 0.6,
    "score_embedding": 0.66625,
    "total_score": 0.6854166666666668,
    "x": 12.1399507522583,
    "y": -0.014757523313164711,
    "cluster_id": 9
  },
  {
    "feature_id": 7,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8517171343167623,
    "similarity_var": 0.004515468479213149,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.6125,
    "total_score": 0.5375,
    "x": -5.919582843780518,
    "y": 15.98864459991455,
    "cluster_id": 10
  },
  {
    "feature_id": 8,
    "explanation_index": 0,
    "text": "Nouns representing buildings, structures, and monuments, often including specific names or descriptive words.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9262821475664774,
    "similarity_var": 2.8152436102225743e-05,
    "score_fuzz": 0.78,
    "score_detection": 0.49,
    "score_embedding": 0.44520000000000004,
    "total_score": 0.5717333333333333,
    "x": 8.005816459655762,
    "y": 0.011324390769004822,
    "cluster_id": -1
  },
  {
    "feature_id": 8,
    "explanation_index": 1,
    "text": "Nouns denoting large, often historically or architecturally significant structures, frequently associated with cultural, historical, or civic importance, and commonly appearing in descriptive or touristic contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9262821475664774,
    "similarity_var": 2.8152436102225743e-05,
    "score_fuzz": 0.81,
    "score_detection": 0.67,
    "score_embedding": 0.5231250000000001,
    "total_score": 0.6677083333333332,
    "x": 8.020101547241211,
    "y": -0.05547521635890007,
    "cluster_id": -1
  },
  {
    "feature_id": 8,
    "explanation_index": 2,
    "text": "The highlighted tokens are nouns that denote physical structures or landmarks\u2014buildings, houses, cathedrals, castles, churches, museums, towers, temples, walls, gates, etc.\u2014often appearing in phrases that describe or locate such places.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9262821475664774,
    "similarity_var": 2.8152436102225743e-05,
    "score_fuzz": 0.9,
    "score_detection": 0.6,
    "score_embedding": 0.4206250000000001,
    "total_score": 0.6402083333333334,
    "x": 14.50693416595459,
    "y": 3.9106552600860596,
    "cluster_id": 11
  },
  {
    "feature_id": 9,
    "explanation_index": 0,
    "text": "Various nouns and adjectives representing concepts, objects, or ideas, often related to science, nature, or abstract notions, and sometimes used in formal or technical contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8403318126996359,
    "similarity_var": 8.550632814142824e-06,
    "score_fuzz": 0.71,
    "score_detection": 0.24,
    "score_embedding": 0.112,
    "total_score": 0.35400000000000004,
    "x": 8.251506805419922,
    "y": 0.5841301679611206,
    "cluster_id": 12
  },
  {
    "feature_id": 9,
    "explanation_index": 1,
    "text": "The word \\\"nature\\\" frequently appears in contexts describing inherent or fundamental characteristics, often in idiomatic expressions like \\\"force of nature\\\" or \\\"by nature,\\\" and is associated with intrinsic qualities of people, systems, or phenomena.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8403318126996359,
    "similarity_var": 8.550632814142824e-06,
    "score_fuzz": 0.61,
    "score_detection": 0.61,
    "score_embedding": 0.36250000000000004,
    "total_score": 0.5275,
    "x": 8.627655029296875,
    "y": 0.9788589477539062,
    "cluster_id": -1
  },
  {
    "feature_id": 9,
    "explanation_index": 2,
    "text": "The highlighted words are the heads of noun phrases that carry the main semantic content of each sentence\u2014typically nouns or pronouns that serve as the subject, object, or key descriptor (e.g., \u201cnature,\u201d \u201cDNA,\u201d \u201cnatural,\u201d \u201cAspects,\u201d \u201cduration,\u201d \u201cstate,\u201d \u201cWhat\u201d). These tokens anchor the central idea or action in the clause.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8403318126996359,
    "similarity_var": 8.550632814142824e-06,
    "score_fuzz": 0.825,
    "score_detection": 0.8,
    "score_embedding": 0.3225,
    "total_score": 0.6491666666666667,
    "x": 16.241836547851562,
    "y": 3.627168893814087,
    "cluster_id": -1
  },
  {
    "feature_id": 10,
    "explanation_index": 0,
    "text": "Verbs or verb phrases indicating movement or direction, often in a physical or metaphorical sense, and sometimes used in idiomatic expressions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9199334979057312,
    "similarity_var": 2.0364571997314822e-05,
    "score_fuzz": 0.81,
    "score_detection": 0.66,
    "score_embedding": 0.542,
    "total_score": 0.6706666666666669,
    "x": 11.095385551452637,
    "y": -0.942093551158905,
    "cluster_id": -1
  },
  {
    "feature_id": 10,
    "explanation_index": 1,
    "text": "Common phrasal verbs and prepositional constructions involving movement or direction, often with \\\"go\\\" or \\\"going to\\\" followed by a preposition or adverb indicating direction, destination, or progression.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9199334979057312,
    "similarity_var": 2.0364571997314822e-05,
    "score_fuzz": 0.87,
    "score_detection": 0.81,
    "score_embedding": 0.636875,
    "total_score": 0.7722916666666667,
    "x": 11.589777946472168,
    "y": -0.8198174834251404,
    "cluster_id": 13
  },
  {
    "feature_id": 10,
    "explanation_index": 2,
    "text": "Tokens that form motion\u2011oriented phrasal verbs and idioms, typically involving \u201cgo\u201d or its variants followed by a preposition or noun (e.g., \u201cgo ahead,\u201d \u201cgo back,\u201d \u201cgo through,\u201d \u201cgo to war\u201d).",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9199334979057312,
    "similarity_var": 2.0364571997314822e-05,
    "score_fuzz": 0.825,
    "score_detection": 0.9,
    "score_embedding": 0.683125,
    "total_score": 0.8027083333333334,
    "x": 11.511385917663574,
    "y": -0.8133242130279541,
    "cluster_id": 13
  },
  {
    "feature_id": 11,
    "explanation_index": 0,
    "text": "Verbs or nouns representing actions, concepts, or objects, often in a formal or technical context, and sometimes related to academic or professional fields.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8606674671173096,
    "similarity_var": 2.203325401476756e-05,
    "score_fuzz": 0.61,
    "score_detection": 0.43,
    "score_embedding": 0.2596,
    "total_score": 0.43320000000000003,
    "x": 10.474642753601074,
    "y": -0.7541494965553284,
    "cluster_id": 14
  },
  {
    "feature_id": 11,
    "explanation_index": 1,
    "text": "Partial or truncated words, often at the end of a token, that are part of a larger word, frequently appearing in contexts involving technical, academic, or compound terms.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8606674671173096,
    "similarity_var": 2.203325401476756e-05,
    "score_fuzz": 0.43,
    "score_detection": 0.49,
    "score_embedding": 0.3475,
    "total_score": 0.42249999999999993,
    "x": 7.238110065460205,
    "y": 2.868802070617676,
    "cluster_id": 15
  },
  {
    "feature_id": 11,
    "explanation_index": 2,
    "text": "the pattern is that the important tokens are often nouns or verbs that are part of a phrase, often with suffixes like -er, -ing, -ed, etc.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8606674671173096,
    "similarity_var": 2.203325401476756e-05,
    "score_fuzz": 0.675,
    "score_detection": 0.625,
    "score_embedding": 0.389375,
    "total_score": 0.563125,
    "x": 11.373137474060059,
    "y": 4.371769905090332,
    "cluster_id": 3
  },
  {
    "feature_id": 12,
    "explanation_index": 0,
    "text": "Proper nouns, names of people, places, organizations, and specific terms, often used as identifiers or references.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.883049488067627,
    "similarity_var": 1.255601763953488e-05,
    "score_fuzz": 0.62,
    "score_detection": 0.44,
    "score_embedding": 0.6444,
    "total_score": 0.5681333333333334,
    "x": 7.451759338378906,
    "y": -0.8392436504364014,
    "cluster_id": 16
  },
  {
    "feature_id": 12,
    "explanation_index": 1,
    "text": "The model attends to proper nouns, abbreviations, and compound terms that represent specific entities, often appearing in contexts involving names, locations, technical terms, or identifiers, with attention distributed across individual components of such multi-part tokens.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.883049488067627,
    "similarity_var": 1.255601763953488e-05,
    "score_fuzz": 0.61,
    "score_detection": 0.46,
    "score_embedding": 0.5850000000000001,
    "total_score": 0.5516666666666667,
    "x": 8.265372276306152,
    "y": 3.24491024017334,
    "cluster_id": -1
  },
  {
    "feature_id": 12,
    "explanation_index": 2,
    "text": "The highlighted tokens are usually proper nouns, place or organization names, or morphological suffixes that signal comparison or grammatical function, often appearing at phrase boundaries or as part of technical terminology.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.883049488067627,
    "similarity_var": 1.255601763953488e-05,
    "score_fuzz": 0.725,
    "score_detection": 0.425,
    "score_embedding": 0.60625,
    "total_score": 0.5854166666666666,
    "x": 14.457928657531738,
    "y": 4.047182083129883,
    "cluster_id": 11
  },
  {
    "feature_id": 13,
    "explanation_index": 0,
    "text": "Code snippets from various programming languages, often including function or method definitions, variable declarations, and conditional statements, with a focus on syntax and structure.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.859511931737264,
    "similarity_var": 8.204895822514243e-05,
    "score_fuzz": 0.31,
    "score_detection": 0.3,
    "score_embedding": 0.5476,
    "total_score": 0.38586666666666664,
    "x": 11.159185409545898,
    "y": 8.676194190979004,
    "cluster_id": 17
  },
  {
    "feature_id": 13,
    "explanation_index": 1,
    "text": "Tokens containing specific identifiers, file extensions, or structural elements in code or markup, often appearing in contexts involving syntax, file paths, or programming constructs.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.859511931737264,
    "similarity_var": 8.204895822514243e-05,
    "score_fuzz": 0.34,
    "score_detection": 0.37,
    "score_embedding": 0.59125,
    "total_score": 0.43375,
    "x": 10.854724884033203,
    "y": 6.145677089691162,
    "cluster_id": 18
  },
  {
    "feature_id": 13,
    "explanation_index": 2,
    "text": "The highlighted fragments are the core lexical items that carry the main semantic or functional content of the surrounding text\u2014key nouns, verbs, adjectives, or code identifiers\u2014often appearing as single words or short phrases that are central to the meaning or operation of the sentence or code snippet.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.859511931737264,
    "similarity_var": 8.204895822514243e-05,
    "score_fuzz": 0.475,
    "score_detection": 0.3,
    "score_embedding": 0.673125,
    "total_score": 0.4827083333333333,
    "x": 15.708878517150879,
    "y": 7.323937892913818,
    "cluster_id": 19
  },
  {
    "feature_id": 14,
    "explanation_index": 0,
    "text": "Verbs that express actions, often in a neutral or objective tone, and are frequently used in everyday language to convey a sense of doing or performing an action.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8792980313301086,
    "similarity_var": 0.000536981091218062,
    "score_fuzz": 0.83,
    "score_detection": 0.52,
    "score_embedding": 0.5148,
    "total_score": 0.6216,
    "x": 10.593826293945312,
    "y": -0.8251397013664246,
    "cluster_id": 14
  },
  {
    "feature_id": 14,
    "explanation_index": 1,
    "text": "Verbs denoting actions, perceptions, or states, often followed by a direct object or complement, with high activation values indicating their centrality in conveying meaning.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8792980313301086,
    "similarity_var": 0.000536981091218062,
    "score_fuzz": 0.81,
    "score_detection": 0.53,
    "score_embedding": 0.40937500000000004,
    "total_score": 0.583125,
    "x": 10.629475593566895,
    "y": -1.0124216079711914,
    "cluster_id": -1
  },
  {
    "feature_id": 14,
    "explanation_index": 2,
    "text": "The highlighted words are the head lexical items of the most semantically salient phrases in each sentence, typically the main verb or noun that carries the core action or object.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8792980313301086,
    "similarity_var": 0.000536981091218062,
    "score_fuzz": 0.825,
    "score_detection": 0.325,
    "score_embedding": 0.391875,
    "total_score": 0.5139583333333333,
    "x": 16.6534366607666,
    "y": 3.632815361022949,
    "cluster_id": 20
  },
  {
    "feature_id": 15,
    "explanation_index": 0,
    "text": "Punctuation marks and special characters, often used to denote code syntax, mathematical expressions, or formatting in text.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8999606370925903,
    "similarity_var": 5.757610312429051e-05,
    "score_fuzz": 0.49,
    "score_detection": 0.39,
    "score_embedding": 0.174,
    "total_score": 0.35133333333333333,
    "x": 8.573386192321777,
    "y": 7.193002700805664,
    "cluster_id": 4
  },
  {
    "feature_id": 15,
    "explanation_index": 1,
    "text": "Delimiters and punctuation marks such as spaces, parentheses, braces, brackets, and special symbols are frequently activated in structured text, often surrounding or separating code elements, JSON fields, or syntactic constructs.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8999606370925903,
    "similarity_var": 5.757610312429051e-05,
    "score_fuzz": 0.48,
    "score_detection": 0.38,
    "score_embedding": 0.29374999999999996,
    "total_score": 0.38458333333333333,
    "x": 9.625175476074219,
    "y": 6.992999076843262,
    "cluster_id": 21
  },
  {
    "feature_id": 15,
    "explanation_index": 2,
    "text": "The highlighted tokens are usually single characters or very short sequences that serve as syntactic delimiters\u2014whitespace, punctuation, braces, brackets, or numeric markers\u2014used to separate or identify elements in code or text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8999606370925903,
    "similarity_var": 5.757610312429051e-05,
    "score_fuzz": 0.8,
    "score_detection": 0.325,
    "score_embedding": 0.24874999999999997,
    "total_score": 0.4579166666666667,
    "x": 13.651545524597168,
    "y": 5.817837715148926,
    "cluster_id": -1
  },
  {
    "feature_id": 17,
    "explanation_index": 0,
    "text": "Various nouns and words that are often used as subjects or objects in sentences, including proper nouns, common nouns, and words with specific meanings or connotations.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8698045015335083,
    "similarity_var": 0.0006173958902901214,
    "score_fuzz": 0.64,
    "score_detection": 0.4,
    "score_embedding": 0.7111999999999999,
    "total_score": 0.5837333333333333,
    "x": 8.520071029663086,
    "y": -0.37076109647750854,
    "cluster_id": -1
  },
  {
    "feature_id": 17,
    "explanation_index": 1,
    "text": "Nouns or noun phrases representing specific locations, abstract concepts, or technical terms, often appearing in contextually significant or semantically dense expressions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8698045015335083,
    "similarity_var": 0.0006173958902901214,
    "score_fuzz": 0.7,
    "score_detection": 0.71,
    "score_embedding": 0.690625,
    "total_score": 0.7002083333333333,
    "x": 8.735040664672852,
    "y": 0.10310415923595428,
    "cluster_id": -1
  },
  {
    "feature_id": 17,
    "explanation_index": 2,
    "text": "The highlighted tokens are the semantic nuclei of phrases\u2014usually nouns, adjectives, or key suffixes\u2014that carry the core meaning of idiomatic or fixed expressions.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8698045015335083,
    "similarity_var": 0.0006173958902901214,
    "score_fuzz": 0.65,
    "score_detection": 0.55,
    "score_embedding": 0.711875,
    "total_score": 0.6372916666666667,
    "x": 15.092645645141602,
    "y": 3.9416654109954834,
    "cluster_id": 22
  },
  {
    "feature_id": 18,
    "explanation_index": 0,
    "text": "Verbs related to perception, attention, or observation, often in the context of watching, listening, or looking at something or someone.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9175043106079102,
    "similarity_var": 7.179411736046859e-05,
    "score_fuzz": 0.86,
    "score_detection": 0.69,
    "score_embedding": 0.592,
    "total_score": 0.714,
    "x": 10.376923561096191,
    "y": -1.310165286064148,
    "cluster_id": 23
  },
  {
    "feature_id": 18,
    "explanation_index": 1,
    "text": "The word \\\"watch\\\" and its related forms (e.g., \\\"watching\\\", \\\"watcher\\\") are frequently activated in contexts involving observation, attention, or viewing media, often in relation to visual perception, surveillance, or media consumption.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9175043106079102,
    "similarity_var": 7.179411736046859e-05,
    "score_fuzz": 0.71,
    "score_detection": 0.69,
    "score_embedding": 0.64,
    "total_score": 0.68,
    "x": 10.323065757751465,
    "y": -1.2961214780807495,
    "cluster_id": 23
  },
  {
    "feature_id": 18,
    "explanation_index": 2,
    "text": "The text repeatedly highlights verbs that denote observation or attention\u2014watch, watching, watcher, watchful, listen, listening, follow, monitor\u2014indicating a focus on monitoring or paying attention.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9175043106079102,
    "similarity_var": 7.179411736046859e-05,
    "score_fuzz": 0.9,
    "score_detection": 0.85,
    "score_embedding": 0.5875,
    "total_score": 0.7791666666666667,
    "x": 10.36703109741211,
    "y": -1.2984888553619385,
    "cluster_id": 23
  },
  {
    "feature_id": 22,
    "explanation_index": 0,
    "text": "Nouns representing a distinct entity, often geographical or abstract, such as the world, society, country, or universe, sometimes used in a broader context or metaphorically.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8832229375839233,
    "similarity_var": 9.73925719757555e-05,
    "score_fuzz": 0.66,
    "score_detection": 0.44,
    "score_embedding": 0.6564000000000001,
    "total_score": 0.5854666666666667,
    "x": 8.269832611083984,
    "y": 0.17225974798202515,
    "cluster_id": 24
  },
  {
    "feature_id": 22,
    "explanation_index": 1,
    "text": "The word \\\"world\\\" frequently appears in phrases denoting a broad, abstract domain or context, often in possessive or relational constructions (e.g., \\\"world of,\\\" \\\"world's,\\\" \\\"in the world\\\"), and is typically associated with conceptual, cultural, or global-scale references.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8832229375839233,
    "similarity_var": 9.73925719757555e-05,
    "score_fuzz": 0.65,
    "score_detection": 0.69,
    "score_embedding": 0.8475000000000001,
    "total_score": 0.7291666666666666,
    "x": 8.92444896697998,
    "y": 0.16278424859046936,
    "cluster_id": -1
  },
  {
    "feature_id": 22,
    "explanation_index": 2,
    "text": "The pattern seems to be that the important tokens are often nouns or noun phrases that refer to large-scale entities: world, America, ocean, etc.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8832229375839233,
    "similarity_var": 9.73925719757555e-05,
    "score_fuzz": 0.7142857142857143,
    "score_detection": 0.475,
    "score_embedding": 0.720625,
    "total_score": 0.6366369047619047,
    "x": 11.367281913757324,
    "y": 4.337867736816406,
    "cluster_id": 3
  },
  {
    "feature_id": 23,
    "explanation_index": 0,
    "text": "Special characters used as word separators or connectors in technical, mathematical, and programming contexts, often denoting relationships between words or variables.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8865957061449686,
    "similarity_var": 0.00018409413665270653,
    "score_fuzz": 0.68,
    "score_detection": 0.48,
    "score_embedding": 0.27240000000000003,
    "total_score": 0.4774666666666667,
    "x": 9.282718658447266,
    "y": 7.57252311706543,
    "cluster_id": -1
  },
  {
    "feature_id": 23,
    "explanation_index": 1,
    "text": "The underscore \\\"_\\\" and hyphen \\\"-\\\" characters are used as word separators in compound identifiers, often in programming, technical notation, or structured data, with underscores being more common in variable and function names, and hyphens in compound terms or URLs.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8865957061449686,
    "similarity_var": 0.00018409413665270653,
    "score_fuzz": 0.84,
    "score_detection": 0.48,
    "score_embedding": 0.29937499999999995,
    "total_score": 0.5397916666666666,
    "x": 9.120798110961914,
    "y": 7.129545211791992,
    "cluster_id": -1
  },
  {
    "feature_id": 23,
    "explanation_index": 2,
    "text": "The highlighted tokens are non\u2011alphabetic symbols that serve as delimiters or operators in code or markup, such as underscores, arrows, hyphens, and punctuation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8865957061449686,
    "similarity_var": 0.00018409413665270653,
    "score_fuzz": 0.7,
    "score_detection": 0.475,
    "score_embedding": 0.30437499999999995,
    "total_score": 0.49312499999999987,
    "x": 13.517755508422852,
    "y": 6.011018753051758,
    "cluster_id": -1
  },
  {
    "feature_id": 25,
    "explanation_index": 0,
    "text": "Chemical elements, compounds, and related terms, often in scientific or technical contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8874309062957764,
    "similarity_var": 8.058402528613821e-05,
    "score_fuzz": 0.74,
    "score_detection": 0.83,
    "score_embedding": 0.3084,
    "total_score": 0.6261333333333333,
    "x": 7.316714763641357,
    "y": 1.201271891593933,
    "cluster_id": 25
  },
  {
    "feature_id": 25,
    "explanation_index": 1,
    "text": "Partially formed chemical or technical terms, often ending in common suffixes like \\\"er\\\", \\\"ion\\\", \\\"ate\\\", \\\"ide\\\", or \\\"al\\\", that are part of scientific, industrial, or technical vocabulary.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8874309062957764,
    "similarity_var": 8.058402528613821e-05,
    "score_fuzz": 0.75,
    "score_detection": 0.7,
    "score_embedding": 0.355,
    "total_score": 0.6016666666666667,
    "x": 8.627544403076172,
    "y": 2.47540020942688,
    "cluster_id": 66
  },
  {
    "feature_id": 25,
    "explanation_index": 2,
    "text": "The model consistently activates tokens that are chemical or gas\u2011related terms\u2014often short, sometimes fragmentary\u2014appearing in scientific or technical contexts, indicating a latent focus on chemical descriptors.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8874309062957764,
    "similarity_var": 8.058402528613821e-05,
    "score_fuzz": 0.9,
    "score_detection": 0.85,
    "score_embedding": 0.33,
    "total_score": 0.6933333333333334,
    "x": 8.059303283691406,
    "y": 3.0925121307373047,
    "cluster_id": 76
  },
  {
    "feature_id": 26,
    "explanation_index": 0,
    "text": "Prepositions, conjunctions, and articles, as well as names and titles, often function as important tokens in text, sometimes indicating relationships or possession, and other times serving as part of proper nouns or honorifics.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9059548775355021,
    "similarity_var": 5.296670138537567e-05,
    "score_fuzz": 0.6,
    "score_detection": 0.44,
    "score_embedding": 0.4152,
    "total_score": 0.4850666666666667,
    "x": 12.433235168457031,
    "y": 0.03853796422481537,
    "cluster_id": -1
  },
  {
    "feature_id": 26,
    "explanation_index": 1,
    "text": "Common function words and proper nouns that appear in contextually specific grammatical or semantic roles, often marking relationships such as possession, attribution, or reference.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9059548775355021,
    "similarity_var": 5.296670138537567e-05,
    "score_fuzz": 0.49,
    "score_detection": 0.37,
    "score_embedding": 0.34437500000000004,
    "total_score": 0.4014583333333333,
    "x": 10.674339294433594,
    "y": 1.2716516256332397,
    "cluster_id": 26
  },
  {
    "feature_id": 26,
    "explanation_index": 2,
    "text": "The highlighted tokens are typically short function words, names, titles, or punctuation that signal relationships, structure, or key entities in the sentence.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9059548775355021,
    "similarity_var": 5.296670138537567e-05,
    "score_fuzz": 0.7,
    "score_detection": 0.35,
    "score_embedding": 0.34624999999999995,
    "total_score": 0.4654166666666666,
    "x": 13.980569839477539,
    "y": 4.396609783172607,
    "cluster_id": -1
  },
  {
    "feature_id": 27,
    "explanation_index": 0,
    "text": "Verbs or nouns related to making up for something, often implying a form of balance, reparation, or improvement, including compensation, offset, and replenishment.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9008477528889974,
    "similarity_var": 0.0011261912349982914,
    "score_fuzz": 0.8,
    "score_detection": 0.66,
    "score_embedding": 0.484,
    "total_score": 0.648,
    "x": 10.703028678894043,
    "y": -0.578335165977478,
    "cluster_id": 85
  },
  {
    "feature_id": 27,
    "explanation_index": 1,
    "text": "Common verb phrases involving \\\"up\\\", \\\"compens\\\", \\\"make\\\", \\\"offset\\\", \\\"mitig\\\", \\\"replen\\\", \\\"correction\\\", \\\"deficiency\\\", \\\"intermediates\\\", \\\"complements\\\", \\\"weaknesses\\\", \\\"involvement\\\", \\\"amends\\\", \\\"unde\\\", and \\\"compensation\\\" that convey completion, adjustment, replacement, or balancing of a state or condition.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9008477528889974,
    "similarity_var": 0.0011261912349982914,
    "score_fuzz": 0.83,
    "score_detection": 0.73,
    "score_embedding": 0.525625,
    "total_score": 0.6952083333333334,
    "x": 11.21168327331543,
    "y": -0.35098448395729065,
    "cluster_id": -1
  },
  {
    "feature_id": 27,
    "explanation_index": 2,
    "text": "The tokens include \\\"compens\\\", \\\"up\\\", \\\"compensate\\\", \\\"compensation\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\", \\\"compens\\\".",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9008477528889974,
    "similarity_var": 0.0011261912349982914,
    "score_fuzz": 0.675,
    "score_detection": 0.525,
    "score_embedding": 0.405625,
    "total_score": 0.5352083333333334,
    "x": 11.025894165039062,
    "y": 3.408635377883911,
    "cluster_id": 27
  },
  {
    "feature_id": 28,
    "explanation_index": 0,
    "text": "Special characters and symbols used in programming languages, such as operators, brackets, and punctuation marks, often used in function calls, variable declarations, and control structures.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8986633618672689,
    "similarity_var": 2.52713439468582e-06,
    "score_fuzz": 0.35,
    "score_detection": 0.45,
    "score_embedding": 0.6032,
    "total_score": 0.46773333333333333,
    "x": 9.591279029846191,
    "y": 7.824407577514648,
    "cluster_id": 6
  },
  {
    "feature_id": 28,
    "explanation_index": 1,
    "text": "Sequences of tokens that represent programming language syntax, identifiers, or type names, often involving camelCase, underscores, or special characters, commonly found in codebases and technical documentation.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8986633618672689,
    "similarity_var": 2.52713439468582e-06,
    "score_fuzz": 0.37,
    "score_detection": 0.44,
    "score_embedding": 0.6325000000000001,
    "total_score": 0.4808333333333334,
    "x": 11.055867195129395,
    "y": 5.921751976013184,
    "cluster_id": -1
  },
  {
    "feature_id": 28,
    "explanation_index": 2,
    "text": "The highlighted fragments are syntactically significant code tokens\u2014identifiers, keywords, operators, and punctuation\u2014that together form programming language constructs such as function calls, class names, and control\u2011flow statements.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8986633618672689,
    "similarity_var": 2.52713439468582e-06,
    "score_fuzz": 0.425,
    "score_detection": 0.5,
    "score_embedding": 0.6412500000000001,
    "total_score": 0.5220833333333333,
    "x": 14.87582015991211,
    "y": 7.094683647155762,
    "cluster_id": -1
  },
  {
    "feature_id": 29,
    "explanation_index": 0,
    "text": "Punctuation marks and special characters, often used to denote formatting, mathematical operations, or citations, and sometimes preceding or following numbers or codes.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.853070080280304,
    "similarity_var": 0.001910657199545085,
    "score_fuzz": 0.78,
    "score_detection": 0.77,
    "score_embedding": 0.6676,
    "total_score": 0.7392,
    "x": 8.534577369689941,
    "y": 7.288163661956787,
    "cluster_id": 4
  },
  {
    "feature_id": 29,
    "explanation_index": 1,
    "text": "Common punctuation, numerical, and symbolic tokens that appear in structured or technical text, often surrounding or within identifiers, mathematical expressions, or formatting markers.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.853070080280304,
    "similarity_var": 0.001910657199545085,
    "score_fuzz": 0.77,
    "score_detection": 0.76,
    "score_embedding": 0.77125,
    "total_score": 0.7670833333333333,
    "x": 10.156694412231445,
    "y": 6.228805065155029,
    "cluster_id": -1
  },
  {
    "feature_id": 29,
    "explanation_index": 2,
    "text": "The highlighted words are the core elements of short phrases\u2014typically a noun or preposition combined with a modifier\u2014that signal a specific relationship or attribute, such as location, compliance, or comparison.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.853070080280304,
    "similarity_var": 0.001910657199545085,
    "score_fuzz": 0.5,
    "score_detection": 0.55,
    "score_embedding": 0.735,
    "total_score": 0.5950000000000001,
    "x": 16.678300857543945,
    "y": 3.679239273071289,
    "cluster_id": 20
  },
  {
    "feature_id": 30,
    "explanation_index": 0,
    "text": "Possessive pronouns and adjectives indicating ownership or association.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.925275961558024,
    "similarity_var": 0.00010960346514900087,
    "score_fuzz": 0.98,
    "score_detection": 0.75,
    "score_embedding": 0.4944,
    "total_score": 0.7414666666666667,
    "x": 12.08021068572998,
    "y": 1.0993330478668213,
    "cluster_id": 28
  },
  {
    "feature_id": 30,
    "explanation_index": 1,
    "text": "Possessive pronouns and possessive markers (e.g., \\\"his\\\", \\\"her\\\", \\\"their\\\", \\\"your\\\", \\\"its\\\", \\\"our\\\", \\\"s\\\") are frequently activated when referring to personal or contextual ownership, identity, or association, often in relation to actions, attributes, or relationships.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.925275961558024,
    "similarity_var": 0.00010960346514900087,
    "score_fuzz": 0.97,
    "score_detection": 0.84,
    "score_embedding": 0.439375,
    "total_score": 0.7497916666666667,
    "x": 12.0379638671875,
    "y": 1.1310181617736816,
    "cluster_id": 28
  },
  {
    "feature_id": 30,
    "explanation_index": 2,
    "text": "The highlighted tokens are possessive pronouns, possessive adjectives, or possessive suffixes that signal ownership or association.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.925275961558024,
    "similarity_var": 0.00010960346514900087,
    "score_fuzz": 1.0,
    "score_detection": 0.75,
    "score_embedding": 0.334375,
    "total_score": 0.6947916666666667,
    "x": 14.135887145996094,
    "y": 3.8047404289245605,
    "cluster_id": 67
  },
  {
    "feature_id": 31,
    "explanation_index": 0,
    "text": "Numerical values, often decimal numbers, and sometimes hexadecimal values, that appear to be part of mathematical expressions, data, or measurements.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8987255692481995,
    "similarity_var": 0.0003060643847234701,
    "score_fuzz": 0.75,
    "score_detection": 0.67,
    "score_embedding": 0.6756,
    "total_score": 0.6985333333333333,
    "x": 6.843381881713867,
    "y": 8.75967025756836,
    "cluster_id": 29
  },
  {
    "feature_id": 31,
    "explanation_index": 1,
    "text": "Individual digits and punctuation marks within numerical or symbolic sequences, particularly in mathematical expressions, timestamps, or formatted data, often carry significant activation, with digits like '8', '9', '6', and '.' being frequently highlighted in contextually precise positions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8987255692481995,
    "similarity_var": 0.0003060643847234701,
    "score_fuzz": 0.84,
    "score_detection": 0.71,
    "score_embedding": 0.5750000000000001,
    "total_score": 0.7083333333333334,
    "x": 7.396495819091797,
    "y": 8.500529289245605,
    "cluster_id": 29
  },
  {
    "feature_id": 31,
    "explanation_index": 2,
    "text": "The highlighted tokens are numeric characters or symbols that form numeric literals (decimal, hexadecimal, scientific notation, etc.), often appearing in sequences that represent numbers.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8987255692481995,
    "similarity_var": 0.0003060643847234701,
    "score_fuzz": 0.725,
    "score_detection": 0.7,
    "score_embedding": 0.586875,
    "total_score": 0.6706249999999999,
    "x": 13.207197189331055,
    "y": 5.911964416503906,
    "cluster_id": 30
  },
  {
    "feature_id": 32,
    "explanation_index": 0,
    "text": "Tokens that are part of a code, mathematical expression, or technical term, often including special characters and symbols.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8688445687294006,
    "similarity_var": 0.00015975463335848872,
    "score_fuzz": 0.65,
    "score_detection": 0.57,
    "score_embedding": 0.536,
    "total_score": 0.5853333333333334,
    "x": 10.677837371826172,
    "y": 5.891770839691162,
    "cluster_id": 18
  },
  {
    "feature_id": 32,
    "explanation_index": 1,
    "text": "Fragments of text containing structural or formatting markers, often surrounded by delimiters, with high activation on punctuation, symbols, or repeated patterns like \\\"<<\\\" and \\\">>\\\", indicating the presence of code, markup, or formatting syntax.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8688445687294006,
    "similarity_var": 0.00015975463335848872,
    "score_fuzz": 0.56,
    "score_detection": 0.67,
    "score_embedding": 0.533125,
    "total_score": 0.5877083333333334,
    "x": 9.931401252746582,
    "y": 6.976064682006836,
    "cluster_id": 69
  },
  {
    "feature_id": 32,
    "explanation_index": 2,
    "text": "The highlighted tokens consistently form coherent semantic units\u2014such as noun phrases, verb phrases, or key technical terms\u2014that carry the main meaning of the surrounding text, regardless of whether the context is natural language, code, or markup.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8688445687294006,
    "similarity_var": 0.00015975463335848872,
    "score_fuzz": 0.3,
    "score_detection": 0.3,
    "score_embedding": 0.435,
    "total_score": 0.345,
    "x": 15.368005752563477,
    "y": 4.465908527374268,
    "cluster_id": 31
  },
  {
    "feature_id": 34,
    "explanation_index": 0,
    "text": "Punctuation marks and common function words, often used to connect clauses or phrases, or to indicate possession, existence, or comparison.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8613350590070089,
    "similarity_var": 0.0028516931259743063,
    "score_fuzz": 0.52,
    "score_detection": 0.43,
    "score_embedding": 0.34559999999999996,
    "total_score": 0.4318666666666666,
    "x": 7.78130578994751,
    "y": 6.585476398468018,
    "cluster_id": 32
  },
  {
    "feature_id": 34,
    "explanation_index": 1,
    "text": "Common function words and short phrases that serve grammatical or structural roles in sentences, often appearing in contexts involving comparison, possession, location, or logical connection.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8613350590070089,
    "similarity_var": 0.0028516931259743063,
    "score_fuzz": 0.45,
    "score_detection": 0.4,
    "score_embedding": 0.39437500000000003,
    "total_score": 0.4147916666666667,
    "x": 10.717784881591797,
    "y": 1.3587125539779663,
    "cluster_id": 26
  },
  {
    "feature_id": 34,
    "explanation_index": 2,
    "text": "The highlighted tokens are consistently short, high\u2011frequency words or essential content words that anchor the main noun or verb phrase in each sentence, indicating that the model focuses on the core semantic units that carry the sentence\u2019s meaning.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8613350590070089,
    "similarity_var": 0.0028516931259743063,
    "score_fuzz": 0.3,
    "score_detection": 0.275,
    "score_embedding": 0.37,
    "total_score": 0.315,
    "x": 15.386673927307129,
    "y": 4.103651523590088,
    "cluster_id": 22
  },
  {
    "feature_id": 35,
    "explanation_index": 0,
    "text": "Punctuation marks and common function words, often at the beginning of a sentence or clause, or used to separate items in a list.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8673890829086304,
    "similarity_var": 0.00016476598938434486,
    "score_fuzz": 0.4631578947368421,
    "score_detection": 0.3,
    "score_embedding": 0.46,
    "total_score": 0.407719298245614,
    "x": 7.814049243927002,
    "y": 6.595941066741943,
    "cluster_id": 32
  },
  {
    "feature_id": 35,
    "explanation_index": 1,
    "text": "Common tokens in technical and formal text, including articles (\\\"a\\\", \\\"an\\\", \\\"the\\\"), punctuation, mathematical symbols, variable names, and structural markers in code or academic writing.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8673890829086304,
    "similarity_var": 0.00016476598938434486,
    "score_fuzz": 0.7,
    "score_detection": 0.72,
    "score_embedding": 0.5725,
    "total_score": 0.6641666666666667,
    "x": 10.191534042358398,
    "y": 6.011577606201172,
    "cluster_id": -1
  },
  {
    "feature_id": 35,
    "explanation_index": 2,
    "text": "The highlighted tokens are individual words, punctuation, or single characters that the model deems important for its behavior, often forming part of a phrase or a standalone element.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8673890829086304,
    "similarity_var": 0.00016476598938434486,
    "score_fuzz": 0.5,
    "score_detection": 0.35,
    "score_embedding": 0.555625,
    "total_score": 0.4685416666666667,
    "x": 14.180660247802734,
    "y": 4.984888076782227,
    "cluster_id": -1
  },
  {
    "feature_id": 36,
    "explanation_index": 0,
    "text": "A variety of medical and injury-related terms, often describing conditions, procedures, or consequences, sometimes in a formal or technical context.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8719122409820557,
    "similarity_var": 0.0004347288335040389,
    "score_fuzz": 0.73,
    "score_detection": 0.62,
    "score_embedding": 0.6892,
    "total_score": 0.6797333333333334,
    "x": 7.413602828979492,
    "y": 1.3702504634857178,
    "cluster_id": 25
  },
  {
    "feature_id": 36,
    "explanation_index": 1,
    "text": "Commonly activated tokens include function words (e.g., \\\"the\\\", \\\"of\\\", \\\"and\\\"), suffixes forming comparative or derived words (e.g., \\\"er\\\", \\\"ion\\\", \\\"ation\\\"), and contextually significant nouns or adjectives related to medical, legal, or physical conditions, often appearing in compound terms or idiomatic expressions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8719122409820557,
    "similarity_var": 0.0004347288335040389,
    "score_fuzz": 0.77,
    "score_detection": 0.57,
    "score_embedding": 0.835,
    "total_score": 0.725,
    "x": 10.149774551391602,
    "y": 3.221452474594116,
    "cluster_id": 33
  },
  {
    "feature_id": 36,
    "explanation_index": 2,
    "text": "The highlighted fragments are mostly subword pieces that belong to idiomatic or domain\u2011specific multi\u2011word expressions, often with a leading space, and include common suffixes (e.g., \u201c\u2011er\u201d for comparatives) or medical terminology, indicating that the model is detecting phrase\u2011level or morphological patterns rather than isolated words.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8719122409820557,
    "similarity_var": 0.0004347288335040389,
    "score_fuzz": 0.725,
    "score_detection": 0.725,
    "score_embedding": 0.801875,
    "total_score": 0.750625,
    "x": 15.688451766967773,
    "y": 7.187004089355469,
    "cluster_id": 19
  },
  {
    "feature_id": 37,
    "explanation_index": 0,
    "text": "Nouns, proper nouns, and common words that are part of a larger phrase or term, often related to science, technology, or everyday objects.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8693426450093588,
    "similarity_var": 0.00027865497956567096,
    "score_fuzz": 0.65,
    "score_detection": 0.43,
    "score_embedding": 0.4628,
    "total_score": 0.5142666666666668,
    "x": 8.243378639221191,
    "y": -0.15040695667266846,
    "cluster_id": -1
  },
  {
    "feature_id": 37,
    "explanation_index": 1,
    "text": "Fragments of technical or scientific terms, often derived from compound words or root morphemes, that appear in contextually specific domains such as medicine, engineering, or chemistry, with high activation on partial word forms indicating sublexical processing.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8693426450093588,
    "similarity_var": 0.00027865497956567096,
    "score_fuzz": 0.56,
    "score_detection": 0.35,
    "score_embedding": 0.446875,
    "total_score": 0.4522916666666667,
    "x": 7.377629280090332,
    "y": 2.3150174617767334,
    "cluster_id": -1
  },
  {
    "feature_id": 37,
    "explanation_index": 2,
    "text": "The highlighted tokens are sub\u2011word fragments that correspond to morphological pieces of words (prefixes, suffixes, or whole words). They often appear as contiguous character sequences that are part of a larger word, sometimes with a preceding space or punctuation, and these fragments are the units the model uses to encode meaning.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8693426450093588,
    "similarity_var": 0.00027865497956567096,
    "score_fuzz": 0.65,
    "score_detection": 0.575,
    "score_embedding": 0.50625,
    "total_score": 0.5770833333333334,
    "x": 14.866942405700684,
    "y": 5.0947442054748535,
    "cluster_id": 77
  },
  {
    "feature_id": 38,
    "explanation_index": 0,
    "text": "Indefinite articles \\\"a\\\" and \\\"an\\\" used to introduce nouns, often in formal or technical contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8774721026420593,
    "similarity_var": 0.0019602229805381435,
    "score_fuzz": 0.9,
    "score_detection": 0.83,
    "score_embedding": 0.5448,
    "total_score": 0.7582666666666666,
    "x": 12.701616287231445,
    "y": 0.634620189666748,
    "cluster_id": 34
  },
  {
    "feature_id": 38,
    "explanation_index": 1,
    "text": "The definite article \\\"a\\\" or \\\"an\\\" is frequently used before nouns denoting measurable quantities, abstract concepts, or specific attributes in scientific and technical contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8774721026420593,
    "similarity_var": 0.0019602229805381435,
    "score_fuzz": 0.9,
    "score_detection": 0.68,
    "score_embedding": 0.52875,
    "total_score": 0.7029166666666667,
    "x": 12.725217819213867,
    "y": 0.6530923247337341,
    "cluster_id": 34
  },
  {
    "feature_id": 38,
    "explanation_index": 2,
    "text": "The highlighted tokens are function words\u2014articles, prepositions, and auxiliary markers\u2014that introduce or link noun phrases, serving as grammatical glue in the sentence structure.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8774721026420593,
    "similarity_var": 0.0019602229805381435,
    "score_fuzz": 0.75,
    "score_detection": 0.575,
    "score_embedding": 0.54875,
    "total_score": 0.6245833333333333,
    "x": 13.611920356750488,
    "y": 3.304326295852661,
    "cluster_id": 35
  },
  {
    "feature_id": 41,
    "explanation_index": 0,
    "text": "Punctuation marks, particularly periods, often used to end sentences or abbreviations, and sometimes used in conjunction with other symbols such as dollar signs or parentheses.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8768815398216248,
    "similarity_var": 0.0001458012865853675,
    "score_fuzz": 0.92,
    "score_detection": 0.57,
    "score_embedding": 0.41679999999999995,
    "total_score": 0.6356,
    "x": 8.1553373336792,
    "y": 6.81771183013916,
    "cluster_id": 36
  },
  {
    "feature_id": 41,
    "explanation_index": 1,
    "text": "The period character (\\\".\\\") is frequently activated in contexts involving mathematical expressions, citations, figure references, and technical formatting, often appearing in close proximity to delimiters like \\\"$\\\", \\\")\\\", \\\"}\\\", or \\\">>\\\", suggesting its role in marking syntactic or structural boundaries in formal or scientific text.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8768815398216248,
    "similarity_var": 0.0001458012865853675,
    "score_fuzz": 0.75,
    "score_detection": 0.32,
    "score_embedding": 0.47125000000000006,
    "total_score": 0.51375,
    "x": 8.37021541595459,
    "y": 7.098171234130859,
    "cluster_id": 37
  },
  {
    "feature_id": 41,
    "explanation_index": 2,
    "text": "The model highlights punctuation marks that signal sentence boundaries or code delimiters.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8768815398216248,
    "similarity_var": 0.0001458012865853675,
    "score_fuzz": 0.85,
    "score_detection": 0.55,
    "score_embedding": 0.5025,
    "total_score": 0.6341666666666667,
    "x": 13.539809226989746,
    "y": 5.33428955078125,
    "cluster_id": -1
  },
  {
    "feature_id": 42,
    "explanation_index": 0,
    "text": "Words that start with \\\"ba\\\", \\\"be\\\", or \\\"bad\\\" often representing nouns or adjectives, sometimes related to concepts of conflict, geography, or objects.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.854931652545929,
    "similarity_var": 0.001632187475211803,
    "score_fuzz": 0.92,
    "score_detection": 0.64,
    "score_embedding": 0.6392,
    "total_score": 0.7330666666666668,
    "x": 8.24068832397461,
    "y": 1.0285296440124512,
    "cluster_id": -1
  },
  {
    "feature_id": 42,
    "explanation_index": 1,
    "text": "Fragments of proper nouns, common words, or morphological variants (e.g., \\\"ba\\\", \\\"bag\\\", \\\"bank\\\", \\\"bad\\\", \\\"battle\\\") that appear in contexts involving names, places, or compound terms, often preceding or following punctuation or being part of a larger lexical unit.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.854931652545929,
    "similarity_var": 0.001632187475211803,
    "score_fuzz": 0.63,
    "score_detection": 0.27,
    "score_embedding": 0.683125,
    "total_score": 0.5277083333333333,
    "x": 7.0865797996521,
    "y": 2.584725856781006,
    "cluster_id": 2
  },
  {
    "feature_id": 42,
    "explanation_index": 2,
    "text": "The salient tokens are subword fragments that appear inside larger words\u2014often prefixes, suffixes, or internal pieces\u2014indicating that the model\u2019s behavior is largely driven by subword\u2011level lexical patterns rather than whole\u2011word tokens.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.854931652545929,
    "similarity_var": 0.001632187475211803,
    "score_fuzz": 0.625,
    "score_detection": 0.6,
    "score_embedding": 0.690625,
    "total_score": 0.6385416666666667,
    "x": 14.766310691833496,
    "y": 5.064724922180176,
    "cluster_id": 77
  },
  {
    "feature_id": 43,
    "explanation_index": 0,
    "text": "Code snippets from various programming languages, including C, C++, GLSL, and others, with a focus on graphics, shaders, and low-level programming.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8875471750895182,
    "similarity_var": 0.0009031926947318741,
    "score_fuzz": 0.63,
    "score_detection": 0.61,
    "score_embedding": 0.5904,
    "total_score": 0.6101333333333333,
    "x": 11.245976448059082,
    "y": 8.759804725646973,
    "cluster_id": 17
  },
  {
    "feature_id": 43,
    "explanation_index": 1,
    "text": "The text latents reveal a pattern of code-related identifiers, particularly in shader and low-level programming contexts, where tokens like `uniform`, `vec`, `float`, `struct`, `template`, `::`, and `u_` are frequently activated, often forming part of type declarations, function signatures, or syntax constructs in C/C++-like languages, with emphasis on naming conventions for variables, types, and namespaces.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8875471750895182,
    "similarity_var": 0.0009031926947318741,
    "score_fuzz": 0.62,
    "score_detection": 0.62,
    "score_embedding": 0.605,
    "total_score": 0.615,
    "x": 10.710718154907227,
    "y": 7.325939178466797,
    "cluster_id": 7
  },
  {
    "feature_id": 43,
    "explanation_index": 2,
    "text": "The highlighted fragments are consistently code identifiers\u2014variable names, function names, or type names\u2014often with prefixes or suffixes that signal their role (e.g., \u201cu_\u201d, \u201cshadow\u201d, \u201cMat\u201d, \u201cCoord\u201d). When several tokens are consecutive, they form a compound identifier. The pattern is that important tokens are code identifiers that participate in a specific operation or data structure.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8875471750895182,
    "similarity_var": 0.0009031926947318741,
    "score_fuzz": 0.475,
    "score_detection": 0.4,
    "score_embedding": 0.52,
    "total_score": 0.465,
    "x": 14.84420108795166,
    "y": 7.063388824462891,
    "cluster_id": -1
  },
  {
    "feature_id": 44,
    "explanation_index": 0,
    "text": "Conjunctions, prepositions, and nouns often used in formal or technical writing, particularly in academic or informative contexts, to connect ideas, list items, or describe relationships between concepts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8902893861134847,
    "similarity_var": 0.0007610994420311892,
    "score_fuzz": 0.71,
    "score_detection": 0.68,
    "score_embedding": 0.6256,
    "total_score": 0.6718666666666667,
    "x": 12.154448509216309,
    "y": 0.10263928025960922,
    "cluster_id": 9
  },
  {
    "feature_id": 44,
    "explanation_index": 1,
    "text": "The word \\\"and\\\" frequently appears in compound structures, connecting related concepts, items, or clauses, often in formal or technical writing, and is especially prominent in lists, comparisons, and conjunctions of ideas.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8902893861134847,
    "similarity_var": 0.0007610994420311892,
    "score_fuzz": 0.66,
    "score_detection": 0.56,
    "score_embedding": 0.6156250000000001,
    "total_score": 0.6118750000000001,
    "x": 11.769491195678711,
    "y": 2.2857816219329834,
    "cluster_id": 38
  },
  {
    "feature_id": 44,
    "explanation_index": 2,
    "text": "The token \u201cand\u201d is a highly frequent conjunction that links clauses, phrases, or items, often appearing with a preceding space and activating strongly across diverse contexts.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8902893861134847,
    "similarity_var": 0.0007610994420311892,
    "score_fuzz": 0.625,
    "score_detection": 0.525,
    "score_embedding": 0.6231249999999999,
    "total_score": 0.5910416666666666,
    "x": 13.197367668151855,
    "y": 3.571898937225342,
    "cluster_id": -1
  },
  {
    "feature_id": 46,
    "explanation_index": 0,
    "text": "En dash or hyphen used to indicate a range of values, typically years, pages, or numerical values.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9250860810279846,
    "similarity_var": 0.000307942609952742,
    "score_fuzz": 0.95,
    "score_detection": 0.73,
    "score_embedding": 0.4612,
    "total_score": 0.7137333333333333,
    "x": 8.08787727355957,
    "y": 7.625889778137207,
    "cluster_id": -1
  },
  {
    "feature_id": 46,
    "explanation_index": 1,
    "text": "The en dash (\u2013) or hyphen (-) is used to indicate ranges, such as dates, page numbers, or numerical intervals, often in academic or formal text.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9250860810279846,
    "similarity_var": 0.000307942609952742,
    "score_fuzz": 0.93,
    "score_detection": 0.78,
    "score_embedding": 0.45687500000000003,
    "total_score": 0.7222916666666667,
    "x": 8.185956001281738,
    "y": 7.49251651763916,
    "cluster_id": -1
  },
  {
    "feature_id": 46,
    "explanation_index": 2,
    "text": "The highlighted tokens are dash characters that signal a range or connection between two elements, such as years, page numbers, or paired terms.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9250860810279846,
    "similarity_var": 0.000307942609952742,
    "score_fuzz": 0.975,
    "score_detection": 0.65,
    "score_embedding": 0.35437499999999994,
    "total_score": 0.6597916666666667,
    "x": 13.219344139099121,
    "y": 5.840139389038086,
    "cluster_id": 30
  },
  {
    "feature_id": 47,
    "explanation_index": 0,
    "text": "Prepositions indicating location, direction, or manner, often used to establish relationships between entities or actions in a sentence.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8998786012331644,
    "similarity_var": 0.0006925105906848077,
    "score_fuzz": 0.88,
    "score_detection": 0.43,
    "score_embedding": 0.5504,
    "total_score": 0.6201333333333333,
    "x": 12.029252052307129,
    "y": -0.29541900753974915,
    "cluster_id": 39
  },
  {
    "feature_id": 47,
    "explanation_index": 1,
    "text": "Prepositional phrases indicating spatial, temporal, or causal relationships, often used to specify conditions, locations, or contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8998786012331644,
    "similarity_var": 0.0006925105906848077,
    "score_fuzz": 0.86,
    "score_detection": 0.48,
    "score_embedding": 0.52875,
    "total_score": 0.6229166666666667,
    "x": 12.05793285369873,
    "y": -0.3497721552848816,
    "cluster_id": 39
  },
  {
    "feature_id": 47,
    "explanation_index": 2,
    "text": "The highlighted tokens are short function words\u2014mostly prepositions and adverbs\u2014that signal spatial, temporal, or relational links between phrases.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8998786012331644,
    "similarity_var": 0.0006925105906848077,
    "score_fuzz": 0.85,
    "score_detection": 0.55,
    "score_embedding": 0.415625,
    "total_score": 0.6052083333333332,
    "x": 13.770148277282715,
    "y": 3.436354637145996,
    "cluster_id": 35
  },
  {
    "feature_id": 48,
    "explanation_index": 0,
    "text": "Proper nouns, names of specific locations, buildings, and institutions, as well as words related to architecture and geography.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8996243476867676,
    "similarity_var": 2.6129203639868592e-05,
    "score_fuzz": 0.5157894736842106,
    "score_detection": 0.46,
    "score_embedding": 0.29,
    "total_score": 0.42192982456140354,
    "x": 7.501306533813477,
    "y": -0.9252435564994812,
    "cluster_id": 16
  },
  {
    "feature_id": 48,
    "explanation_index": 1,
    "text": "Proper nouns and place names, particularly those denoting buildings, locations, or branded entities, are frequently activated when they appear in context, often accompanied by descriptive or directional terms like \\\"of\\\", \\\"in\\\", \\\"at\\\", or \\\"on\\\".",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8996243476867676,
    "similarity_var": 2.6129203639868592e-05,
    "score_fuzz": 0.54,
    "score_detection": 0.48,
    "score_embedding": 0.29937500000000006,
    "total_score": 0.43979166666666664,
    "x": 7.059042930603027,
    "y": -1.0911353826522827,
    "cluster_id": 40
  },
  {
    "feature_id": 48,
    "explanation_index": 2,
    "text": "The highlighted tokens are nouns or noun phrases that denote places, buildings, or objects, often forming part of a larger phrase and sometimes preceded by prepositions or articles.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8996243476867676,
    "similarity_var": 2.6129203639868592e-05,
    "score_fuzz": 0.6,
    "score_detection": 0.375,
    "score_embedding": 0.35250000000000004,
    "total_score": 0.44250000000000006,
    "x": 14.578703880310059,
    "y": 3.957658529281616,
    "cluster_id": 11
  },
  {
    "feature_id": 49,
    "explanation_index": 0,
    "text": "Articles and other determiners, often preceding nouns or noun phrases, and sometimes used in similes or comparisons.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8784655531247457,
    "similarity_var": 4.265653444769492e-05,
    "score_fuzz": 0.74,
    "score_detection": 0.49,
    "score_embedding": 0.6552,
    "total_score": 0.6284,
    "x": 12.653034210205078,
    "y": 0.4853461682796478,
    "cluster_id": -1
  },
  {
    "feature_id": 49,
    "explanation_index": 1,
    "text": "The definite and indefinite articles \\\"a\\\", \\\"an\\\", \\\"the\\\", and possessive pronouns like \\\"his\\\", \\\"your\\\", \\\"their\\\" are frequently activated when introducing or specifying entities, roles, or attributes in context.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8784655531247457,
    "similarity_var": 4.265653444769492e-05,
    "score_fuzz": 0.69,
    "score_detection": 0.5,
    "score_embedding": 0.615625,
    "total_score": 0.601875,
    "x": 12.330388069152832,
    "y": 0.9712685942649841,
    "cluster_id": -1
  },
  {
    "feature_id": 49,
    "explanation_index": 2,
    "text": "The highlighted tokens are typically short function words\u2014articles, prepositions, or conjunctions\u2014that appear in frequent collocations or idiomatic phrases (e.g., \u201ca\u201d before a noun or adjective, \u201clike a\u201d, \u201cthe\u201d, \u201cof\u201d).",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8784655531247457,
    "similarity_var": 4.265653444769492e-05,
    "score_fuzz": 0.75,
    "score_detection": 0.475,
    "score_embedding": 0.6287499999999999,
    "total_score": 0.6179166666666667,
    "x": 14.010831832885742,
    "y": 3.6274466514587402,
    "cluster_id": 0
  },
  {
    "feature_id": 50,
    "explanation_index": 0,
    "text": "Auxiliary verbs and pronouns often used in formal or written contexts to provide additional information or clarify relationships between entities.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8644817074139913,
    "similarity_var": 0.0008181277405070217,
    "score_fuzz": 0.8,
    "score_detection": 0.57,
    "score_embedding": 0.4452,
    "total_score": 0.6050666666666668,
    "x": 11.443477630615234,
    "y": 0.965026319026947,
    "cluster_id": -1
  },
  {
    "feature_id": 50,
    "explanation_index": 1,
    "text": "Pronouns and auxiliary verbs frequently appear in contexts involving conditional, future, or hypothetical statements, often signaling intent, possibility, or necessity.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8644817074139913,
    "similarity_var": 0.0008181277405070217,
    "score_fuzz": 0.81,
    "score_detection": 0.65,
    "score_embedding": 0.51875,
    "total_score": 0.6595833333333333,
    "x": 11.406951904296875,
    "y": 0.9422207474708557,
    "cluster_id": -1
  },
  {
    "feature_id": 50,
    "explanation_index": 2,
    "text": "The highlighted words are usually single tokens that form the core of a clause\u2014modal verbs, pronouns, prepositions, or key nouns\u2014capturing the main semantic or syntactic function of the sentence.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8644817074139913,
    "similarity_var": 0.0008181277405070217,
    "score_fuzz": 0.775,
    "score_detection": 0.525,
    "score_embedding": 0.5225,
    "total_score": 0.6075,
    "x": 16.184978485107422,
    "y": 3.6303980350494385,
    "cluster_id": -1
  },
  {
    "feature_id": 51,
    "explanation_index": 0,
    "text": "Technical terms and concepts related to physics, particularly in the fields of quantum mechanics, materials science, and engineering, often describing properties, behaviors, or phenomena of various systems and materials.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8911324938138326,
    "similarity_var": 0.0004447749639532441,
    "score_fuzz": 0.81,
    "score_detection": 0.74,
    "score_embedding": 0.5904,
    "total_score": 0.7134666666666667,
    "x": 7.417725086212158,
    "y": 1.0773128271102905,
    "cluster_id": 25
  },
  {
    "feature_id": 51,
    "explanation_index": 1,
    "text": "Partial word forms (typically stems or roots) that are part of technical or scientific terms, especially in physics and engineering contexts, often appearing in compound words related to resonance, oscillation, vibration, and material properties.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8911324938138326,
    "similarity_var": 0.0004447749639532441,
    "score_fuzz": 0.75,
    "score_detection": 0.74,
    "score_embedding": 0.559375,
    "total_score": 0.683125,
    "x": 7.345409870147705,
    "y": 2.558349370956421,
    "cluster_id": -1
  },
  {
    "feature_id": 51,
    "explanation_index": 2,
    "text": "The pattern is that the important tokens are fragments of technical terms, often stems of words that appear in scientific or technical contexts.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8911324938138326,
    "similarity_var": 0.0004447749639532441,
    "score_fuzz": 0.525,
    "score_detection": 0.475,
    "score_embedding": 0.3025,
    "total_score": 0.43416666666666665,
    "x": 11.07512378692627,
    "y": 4.430016040802002,
    "cluster_id": -1
  },
  {
    "feature_id": 52,
    "explanation_index": 0,
    "text": "Punctuation marks and conjunctions, often used to connect clauses or items in a list, and sometimes preceding or following a quotation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8799275557200114,
    "similarity_var": 2.7865380202582757e-05,
    "score_fuzz": 0.68,
    "score_detection": 0.74,
    "score_embedding": 0.3596,
    "total_score": 0.5932,
    "x": 7.872097969055176,
    "y": 6.499100685119629,
    "cluster_id": 5
  },
  {
    "feature_id": 52,
    "explanation_index": 1,
    "text": "Common conjunctions like \\\"and\\\", possessive pronouns like \\\"his\\\", and function words like \\\"in\\\", \\\"the\\\", \\\"to\\\", \\\"it\\\", \\\"you\\\", \\\"I\\\", \\\"m\\\", \\\"s\\\", \\\"er\\\", and punctuation tokens such as commas, periods, and parentheses are frequently activated in diverse syntactic and semantic contexts, often serving grammatical or structural roles in sentences.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8799275557200114,
    "similarity_var": 2.7865380202582757e-05,
    "score_fuzz": 0.71,
    "score_detection": 0.73,
    "score_embedding": 0.316875,
    "total_score": 0.585625,
    "x": 10.789731979370117,
    "y": 2.35250186920166,
    "cluster_id": -1
  },
  {
    "feature_id": 52,
    "explanation_index": 2,
    "text": "The model highlights short function words that serve as syntactic glue\u2014conjunctions, prepositions, articles, and occasionally punctuation\u2014often in brief sequences that link clauses or items.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8799275557200114,
    "similarity_var": 2.7865380202582757e-05,
    "score_fuzz": 0.7,
    "score_detection": 0.8,
    "score_embedding": 0.29499999999999993,
    "total_score": 0.5983333333333333,
    "x": 13.042305946350098,
    "y": 3.233144760131836,
    "cluster_id": 82
  },
  {
    "feature_id": 53,
    "explanation_index": 0,
    "text": "Proper nouns, geographical locations, names, and titles, often denoted by capitalization, and sometimes accompanied by specific details or descriptions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8679483731587728,
    "similarity_var": 0.0011991039245684316,
    "score_fuzz": 0.54,
    "score_detection": 0.39,
    "score_embedding": 0.3712,
    "total_score": 0.43373333333333336,
    "x": 7.337560176849365,
    "y": -0.9718368053436279,
    "cluster_id": 16
  },
  {
    "feature_id": 53,
    "explanation_index": 1,
    "text": "Proper nouns and geographical names are frequently activated, often in context with locations, institutions, or specific entities, particularly when they appear in titles, place names, or formal designations.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8679483731587728,
    "similarity_var": 0.0011991039245684316,
    "score_fuzz": 0.44,
    "score_detection": 0.39,
    "score_embedding": 0.5406249999999999,
    "total_score": 0.456875,
    "x": 7.157268524169922,
    "y": -1.1144413948059082,
    "cluster_id": 40
  },
  {
    "feature_id": 53,
    "explanation_index": 2,
    "text": "The highlighted tokens tend to belong to frequent collocations or idiomatic patterns\u2014such as common prepositional phrases, comparative suffixes, and nouns that denote containers or places\u2014along with high\u2011frequency function words that often appear in these expressions.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8679483731587728,
    "similarity_var": 0.0011991039245684316,
    "score_fuzz": 0.325,
    "score_detection": 0.2,
    "score_embedding": 0.596875,
    "total_score": 0.3739583333333334,
    "x": 14.0707426071167,
    "y": 3.720966339111328,
    "cluster_id": 67
  },
  {
    "feature_id": 54,
    "explanation_index": 0,
    "text": "Prepositions, articles, and nouns related to location, distance, and elevation, often used in descriptive phrases or sentences about geography, travel, and spatial relationships.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8865427374839783,
    "similarity_var": 0.00044538324608112134,
    "score_fuzz": 0.74,
    "score_detection": 0.69,
    "score_embedding": 0.6012,
    "total_score": 0.6770666666666667,
    "x": 12.331389427185059,
    "y": -0.20245836675167084,
    "cluster_id": -1
  },
  {
    "feature_id": 54,
    "explanation_index": 1,
    "text": "Commonly activated tokens include prepositions, numerical values, units of measurement, and words related to geographic or physical attributes, often appearing in contexts involving spatial, elevation, or distance descriptions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8865427374839783,
    "similarity_var": 0.00044538324608112134,
    "score_fuzz": 0.7,
    "score_detection": 0.67,
    "score_embedding": 0.37124999999999997,
    "total_score": 0.5804166666666667,
    "x": 10.192061424255371,
    "y": 3.605423927307129,
    "cluster_id": 41
  },
  {
    "feature_id": 54,
    "explanation_index": 2,
    "text": "The highlighted tokens are typically short, high\u2011frequency function words or common nouns that serve as connectors or descriptors in spatial, comparative, or state\u2011describing contexts.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8865427374839783,
    "similarity_var": 0.00044538324608112134,
    "score_fuzz": 0.55,
    "score_detection": 0.4,
    "score_embedding": 0.281875,
    "total_score": 0.410625,
    "x": 13.793956756591797,
    "y": 3.945986032485962,
    "cluster_id": 42
  },
  {
    "feature_id": 55,
    "explanation_index": 0,
    "text": "Prepositions and articles often precede nouns, while verbs and nouns often follow them, and sometimes a possessive pronoun or a name is used to describe a person or entity.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8550736308097839,
    "similarity_var": 0.00013362451988285784,
    "score_fuzz": 0.56,
    "score_detection": 0.46,
    "score_embedding": 0.5008,
    "total_score": 0.5069333333333333,
    "x": 12.915192604064941,
    "y": 0.3010852336883545,
    "cluster_id": 43
  },
  {
    "feature_id": 55,
    "explanation_index": 1,
    "text": "Frequent use of the word \\\"to\\\" in infinitive verb constructions, and common use of possessive pronouns, definite articles, and proper nouns in political and institutional contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8550736308097839,
    "similarity_var": 0.00013362451988285784,
    "score_fuzz": 0.5263157894736842,
    "score_detection": 0.44,
    "score_embedding": 0.36812500000000004,
    "total_score": 0.4448135964912281,
    "x": 11.555906295776367,
    "y": 0.01698957197368145,
    "cluster_id": 53
  },
  {
    "feature_id": 55,
    "explanation_index": 2,
    "text": "The highlighted tokens are usually short function words or fragments of names that together form a prepositional or verb phrase central to the sentence, often indicating location, time, or action.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8550736308097839,
    "similarity_var": 0.00013362451988285784,
    "score_fuzz": 0.425,
    "score_detection": 0.675,
    "score_embedding": 0.56125,
    "total_score": 0.5537500000000001,
    "x": 14.09303092956543,
    "y": 3.706484317779541,
    "cluster_id": 67
  },
  {
    "feature_id": 56,
    "explanation_index": 0,
    "text": "A suffix or prefix of a word, often indicating a relationship to a concept or object.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8785060048103333,
    "similarity_var": 0.00047963452525578987,
    "score_fuzz": 0.75,
    "score_detection": 0.5,
    "score_embedding": 0.6,
    "total_score": 0.6166666666666667,
    "x": 8.307990074157715,
    "y": 2.189485788345337,
    "cluster_id": 44
  },
  {
    "feature_id": 56,
    "explanation_index": 1,
    "text": "Common suffixes or root fragments of words, often appearing in compound or technical terms, with high activation values when part of a larger lexical unit.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8785060048103333,
    "similarity_var": 0.00047963452525578987,
    "score_fuzz": 0.72,
    "score_detection": 0.54,
    "score_embedding": 0.638125,
    "total_score": 0.6327083333333333,
    "x": 8.171894073486328,
    "y": 2.5432634353637695,
    "cluster_id": -1
  },
  {
    "feature_id": 56,
    "explanation_index": 2,
    "text": "The activations consistently highlight partial word fragments\u2014mostly suffixes or prefixes\u2014that recur across different lexical items, indicating that the model\u2019s internal representations are sensitive to subword morphological units rather than whole words.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8785060048103333,
    "similarity_var": 0.00047963452525578987,
    "score_fuzz": 0.825,
    "score_detection": 0.425,
    "score_embedding": 0.5331250000000001,
    "total_score": 0.594375,
    "x": 7.9943623542785645,
    "y": 3.2848613262176514,
    "cluster_id": 76
  },
  {
    "feature_id": 57,
    "explanation_index": 0,
    "text": "Punctuation marks and special characters, often used to denote formatting, mathematical operations, or programming syntax.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8533546924591064,
    "similarity_var": 0.00034767683968794927,
    "score_fuzz": 0.4421052631578947,
    "score_detection": 0.31,
    "score_embedding": 0.324,
    "total_score": 0.3587017543859649,
    "x": 8.595836639404297,
    "y": 7.250547885894775,
    "cluster_id": 4
  },
  {
    "feature_id": 57,
    "explanation_index": 1,
    "text": "The presence of isolated or paired punctuation marks, symbols, or whitespace sequences that appear to mark structural or syntactic boundaries in text, often surrounding or separating content, with minimal semantic weight but high activation in model tokens.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8533546924591064,
    "similarity_var": 0.00034767683968794927,
    "score_fuzz": 0.49,
    "score_detection": 0.41,
    "score_embedding": 0.25375,
    "total_score": 0.3845833333333333,
    "x": 13.41702651977539,
    "y": 5.349130153656006,
    "cluster_id": -1
  },
  {
    "feature_id": 57,
    "explanation_index": 2,
    "text": "The markers consistently capture contiguous token sequences that form semantically or syntactically salient units\u2014ranging from single words, multi\u2011word phrases, punctuation, numbers, or code symbols\u2014indicating that the model flags any contiguous block that carries a distinct meaning or function.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8533546924591064,
    "similarity_var": 0.00034767683968794927,
    "score_fuzz": 0.475,
    "score_detection": 0.55,
    "score_embedding": 0.285625,
    "total_score": 0.43687499999999996,
    "x": 14.494930267333984,
    "y": 5.081334114074707,
    "cluster_id": -1
  },
  {
    "feature_id": 58,
    "explanation_index": 0,
    "text": "Adjectives or adverbs describing a state, emotion, or characteristic, often with a negative connotation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8689846396446228,
    "similarity_var": 9.294036968536072e-05,
    "score_fuzz": 0.8,
    "score_detection": 0.63,
    "score_embedding": 0.43799999999999994,
    "total_score": 0.6226666666666667,
    "x": 9.054156303405762,
    "y": 1.2573606967926025,
    "cluster_id": 45
  },
  {
    "feature_id": 58,
    "explanation_index": 1,
    "text": "Adjectives and noun phrases describing emotional states, physical conditions, or abstract qualities, often used to convey subjective experience or evaluation.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8689846396446228,
    "similarity_var": 9.294036968536072e-05,
    "score_fuzz": 0.83,
    "score_detection": 0.64,
    "score_embedding": 0.42625,
    "total_score": 0.6320833333333333,
    "x": 8.925928115844727,
    "y": 1.174621820449829,
    "cluster_id": 45
  },
  {
    "feature_id": 58,
    "explanation_index": 2,
    "text": "The highlighted tokens are core descriptive words\u2014mostly adjectives, nouns, or short evaluative phrases\u2014that carry the main sentiment or detail of a sentence, often negative or strongly descriptive, and they function as the key content words that shape the meaning of the surrounding clause.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8689846396446228,
    "similarity_var": 9.294036968536072e-05,
    "score_fuzz": 0.825,
    "score_detection": 0.525,
    "score_embedding": 0.45624999999999993,
    "total_score": 0.6020833333333333,
    "x": 15.186644554138184,
    "y": 3.914724111557007,
    "cluster_id": 22
  },
  {
    "feature_id": 59,
    "explanation_index": 0,
    "text": "Various nouns and common words related to travel, accommodations, and outdoor activities, often in the context of tourism and leisure.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9198557734489441,
    "similarity_var": 0.0007834872025611617,
    "score_fuzz": 0.43157894736842106,
    "score_detection": 0.36,
    "score_embedding": 0.41280000000000006,
    "total_score": 0.40145964912280707,
    "x": 8.29532241821289,
    "y": -0.35328859090805054,
    "cluster_id": -1
  },
  {
    "feature_id": 59,
    "explanation_index": 1,
    "text": "Common nouns and noun phrases related to outdoor recreation, accommodation, or travel destinations, often appearing in contexts involving camping, lodging, or recreational facilities.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9198557734489441,
    "similarity_var": 0.0007834872025611617,
    "score_fuzz": 0.48,
    "score_detection": 0.4,
    "score_embedding": 0.45125,
    "total_score": 0.44375000000000003,
    "x": 8.416533470153809,
    "y": -0.33142709732055664,
    "cluster_id": -1
  },
  {
    "feature_id": 59,
    "explanation_index": 2,
    "text": "the pattern: many tokens are about camping, camp, campground, etc.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9198557734489441,
    "similarity_var": 0.0007834872025611617,
    "score_fuzz": 0.4,
    "score_detection": 0.45,
    "score_embedding": 0.47250000000000003,
    "total_score": 0.4408333333333334,
    "x": 10.84202766418457,
    "y": 4.386059284210205,
    "cluster_id": -1
  },
  {
    "feature_id": 60,
    "explanation_index": 0,
    "text": "Definite articles, often marking the beginning of a sentence or a new idea, and sometimes preceding a noun or a quotation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8802974224090576,
    "similarity_var": 0.0007268169726728502,
    "score_fuzz": 0.92,
    "score_detection": 0.69,
    "score_embedding": 0.27959999999999996,
    "total_score": 0.6298666666666666,
    "x": 12.808402061462402,
    "y": 0.5208923816680908,
    "cluster_id": 34
  },
  {
    "feature_id": 60,
    "explanation_index": 1,
    "text": "The definite article \\\"the\\\" frequently appears in academic and technical writing to refer to specific, previously mentioned, or contextually known entities, often preceding nouns that denote abstract concepts, research findings, or defined components within a study.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8802974224090576,
    "similarity_var": 0.0007268169726728502,
    "score_fuzz": 0.8,
    "score_detection": 0.48,
    "score_embedding": 0.40625000000000006,
    "total_score": 0.5620833333333334,
    "x": 12.668488502502441,
    "y": 0.6753508448600769,
    "cluster_id": 34
  },
  {
    "feature_id": 60,
    "explanation_index": 2,
    "text": "The highlighted words are typically the initial token of a clause or noun phrase, often a small function word such as an article or demonstrative, that signals the start of a new syntactic unit.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8802974224090576,
    "similarity_var": 0.0007268169726728502,
    "score_fuzz": 0.875,
    "score_detection": 0.475,
    "score_embedding": 0.34875,
    "total_score": 0.56625,
    "x": 16.60204315185547,
    "y": 3.654939651489258,
    "cluster_id": 20
  },
  {
    "feature_id": 61,
    "explanation_index": 0,
    "text": "Negation words or phrases, often used to indicate the absence or opposite of something, typically preceding a clause or phrase.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9059754610061646,
    "similarity_var": 7.577340861075754e-05,
    "score_fuzz": 0.96,
    "score_detection": 0.75,
    "score_embedding": 0.69,
    "total_score": 0.7999999999999999,
    "x": 10.719898223876953,
    "y": 2.710092067718506,
    "cluster_id": 46
  },
  {
    "feature_id": 61,
    "explanation_index": 1,
    "text": "Negation markers such as \\\"not\\\", \\\"ne...pas\\\", \\\"without\\\", \\\"non-\\\", and contractions like \\\"don't\\\" or \\\"doesn't\\\" are frequently activated when expressing denial, absence, or exclusion, often in contexts involving logical or factual negation.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9059754610061646,
    "similarity_var": 7.577340861075754e-05,
    "score_fuzz": 0.94,
    "score_detection": 0.87,
    "score_embedding": 0.438125,
    "total_score": 0.749375,
    "x": 10.76236343383789,
    "y": 2.7628109455108643,
    "cluster_id": 46
  },
  {
    "feature_id": 61,
    "explanation_index": 2,
    "text": "Tokens that signal negation or absence (e.g., \u201cnot\u201d, \u201cwithout\u201d, \u201cne \u2026 pas\u201d, \u201cnever\u201d, contractions like \u201cn't\u201d).",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9059754610061646,
    "similarity_var": 7.577340861075754e-05,
    "score_fuzz": 0.925,
    "score_detection": 0.8,
    "score_embedding": 0.52125,
    "total_score": 0.7487499999999999,
    "x": 10.747608184814453,
    "y": 2.810344696044922,
    "cluster_id": 46
  },
  {
    "feature_id": 62,
    "explanation_index": 0,
    "text": "Various tokens including articles, prepositions, conjunctions, and adjectives that provide context and structure to sentences, often used in formal or technical writing.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8714748024940491,
    "similarity_var": 0.000412717720311188,
    "score_fuzz": 0.72,
    "score_detection": 0.76,
    "score_embedding": 0.28920000000000007,
    "total_score": 0.5897333333333333,
    "x": 10.625141143798828,
    "y": 4.51545524597168,
    "cluster_id": 47
  },
  {
    "feature_id": 62,
    "explanation_index": 1,
    "text": "Common function, variable, or structural tokens in programming, mathematical, or technical contexts, often appearing in sequences related to syntax, operations, or logical constructs.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8714748024940491,
    "similarity_var": 0.000412717720311188,
    "score_fuzz": 0.32,
    "score_detection": 0.24,
    "score_embedding": 0.22875,
    "total_score": 0.2629166666666667,
    "x": 11.01806354522705,
    "y": 5.096722602844238,
    "cluster_id": -1
  },
  {
    "feature_id": 62,
    "explanation_index": 2,
    "text": "The highlighted tokens are typically short, function\u2011like words that anchor the highlighted phrase\u2014prepositions, articles, conjunctions, or brief modifiers that form the core of a noun or prepositional phrase.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8714748024940491,
    "similarity_var": 0.000412717720311188,
    "score_fuzz": 0.6,
    "score_detection": 0.65,
    "score_embedding": 0.296875,
    "total_score": 0.515625,
    "x": 14.27340030670166,
    "y": 3.8045589923858643,
    "cluster_id": -1
  },
  {
    "feature_id": 64,
    "explanation_index": 0,
    "text": "Function words and prepositions, often used to connect clauses or phrases, and sometimes nouns representing relationships, family, or social status.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8714021444320679,
    "similarity_var": 0.0015874751542336678,
    "score_fuzz": 0.4842105263157895,
    "score_detection": 0.49,
    "score_embedding": 0.692,
    "total_score": 0.5554035087719298,
    "x": 10.68185043334961,
    "y": 1.1819034814834595,
    "cluster_id": 26
  },
  {
    "feature_id": 64,
    "explanation_index": 1,
    "text": "Common function words and multi-word phrases that serve grammatical or contextual linking roles, often appearing in sequences involving relationships, possession, comparison, or listing.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8714021444320679,
    "similarity_var": 0.0015874751542336678,
    "score_fuzz": 0.42105263157894735,
    "score_detection": 0.47,
    "score_embedding": 0.549375,
    "total_score": 0.4801425438596491,
    "x": 10.663031578063965,
    "y": 1.301718831062317,
    "cluster_id": 26
  },
  {
    "feature_id": 64,
    "explanation_index": 2,
    "text": "Important tokens tend to be short, high\u2011frequency words that appear in many contexts, often forming part of common collocations or key phrases.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8714021444320679,
    "similarity_var": 0.0015874751542336678,
    "score_fuzz": 0.325,
    "score_detection": 0.275,
    "score_embedding": 0.48375,
    "total_score": 0.36125000000000007,
    "x": 11.47774600982666,
    "y": 4.5640740394592285,
    "cluster_id": 78
  },
  {
    "feature_id": 65,
    "explanation_index": 0,
    "text": "Verbs or words that indicate actions, changes, or states, often used in formal or written contexts, and sometimes used to introduce or conclude a quotation or statement.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8447073300679525,
    "similarity_var": 6.782670525337962e-05,
    "score_fuzz": 0.5,
    "score_detection": 0.47,
    "score_embedding": 0.46599999999999997,
    "total_score": 0.47866666666666663,
    "x": 10.528090476989746,
    "y": -0.7964106202125549,
    "cluster_id": 14
  },
  {
    "feature_id": 65,
    "explanation_index": 1,
    "text": "Common function words and particles (such as \\\"to\\\", \\\"in\\\", \\\"with\\\", \\\"of\\\", \\\"and\\\", \\\"than\\\", \\\"like\\\", \\\"er\\\") that serve grammatical or structural roles in sentences, often appearing in contextually significant phrases or constructions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8447073300679525,
    "similarity_var": 6.782670525337962e-05,
    "score_fuzz": 0.47,
    "score_detection": 0.5,
    "score_embedding": 0.450625,
    "total_score": 0.4735416666666667,
    "x": 10.687255859375,
    "y": 2.123666286468506,
    "cluster_id": -1
  },
  {
    "feature_id": 65,
    "explanation_index": 2,
    "text": "The highlighted tokens are the semantic anchors of fixed multi\u2011word expressions or morphological markers that signal comparison. They are usually the core verb or noun that carries the main meaning of an idiom or collocation, or a suffix (e.g., \u201c\u2011er\u201d) that marks a comparative form.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8447073300679525,
    "similarity_var": 6.782670525337962e-05,
    "score_fuzz": 0.5,
    "score_detection": 0.475,
    "score_embedding": 0.499375,
    "total_score": 0.49145833333333333,
    "x": 14.70572280883789,
    "y": 3.885457754135132,
    "cluster_id": 11
  },
  {
    "feature_id": 67,
    "explanation_index": 0,
    "text": "Negation and degree adverbs, often used in informal or conversational contexts, typically in the form of auxiliary verbs or adverbs like \\\"not\\\", \\\"yet\\\", \\\"quite\\\", and \\\"t\\\", which are used to express contrast, uncertainty, or degree.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8740062316258749,
    "similarity_var": 0.0007544666956044288,
    "score_fuzz": 0.88,
    "score_detection": 0.87,
    "score_embedding": 0.44880000000000003,
    "total_score": 0.7329333333333333,
    "x": 10.582812309265137,
    "y": 2.5827295780181885,
    "cluster_id": -1
  },
  {
    "feature_id": 67,
    "explanation_index": 1,
    "text": "The use of negation markers (\\\"not\\\", \\\"n't\\\") and temporal qualifiers (\\\"yet\\\", \\\"quite\\\") in contexts indicating incompleteness, absence, or unfulfilled expectations.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8740062316258749,
    "similarity_var": 0.0007544666956044288,
    "score_fuzz": 0.87,
    "score_detection": 0.89,
    "score_embedding": 0.704375,
    "total_score": 0.8214583333333333,
    "x": 10.773009300231934,
    "y": 2.783006191253662,
    "cluster_id": 46
  },
  {
    "feature_id": 67,
    "explanation_index": 2,
    "text": "The highlighted tokens are short, high\u2011frequency function words that form common collocations\u2014especially negation and emphasis such as \u201cnot yet,\u201d \u201cquite,\u201d \u201cyou,\u201d \u201cenough,\u201d and the fragment \u201ct.\u201d They serve as grammatical connectors or particles rather than content words, and they recur across the examples.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8740062316258749,
    "similarity_var": 0.0007544666956044288,
    "score_fuzz": 0.825,
    "score_detection": 0.8,
    "score_embedding": 0.15625,
    "total_score": 0.59375,
    "x": 13.79306411743164,
    "y": 3.6283652782440186,
    "cluster_id": -1
  },
  {
    "feature_id": 68,
    "explanation_index": 0,
    "text": "Various programming language syntax elements, including access modifiers, type declarations, method and variable names, and symbols used in different programming languages such as Kotlin, Java, C++, and others.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.89154452085495,
    "similarity_var": 0.001155942944665848,
    "score_fuzz": 0.65,
    "score_detection": 0.61,
    "score_embedding": 0.40279999999999994,
    "total_score": 0.5542666666666666,
    "x": 10.659930229187012,
    "y": 8.341079711914062,
    "cluster_id": 48
  },
  {
    "feature_id": 68,
    "explanation_index": 1,
    "text": "Common programming language syntax elements such as access modifiers, class and method declarations, object references, and punctuation used in code structure.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.89154452085495,
    "similarity_var": 0.001155942944665848,
    "score_fuzz": 0.65,
    "score_detection": 0.59,
    "score_embedding": 0.524375,
    "total_score": 0.588125,
    "x": 10.596386909484863,
    "y": 8.278646469116211,
    "cluster_id": 48
  },
  {
    "feature_id": 68,
    "explanation_index": 2,
    "text": "The markers consistently enclose syntactically significant code tokens\u2014keywords, identifiers, punctuation, and operators\u2014highlighting the elements that define the structure and meaning of the code.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.89154452085495,
    "similarity_var": 0.001155942944665848,
    "score_fuzz": 0.525,
    "score_detection": 0.55,
    "score_embedding": 0.433125,
    "total_score": 0.5027083333333334,
    "x": 13.652129173278809,
    "y": 6.74336051940918,
    "cluster_id": 8
  },
  {
    "feature_id": 69,
    "explanation_index": 0,
    "text": "The word \\\"as\\\" is used in various contexts, often indicating a role, function, or comparison, and sometimes introducing a clause or phrase that provides additional information.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9088398416837057,
    "similarity_var": 0.0007616189273783725,
    "score_fuzz": 0.96,
    "score_detection": 0.92,
    "score_embedding": 0.5872,
    "total_score": 0.8224,
    "x": 11.74333381652832,
    "y": 2.646364450454712,
    "cluster_id": 49
  },
  {
    "feature_id": 69,
    "explanation_index": 1,
    "text": "The word \\\"as\\\" frequently appears in comparative, functional, or temporal contexts, often introducing a clause that defines a role, condition, or time frame, and is commonly used in constructions like \\\"as well as,\\\" \\\"as a,\\\" or \\\"as time went by.\\\"",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9088398416837057,
    "similarity_var": 0.0007616189273783725,
    "score_fuzz": 0.95,
    "score_detection": 0.93,
    "score_embedding": 0.41562499999999997,
    "total_score": 0.7652083333333333,
    "x": 11.75072956085205,
    "y": 2.62662672996521,
    "cluster_id": 49
  },
  {
    "feature_id": 69,
    "explanation_index": 2,
    "text": "The recurring latent is the function word \u201cas\u201d, which appears in many grammatical roles\u2014often as a preposition or conjunction\u2014forming common phrases such as \u201cas well as\u201d, \u201cas a\u201d, \u201cas a unit\u201d, and \u201cas a setting\u201d. It is frequently capitalized at sentence starts and is paired with a variety of following words, indicating its role as a versatile connective element in the text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9088398416837057,
    "similarity_var": 0.0007616189273783725,
    "score_fuzz": 0.925,
    "score_detection": 0.9,
    "score_embedding": 0.52,
    "total_score": 0.7816666666666667,
    "x": 11.733626365661621,
    "y": 2.6957743167877197,
    "cluster_id": 49
  },
  {
    "feature_id": 70,
    "explanation_index": 0,
    "text": "Articles, possessive pronouns, and adjectives often precede nouns, while prepositions often precede articles or nouns, and comparative or superlative adjectives often describe nouns.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8649413386980692,
    "similarity_var": 0.0004168661217020839,
    "score_fuzz": 0.65,
    "score_detection": 0.49,
    "score_embedding": 0.39080000000000004,
    "total_score": 0.5102666666666668,
    "x": 12.94308853149414,
    "y": 0.2885104715824127,
    "cluster_id": 43
  },
  {
    "feature_id": 70,
    "explanation_index": 1,
    "text": "Commonly activated tokens include possessive forms (e.g., \\\"its\\\", \\\"their\\\", \\\"s\\\"), definite articles (\\\"the\\\"), prepositions (\\\"of\\\", \\\"in\\\", \\\"regarding\\\"), and adjectives or adverbs that describe quality or extent, often appearing in evaluative or comparative contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8649413386980692,
    "similarity_var": 0.0004168661217020839,
    "score_fuzz": 0.8,
    "score_detection": 0.52,
    "score_embedding": 0.5375,
    "total_score": 0.6191666666666666,
    "x": 10.295431137084961,
    "y": 3.1882903575897217,
    "cluster_id": 50
  },
  {
    "feature_id": 70,
    "explanation_index": 2,
    "text": "The highlighted tokens are almost always the building blocks of multi\u2011word expressions that carry a distinct semantic load\u2014idioms, comparative adjectives, noun phrases, or prepositional phrases. They tend to be the function words that link the core content words, so the activations cluster around the grammatical glue that makes a phrase meaningful.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8649413386980692,
    "similarity_var": 0.0004168661217020839,
    "score_fuzz": 0.575,
    "score_detection": 0.5,
    "score_embedding": 0.52375,
    "total_score": 0.5329166666666666,
    "x": 14.839139938354492,
    "y": 3.9666428565979004,
    "cluster_id": -1
  },
  {
    "feature_id": 71,
    "explanation_index": 0,
    "text": "Various programming language constructs, including function definitions, conditional statements, loops, assignments, and type definitions, often with a focus on syntax and structure.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8918774326642355,
    "similarity_var": 0.00019450892450439345,
    "score_fuzz": 0.52,
    "score_detection": 0.4631578947368421,
    "score_embedding": 0.22080000000000002,
    "total_score": 0.401319298245614,
    "x": 10.789687156677246,
    "y": 8.389240264892578,
    "cluster_id": 48
  },
  {
    "feature_id": 71,
    "explanation_index": 1,
    "text": "The token sequences involving comparison, assignment, and control flow operators (like `=>`, `:=`, `=`, `if`, `then`, `else`, `return`, `in`, `do`, `with`, `case`, `for`, `while`, `match`, `when`, `finally`, `try`, `catch`, `throw`, `and`, `or`, `not`, `as`, `is`, `in`, `of`, `to`, `from`, `with`, `without`, `on`, `off`, `up`, `down`, `left`, `right`, `over`, `under`, `before`, `after`, `during`, `until`, `while`, `unless`, `provided`, `given`, `assuming`, `supposing`, `considering`, `regardless`, `despite`, `although`, `even though`, `since`, `because`, `so`, `thus`, `hence`, `therefore`, `accordingly`, `consequently`, `meanwhile`, `simultaneously`, `subsequently`, `eventually`, `finally`, `ultimately`, `in conclusion`, `to sum up`, `in summary`, `in short`, `in brief`, `in essence`, `in a nutshell`, `in other words`, `that is to say`, `namely`, `specifically`, `particularly`, `especially`, `especially`, `notably`, `significantly`, `remarkably`, `strikingly`, `interestingly`, `curiously`, `surprisingly`, `unexpectedly`, `astonishingly`, `incredibly`, `amazingly`, `incredibly`, `unbelievably`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly`, `incredibly",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8918774326642355,
    "similarity_var": 0.00019450892450439345,
    "score_fuzz": 0.56,
    "score_detection": 0.5052631578947369,
    "score_embedding": 0.40312499999999996,
    "total_score": 0.48946271929824564,
    "x": 11.053603172302246,
    "y": 5.5484514236450195,
    "cluster_id": 51
  },
  {
    "feature_id": 71,
    "explanation_index": 2,
    "text": "The highlighted tokens are core syntactic elements that govern program behavior: assignment, comparison, logical operators, control\u2011flow keywords, and function/closure delimiters.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8918774326642355,
    "similarity_var": 0.00019450892450439345,
    "score_fuzz": 0.65,
    "score_detection": 0.55,
    "score_embedding": 0.29000000000000004,
    "total_score": 0.49666666666666676,
    "x": 13.672024726867676,
    "y": 6.686910629272461,
    "cluster_id": 8
  },
  {
    "feature_id": 72,
    "explanation_index": 0,
    "text": "Truncated words or word parts, often suffixes or prefixes, that are part of a larger word or phrase.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8810092012087504,
    "similarity_var": 0.0013307919668987566,
    "score_fuzz": 0.5,
    "score_detection": 0.47,
    "score_embedding": 0.3968,
    "total_score": 0.4556,
    "x": 7.313518524169922,
    "y": 2.8510286808013916,
    "cluster_id": 15
  },
  {
    "feature_id": 72,
    "explanation_index": 1,
    "text": "Partial word fragments at the end of tokens, often representing suffixes or root forms of words, particularly in contexts involving technical terms, proper names, or morphological variations.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8810092012087504,
    "similarity_var": 0.0013307919668987566,
    "score_fuzz": 0.54,
    "score_detection": 0.5,
    "score_embedding": 0.42625,
    "total_score": 0.48875,
    "x": 7.192245006561279,
    "y": 2.9053425788879395,
    "cluster_id": 15
  },
  {
    "feature_id": 72,
    "explanation_index": 2,
    "text": "The pattern might be that the tokens are substrings that appear in the text, often at word boundaries or inside words.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8810092012087504,
    "similarity_var": 0.0013307919668987566,
    "score_fuzz": 0.55,
    "score_detection": 0.525,
    "score_embedding": 0.4525,
    "total_score": 0.5091666666666668,
    "x": 11.405279159545898,
    "y": 4.139139175415039,
    "cluster_id": -1
  },
  {
    "feature_id": 73,
    "explanation_index": 0,
    "text": "Verbs and nouns related to providing, giving, applying, requiring, and supplying, often in contexts of problem-solving, explanation, or instruction.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8267295757929484,
    "similarity_var": 0.0003539607285326775,
    "score_fuzz": 0.75,
    "score_detection": 0.7,
    "score_embedding": 0.6996,
    "total_score": 0.7165333333333334,
    "x": 10.572443962097168,
    "y": -0.5523598790168762,
    "cluster_id": -1
  },
  {
    "feature_id": 73,
    "explanation_index": 1,
    "text": "The token \\\"supp\\\" and its variants (e.g., \\\"supplement\\\", \\\"supposed\\\", \\\"supply\\\", \\\"supreme\\\") are frequently activated in contexts involving addition, assumption, or extremity, often linked to abstract or evaluative concepts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8267295757929484,
    "similarity_var": 0.0003539607285326775,
    "score_fuzz": 0.64,
    "score_detection": 0.62,
    "score_embedding": 0.6925,
    "total_score": 0.6508333333333334,
    "x": 10.1511812210083,
    "y": 3.1668553352355957,
    "cluster_id": 33
  },
  {
    "feature_id": 73,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8267295757929484,
    "similarity_var": 0.0003539607285326775,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.669375,
    "total_score": 0.5564583333333334,
    "x": -7.905266284942627,
    "y": 9.154891014099121,
    "cluster_id": 52
  },
  {
    "feature_id": 74,
    "explanation_index": 0,
    "text": "Informal expressions and colloquialisms, often used in spoken language or dialogue, including phrases that convey agreement, confirmation, or acknowledgment, such as \\\"right\\\", \\\"okay\\\", \\\"you know\\\", and \\\"really\\\", as well as phrases that express familiarity or friendliness, like \\\"man\\\", \\\"chap\\\", and \\\"folks\\\".",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8127118150393168,
    "similarity_var": 0.0027806727204462175,
    "score_fuzz": 0.78,
    "score_detection": 0.82,
    "score_embedding": 0.6275999999999999,
    "total_score": 0.7425333333333333,
    "x": 10.286910057067871,
    "y": 0.10717558860778809,
    "cluster_id": -1
  },
  {
    "feature_id": 74,
    "explanation_index": 1,
    "text": "Common conversational fillers and tag questions used to seek agreement, confirmation, or express casual emphasis, often appearing in informal speech and dialogue.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8127118150393168,
    "similarity_var": 0.0027806727204462175,
    "score_fuzz": 0.83,
    "score_detection": 0.78,
    "score_embedding": 0.6475000000000001,
    "total_score": 0.7525,
    "x": 10.26618766784668,
    "y": 0.28849321603775024,
    "cluster_id": -1
  },
  {
    "feature_id": 74,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8127118150393168,
    "similarity_var": 0.0027806727204462175,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.31500000000000006,
    "total_score": 0.4383333333333333,
    "x": -5.898983955383301,
    "y": 16.00969696044922,
    "cluster_id": 10
  },
  {
    "feature_id": 75,
    "explanation_index": 0,
    "text": "Special characters, symbols, and keywords in programming languages and coding environments.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8998227119445801,
    "similarity_var": 0.00017540727370383516,
    "score_fuzz": 0.47,
    "score_detection": 0.5,
    "score_embedding": 0.4508,
    "total_score": 0.47359999999999997,
    "x": 9.449543952941895,
    "y": 7.803619861602783,
    "cluster_id": 6
  },
  {
    "feature_id": 75,
    "explanation_index": 1,
    "text": "Patterns involving code syntax, identifiers, and structural elements such as brackets, parentheses, and delimiters in programming contexts, often indicating variable names, function calls, or configuration settings.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8998227119445801,
    "similarity_var": 0.00017540727370383516,
    "score_fuzz": 0.47,
    "score_detection": 0.48,
    "score_embedding": 0.4375,
    "total_score": 0.46249999999999997,
    "x": 10.621564865112305,
    "y": 7.432705879211426,
    "cluster_id": 7
  },
  {
    "feature_id": 75,
    "explanation_index": 2,
    "text": "The highlighted fragments are consistently substrings of programming identifiers\u2014function names, variable names, class names, property names, constants, and similar tokens. They appear in a wide range of coding contexts, from method calls and assignments to string literals, comments, XML/HTML attributes, and URLs. The pattern shows that the model focuses on these meaningful code tokens rather than the surrounding syntax.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8998227119445801,
    "similarity_var": 0.00017540727370383516,
    "score_fuzz": 0.4,
    "score_detection": 0.5,
    "score_embedding": 0.40875,
    "total_score": 0.43625,
    "x": 14.941293716430664,
    "y": 7.221676349639893,
    "cluster_id": -1
  },
  {
    "feature_id": 77,
    "explanation_index": 0,
    "text": "The preposition \\\"for\\\" is used in various contexts, often indicating purpose, direction, or intended use, and is commonly found in phrases that express a relationship between entities, actions, or ideas.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9248228867848715,
    "similarity_var": 0.0002904930185023444,
    "score_fuzz": 0.95,
    "score_detection": 0.86,
    "score_embedding": 0.602,
    "total_score": 0.8039999999999999,
    "x": 11.692643165588379,
    "y": 0.1071866825222969,
    "cluster_id": 53
  },
  {
    "feature_id": 77,
    "explanation_index": 1,
    "text": "The preposition \\\"for\\\" is used to indicate purpose, intention, or benefit, often preceding a noun or noun phrase that specifies the recipient, goal, or reason.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9248228867848715,
    "similarity_var": 0.0002904930185023444,
    "score_fuzz": 0.94,
    "score_detection": 0.87,
    "score_embedding": 0.5325,
    "total_score": 0.7808333333333334,
    "x": 11.66557502746582,
    "y": 0.09361260384321213,
    "cluster_id": 53
  },
  {
    "feature_id": 77,
    "explanation_index": 2,
    "text": "The preposition \u201cfor\u201d signals purpose or target in the text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9248228867848715,
    "similarity_var": 0.0002904930185023444,
    "score_fuzz": 1.0,
    "score_detection": 0.85,
    "score_embedding": 0.57375,
    "total_score": 0.8079166666666667,
    "x": 11.648208618164062,
    "y": 0.05341768637299538,
    "cluster_id": 53
  },
  {
    "feature_id": 79,
    "explanation_index": 0,
    "text": "Verbs of perception, observation, or experience, often used to describe an action of gaining insight or awareness, frequently in the context of witnessing, seeing, or hearing something.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.862043023109436,
    "similarity_var": 0.003261759572758649,
    "score_fuzz": 0.77,
    "score_detection": 0.65,
    "score_embedding": 0.5024,
    "total_score": 0.6407999999999999,
    "x": 10.380809783935547,
    "y": -1.2779603004455566,
    "cluster_id": 23
  },
  {
    "feature_id": 79,
    "explanation_index": 1,
    "text": "Verbs related to perception or observation (e.g., see, witness, observe, imagine, hear, admire) are frequently activated when describing experiences, actions, or visual access to people, places, or processes.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.862043023109436,
    "similarity_var": 0.003261759572758649,
    "score_fuzz": 0.7789473684210526,
    "score_detection": 0.63,
    "score_embedding": 0.526875,
    "total_score": 0.6452741228070176,
    "x": 10.386868476867676,
    "y": -1.2760035991668701,
    "cluster_id": 23
  },
  {
    "feature_id": 79,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.862043023109436,
    "similarity_var": 0.003261759572758649,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.47187500000000004,
    "total_score": 0.49062500000000003,
    "x": -7.918924808502197,
    "y": 9.1412935256958,
    "cluster_id": 52
  },
  {
    "feature_id": 80,
    "explanation_index": 0,
    "text": "Words related to smoking or nicotine, often appearing in contexts of health, behavior, or addiction.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9101528525352478,
    "similarity_var": 0.00017209825462553377,
    "score_fuzz": 0.67,
    "score_detection": 0.48,
    "score_embedding": 0.29159999999999997,
    "total_score": 0.48053333333333326,
    "x": 7.8285908699035645,
    "y": 1.2247956991195679,
    "cluster_id": -1
  },
  {
    "feature_id": 80,
    "explanation_index": 1,
    "text": "The token \\\"smoking\\\" and its variants (e.g., \\\"cigarette\\\", \\\"cig\\\", \\\"Nic\\\") are frequently activated in contexts related to health, medical studies, and behavioral habits, often appearing in association with risk factors, treatments, or demographic data.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9101528525352478,
    "similarity_var": 0.00017209825462553377,
    "score_fuzz": 0.57,
    "score_detection": 0.48,
    "score_embedding": 0.29312499999999997,
    "total_score": 0.4477083333333332,
    "x": 9.986787796020508,
    "y": 3.135826587677002,
    "cluster_id": -1
  },
  {
    "feature_id": 80,
    "explanation_index": 2,
    "text": "The highlighted fragments are parts of tobacco\u2011related terms (nicotine, cigarette, smoking, cigar, etc.), indicating that the text is focused on smoking or nicotine use.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9101528525352478,
    "similarity_var": 0.00017209825462553377,
    "score_fuzz": 0.5,
    "score_detection": 0.325,
    "score_embedding": 0.255,
    "total_score": 0.36000000000000004,
    "x": 15.595019340515137,
    "y": 7.2710418701171875,
    "cluster_id": 19
  },
  {
    "feature_id": 81,
    "explanation_index": 0,
    "text": "Prefixes or suffixes of words, often indicating a change in meaning or grammatical function, or function words that provide context or connection between clauses.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9034584760665894,
    "similarity_var": 0.00010853120231738937,
    "score_fuzz": 0.54,
    "score_detection": 0.43,
    "score_embedding": 0.3,
    "total_score": 0.42333333333333334,
    "x": 8.3117094039917,
    "y": 2.133704662322998,
    "cluster_id": 44
  },
  {
    "feature_id": 81,
    "explanation_index": 1,
    "text": "High activation on function words (like \\\"the\\\", \\\"of\\\", \\\"and\\\", \\\"in\\\") and suffixes (like \\\"er\\\", \\\"ing\\\", \\\"ly\\\") when they appear in contextually significant phrases, often marking grammatical structure, comparison, possession, or modification.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9034584760665894,
    "similarity_var": 0.00010853120231738937,
    "score_fuzz": 0.55,
    "score_detection": 0.48,
    "score_embedding": 0.405,
    "total_score": 0.47833333333333333,
    "x": 10.371726989746094,
    "y": 2.825988292694092,
    "cluster_id": -1
  },
  {
    "feature_id": 81,
    "explanation_index": 2,
    "text": "The highlighted tokens are primarily function words and morphological suffixes that signal grammatical relations and form idiomatic or collocational phrases.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9034584760665894,
    "similarity_var": 0.00010853120231738937,
    "score_fuzz": 0.475,
    "score_detection": 0.5,
    "score_embedding": 0.43687499999999996,
    "total_score": 0.470625,
    "x": 13.870859146118164,
    "y": 3.5593535900115967,
    "cluster_id": -1
  },
  {
    "feature_id": 82,
    "explanation_index": 0,
    "text": "Past tense or past participle verb forms, often in formal or technical contexts, describing actions, states, or conditions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.840633233388265,
    "similarity_var": 0.000909620090805024,
    "score_fuzz": 0.7222222222222222,
    "score_detection": 0.47,
    "score_embedding": 0.7968000000000001,
    "total_score": 0.6630074074074074,
    "x": 10.44304370880127,
    "y": -0.7445178627967834,
    "cluster_id": 14
  },
  {
    "feature_id": 82,
    "explanation_index": 1,
    "text": "Nouns and adjectives denoting abstract or physical states, relationships, or conditions, often describing attributes, actions, or qualities in scientific, technical, or evaluative contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.840633233388265,
    "similarity_var": 0.000909620090805024,
    "score_fuzz": 0.6842105263157895,
    "score_detection": 0.35,
    "score_embedding": 0.6925000000000001,
    "total_score": 0.5755701754385966,
    "x": 8.456425666809082,
    "y": 0.8614295721054077,
    "cluster_id": 54
  },
  {
    "feature_id": 82,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core lexical items that carry the main semantic content of each phrase\u2014typically nouns, adjectives, verbs, or key suffixes\u2014while surrounding function words and punctuation are not marked. This pattern shows that the model focuses on the substantive words that define the meaning of the sentence.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.840633233388265,
    "similarity_var": 0.000909620090805024,
    "score_fuzz": 0.775,
    "score_detection": 0.4,
    "score_embedding": 0.755,
    "total_score": 0.6433333333333334,
    "x": 15.352020263671875,
    "y": 4.19380521774292,
    "cluster_id": 22
  },
  {
    "feature_id": 84,
    "explanation_index": 0,
    "text": "The word \\\"with\\\" is often used as a preposition to indicate accompaniment, association, or relationship between entities, and is commonly found in various contexts, including phrases, sentences, and idiomatic expressions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9239914019902548,
    "similarity_var": 0.0004752203727546897,
    "score_fuzz": 0.96,
    "score_detection": 0.97,
    "score_embedding": 0.6244000000000001,
    "total_score": 0.8514666666666667,
    "x": 12.059781074523926,
    "y": 0.2926400303840637,
    "cluster_id": -1
  },
  {
    "feature_id": 84,
    "explanation_index": 1,
    "text": "The word \\\"with\\\" frequently appears in contexts indicating accompaniment, association, or instrumental relationship, often preceding a noun or phrase that specifies the means, partner, or context of an action.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9239914019902548,
    "similarity_var": 0.0004752203727546897,
    "score_fuzz": 0.97,
    "score_detection": 0.95,
    "score_embedding": 0.6075,
    "total_score": 0.8424999999999999,
    "x": 11.964862823486328,
    "y": 0.6116785407066345,
    "cluster_id": -1
  },
  {
    "feature_id": 84,
    "explanation_index": 2,
    "text": "The pattern: the token \\\"with\\\" appears in many contexts.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9239914019902548,
    "similarity_var": 0.0004752203727546897,
    "score_fuzz": 0.925,
    "score_detection": 0.95,
    "score_embedding": 0.556875,
    "total_score": 0.8106249999999999,
    "x": 11.609081268310547,
    "y": 2.604618549346924,
    "cluster_id": -1
  },
  {
    "feature_id": 86,
    "explanation_index": 0,
    "text": "Specialized terms, abbreviations, and proper nouns, often denoting technical, scientific, or formal concepts, names, or titles.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8925106326738993,
    "similarity_var": 4.870902482265491e-05,
    "score_fuzz": 0.62,
    "score_detection": 0.42,
    "score_embedding": 0.5635999999999999,
    "total_score": 0.5345333333333333,
    "x": 7.615400791168213,
    "y": 0.614235520362854,
    "cluster_id": -1
  },
  {
    "feature_id": 86,
    "explanation_index": 1,
    "text": "Common patterns include abbreviations, technical terms, and compound identifiers in code or academic contexts, often involving capitalized or hyphenated segments, frequently appearing in programming, scientific notation, or formal documentation.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8925106326738993,
    "similarity_var": 4.870902482265491e-05,
    "score_fuzz": 0.46,
    "score_detection": 0.35,
    "score_embedding": 0.573125,
    "total_score": 0.46104166666666674,
    "x": 10.441731452941895,
    "y": 6.5874786376953125,
    "cluster_id": -1
  },
  {
    "feature_id": 86,
    "explanation_index": 2,
    "text": "The highlighted tokens are technical identifiers, placeholders, or proper nouns that appear in code, templates, or formal references, often capitalized or containing special characters, and are not ordinary words.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8925106326738993,
    "similarity_var": 4.870902482265491e-05,
    "score_fuzz": 0.45,
    "score_detection": 0.5,
    "score_embedding": 0.41000000000000003,
    "total_score": 0.4533333333333333,
    "x": 13.876518249511719,
    "y": 4.728921413421631,
    "cluster_id": -1
  },
  {
    "feature_id": 87,
    "explanation_index": 0,
    "text": "Prices, monetary values, and numerical data, often denoted by currency symbols or decimal points, and sometimes used in comparisons or to describe costs and values.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9237136642138163,
    "similarity_var": 9.556095285824364e-05,
    "score_fuzz": 0.49,
    "score_detection": 0.39,
    "score_embedding": 0.3012,
    "total_score": 0.3937333333333333,
    "x": 6.887563228607178,
    "y": 8.70667839050293,
    "cluster_id": 29
  },
  {
    "feature_id": 87,
    "explanation_index": 1,
    "text": "Patterns involving currency symbols, numbers, and separators in pricing or monetary values, often appearing in contexts of cost, pricing, or financial figures.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9237136642138163,
    "similarity_var": 9.556095285824364e-05,
    "score_fuzz": 0.6,
    "score_detection": 0.39,
    "score_embedding": 0.275,
    "total_score": 0.4216666666666667,
    "x": 7.162862777709961,
    "y": 8.349989891052246,
    "cluster_id": -1
  },
  {
    "feature_id": 87,
    "explanation_index": 2,
    "text": "Tokens that denote monetary amounts, currency symbols, numeric values, and price ranges, often combined with slashes or periods.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9237136642138163,
    "similarity_var": 9.556095285824364e-05,
    "score_fuzz": 0.5,
    "score_detection": 0.425,
    "score_embedding": 0.3293750000000001,
    "total_score": 0.418125,
    "x": 10.33138656616211,
    "y": 5.590406894683838,
    "cluster_id": -1
  },
  {
    "feature_id": 88,
    "explanation_index": 0,
    "text": "Tokens that are often nouns, abbreviations, or words that are part of a larger phrase or sentence, sometimes indicating a proper noun, a scientific term, or a specific concept.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8749314149220785,
    "similarity_var": 0.0011577678320556907,
    "score_fuzz": 0.7368421052631579,
    "score_detection": 0.77,
    "score_embedding": 0.5188,
    "total_score": 0.6752140350877194,
    "x": 10.213644981384277,
    "y": 4.356779098510742,
    "cluster_id": 1
  },
  {
    "feature_id": 88,
    "explanation_index": 1,
    "text": "Partial word tokens that are part of compound or multi-word terms, often appearing in contexts involving biological, scientific, or technical terminology, where the full word is split across tokens.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8749314149220785,
    "similarity_var": 0.0011577678320556907,
    "score_fuzz": 0.6526315789473685,
    "score_detection": 0.55,
    "score_embedding": 0.6456249999999999,
    "total_score": 0.6160855263157895,
    "x": 7.214365005493164,
    "y": 2.832366704940796,
    "cluster_id": 15
  },
  {
    "feature_id": 88,
    "explanation_index": 2,
    "text": "The highlighted tokens are the semantic core of a phrase\u2014usually a noun, a key modifier in an idiom, or a suffix that signals comparison\u2014so the model activates the words that carry the main meaning of the collocation or named entity.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8749314149220785,
    "similarity_var": 0.0011577678320556907,
    "score_fuzz": 0.7,
    "score_detection": 0.575,
    "score_embedding": 0.60125,
    "total_score": 0.6254166666666666,
    "x": 15.089314460754395,
    "y": 4.774369716644287,
    "cluster_id": 55
  },
  {
    "feature_id": 89,
    "explanation_index": 0,
    "text": "Terms related to medical and biological concepts, including diseases, conditions, tests, and biological processes, often represented by technical or scientific names.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9186004598935446,
    "similarity_var": 1.4290768529039926e-05,
    "score_fuzz": 0.64,
    "score_detection": 0.5,
    "score_embedding": 0.5915999999999999,
    "total_score": 0.5772,
    "x": 7.307424068450928,
    "y": 1.2786526679992676,
    "cluster_id": 25
  },
  {
    "feature_id": 89,
    "explanation_index": 1,
    "text": "Medical terminology involving anatomical locations, biological markers, or clinical conditions, often appearing as compound terms or abbreviations with high activation in biomedical contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9186004598935446,
    "similarity_var": 1.4290768529039926e-05,
    "score_fuzz": 0.66,
    "score_detection": 0.5,
    "score_embedding": 0.553125,
    "total_score": 0.5710416666666668,
    "x": 7.36465311050415,
    "y": 1.5034514665603638,
    "cluster_id": -1
  },
  {
    "feature_id": 89,
    "explanation_index": 2,
    "text": "The highlighted tokens are domain\u2011specific medical terms\u2014biomarkers, diseases, lab tests, anatomical parts, and abbreviations\u2014typically nouns or adjectives that appear in clinical or research contexts.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9186004598935446,
    "similarity_var": 1.4290768529039926e-05,
    "score_fuzz": 0.675,
    "score_detection": 0.525,
    "score_embedding": 0.5449999999999999,
    "total_score": 0.5816666666666667,
    "x": 13.690433502197266,
    "y": 4.4584059715271,
    "cluster_id": -1
  },
  {
    "feature_id": 90,
    "explanation_index": 0,
    "text": "Nouns representing objects, concepts, or entities, often in a specific context or domain.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9044005076090494,
    "similarity_var": 0.00040733132821991883,
    "score_fuzz": 0.78,
    "score_detection": 0.68,
    "score_embedding": 0.1508,
    "total_score": 0.5369333333333334,
    "x": 8.231685638427734,
    "y": 0.21436245739459991,
    "cluster_id": 24
  },
  {
    "feature_id": 90,
    "explanation_index": 1,
    "text": "Nouns or noun phrases representing physical locations, objects, or abstract concepts that are central to the context, often appearing in technical, descriptive, or structured text.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9044005076090494,
    "similarity_var": 0.00040733132821991883,
    "score_fuzz": 0.77,
    "score_detection": 0.56,
    "score_embedding": 0.134375,
    "total_score": 0.488125,
    "x": 8.483778953552246,
    "y": 0.0961422249674797,
    "cluster_id": 24
  },
  {
    "feature_id": 90,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core content words\u2014mostly nouns or noun phrases\u2014that carry the main semantic load of each sentence, often serving as subjects, objects, or key concepts, and may appear as single words or multi\u2011word expressions.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9044005076090494,
    "similarity_var": 0.00040733132821991883,
    "score_fuzz": 0.825,
    "score_detection": 0.775,
    "score_embedding": 0.18437499999999998,
    "total_score": 0.5947916666666667,
    "x": 15.426371574401855,
    "y": 4.0163726806640625,
    "cluster_id": 22
  },
  {
    "feature_id": 91,
    "explanation_index": 0,
    "text": "Nouns and phrases related to food, often describing dishes or ingredients, and sometimes including conjunctions or prepositions connecting them.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9099465608596802,
    "similarity_var": 2.3279121116104307e-05,
    "score_fuzz": 0.53,
    "score_detection": 0.44,
    "score_embedding": 0.4052,
    "total_score": 0.4584,
    "x": 8.84851360321045,
    "y": 0.2736682891845703,
    "cluster_id": -1
  },
  {
    "feature_id": 91,
    "explanation_index": 1,
    "text": "The word \\\"and\\\" frequently appears in lists of food items or ingredients, often connecting two or more components of a dish, particularly in culinary descriptions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9099465608596802,
    "similarity_var": 2.3279121116104307e-05,
    "score_fuzz": 0.41,
    "score_detection": 0.43,
    "score_embedding": 0.40249999999999997,
    "total_score": 0.4141666666666666,
    "x": 11.798382759094238,
    "y": 2.2591071128845215,
    "cluster_id": 38
  },
  {
    "feature_id": 91,
    "explanation_index": 2,
    "text": "The highlighted tokens are mainly food\u2011related nouns and cooking\u2011method words (e.g., \u201cbeef,\u201d \u201cchips,\u201d \u201clobster,\u201d \u201csteak,\u201d \u201csalmon,\u201d \u201cseafood,\u201d \u201cbaked,\u201d \u201croasted,\u201d \u201cgrilled\u201d) and the linking words that connect them (\u201cand,\u201d \u201cwith,\u201d \u201cin\u201d). These form compound dish names or ingredient lists, so the pattern is that important tokens are the building blocks of culinary descriptions.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9099465608596802,
    "similarity_var": 2.3279121116104307e-05,
    "score_fuzz": 0.55,
    "score_detection": 0.475,
    "score_embedding": 0.44062500000000004,
    "total_score": 0.48854166666666665,
    "x": 14.961973190307617,
    "y": 4.1894731521606445,
    "cluster_id": 22
  },
  {
    "feature_id": 92,
    "explanation_index": 0,
    "text": "Punctuation marks, often used to denote special formatting, mathematical expressions, or programming syntax, and sometimes used in conjunction with other special characters.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.910734752813975,
    "similarity_var": 0.0008125881156628464,
    "score_fuzz": 0.5157894736842106,
    "score_detection": 0.34,
    "score_embedding": 0.47759999999999997,
    "total_score": 0.4444631578947369,
    "x": 8.438604354858398,
    "y": 7.0754313468933105,
    "cluster_id": 37
  },
  {
    "feature_id": 92,
    "explanation_index": 1,
    "text": "Special characters and punctuation marks used in formatting, markup, or encoding, often appearing in structured text, code, or mathematical notation.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.910734752813975,
    "similarity_var": 0.0008125881156628464,
    "score_fuzz": 0.5,
    "score_detection": 0.35,
    "score_embedding": 0.449375,
    "total_score": 0.433125,
    "x": 8.734216690063477,
    "y": 7.307923316955566,
    "cluster_id": 4
  },
  {
    "feature_id": 92,
    "explanation_index": 2,
    "text": "The highlighted tokens are usually punctuation, short words, or symbols that act as delimiters or structural markers in the text, often appearing in code, markup, or idiomatic expressions.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.910734752813975,
    "similarity_var": 0.0008125881156628464,
    "score_fuzz": 0.575,
    "score_detection": 0.325,
    "score_embedding": 0.364375,
    "total_score": 0.42145833333333327,
    "x": 13.867464065551758,
    "y": 5.407021522521973,
    "cluster_id": 62
  },
  {
    "feature_id": 93,
    "explanation_index": 0,
    "text": "Conjunctions connecting words, phrases, or clauses in a sentence, often indicating addition, contrast, or choice.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8625195026397705,
    "similarity_var": 0.00015177777272394147,
    "score_fuzz": 0.93,
    "score_detection": 0.7,
    "score_embedding": 0.3418,
    "total_score": 0.6572666666666667,
    "x": 12.018741607666016,
    "y": 0.4405311644077301,
    "cluster_id": -1
  },
  {
    "feature_id": 93,
    "explanation_index": 1,
    "text": "The conjunctions \\\"y\\\", \\\"et\\\", \\\"und\\\", \\\"e\\\", \\\"and\\\", \\\"ou\\\", \\\"o\\\", \\\"a\\\", \\\"i\\\", \\\"\u00e9s\\\", \\\"og\\\", \\\"ja\\\", \\\"to\\\", \\\"\u4e0e\\\", \\\"\u3068\\\", \\\"\u0438\\\", \\\"\u0438\u043b\u0438\\\", \\\"or\\\", \\\"nor\\\", \\\"but\\\", \\\"yet\\\", \\\"still\\\", \\\"however\\\", \\\"nevertheless\\\", \\\"nonetheless\\\", \\\"though\\\", \\\"although\\\", \\\"despite\\\", \\\"in spite of\\\", \\\"even though\\\", \\\"while\\\", \\\"whereas\\\", \\\"where\\\", \\\"when\\\", \\\"if\\\", \\\"unless\\\", \\\"provided that\\\", \\\"as long as\\\", \\\"so that\\\", \\\"in order that\\\", \\\"because\\\", \\\"since\\\", \\\"as\\\", \\\"due to\\\", \\\"owing to\\\", \\\"on account of\\\", \\\"for\\\", \\\"so\\\", \\\"therefore\\\", \\\"thus\\\", \\\"hence\\\", \\\"accordingly\\\", \\\"consequently\\\", \\\"then\\\", \\\"next\\\", \\\"finally\\\", \\\"meanwhile\\\", \\\"subsequently\\\", \\\"afterward\\\", \\\"later\\\", \\\"soon\\\", \\\"immediately\\\", \\\"promptly\\\", \\\"quickly\\\", \\\"rapidly\\\", \\\"swiftly\\\", \\\"fast\\\", \\\"quick\\\", \\\"fast-paced\\\", \\\"hurried\\\", \\\"rushed\\\", \\\"expeditious\\\", \\\"prompt\\\", \\\"timely\\\", \\\"on time\\\", \\\"late\\\", \\\"delayed\\\", \\\"behind schedule\\\", \\\"ahead of schedule\\\", \\\"early\\\", \\\"premature\\\", \\\"prematurely\\\", \\\"in advance\\\", \\\"ahead\\\", \\\"forward\\\", \\\"forward-looking\\\", \\\"proactive\\\", \\\"anticipatory\\\", \\\"predictive\\\", \\\"forecasting\\\", \\\"projecting\\\", \\\"planning\\\", \\\"strategizing\\\", \\\"organizing\\\", \\\"coordinating\\\", \\\"managing\\\", \\\"leading\\\", \\\"directing\\\", \\\"governing\\\", \\\"administering\\\", \\\"regulating\\\", \\\"controlling\\\", \\\"monitoring\\\", \\\"evaluating\\\", \\\"assessing\\\", \\\"measuring\\\", \\\"quantifying\\\", \\\"qualifying\\\", \\\"describing\\\", \\\"explaining\\\", \\\"clarifying\\\", \\\"elucidating\\\", \\\"interpreting\\\", \\\"analyzing\\\", \\\"examining\\\", \\\"investigating\\\", \\\"studying\\\", \\\"researching\\\", \\\"observing\\\", \\\"noticing\\\", \\\"perceiving\\\", \\\"sensing\\\", \\\"feeling\\\", \\\"experiencing\\\", \\\"living\\\", \\\"being\\\", \\\"existing\\\", \\\"occurring\\\", \\\"happening\\\", \\\"taking place\\\", \\\"coming about",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8625195026397705,
    "similarity_var": 0.00015177777272394147,
    "score_fuzz": 0.94,
    "score_detection": 0.76,
    "score_embedding": 0.41125,
    "total_score": 0.70375,
    "x": 11.094061851501465,
    "y": 3.0532472133636475,
    "cluster_id": -1
  },
  {
    "feature_id": 93,
    "explanation_index": 2,
    "text": "the pattern is that the important tokens are conjunctions that mean \\\"and\\\" or \\\"or\\\" in various languages.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8625195026397705,
    "similarity_var": 0.00015177777272394147,
    "score_fuzz": 0.975,
    "score_detection": 0.875,
    "score_embedding": 0.453125,
    "total_score": 0.7677083333333333,
    "x": 11.37040901184082,
    "y": 4.053689002990723,
    "cluster_id": -1
  },
  {
    "feature_id": 95,
    "explanation_index": 0,
    "text": "Function words and nouns that are part of common verb phrases, idiomatic expressions, or descriptive phrases, often indicating a relationship, action, or state.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8222408493359884,
    "similarity_var": 0.0008977479799822971,
    "score_fuzz": 0.44,
    "score_detection": 0.44,
    "score_embedding": 0.6556,
    "total_score": 0.5118666666666667,
    "x": 10.650372505187988,
    "y": 1.1776059865951538,
    "cluster_id": 26
  },
  {
    "feature_id": 95,
    "explanation_index": 1,
    "text": "Common pronouns, determiners, and auxiliary verbs that function as grammatical connectors or modals, often appearing in contexts involving conditionals, possibilities, or references to previously mentioned entities.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8222408493359884,
    "similarity_var": 0.0008977479799822971,
    "score_fuzz": 0.44,
    "score_detection": 0.36,
    "score_embedding": 0.5637500000000001,
    "total_score": 0.45458333333333334,
    "x": 11.249105453491211,
    "y": 1.0001591444015503,
    "cluster_id": -1
  },
  {
    "feature_id": 95,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8222408493359884,
    "similarity_var": 0.0008977479799822971,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.6587500000000001,
    "total_score": 0.5529166666666666,
    "x": -5.93327522277832,
    "y": 15.975439071655273,
    "cluster_id": 10
  },
  {
    "feature_id": 96,
    "explanation_index": 0,
    "text": "Code snippets in various programming languages, often containing function or method definitions, conditional statements, loops, and variable declarations, with a focus on syntax and structure.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8497005502382914,
    "similarity_var": 0.0006743007614184016,
    "score_fuzz": 0.32,
    "score_detection": 0.36,
    "score_embedding": 0.5888,
    "total_score": 0.42293333333333333,
    "x": 11.196749687194824,
    "y": 8.700876235961914,
    "cluster_id": 17
  },
  {
    "feature_id": 96,
    "explanation_index": 1,
    "text": "The newline character (\\\"\\n\\\") frequently appears in code and markup contexts, often separating syntactic elements such as statements, blocks, or tags, and is especially prominent around structural or syntactic boundaries like braces, parentheses, and tags.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8497005502382914,
    "similarity_var": 0.0006743007614184016,
    "score_fuzz": 0.58,
    "score_detection": 0.44,
    "score_embedding": 0.77125,
    "total_score": 0.5970833333333333,
    "x": 9.701383590698242,
    "y": 6.54544734954834,
    "cluster_id": 87
  },
  {
    "feature_id": 96,
    "explanation_index": 2,
    "text": "The delimiters mark code fragments that are empty or consist solely of whitespace, so the highlighted tokens are typically space or newline characters.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8497005502382914,
    "similarity_var": 0.0006743007614184016,
    "score_fuzz": 0.85,
    "score_detection": 0.375,
    "score_embedding": 0.754375,
    "total_score": 0.6597916666666667,
    "x": 13.611966133117676,
    "y": 6.140024185180664,
    "cluster_id": -1
  },
  {
    "feature_id": 97,
    "explanation_index": 0,
    "text": "Accessing properties or methods of objects using dot notation or arrow notation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9071271419525146,
    "similarity_var": 0.000780588422503096,
    "score_fuzz": 0.6947368421052632,
    "score_detection": 0.53,
    "score_embedding": 0.33440000000000003,
    "total_score": 0.5197122807017545,
    "x": 10.361821174621582,
    "y": 8.06926155090332,
    "cluster_id": -1
  },
  {
    "feature_id": 97,
    "explanation_index": 1,
    "text": "The dot (.) and arrow (->) operators are used to access methods or properties of objects or classes in programming languages, often indicating method chaining or object-oriented syntax.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9071271419525146,
    "similarity_var": 0.000780588422503096,
    "score_fuzz": 0.75,
    "score_detection": 0.57,
    "score_embedding": 0.37750000000000006,
    "total_score": 0.5658333333333333,
    "x": 10.317801475524902,
    "y": 8.058014869689941,
    "cluster_id": -1
  },
  {
    "feature_id": 97,
    "explanation_index": 2,
    "text": "The highlighted tokens are the syntax elements that connect identifiers in code, such as the dot operator, arrow operator, parentheses, and other punctuation that indicate method or property access, function calls, or object references.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9071271419525146,
    "similarity_var": 0.000780588422503096,
    "score_fuzz": 0.6,
    "score_detection": 0.55,
    "score_embedding": 0.295,
    "total_score": 0.48166666666666663,
    "x": 13.769338607788086,
    "y": 6.528750419616699,
    "cluster_id": 8
  },
  {
    "feature_id": 98,
    "explanation_index": 0,
    "text": "Adjectives or adverbs describing a state of being, often related to availability, existence, or suitability, and sometimes indicating a condition or status.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.918194035689036,
    "similarity_var": 9.936639501341282e-06,
    "score_fuzz": 0.87,
    "score_detection": 0.57,
    "score_embedding": 0.48400000000000004,
    "total_score": 0.6413333333333333,
    "x": 8.973977088928223,
    "y": 1.0630277395248413,
    "cluster_id": -1
  },
  {
    "feature_id": 98,
    "explanation_index": 1,
    "text": "Words indicating availability, accessibility, or presence, often used in contexts describing access to resources, options, or conditions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.918194035689036,
    "similarity_var": 9.936639501341282e-06,
    "score_fuzz": 0.8421052631578947,
    "score_detection": 0.36,
    "score_embedding": 0.478125,
    "total_score": 0.5600767543859648,
    "x": 9.034209251403809,
    "y": 0.8775318264961243,
    "cluster_id": -1
  },
  {
    "feature_id": 98,
    "explanation_index": 2,
    "text": "The highlighted words are common adjectives or nouns that frequently signal availability, distribution, eligibility, or status in formal or descriptive contexts.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.918194035689036,
    "similarity_var": 9.936639501341282e-06,
    "score_fuzz": 0.925,
    "score_detection": 0.475,
    "score_embedding": 0.566875,
    "total_score": 0.655625,
    "x": 16.70119857788086,
    "y": 3.5465571880340576,
    "cluster_id": 20
  },
  {
    "feature_id": 101,
    "explanation_index": 0,
    "text": "Plural nouns or words with plural suffixes, often representing a collection or multiple instances of something.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8882794976234436,
    "similarity_var": 0.0004996012088748595,
    "score_fuzz": 0.83,
    "score_detection": 0.33,
    "score_embedding": 0.27159999999999995,
    "total_score": 0.4772,
    "x": 8.187764167785645,
    "y": 0.26057323813438416,
    "cluster_id": 24
  },
  {
    "feature_id": 101,
    "explanation_index": 1,
    "text": "Plural nouns or noun phrases ending in a suffix like -s, -es, or -ies, often referring to abstract or concrete entities, frequently appearing in contexts involving systems, categories, or measurable outcomes.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8882794976234436,
    "similarity_var": 0.0004996012088748595,
    "score_fuzz": 0.82,
    "score_detection": 0.36,
    "score_embedding": 0.285625,
    "total_score": 0.48854166666666665,
    "x": 8.148810386657715,
    "y": 0.36975792050361633,
    "cluster_id": 12
  },
  {
    "feature_id": 101,
    "explanation_index": 2,
    "text": "The highlighted fragments are consistently the final morphemes of words\u2014mostly plural or other inflectional endings\u2014suggesting the model is attuned to morphological suffixes that signal grammatical function.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8882794976234436,
    "similarity_var": 0.0004996012088748595,
    "score_fuzz": 0.75,
    "score_detection": 0.35,
    "score_embedding": 0.37124999999999997,
    "total_score": 0.49041666666666667,
    "x": 15.698686599731445,
    "y": 7.085657119750977,
    "cluster_id": 19
  },
  {
    "feature_id": 103,
    "explanation_index": 0,
    "text": "A variety of words and word parts, often including proper nouns, prefixes, and suffixes, that appear to be randomly selected from a wide range of texts, including technical, scientific, and everyday language.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8627408544222513,
    "similarity_var": 0.00034532132668690317,
    "score_fuzz": 0.6210526315789474,
    "score_detection": 0.59,
    "score_embedding": 0.2844,
    "total_score": 0.4984842105263158,
    "x": 8.243468284606934,
    "y": 1.820451259613037,
    "cluster_id": -1
  },
  {
    "feature_id": 103,
    "explanation_index": 1,
    "text": "Substrings of proper nouns or technical terms, often appearing as partial or fragmented forms of names, acronyms, or specialized vocabulary, with activation patterns indicating recognition of morphological components within longer identifiers.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8627408544222513,
    "similarity_var": 0.00034532132668690317,
    "score_fuzz": 0.56,
    "score_detection": 0.43157894736842106,
    "score_embedding": 0.27249999999999996,
    "total_score": 0.42135964912280705,
    "x": 7.9041948318481445,
    "y": 2.8005120754241943,
    "cluster_id": -1
  },
  {
    "feature_id": 103,
    "explanation_index": 2,
    "text": "the tokens are substrings of longer words, like \\\"Pet\\\" is part of \\\"Petrov\\\", \\\"Petrovich\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\", \\\"Pet\\\".",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8627408544222513,
    "similarity_var": 0.00034532132668690317,
    "score_fuzz": 0.575,
    "score_detection": 0.7,
    "score_embedding": 0.35500000000000004,
    "total_score": 0.5433333333333333,
    "x": 11.001201629638672,
    "y": 3.3652212619781494,
    "cluster_id": 27
  },
  {
    "feature_id": 104,
    "explanation_index": 0,
    "text": "Nouns representing concepts, entities, or objects, often in formal or technical contexts, including mathematical, scientific, and legal terminology.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8376826047897339,
    "similarity_var": 0.0005350332977679765,
    "score_fuzz": 0.7368421052631579,
    "score_detection": 0.5789473684210527,
    "score_embedding": 0.44439999999999996,
    "total_score": 0.5867298245614035,
    "x": 8.006994247436523,
    "y": 0.4695485532283783,
    "cluster_id": 12
  },
  {
    "feature_id": 104,
    "explanation_index": 1,
    "text": "The term \\\"factor\\\" and its variants (e.g., \\\"factors\\\", \\\"factorial\\\", \\\"fractional\\\") are frequently activated in mathematical and technical contexts involving divisibility, decomposition, or quantitative properties, often appearing in questions or statements about numbers, equations, or system parameters.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8376826047897339,
    "similarity_var": 0.0005350332977679765,
    "score_fuzz": 0.65,
    "score_detection": 0.631578947368421,
    "score_embedding": 0.6137500000000001,
    "total_score": 0.6317763157894737,
    "x": 9.077112197875977,
    "y": 7.811725616455078,
    "cluster_id": -1
  },
  {
    "feature_id": 104,
    "explanation_index": 2,
    "text": "The pattern seems to be that the important tokens are nouns or noun phrases that are often part of a larger phrase, sometimes with preceding words like \\\"the\\\", \\\"a\\\", etc.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8376826047897339,
    "similarity_var": 0.0005350332977679765,
    "score_fuzz": 0.85,
    "score_detection": 0.75,
    "score_embedding": 0.315625,
    "total_score": 0.6385416666666667,
    "x": 11.364513397216797,
    "y": 4.351436138153076,
    "cluster_id": 3
  },
  {
    "feature_id": 105,
    "explanation_index": 0,
    "text": "Special characters and symbols used in various contexts such as programming, mathematics, and formatting, often serving as operators, delimiters, or indicators of specific functions or relationships.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.897229810555776,
    "similarity_var": 0.00032884891033151895,
    "score_fuzz": 0.64,
    "score_detection": 0.55,
    "score_embedding": 0.6892,
    "total_score": 0.6264,
    "x": 9.192716598510742,
    "y": 7.712475776672363,
    "cluster_id": -1
  },
  {
    "feature_id": 105,
    "explanation_index": 1,
    "text": "Specialized tokens or symbols (like underscores, hyphens, angle brackets, or punctuation) used to denote technical constructs, identifiers, or formatting in code, markup, or scientific notation.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.897229810555776,
    "similarity_var": 0.00032884891033151895,
    "score_fuzz": 0.57,
    "score_detection": 0.5,
    "score_embedding": 0.730625,
    "total_score": 0.6002083333333332,
    "x": 10.765439987182617,
    "y": 6.034961223602295,
    "cluster_id": 18
  },
  {
    "feature_id": 105,
    "explanation_index": 2,
    "text": "The highlighted fragments are consistently short sub\u2011tokens that sit at the edges of larger identifiers or words\u2014underscores, colons, arrows, or keyword fragments such as \u201cIF\u201d or \u201cBundle.\u201d They function as syntactic or semantic delimiters, marking the start or end of a compound token or a special construct in code or text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.897229810555776,
    "similarity_var": 0.00032884891033151895,
    "score_fuzz": 0.625,
    "score_detection": 0.625,
    "score_embedding": 0.74,
    "total_score": 0.6633333333333333,
    "x": 15.332176208496094,
    "y": 7.237146854400635,
    "cluster_id": 56
  },
  {
    "feature_id": 106,
    "explanation_index": 0,
    "text": "Verbs or nouns related to sharing, possession, or commonality, often in the context of social interactions, personal relationships, or collective ownership.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8888346354166666,
    "similarity_var": 0.00035245597042493025,
    "score_fuzz": 0.76,
    "score_detection": 0.68,
    "score_embedding": 0.6576,
    "total_score": 0.6991999999999999,
    "x": 10.443232536315918,
    "y": -0.700486421585083,
    "cluster_id": 14
  },
  {
    "feature_id": 106,
    "explanation_index": 1,
    "text": "The word \\\"share\\\" and its variants (e.g., shared, sharing) are frequently activated in contexts involving distribution, collaboration, or common use of resources, often in relation to digital content, data, or social interactions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8888346354166666,
    "similarity_var": 0.00035245597042493025,
    "score_fuzz": 0.69,
    "score_detection": 0.68,
    "score_embedding": 0.71875,
    "total_score": 0.69625,
    "x": 10.032980918884277,
    "y": 1.5795137882232666,
    "cluster_id": -1
  },
  {
    "feature_id": 106,
    "explanation_index": 2,
    "text": "The activations repeatedly flag the word \u201cshare\u201d and its morphological variants (e.g., \u201cshared,\u201d \u201csharing,\u201d \u201cshare a,\u201d \u201cshare an,\u201d \u201cshare the\u201d), often coupled with articles or prepositions, indicating that the model consistently focuses on the concept of sharing across varied contexts.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8888346354166666,
    "similarity_var": 0.00035245597042493025,
    "score_fuzz": 0.75,
    "score_detection": 0.725,
    "score_embedding": 0.673125,
    "total_score": 0.7160416666666668,
    "x": 10.056853294372559,
    "y": 1.533471941947937,
    "cluster_id": -1
  },
  {
    "feature_id": 107,
    "explanation_index": 0,
    "text": "Prepositions and articles, often preceding nouns, especially those referring to geographical locations, historical periods, or social classes.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8400861422220866,
    "similarity_var": 0.0016686481003260506,
    "score_fuzz": 0.45,
    "score_detection": 0.43,
    "score_embedding": 0.6432,
    "total_score": 0.5077333333333334,
    "x": 12.731008529663086,
    "y": 0.1671377420425415,
    "cluster_id": 57
  },
  {
    "feature_id": 107,
    "explanation_index": 1,
    "text": "Common use of the word \\\"the\\\" preceding nouns in historical, geographical, or cultural contexts, often in compound terms or descriptive phrases.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8400861422220866,
    "similarity_var": 0.0016686481003260506,
    "score_fuzz": 0.48,
    "score_detection": 0.45,
    "score_embedding": 0.669375,
    "total_score": 0.533125,
    "x": 12.666605949401855,
    "y": 0.6473238468170166,
    "cluster_id": 34
  },
  {
    "feature_id": 107,
    "explanation_index": 2,
    "text": "the patterns in the examples.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8400861422220866,
    "similarity_var": 0.0016686481003260506,
    "score_fuzz": 0.475,
    "score_detection": 0.35,
    "score_embedding": 0.73125,
    "total_score": 0.5187499999999999,
    "x": 5.19473123550415,
    "y": 9.922369003295898,
    "cluster_id": 58
  },
  {
    "feature_id": 108,
    "explanation_index": 0,
    "text": "Technical and scientific terms, often nouns or adjectives, related to medical and biological concepts, including measurements, levels, and expressions, as well as statistical and analytical terms.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8818868597348531,
    "similarity_var": 0.0003441870973980422,
    "score_fuzz": 0.63,
    "score_detection": 0.49,
    "score_embedding": 0.404,
    "total_score": 0.508,
    "x": 7.4085798263549805,
    "y": 1.126640796661377,
    "cluster_id": 25
  },
  {
    "feature_id": 108,
    "explanation_index": 1,
    "text": "Key medical and statistical terms related to clinical outcomes, biomarkers, and study findings, often involving comparisons, associations, or measurements in research contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8818868597348531,
    "similarity_var": 0.0003441870973980422,
    "score_fuzz": 0.62,
    "score_detection": 0.47,
    "score_embedding": 0.291875,
    "total_score": 0.460625,
    "x": 7.311720371246338,
    "y": 1.3481682538986206,
    "cluster_id": 25
  },
  {
    "feature_id": 108,
    "explanation_index": 2,
    "text": "The highlighted portions are key scientific terms or phrases\u2014usually noun or adjective phrases that denote variables, concepts, or findings\u2014and the activations list the individual tokens that make up each highlighted segment.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8818868597348531,
    "similarity_var": 0.0003441870973980422,
    "score_fuzz": 0.65,
    "score_detection": 0.675,
    "score_embedding": 0.44625000000000004,
    "total_score": 0.5904166666666667,
    "x": 16.65870475769043,
    "y": 3.7106070518493652,
    "cluster_id": 20
  },
  {
    "feature_id": 109,
    "explanation_index": 0,
    "text": "Prepositions and nouns often function as important tokens, with prepositions like \\\"from\\\", \\\"of\\\", and \\\"in\\\" frequently appearing, while nouns tend to represent objects, concepts, or actions, such as \\\"paper\\\", \\\"speech\\\", \\\"risk\\\", and \\\"experience\\\".",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8557523687680563,
    "similarity_var": 3.8754927888678336e-05,
    "score_fuzz": 0.52,
    "score_detection": 0.31,
    "score_embedding": 0.46840000000000004,
    "total_score": 0.4328,
    "x": 12.503098487854004,
    "y": -0.38931694626808167,
    "cluster_id": 63
  },
  {
    "feature_id": 109,
    "explanation_index": 1,
    "text": "Common noun phrases or key terms that denote specific concepts, locations, or abstract ideas, often appearing in academic, technical, or descriptive contexts, with high activation values on content-bearing words.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8557523687680563,
    "similarity_var": 3.8754927888678336e-05,
    "score_fuzz": 0.38,
    "score_detection": 0.21,
    "score_embedding": 0.45687500000000003,
    "total_score": 0.3489583333333333,
    "x": 8.920951843261719,
    "y": -0.12792186439037323,
    "cluster_id": 83
  },
  {
    "feature_id": 109,
    "explanation_index": 2,
    "text": "The highlighted words are typically function words or small content words that serve as the glue in key collocations or idiomatic expressions, linking the main lexical items and carrying essential semantic weight.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8557523687680563,
    "similarity_var": 3.8754927888678336e-05,
    "score_fuzz": 0.375,
    "score_detection": 0.475,
    "score_embedding": 0.49562500000000004,
    "total_score": 0.44854166666666667,
    "x": 16.73644256591797,
    "y": 3.6806416511535645,
    "cluster_id": 20
  },
  {
    "feature_id": 112,
    "explanation_index": 0,
    "text": "Class, struct, and interface declarations in various programming languages.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8985867698987325,
    "similarity_var": 0.0009746771962121495,
    "score_fuzz": 0.84,
    "score_detection": 0.73,
    "score_embedding": 0.606,
    "total_score": 0.7253333333333333,
    "x": 10.726021766662598,
    "y": 8.408013343811035,
    "cluster_id": 48
  },
  {
    "feature_id": 112,
    "explanation_index": 1,
    "text": "The pattern involves identifiers that represent class, struct, or type definitions in code, often appearing with keywords like \\\"class\\\", \\\"struct\\\", or \\\"type\\\", and frequently followed by a capitalized name or compound identifier, with high activation on the name components and surrounding syntax.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8985867698987325,
    "similarity_var": 0.0009746771962121495,
    "score_fuzz": 0.73,
    "score_detection": 0.75,
    "score_embedding": 0.536875,
    "total_score": 0.6722916666666666,
    "x": 10.676289558410645,
    "y": 7.1319403648376465,
    "cluster_id": -1
  },
  {
    "feature_id": 112,
    "explanation_index": 2,
    "text": "The highlighted tokens are identifiers that denote types or classes in code, often capitalized and introduced by keywords such as class, struct, interface, or template parameter.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8985867698987325,
    "similarity_var": 0.0009746771962121495,
    "score_fuzz": 0.7,
    "score_detection": 0.675,
    "score_embedding": 0.6031249999999999,
    "total_score": 0.6593749999999999,
    "x": 13.859650611877441,
    "y": 6.6311187744140625,
    "cluster_id": 8
  },
  {
    "feature_id": 113,
    "explanation_index": 0,
    "text": "Nouns or words that represent a distinct object, concept, or idea, often in a formal or technical context, and sometimes in a specific field such as science, technology, or medicine.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8779075741767883,
    "similarity_var": 0.0002887689112469616,
    "score_fuzz": 0.41,
    "score_detection": 0.28,
    "score_embedding": 0.4176000000000001,
    "total_score": 0.36920000000000003,
    "x": 8.125625610351562,
    "y": 0.4095887541770935,
    "cluster_id": 12
  },
  {
    "feature_id": 113,
    "explanation_index": 1,
    "text": "Commonly activated tokens are often suffixes or parts of compound words, particularly in technical, scientific, or formal contexts, with frequent emphasis on specific morphological endings like \\\"-er\\\", \\\"-ing\\\", \\\"-ion\\\", \\\"-ity\\\", and \\\"-al\\\", as well as standalone terms in proper nouns, technical jargon, or domain-specific terminology.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8779075741767883,
    "similarity_var": 0.0002887689112469616,
    "score_fuzz": 0.58,
    "score_detection": 0.27,
    "score_embedding": 0.36500000000000005,
    "total_score": 0.405,
    "x": 9.90583324432373,
    "y": 3.3286631107330322,
    "cluster_id": -1
  },
  {
    "feature_id": 113,
    "explanation_index": 2,
    "text": "The highlighted tokens are the words that the model\u2019s activation signals as most relevant to the surrounding context, typically nouns, adjectives, or key terms that carry semantic weight, including idiomatic phrases, comparative suffixes, or domain\u2011specific entities.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8779075741767883,
    "similarity_var": 0.0002887689112469616,
    "score_fuzz": 0.575,
    "score_detection": 0.35,
    "score_embedding": 0.48750000000000004,
    "total_score": 0.4708333333333334,
    "x": 15.1061372756958,
    "y": 4.678025245666504,
    "cluster_id": 55
  },
  {
    "feature_id": 115,
    "explanation_index": 0,
    "text": "Tokens that are part of proper nouns, titles, names, or specific identifiers, often denoting a unique entity, location, or concept.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8549677729606628,
    "similarity_var": 5.3922150913858026e-05,
    "score_fuzz": 0.59,
    "score_detection": 0.52,
    "score_embedding": 0.4084,
    "total_score": 0.5061333333333332,
    "x": 10.187973976135254,
    "y": 4.371549129486084,
    "cluster_id": 1
  },
  {
    "feature_id": 115,
    "explanation_index": 1,
    "text": "Fragments of proper nouns, technical terms, or identifiers often appear with partial or split spelling, frequently adjacent to punctuation or special characters, and are typically associated with scientific, academic, or formal text.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8549677729606628,
    "similarity_var": 5.3922150913858026e-05,
    "score_fuzz": 0.6,
    "score_detection": 0.7,
    "score_embedding": 0.463125,
    "total_score": 0.5877083333333333,
    "x": 6.987513065338135,
    "y": 2.666161298751831,
    "cluster_id": 2
  },
  {
    "feature_id": 115,
    "explanation_index": 2,
    "text": "The highlighted fragments are contiguous sequences of words or symbols that form a meaningful unit\u2014idiomatic expressions, comparative adjectives, noun phrases, code tokens, or reference components\u2014whose presence strongly influences the model\u2019s output.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8549677729606628,
    "similarity_var": 5.3922150913858026e-05,
    "score_fuzz": 0.45,
    "score_detection": 0.625,
    "score_embedding": 0.48,
    "total_score": 0.5183333333333333,
    "x": 15.687031745910645,
    "y": 7.30816125869751,
    "cluster_id": 19
  },
  {
    "feature_id": 116,
    "explanation_index": 0,
    "text": "Chemical and biological terms, often representing enzymes, acids, proteins, and other compounds, typically denoted by their scientific names or abbreviations.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8900015751520792,
    "similarity_var": 0.00011325817426745113,
    "score_fuzz": 0.81,
    "score_detection": 0.49,
    "score_embedding": 0.7575999999999999,
    "total_score": 0.6858666666666666,
    "x": 7.294133186340332,
    "y": 1.3182682991027832,
    "cluster_id": 25
  },
  {
    "feature_id": 116,
    "explanation_index": 1,
    "text": "Shortened or truncated forms of biochemical and molecular biology terms, often appearing as partial words or fragments, are frequently activated in scientific text, particularly when representing complex compound names, enzyme names, or metabolic pathways.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8900015751520792,
    "similarity_var": 0.00011325817426745113,
    "score_fuzz": 0.65,
    "score_detection": 0.51,
    "score_embedding": 0.5856250000000001,
    "total_score": 0.581875,
    "x": 7.516725540161133,
    "y": 2.5504117012023926,
    "cluster_id": -1
  },
  {
    "feature_id": 116,
    "explanation_index": 2,
    "text": "The activations consistently highlight subword fragments that belong to technical terms\u2014often chemical or biological names\u2014capturing prefixes, suffixes, or internal substrings, sometimes with preceding spaces or punctuation. These fragments are the building blocks of longer domain\u2011specific words, indicating the model\u2019s focus on the compositional structure of scientific terminology.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8900015751520792,
    "similarity_var": 0.00011325817426745113,
    "score_fuzz": 0.675,
    "score_detection": 0.475,
    "score_embedding": 0.60625,
    "total_score": 0.5854166666666666,
    "x": 7.839534759521484,
    "y": 2.869912624359131,
    "cluster_id": -1
  },
  {
    "feature_id": 117,
    "explanation_index": 0,
    "text": "Adjectives and nouns that describe or modify a concept, object, or idea, often indicating a specific characteristic, origin, or relationship.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8347410162289938,
    "similarity_var": 0.00010099507632411866,
    "score_fuzz": 0.56,
    "score_detection": 0.4631578947368421,
    "score_embedding": 0.4404,
    "total_score": 0.48785263157894737,
    "x": 8.425570487976074,
    "y": 0.8322250247001648,
    "cluster_id": 54
  },
  {
    "feature_id": 117,
    "explanation_index": 1,
    "text": "Commonly activated tokens include function words (e.g., \\\"the\\\", \\\"to\\\", \\\"of\\\", \\\"and\\\"), comparative or derivational suffixes (e.g., \\\"er\\\", \\\"ing\\\", \\\"ised\\\"), and content words related to abstract concepts, spatial relations, or specific domains (e.g., \\\"spatial\\\", \\\"digital\\\", \\\"multiverse\\\", \\\"access\\\", \\\"structures\\\"), often appearing in academic or analytical contexts with a focus on relationships, processes, or systemic frameworks.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8347410162289938,
    "similarity_var": 0.00010099507632411866,
    "score_fuzz": 0.54,
    "score_detection": 0.45,
    "score_embedding": 0.536875,
    "total_score": 0.5089583333333333,
    "x": 10.154516220092773,
    "y": 3.1655960083007812,
    "cluster_id": 33
  },
  {
    "feature_id": 117,
    "explanation_index": 2,
    "text": "The highlighted tokens are always part of a contiguous, semantically\u2011rich unit\u2014an idiom, a comparative suffix, or a noun phrase\u2014that carries a clear meaning or relationship in the sentence.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8347410162289938,
    "similarity_var": 0.00010099507632411866,
    "score_fuzz": 0.7,
    "score_detection": 0.35,
    "score_embedding": 0.610625,
    "total_score": 0.5535416666666666,
    "x": 15.26254653930664,
    "y": 4.532814025878906,
    "cluster_id": -1
  },
  {
    "feature_id": 119,
    "explanation_index": 0,
    "text": "Error messages, warnings, and debugging information, often including quotes or specific details about the issue.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.908222516377767,
    "similarity_var": 0.0001624089287691138,
    "score_fuzz": 0.83,
    "score_detection": 0.79,
    "score_embedding": 0.5572,
    "total_score": 0.7257333333333333,
    "x": 10.019572257995605,
    "y": 7.099964141845703,
    "cluster_id": -1
  },
  {
    "feature_id": 119,
    "explanation_index": 1,
    "text": "Fragments of error messages, system logs, or diagnostic text often containing structured syntax with quoted strings, error codes, or technical identifiers, typically appearing in programming or debugging contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.908222516377767,
    "similarity_var": 0.0001624089287691138,
    "score_fuzz": 0.74,
    "score_detection": 0.75,
    "score_embedding": 0.44375,
    "total_score": 0.6445833333333333,
    "x": 10.359153747558594,
    "y": 6.980046272277832,
    "cluster_id": 86
  },
  {
    "feature_id": 119,
    "explanation_index": 2,
    "text": "The examples focus on code fragments that report failures or exceptional states; the highlighted tokens are those that signal error conditions\u2014phrases like \u201cerror\u201d, \u201cfailed\u201d, \u201cexception\u201d, \u201cno such\u201d, \u201cunsupported\u201d, \u201cinvariant\u201d, \u201cnull\u201d, \u201cpointer\u201d, \u201cfile\u201d, \u201cdirectory\u201d, \u201ctimeout\u201d, etc.\u2014which appear in log messages, exception strings, and diagnostic comments.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.908222516377767,
    "similarity_var": 0.0001624089287691138,
    "score_fuzz": 0.825,
    "score_detection": 0.875,
    "score_embedding": 0.7499999999999999,
    "total_score": 0.8166666666666665,
    "x": 10.581624031066895,
    "y": 6.902174949645996,
    "cluster_id": -1
  },
  {
    "feature_id": 120,
    "explanation_index": 0,
    "text": "Abbreviations, variable names, and symbols, often denoted by a single letter, typically \\\"p\\\", and sometimes used in mathematical or programming contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8191335002581278,
    "similarity_var": 0.004234193373428575,
    "score_fuzz": 0.76,
    "score_detection": 0.65,
    "score_embedding": 0.4128,
    "total_score": 0.6076,
    "x": 9.088083267211914,
    "y": 7.6648664474487305,
    "cluster_id": 68
  },
  {
    "feature_id": 120,
    "explanation_index": 1,
    "text": "The token sequences \\\"P\\\", \\\"p\\\", \\\"PD\\\", \\\"PL\\\", \\\"PC\\\", \\\"Peas\\\", \\\"Ports\\\", \\\"Phys\\\", \\\"pitch\\\", \\\"physic\\\", \\\"PAS\\\", \\\"perturb\\\", \\\"paving\\\", and similar are often used as abbreviations, identifiers, or parts of proper nouns, particularly in scientific, technical, or mathematical contexts, where they represent specific terms, variables, or named entities.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8191335002581278,
    "similarity_var": 0.004234193373428575,
    "score_fuzz": 0.68,
    "score_detection": 0.5,
    "score_embedding": 0.303125,
    "total_score": 0.49437500000000006,
    "x": 9.724237442016602,
    "y": 3.3214352130889893,
    "cluster_id": -1
  },
  {
    "feature_id": 120,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8191335002581278,
    "similarity_var": 0.004234193373428575,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.234375,
    "total_score": 0.4114583333333333,
    "x": -5.891068458557129,
    "y": 16.013893127441406,
    "cluster_id": 10
  },
  {
    "feature_id": 122,
    "explanation_index": 0,
    "text": "Adjectives or nouns that describe a relationship, characteristic, or attribute, often used in formal or technical contexts, such as mathematics, science, and technology.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8284931381543478,
    "similarity_var": 0.00032402931692448393,
    "score_fuzz": 0.63,
    "score_detection": 0.31,
    "score_embedding": 0.20440000000000003,
    "total_score": 0.3814666666666667,
    "x": 8.418627738952637,
    "y": 0.8795052766799927,
    "cluster_id": 54
  },
  {
    "feature_id": 122,
    "explanation_index": 1,
    "text": "The phrase \\\"common\\\" or its synonyms (e.g., \\\"highest\\\", \\\"greatest\\\", \\\"similarities\\\", \\\"resemblance\\\") frequently appears in contexts involving mathematical comparisons, particularly related to divisors, factors, or shared properties between entities.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8284931381543478,
    "similarity_var": 0.00032402931692448393,
    "score_fuzz": 0.66,
    "score_detection": 0.69,
    "score_embedding": 0.42937499999999995,
    "total_score": 0.593125,
    "x": 9.939940452575684,
    "y": 2.216132879257202,
    "cluster_id": -1
  },
  {
    "feature_id": 122,
    "explanation_index": 2,
    "text": "The highlighted tokens are high\u2011frequency, generic words that appear in many contexts\u2014function words, common nouns, and key terms in recurring phrases (e.g., \u201ccommon\u201d, \u201cgreatest\u201d, \u201csimilarities\u201d, \u201clength\u201d, \u201cfamily\u201d). The model\u2019s activations tend to focus on these ubiquitous connectors and standard phrase components rather than on content\u2011specific vocabulary.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8284931381543478,
    "similarity_var": 0.00032402931692448393,
    "score_fuzz": 0.875,
    "score_detection": 0.675,
    "score_embedding": 0.30374999999999996,
    "total_score": 0.6179166666666667,
    "x": 13.730534553527832,
    "y": 3.9535880088806152,
    "cluster_id": 42
  },
  {
    "feature_id": 123,
    "explanation_index": 0,
    "text": "Words related to maritime or nautical themes, such as boats, ships, harbors, and ports, as well as words associated with the sea or water.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9516018827756246,
    "similarity_var": 2.581995708636795e-05,
    "score_fuzz": 0.63,
    "score_detection": 0.38,
    "score_embedding": 0.406,
    "total_score": 0.472,
    "x": 8.404051780700684,
    "y": -0.22334176301956177,
    "cluster_id": -1
  },
  {
    "feature_id": 123,
    "explanation_index": 1,
    "text": "Nouns and noun phrases related to maritime environments, vessels, ports, and coastal geography, often associated with water-based transportation, navigation, or seafaring activities.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9516018827756246,
    "similarity_var": 2.581995708636795e-05,
    "score_fuzz": 0.55,
    "score_detection": 0.39,
    "score_embedding": 0.36125,
    "total_score": 0.43375,
    "x": 8.338220596313477,
    "y": -0.1902153044939041,
    "cluster_id": -1
  },
  {
    "feature_id": 123,
    "explanation_index": 2,
    "text": "The highlighted tokens are predominantly maritime\u2011related nouns and terms\u2014boats, ships, harbors, ports, sea, docks, etc.\u2014that describe water transport or coastal settings.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9516018827756246,
    "similarity_var": 2.581995708636795e-05,
    "score_fuzz": 0.5,
    "score_detection": 0.325,
    "score_embedding": 0.36750000000000005,
    "total_score": 0.39749999999999996,
    "x": 8.508380889892578,
    "y": -0.14071424305438995,
    "cluster_id": -1
  },
  {
    "feature_id": 124,
    "explanation_index": 0,
    "text": "Verbs expressing assertion, declaration, or expression of thought, often used in formal or academic writing to convey a point or present evidence.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9147359728813171,
    "similarity_var": 0.000676287814551794,
    "score_fuzz": 0.88,
    "score_detection": 0.44,
    "score_embedding": 0.11599999999999999,
    "total_score": 0.47866666666666663,
    "x": 10.407129287719727,
    "y": -0.8091409206390381,
    "cluster_id": 14
  },
  {
    "feature_id": 124,
    "explanation_index": 1,
    "text": "Verbs expressing mental states, assertions, or conclusions, often used to report beliefs, findings, or claims in academic or formal discourse.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9147359728813171,
    "similarity_var": 0.000676287814551794,
    "score_fuzz": 0.93,
    "score_detection": 0.42,
    "score_embedding": 0.0525,
    "total_score": 0.4675,
    "x": 10.400547981262207,
    "y": -0.8431133031845093,
    "cluster_id": 14
  },
  {
    "feature_id": 124,
    "explanation_index": 2,
    "text": "The highlighted tokens are single\u2011word verbs that serve as the main predicate of a clause, usually positioned in the middle of a sentence, in present or past tense, and used to express an action, state, or assertion in formal or academic writing.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9147359728813171,
    "similarity_var": 0.000676287814551794,
    "score_fuzz": 0.85,
    "score_detection": 0.425,
    "score_embedding": 0.106875,
    "total_score": 0.460625,
    "x": 14.675041198730469,
    "y": 3.363274574279785,
    "cluster_id": -1
  },
  {
    "feature_id": 125,
    "explanation_index": 0,
    "text": "A variety of words or parts of words, often function words, prefixes, or suffixes, that appear in a wide range of contexts, including programming code, formal documents, and everyday writing.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8824851711591085,
    "similarity_var": 0.0003188651506920653,
    "score_fuzz": 0.33,
    "score_detection": 0.24,
    "score_embedding": 0.35000000000000003,
    "total_score": 0.3066666666666667,
    "x": 8.28042221069336,
    "y": 2.068471670150757,
    "cluster_id": 44
  },
  {
    "feature_id": 125,
    "explanation_index": 1,
    "text": "Partial word fragments at the start or end of tokens, often representing parts of compound words or technical terms, with higher activation on the middle or trailing segments.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8824851711591085,
    "similarity_var": 0.0003188651506920653,
    "score_fuzz": 0.56,
    "score_detection": 0.31,
    "score_embedding": 0.46062500000000006,
    "total_score": 0.4435416666666667,
    "x": 7.092360496520996,
    "y": 2.9131016731262207,
    "cluster_id": 59
  },
  {
    "feature_id": 125,
    "explanation_index": 2,
    "text": "The highlighted fragments are substrings that appear within larger words, often representing root or stem components, and they occur across both natural language and code identifiers.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8824851711591085,
    "similarity_var": 0.0003188651506920653,
    "score_fuzz": 0.5,
    "score_detection": 0.15,
    "score_embedding": 0.318125,
    "total_score": 0.3227083333333333,
    "x": 15.349235534667969,
    "y": 7.291639804840088,
    "cluster_id": 56
  },
  {
    "feature_id": 126,
    "explanation_index": 0,
    "text": "Nouns representing concepts, objects, or fields of study, often related to formal or technical topics, such as law, science, economics, and social issues.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8345128099123637,
    "similarity_var": 0.00296794148114622,
    "score_fuzz": 0.75,
    "score_detection": 0.41,
    "score_embedding": 0.3644,
    "total_score": 0.5081333333333333,
    "x": 8.040493965148926,
    "y": 0.4521732032299042,
    "cluster_id": 12
  },
  {
    "feature_id": 126,
    "explanation_index": 1,
    "text": "Common nouns or proper nouns that are part of established technical, legal, or institutional terms, often appearing in formal or specialized contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8345128099123637,
    "similarity_var": 0.00296794148114622,
    "score_fuzz": 0.67,
    "score_detection": 0.41,
    "score_embedding": 0.43375,
    "total_score": 0.5045833333333334,
    "x": 8.445783615112305,
    "y": -0.5559056401252747,
    "cluster_id": -1
  },
  {
    "feature_id": 126,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8345128099123637,
    "similarity_var": 0.00296794148114622,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.520625,
    "total_score": 0.506875,
    "x": -5.896982669830322,
    "y": 16.011699676513672,
    "cluster_id": 10
  },
  {
    "feature_id": 127,
    "explanation_index": 0,
    "text": "Two-digit year representations in citations and references.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8660079638163248,
    "similarity_var": 0.0005362991378545543,
    "score_fuzz": 0.83,
    "score_detection": 0.82,
    "score_embedding": 0.5644,
    "total_score": 0.7381333333333333,
    "x": 7.30113410949707,
    "y": 8.598967552185059,
    "cluster_id": 29
  },
  {
    "feature_id": 127,
    "explanation_index": 1,
    "text": "The digit \\\"0\\\" frequently appears in year references, particularly in the context of academic citations and timestamps, often following a \\\"2\\\" to form years in the 2000s.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8660079638163248,
    "similarity_var": 0.0005362991378545543,
    "score_fuzz": 0.77,
    "score_detection": 0.67,
    "score_embedding": 0.540625,
    "total_score": 0.6602083333333333,
    "x": 7.440040111541748,
    "y": 8.491808891296387,
    "cluster_id": 29
  },
  {
    "feature_id": 127,
    "explanation_index": 2,
    "text": "The pattern: The examples are all about numbers in citations, like \\\"1<<9>>98\\\" etc.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8660079638163248,
    "similarity_var": 0.0005362991378545543,
    "score_fuzz": 0.85,
    "score_detection": 0.6,
    "score_embedding": 0.546875,
    "total_score": 0.665625,
    "x": 8.431327819824219,
    "y": 7.48267936706543,
    "cluster_id": -1
  },
  {
    "feature_id": 128,
    "explanation_index": 0,
    "text": "Names of organizations, groups, and individuals involved in terrorism, politics, or military conflicts, as well as words related to terrorism, war, and violence.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8470838069915771,
    "similarity_var": 0.003065811545769274,
    "score_fuzz": 0.65,
    "score_detection": 0.51,
    "score_embedding": 0.5244,
    "total_score": 0.5614666666666667,
    "x": 7.495910167694092,
    "y": -0.867373526096344,
    "cluster_id": 16
  },
  {
    "feature_id": 128,
    "explanation_index": 1,
    "text": "The token \\\"er\\\" appears in words related to comparative forms, particularly in adjectives describing size, intensity, or degree, often in contexts involving evaluation or contrast.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8470838069915771,
    "similarity_var": 0.003065811545769274,
    "score_fuzz": 0.48,
    "score_detection": 0.51,
    "score_embedding": 0.483125,
    "total_score": 0.49104166666666665,
    "x": 11.833785057067871,
    "y": 3.3949644565582275,
    "cluster_id": 60
  },
  {
    "feature_id": 128,
    "explanation_index": 2,
    "text": "Tokens that are components of extremist group names or terrorism\u2011related terminology, frequently appearing in contexts about conflict, security, or political events.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8470838069915771,
    "similarity_var": 0.003065811545769274,
    "score_fuzz": 0.65,
    "score_detection": 0.55,
    "score_embedding": 0.5868749999999999,
    "total_score": 0.5956250000000001,
    "x": 10.093160629272461,
    "y": 4.29033088684082,
    "cluster_id": 1
  },
  {
    "feature_id": 129,
    "explanation_index": 0,
    "text": "CSS properties, HTML attributes, and programming keywords.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8596834143002828,
    "similarity_var": 0.0011290881584697687,
    "score_fuzz": 0.71,
    "score_detection": 0.52,
    "score_embedding": 0.6023999999999999,
    "total_score": 0.6107999999999999,
    "x": 10.478119850158691,
    "y": 8.17609691619873,
    "cluster_id": -1
  },
  {
    "feature_id": 129,
    "explanation_index": 1,
    "text": "Tokens related to CSS, HTML, or programming language syntax, particularly property names and identifiers, often appear in contexts involving styling, layout, or configuration, with higher activation values for more specific or structurally significant terms.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8596834143002828,
    "similarity_var": 0.0011290881584697687,
    "score_fuzz": 0.56,
    "score_detection": 0.44,
    "score_embedding": 0.5525000000000001,
    "total_score": 0.5175000000000001,
    "x": 10.816753387451172,
    "y": 6.237606525421143,
    "cluster_id": 18
  },
  {
    "feature_id": 129,
    "explanation_index": 2,
    "text": "The pattern: tokens inside << >> are important.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8596834143002828,
    "similarity_var": 0.0011290881584697687,
    "score_fuzz": 0.8,
    "score_detection": 0.6,
    "score_embedding": 0.5025,
    "total_score": 0.6341666666666667,
    "x": 9.547338485717773,
    "y": 6.498852252960205,
    "cluster_id": 61
  },
  {
    "feature_id": 130,
    "explanation_index": 0,
    "text": "Common tokens include \\\"state\\\", \\\"the\\\", and \\\"of\\\", often used in formal or technical contexts, such as academic or government-related texts, and sometimes appearing in phrases like \\\"state of the art\\\" or \\\"state v\\\".",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8727327783902487,
    "similarity_var": 0.00037539451815939,
    "score_fuzz": 0.85,
    "score_detection": 0.84,
    "score_embedding": 0.6564,
    "total_score": 0.7821333333333333,
    "x": 10.377167701721191,
    "y": 3.3538544178009033,
    "cluster_id": -1
  },
  {
    "feature_id": 130,
    "explanation_index": 1,
    "text": "The word \\\"state\\\" frequently appears in contexts related to government, condition, or status, often in compound phrases like \\\"state of\\\" or \\\"state-run,\\\" and is commonly associated with administrative, legal, or descriptive references to a condition or jurisdiction.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8727327783902487,
    "similarity_var": 0.00037539451815939,
    "score_fuzz": 0.73,
    "score_detection": 0.74,
    "score_embedding": 0.7537499999999999,
    "total_score": 0.74125,
    "x": 10.49107837677002,
    "y": 3.251967430114746,
    "cluster_id": -1
  },
  {
    "feature_id": 130,
    "explanation_index": 2,
    "text": "Tokens that belong to frequent multi\u2011word collocations\u2014particularly those containing the word \u201cstate\u201d and common function words like \u201cthe\u201d and \u201cof\u201d\u2014are highlighted.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8727327783902487,
    "similarity_var": 0.00037539451815939,
    "score_fuzz": 0.775,
    "score_detection": 0.725,
    "score_embedding": 0.51875,
    "total_score": 0.6729166666666666,
    "x": 14.336393356323242,
    "y": 3.8942103385925293,
    "cluster_id": -1
  },
  {
    "feature_id": 131,
    "explanation_index": 0,
    "text": "Proper nouns, technical terms, and common words in various contexts, often denoting specific objects, locations, concepts, or individuals.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8743767937024435,
    "similarity_var": 0.002040443697233564,
    "score_fuzz": 0.62,
    "score_detection": 0.41,
    "score_embedding": 0.42,
    "total_score": 0.48333333333333334,
    "x": 7.700931549072266,
    "y": -0.6664177179336548,
    "cluster_id": 16
  },
  {
    "feature_id": 131,
    "explanation_index": 1,
    "text": "Common nouns or noun phrases representing specific locations, objects, or abstract concepts, often appearing in technical, geographical, or contextual descriptions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8743767937024435,
    "similarity_var": 0.002040443697233564,
    "score_fuzz": 0.52,
    "score_detection": 0.28,
    "score_embedding": 0.460625,
    "total_score": 0.42020833333333335,
    "x": 8.750266075134277,
    "y": -0.22809457778930664,
    "cluster_id": -1
  },
  {
    "feature_id": 131,
    "explanation_index": 2,
    "text": "The highlighted tokens are the semantic core of phrases\u2014primarily nouns, proper nouns, and key adjectives\u2014that carry the main meaning while function words are omitted.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8743767937024435,
    "similarity_var": 0.002040443697233564,
    "score_fuzz": 0.65,
    "score_detection": 0.35,
    "score_embedding": 0.3125,
    "total_score": 0.4375,
    "x": 15.336345672607422,
    "y": 4.128273010253906,
    "cluster_id": 22
  },
  {
    "feature_id": 132,
    "explanation_index": 0,
    "text": "Hexadecimal or numerical values embedded within a larger string or code, often representing memory addresses, data values, or indices.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8871314922968546,
    "similarity_var": 2.2463185410338658e-05,
    "score_fuzz": 0.4,
    "score_detection": 0.3,
    "score_embedding": 0.25680000000000003,
    "total_score": 0.31893333333333335,
    "x": 7.044057846069336,
    "y": 8.692119598388672,
    "cluster_id": 29
  },
  {
    "feature_id": 132,
    "explanation_index": 1,
    "text": "The final character or token within a sequence of hexadecimal, numeric, or symbolic values, often indicating a specific identifier, address, or data field.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8871314922968546,
    "similarity_var": 2.2463185410338658e-05,
    "score_fuzz": 0.48,
    "score_detection": 0.36,
    "score_embedding": 0.271875,
    "total_score": 0.370625,
    "x": 7.732706069946289,
    "y": 8.316933631896973,
    "cluster_id": 29
  },
  {
    "feature_id": 132,
    "explanation_index": 2,
    "text": "Short alphanumeric tokens\u2014often single characters or two\u2011digit hex values\u2014that serve as identifiers, numeric constants, or code markers.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8871314922968546,
    "similarity_var": 2.2463185410338658e-05,
    "score_fuzz": 0.45,
    "score_detection": 0.275,
    "score_embedding": 0.354375,
    "total_score": 0.35979166666666673,
    "x": 7.8292555809021,
    "y": 8.371394157409668,
    "cluster_id": -1
  },
  {
    "feature_id": 133,
    "explanation_index": 0,
    "text": "Proper nouns, technical terms, and specific words that provide context or clarity in a sentence, often denoting names, locations, concepts, or objects.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8579079707463583,
    "similarity_var": 0.00010052751690952592,
    "score_fuzz": 0.68,
    "score_detection": 0.71,
    "score_embedding": 0.28880000000000006,
    "total_score": 0.5596000000000001,
    "x": 7.7931036949157715,
    "y": -0.5836628079414368,
    "cluster_id": 16
  },
  {
    "feature_id": 133,
    "explanation_index": 1,
    "text": "Repeated or recurring tokens, often part of compound words, proper nouns, or technical terms, that appear in contexts involving specific domains such as programming, scientific notation, or named entities, with activation values indicating their importance in context.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8579079707463583,
    "similarity_var": 0.00010052751690952592,
    "score_fuzz": 0.29,
    "score_detection": 0.25,
    "score_embedding": 0.205,
    "total_score": 0.24833333333333332,
    "x": 10.199650764465332,
    "y": 4.148967742919922,
    "cluster_id": 1
  },
  {
    "feature_id": 133,
    "explanation_index": 2,
    "text": "The highlighted words are the core lexical units that together form a semantically salient phrase or unit\u2014often a noun phrase, a comparative adjective (including the \u201c\u2011er\u201d suffix), or a key term in a technical or cultural context. They carry the main meaning of the surrounding phrase.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8579079707463583,
    "similarity_var": 0.00010052751690952592,
    "score_fuzz": 0.775,
    "score_detection": 0.8,
    "score_embedding": 0.22875,
    "total_score": 0.6012500000000001,
    "x": 16.628849029541016,
    "y": 3.6852192878723145,
    "cluster_id": 20
  },
  {
    "feature_id": 134,
    "explanation_index": 0,
    "text": "Punctuation marks, often used to denote the start or end of a quotation, section, or code snippet, and sometimes used to separate items or indicate a break in thought.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8739713430404663,
    "similarity_var": 0.00021998341271493396,
    "score_fuzz": 0.59,
    "score_detection": 0.37,
    "score_embedding": 0.26680000000000004,
    "total_score": 0.4089333333333333,
    "x": 8.299776077270508,
    "y": 6.791969299316406,
    "cluster_id": 36
  },
  {
    "feature_id": 134,
    "explanation_index": 1,
    "text": "The token sequences \\\"<<\\\" and \\\">>\\\" are used to delimit content segments, often surrounding text that is contextually or structurally significant, such as quoted material, code, mathematical expressions, or metadata, with activations primarily occurring at the boundaries and within the delimiters.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8739713430404663,
    "similarity_var": 0.00021998341271493396,
    "score_fuzz": 0.42,
    "score_detection": 0.41,
    "score_embedding": 0.41125,
    "total_score": 0.41375,
    "x": 9.545763969421387,
    "y": 6.595334529876709,
    "cluster_id": 61
  },
  {
    "feature_id": 134,
    "explanation_index": 2,
    "text": "The highlighted tokens are not ordinary words but structural markers\u2014delimiters, punctuation, whitespace, or formatting tags\u2014that signal the boundaries or emphasis of a text segment.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8739713430404663,
    "similarity_var": 0.00021998341271493396,
    "score_fuzz": 0.7,
    "score_detection": 0.35,
    "score_embedding": 0.34937500000000005,
    "total_score": 0.46645833333333325,
    "x": 13.915005683898926,
    "y": 5.321993827819824,
    "cluster_id": 62
  },
  {
    "feature_id": 136,
    "explanation_index": 0,
    "text": "Prepositions and conjunctions, often used to connect clauses or phrases, and sometimes function words like articles, auxiliary verbs, and adverbs, which provide grammatical structure and context.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8786210616429647,
    "similarity_var": 0.00015709400647365458,
    "score_fuzz": 0.73,
    "score_detection": 0.53,
    "score_embedding": 0.41600000000000004,
    "total_score": 0.5586666666666668,
    "x": 12.217225074768066,
    "y": -0.01190873607993126,
    "cluster_id": 9
  },
  {
    "feature_id": 136,
    "explanation_index": 1,
    "text": "Prepositions and particles (e.g., \\\"in\\\", \\\"on\\\", \\\"of\\\", \\\"to\\\", \\\"with\\\", \\\"for\\\", \\\"at\\\", \\\"by\\\") frequently appear in contextually critical positions, often linking clauses, modifying nouns, or introducing relationships between entities, with high activation values indicating their syntactic and semantic importance in sentence structure.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8786210616429647,
    "similarity_var": 0.00015709400647365458,
    "score_fuzz": 0.68,
    "score_detection": 0.44,
    "score_embedding": 0.42375,
    "total_score": 0.5145833333333334,
    "x": 12.421918869018555,
    "y": -0.49642154574394226,
    "cluster_id": 63
  },
  {
    "feature_id": 136,
    "explanation_index": 2,
    "text": "The highlighted tokens are the words that together form a phrase\u2014usually a prepositional or verb phrase\u2014that is semantically relevant to the surrounding context; they tend to be function words or short content words that anchor that phrase.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8786210616429647,
    "similarity_var": 0.00015709400647365458,
    "score_fuzz": 0.75,
    "score_detection": 0.35,
    "score_embedding": 0.444375,
    "total_score": 0.5147916666666666,
    "x": 14.439388275146484,
    "y": 3.68674635887146,
    "cluster_id": -1
  },
  {
    "feature_id": 137,
    "explanation_index": 0,
    "text": "Phrases or words that introduce a comparison, a clarification, or an example, often used to provide additional information or context.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.816438615322113,
    "similarity_var": 0.0006677292561031815,
    "score_fuzz": 0.6,
    "score_detection": 0.63,
    "score_embedding": 0.6112000000000001,
    "total_score": 0.6137333333333334,
    "x": 11.07996940612793,
    "y": 1.2109405994415283,
    "cluster_id": -1
  },
  {
    "feature_id": 137,
    "explanation_index": 1,
    "text": "Pronouns and demonstratives referring to people or entities in context, often used to establish perspective or continuity in narrative or argument.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.816438615322113,
    "similarity_var": 0.0006677292561031815,
    "score_fuzz": 0.63,
    "score_detection": 0.42,
    "score_embedding": 0.48875,
    "total_score": 0.5129166666666667,
    "x": 11.628681182861328,
    "y": 1.1167452335357666,
    "cluster_id": 64
  },
  {
    "feature_id": 137,
    "explanation_index": 2,
    "text": "the patterns.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.816438615322113,
    "similarity_var": 0.0006677292561031815,
    "score_fuzz": 0.525,
    "score_detection": 0.25,
    "score_embedding": 0.5606249999999999,
    "total_score": 0.44520833333333326,
    "x": 5.127931118011475,
    "y": 9.979829788208008,
    "cluster_id": 58
  },
  {
    "feature_id": 138,
    "explanation_index": 0,
    "text": "Code snippets from various programming languages, including Go, Java, and C++, with a focus on Kubernetes, cloud computing, and networking.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8596102794011434,
    "similarity_var": 0.0005063008368758737,
    "score_fuzz": 0.74,
    "score_detection": 0.74,
    "score_embedding": 0.41,
    "total_score": 0.63,
    "x": 11.221965789794922,
    "y": 8.737283706665039,
    "cluster_id": 17
  },
  {
    "feature_id": 138,
    "explanation_index": 1,
    "text": "The text latents involve structured code and documentation patterns, particularly in API and software development contexts, with frequent use of identifiers, type names, and syntactic elements like parentheses, dots, and special characters, often related to programming constructs, package paths, and metadata annotations.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8596102794011434,
    "similarity_var": 0.0005063008368758737,
    "score_fuzz": 0.61,
    "score_detection": 0.65,
    "score_embedding": 0.34437500000000004,
    "total_score": 0.5347916666666667,
    "x": 10.18075942993164,
    "y": 6.5804009437561035,
    "cluster_id": -1
  },
  {
    "feature_id": 138,
    "explanation_index": 2,
    "text": "The highlighted tokens are domain\u2011specific identifiers\u2014nouns and verbs that name resources, types, or actions in code and documentation, often appearing in function names, comments, or variable declarations.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8596102794011434,
    "similarity_var": 0.0005063008368758737,
    "score_fuzz": 0.65,
    "score_detection": 0.6,
    "score_embedding": 0.37812499999999993,
    "total_score": 0.5427083333333332,
    "x": 13.728793144226074,
    "y": 4.885708332061768,
    "cluster_id": -1
  },
  {
    "feature_id": 139,
    "explanation_index": 0,
    "text": "The conjunction \\\"and\\\" used to connect clauses, phrases, or words, often indicating a relationship of addition, accompaniment, or continuation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9251948197682699,
    "similarity_var": 0.00022986300368741137,
    "score_fuzz": 0.92,
    "score_detection": 0.75,
    "score_embedding": 0.5968000000000001,
    "total_score": 0.7555999999999999,
    "x": 11.813312530517578,
    "y": 2.175177574157715,
    "cluster_id": 38
  },
  {
    "feature_id": 139,
    "explanation_index": 1,
    "text": "The word \\\"and\\\" is frequently used to connect clauses, ideas, or items in a list, often indicating a continuation or addition of information, with consistent activation across diverse contexts including logical, temporal, and descriptive relationships.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9251948197682699,
    "similarity_var": 0.00022986300368741137,
    "score_fuzz": 0.92,
    "score_detection": 0.74,
    "score_embedding": 0.521875,
    "total_score": 0.7272916666666668,
    "x": 11.769082069396973,
    "y": 2.2335047721862793,
    "cluster_id": 38
  },
  {
    "feature_id": 139,
    "explanation_index": 2,
    "text": "The highlighted token is the coordinating conjunction \u201cand,\u201d used to link clauses, phrases, or items within a sentence.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9251948197682699,
    "similarity_var": 0.00022986300368741137,
    "score_fuzz": 0.95,
    "score_detection": 0.775,
    "score_embedding": 0.505,
    "total_score": 0.7433333333333333,
    "x": 13.521232604980469,
    "y": 3.7049765586853027,
    "cluster_id": -1
  },
  {
    "feature_id": 140,
    "explanation_index": 0,
    "text": "Prepositions and conjunctions, often used in formal or legal language, that connect clauses or phrases, and sometimes function words that are part of idiomatic expressions or phrases.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8201578259468079,
    "similarity_var": 0.0011638854280514959,
    "score_fuzz": 0.49,
    "score_detection": 0.58,
    "score_embedding": 0.6536000000000001,
    "total_score": 0.5745333333333332,
    "x": 12.152132987976074,
    "y": 0.042248666286468506,
    "cluster_id": 9
  },
  {
    "feature_id": 140,
    "explanation_index": 1,
    "text": "High activation values for functionally important words in legal and formal text, particularly prepositions, articles, and common legal phrasing, indicating structural and semantic reliance on precise linguistic forms for legal reasoning and condition specification.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8201578259468079,
    "similarity_var": 0.0011638854280514959,
    "score_fuzz": 0.53,
    "score_detection": 0.6,
    "score_embedding": 0.7193750000000001,
    "total_score": 0.6164583333333333,
    "x": 8.914076805114746,
    "y": 4.184045314788818,
    "cluster_id": -1
  },
  {
    "feature_id": 140,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8201578259468079,
    "similarity_var": 0.0011638854280514959,
    "score_fuzz": 0.5,
    "score_detection": 0.475,
    "score_embedding": 0.745625,
    "total_score": 0.5735416666666667,
    "x": -7.947848320007324,
    "y": 9.112398147583008,
    "cluster_id": 52
  },
  {
    "feature_id": 142,
    "explanation_index": 0,
    "text": "The linking verbs \\\"is\\\" and \\\"are\\\" used to connect the subject of a sentence to additional information, often in formal or written contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9000452955563863,
    "similarity_var": 0.0011042698253199824,
    "score_fuzz": 0.96,
    "score_detection": 0.79,
    "score_embedding": 0.5347999999999999,
    "total_score": 0.7615999999999999,
    "x": 11.557357788085938,
    "y": 2.193005323410034,
    "cluster_id": -1
  },
  {
    "feature_id": 142,
    "explanation_index": 1,
    "text": "The words \\\"is\\\" and \\\"are\\\" are frequently used as linking verbs to connect subjects with descriptions, states, or attributes, often appearing in formal or scientific writing to assert identity, classification, or condition.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9000452955563863,
    "similarity_var": 0.0011042698253199824,
    "score_fuzz": 0.97,
    "score_detection": 0.78,
    "score_embedding": 0.6325000000000001,
    "total_score": 0.7941666666666668,
    "x": 11.544196128845215,
    "y": 2.2983224391937256,
    "cluster_id": -1
  },
  {
    "feature_id": 142,
    "explanation_index": 2,
    "text": "The highlighted tokens are short, high\u2011frequency function words that serve grammatical linking roles\u2014primarily copulas (\u201cis\u201d, \u201care\u201d) and determiners (\u201cthe\u201d, \u201ca\u201d)\u2014which appear across diverse contexts.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9000452955563863,
    "similarity_var": 0.0011042698253199824,
    "score_fuzz": 0.95,
    "score_detection": 0.45,
    "score_embedding": 0.5725000000000001,
    "total_score": 0.6575000000000001,
    "x": 13.434026718139648,
    "y": 3.218228816986084,
    "cluster_id": 35
  },
  {
    "feature_id": 143,
    "explanation_index": 0,
    "text": "The word \\\"most\\\" is used to form superlatives, often to describe something as being of the highest degree or extent, and is commonly used in comparative and superlative constructions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9243194262186686,
    "similarity_var": 6.7663678408615e-05,
    "score_fuzz": 0.94,
    "score_detection": 0.95,
    "score_embedding": 0.5604,
    "total_score": 0.8168000000000001,
    "x": 9.937468528747559,
    "y": 2.1879982948303223,
    "cluster_id": -1
  },
  {
    "feature_id": 143,
    "explanation_index": 1,
    "text": "The word \\\"most\\\" or \\\"more\\\" is used to indicate a superlative or comparative degree, often in contexts involving quantity, intensity, or frequency, and is frequently associated with evaluative or generalizing statements.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9243194262186686,
    "similarity_var": 6.7663678408615e-05,
    "score_fuzz": 0.99,
    "score_detection": 0.96,
    "score_embedding": 0.5231250000000001,
    "total_score": 0.824375,
    "x": 9.921831130981445,
    "y": 2.185401678085327,
    "cluster_id": -1
  },
  {
    "feature_id": 143,
    "explanation_index": 2,
    "text": "The token \u201cmost\u201d (and occasionally \u201cmore\u201d) is a highly salient word that appears across many contexts, typically functioning as a superlative or comparative modifier.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9243194262186686,
    "similarity_var": 6.7663678408615e-05,
    "score_fuzz": 1.0,
    "score_detection": 0.975,
    "score_embedding": 0.40437500000000004,
    "total_score": 0.793125,
    "x": 9.944202423095703,
    "y": 2.245250940322876,
    "cluster_id": -1
  },
  {
    "feature_id": 144,
    "explanation_index": 0,
    "text": "Various tokens including nouns, adjectives, adverbs, and conjunctions that appear in a wide range of contexts, often with no specific pattern or relationship to the surrounding text.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8583456873893738,
    "similarity_var": 6.728436529594244e-05,
    "score_fuzz": 0.53,
    "score_detection": 0.42,
    "score_embedding": 0.4864,
    "total_score": 0.47879999999999995,
    "x": 10.637310028076172,
    "y": 4.4668989181518555,
    "cluster_id": 47
  },
  {
    "feature_id": 144,
    "explanation_index": 1,
    "text": "Fragments of words, often parts of compound or technical terms, that appear in isolation due to formatting, encoding, or truncation, with varying activation levels depending on context and length.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8583456873893738,
    "similarity_var": 6.728436529594244e-05,
    "score_fuzz": 0.54,
    "score_detection": 0.63,
    "score_embedding": 0.643125,
    "total_score": 0.604375,
    "x": 7.016850471496582,
    "y": 2.517873525619507,
    "cluster_id": 2
  },
  {
    "feature_id": 144,
    "explanation_index": 2,
    "text": "The highlighted tokens are usually the core lexical elements of a phrase\u2014often a noun, verb, adjective, or technical term\u2014that carry the main semantic or functional weight in the surrounding context.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8583456873893738,
    "similarity_var": 6.728436529594244e-05,
    "score_fuzz": 0.55,
    "score_detection": 0.35,
    "score_embedding": 0.591875,
    "total_score": 0.4972916666666667,
    "x": 15.184240341186523,
    "y": 4.0009236335754395,
    "cluster_id": 22
  },
  {
    "feature_id": 145,
    "explanation_index": 0,
    "text": "Function words and prepositions often used in phrases to indicate location, time, quantity, or comparison, and sometimes used to connect clauses or phrases.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8430826465288798,
    "similarity_var": 0.0026049290944559146,
    "score_fuzz": 0.66,
    "score_detection": 0.47,
    "score_embedding": 0.3632,
    "total_score": 0.4977333333333333,
    "x": 10.68808364868164,
    "y": 1.1356147527694702,
    "cluster_id": 26
  },
  {
    "feature_id": 145,
    "explanation_index": 1,
    "text": "Common prepositional phrases and quantifiers used in measurement, time, and spatial relationships, often involving \\\"there\\\", \\\"in\\\", \\\"for\\\", \\\"to\\\", \\\"of\\\", \\\"on\\\", \\\"between\\\", and \\\"into\\\", with high activation on functional words that structure comparative or quantitative expressions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8430826465288798,
    "similarity_var": 0.0026049290944559146,
    "score_fuzz": 0.6,
    "score_detection": 0.45,
    "score_embedding": 0.436875,
    "total_score": 0.495625,
    "x": 12.392821311950684,
    "y": -0.5523701906204224,
    "cluster_id": 63
  },
  {
    "feature_id": 145,
    "explanation_index": 2,
    "text": "the pattern is question phrasing about quantity conversion or time difference.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8430826465288798,
    "similarity_var": 0.0026049290944559146,
    "score_fuzz": 0.55,
    "score_detection": 0.525,
    "score_embedding": 0.670625,
    "total_score": 0.581875,
    "x": 5.257779121398926,
    "y": 9.876554489135742,
    "cluster_id": 58
  },
  {
    "feature_id": 146,
    "explanation_index": 0,
    "text": "Verbs that convey the idea of presenting, explaining, or showing information, often used in academic or formal writing to describe research, methods, or results.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9246625105539957,
    "similarity_var": 0.00022155945428023767,
    "score_fuzz": 0.97,
    "score_detection": 0.79,
    "score_embedding": 0.7684,
    "total_score": 0.8428,
    "x": 10.397573471069336,
    "y": -0.9602429866790771,
    "cluster_id": -1
  },
  {
    "feature_id": 146,
    "explanation_index": 1,
    "text": "Verbs related to conveying information, such as describing, showing, explaining, demonstrating, detailing, and defining, often appear in contexts involving exposition, analysis, or presentation of data, concepts, or processes.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9246625105539957,
    "similarity_var": 0.00022155945428023767,
    "score_fuzz": 0.97,
    "score_detection": 0.88,
    "score_embedding": 0.6849999999999999,
    "total_score": 0.8450000000000001,
    "x": 10.434228897094727,
    "y": -0.9457924962043762,
    "cluster_id": -1
  },
  {
    "feature_id": 146,
    "explanation_index": 2,
    "text": "The text repeatedly uses verbs that signal explanation, description, demonstration, or illustration, especially in academic or technical contexts.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9246625105539957,
    "similarity_var": 0.00022155945428023767,
    "score_fuzz": 0.95,
    "score_detection": 0.875,
    "score_embedding": 0.685625,
    "total_score": 0.836875,
    "x": 10.347015380859375,
    "y": -0.8700657486915588,
    "cluster_id": 14
  },
  {
    "feature_id": 147,
    "explanation_index": 0,
    "text": "Mathematical operations and symbols, including addition, exponentiation, and comparison, often used in equations and formulas.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8783062696456909,
    "similarity_var": 5.141743765572452e-05,
    "score_fuzz": 0.69,
    "score_detection": 0.6,
    "score_embedding": 0.434,
    "total_score": 0.5746666666666667,
    "x": 9.394807815551758,
    "y": 8.539620399475098,
    "cluster_id": 65
  },
  {
    "feature_id": 147,
    "explanation_index": 1,
    "text": "The symbol \\\"+\\\" and its variants (e.g., \\\"+\\\", \\\"++\\\", \\\"+*\\\", \\\"\u00b1\\\", \\\"^+\\\", \\\"\u00d7\\\", \\\"->\\\", \\\"\u00b1\\\") are used in mathematical and technical contexts to denote operations, relationships, or annotations, with high activation indicating their importance in structural or semantic parsing.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8783062696456909,
    "similarity_var": 5.141743765572452e-05,
    "score_fuzz": 0.73,
    "score_detection": 0.66,
    "score_embedding": 0.37812500000000004,
    "total_score": 0.5893750000000001,
    "x": 9.551950454711914,
    "y": 6.9961628913879395,
    "cluster_id": 21
  },
  {
    "feature_id": 147,
    "explanation_index": 2,
    "text": "Tokens that represent addition or the plus sign in various forms.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8783062696456909,
    "similarity_var": 5.141743765572452e-05,
    "score_fuzz": 0.9,
    "score_detection": 0.8,
    "score_embedding": 0.38437499999999997,
    "total_score": 0.6947916666666667,
    "x": 10.547872543334961,
    "y": 5.822363376617432,
    "cluster_id": -1
  },
  {
    "feature_id": 148,
    "explanation_index": 0,
    "text": "Prepositions, articles, and adjectives often precede nouns, and sometimes verbs or adverbs, in various contexts, including descriptive phrases, comparisons, and explanations.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.885714034239451,
    "similarity_var": 0.0003826629435468791,
    "score_fuzz": 0.67,
    "score_detection": 0.49,
    "score_embedding": 0.45399999999999996,
    "total_score": 0.538,
    "x": 12.926997184753418,
    "y": 0.2542153000831604,
    "cluster_id": 43
  },
  {
    "feature_id": 148,
    "explanation_index": 1,
    "text": "Prepositions and determiners (such as \\\"of\\\", \\\"the\\\", \\\"in\\\", \\\"on\\\") frequently appear in context with nouns or phrases that specify spatial, temporal, or relational connections, often forming part of common collocations or grammatical structures.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.885714034239451,
    "similarity_var": 0.0003826629435468791,
    "score_fuzz": 0.63,
    "score_detection": 0.54,
    "score_embedding": 0.37125,
    "total_score": 0.51375,
    "x": 12.402912139892578,
    "y": -0.4998771548271179,
    "cluster_id": 63
  },
  {
    "feature_id": 148,
    "explanation_index": 2,
    "text": "The model highlights short, high\u2011frequency function words and small modifiers that form common phrases or idioms\u2014especially prepositions, articles, conjunctions, and comparative suffixes\u2014as well as nouns that denote objects or places within those phrases.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.885714034239451,
    "similarity_var": 0.0003826629435468791,
    "score_fuzz": 0.525,
    "score_detection": 0.45,
    "score_embedding": 0.5331250000000001,
    "total_score": 0.5027083333333334,
    "x": 8.460641860961914,
    "y": 3.308300733566284,
    "cluster_id": -1
  },
  {
    "feature_id": 149,
    "explanation_index": 0,
    "text": "Fragments of words or abbreviations, often indicating a prefix or suffix, sometimes denoting a proper noun, technical term, or abbreviation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9049198627471924,
    "similarity_var": 0.0003261343062774813,
    "score_fuzz": 0.7,
    "score_detection": 0.61,
    "score_embedding": 0.5267999999999999,
    "total_score": 0.6122666666666666,
    "x": 7.542629241943359,
    "y": 2.620065689086914,
    "cluster_id": -1
  },
  {
    "feature_id": 149,
    "explanation_index": 1,
    "text": "Short, capitalized or lowercase substrings that form parts of proper nouns, technical terms, or abbreviations, often appearing in contexts involving code, scientific notation, or named entities.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9049198627471924,
    "similarity_var": 0.0003261343062774813,
    "score_fuzz": 0.67,
    "score_detection": 0.42,
    "score_embedding": 0.525,
    "total_score": 0.5383333333333334,
    "x": 7.720325946807861,
    "y": 2.4495534896850586,
    "cluster_id": -1
  },
  {
    "feature_id": 149,
    "explanation_index": 2,
    "text": "The highlighted fragments are typically partial words or identifiers that carry semantic weight\u2014often prefixes, suffixes, or internal substrings of nouns, proper names, or code tokens\u2014used to flag key concepts or categories.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9049198627471924,
    "similarity_var": 0.0003261343062774813,
    "score_fuzz": 0.65,
    "score_detection": 0.3,
    "score_embedding": 0.47750000000000004,
    "total_score": 0.47583333333333333,
    "x": 15.557869911193848,
    "y": 7.238028049468994,
    "cluster_id": 19
  },
  {
    "feature_id": 150,
    "explanation_index": 0,
    "text": "Tokens that are part of proper nouns, technical terms, or descriptive words, often related to technology, architecture, or design.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8880667686462402,
    "similarity_var": 0.0009386447256005681,
    "score_fuzz": 0.65,
    "score_detection": 0.55,
    "score_embedding": 0.5676,
    "total_score": 0.5892000000000001,
    "x": 10.165326118469238,
    "y": 4.241726875305176,
    "cluster_id": 1
  },
  {
    "feature_id": 150,
    "explanation_index": 1,
    "text": "Commonly activated tokens include suffixes like \\\"er\\\", \\\"ing\\\", \\\"ed\\\", and \\\"s\\\", as well as words related to technical specifications, architectural terms, and descriptive adjectives, often appearing in contexts involving design, technology, or physical spaces.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8880667686462402,
    "similarity_var": 0.0009386447256005681,
    "score_fuzz": 0.7,
    "score_detection": 0.64,
    "score_embedding": 0.5918749999999999,
    "total_score": 0.6439583333333333,
    "x": 10.024364471435547,
    "y": 3.393233060836792,
    "cluster_id": -1
  },
  {
    "feature_id": 150,
    "explanation_index": 2,
    "text": "The highlighted tokens are the semantic core of each sentence\u2014primarily nouns and adjectives (often part of product or brand names or descriptive phrases) that carry the main meaning and define the subject, object, or attribute.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8880667686462402,
    "similarity_var": 0.0009386447256005681,
    "score_fuzz": 0.775,
    "score_detection": 0.7,
    "score_embedding": 0.40187500000000004,
    "total_score": 0.625625,
    "x": 15.166152954101562,
    "y": 4.021279335021973,
    "cluster_id": 22
  },
  {
    "feature_id": 151,
    "explanation_index": 0,
    "text": "Verbs or nouns representing actions, processes, or states that are often formal or technical in nature, and may be related to research, law, business, or other specialized domains.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8158083558082581,
    "similarity_var": 0.0002159308992967605,
    "score_fuzz": 0.5,
    "score_detection": 0.32,
    "score_embedding": 0.2272,
    "total_score": 0.3490666666666667,
    "x": 10.518277168273926,
    "y": -0.7702786922454834,
    "cluster_id": 14
  },
  {
    "feature_id": 151,
    "explanation_index": 1,
    "text": "Words ending in common suffixes like -ed, -ing, -tion, -ance, -ment, -ity, -ism, -or, -er, -al, -ive, -able, -ible, -ous, -ful, -less, -ly, -ness, -ship, -hood, -ism, -ist, -ity, -ance, -ence, -ancy, -ency, -ancy, -ency, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition, -ation, -ition",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8158083558082581,
    "similarity_var": 0.0002159308992967605,
    "score_fuzz": 0.67,
    "score_detection": 0.38,
    "score_embedding": 0.209375,
    "total_score": 0.41979166666666673,
    "x": 8.538227081298828,
    "y": 2.3832859992980957,
    "cluster_id": 66
  },
  {
    "feature_id": 151,
    "explanation_index": 2,
    "text": "The activations consistently target the core lexical items\u2014verbs, nouns, adjectives, and sometimes morphological suffixes\u2014that form the semantic nucleus of idiomatic or collocational phrases, while function words are largely ignored.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8158083558082581,
    "similarity_var": 0.0002159308992967605,
    "score_fuzz": 0.725,
    "score_detection": 0.5,
    "score_embedding": 0.28374999999999995,
    "total_score": 0.5029166666666667,
    "x": 12.871757507324219,
    "y": 3.1980795860290527,
    "cluster_id": 82
  },
  {
    "feature_id": 152,
    "explanation_index": 0,
    "text": "Proper nouns, abbreviations, and technical terms, often representing names of institutions, locations, and organizations, as well as medical and technical terminology.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8909642696380615,
    "similarity_var": 0.00022484832848827332,
    "score_fuzz": 0.56,
    "score_detection": 0.52,
    "score_embedding": 0.426,
    "total_score": 0.502,
    "x": 7.520781517028809,
    "y": -0.3668891191482544,
    "cluster_id": -1
  },
  {
    "feature_id": 152,
    "explanation_index": 1,
    "text": "Named entities, particularly proper nouns and acronyms, often appear in isolation or as partial tokens, with high activation values when they represent specific locations, institutions, or technical terms.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8909642696380615,
    "similarity_var": 0.00022484832848827332,
    "score_fuzz": 0.52,
    "score_detection": 0.44,
    "score_embedding": 0.43562500000000004,
    "total_score": 0.4652083333333333,
    "x": 6.810510635375977,
    "y": -0.7778581976890564,
    "cluster_id": 84
  },
  {
    "feature_id": 152,
    "explanation_index": 2,
    "text": "The highlighted tokens are usually nouns or proper nouns that belong to named entities, technical terms, or key multi\u2011word expressions, and occasionally morphological suffixes that signal grammatical roles; these tokens carry the core semantic or contextual weight of the sentence.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8909642696380615,
    "similarity_var": 0.00022484832848827332,
    "score_fuzz": 0.65,
    "score_detection": 0.4,
    "score_embedding": 0.455,
    "total_score": 0.5016666666666667,
    "x": 14.628762245178223,
    "y": 3.980821132659912,
    "cluster_id": 11
  },
  {
    "feature_id": 153,
    "explanation_index": 0,
    "text": "Nouns representing concepts related to relationships, life events, and institutions, often in a formal or official context.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.88197127978007,
    "similarity_var": 0.0011324796698070193,
    "score_fuzz": 0.83,
    "score_detection": 0.73,
    "score_embedding": 0.6508,
    "total_score": 0.7369333333333333,
    "x": 8.064736366271973,
    "y": 0.06579894572496414,
    "cluster_id": -1
  },
  {
    "feature_id": 153,
    "explanation_index": 1,
    "text": "Nouns denoting social or personal relationships, life events, or institutional structures, often associated with human experiences such as marriage, divorce, birth, love, and family roles, with high activation values indicating their semantic centrality in context.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.88197127978007,
    "similarity_var": 0.0011324796698070193,
    "score_fuzz": 0.76,
    "score_detection": 0.7,
    "score_embedding": 0.48375,
    "total_score": 0.6479166666666667,
    "x": 8.126317977905273,
    "y": -0.04722670838236809,
    "cluster_id": -1
  },
  {
    "feature_id": 153,
    "explanation_index": 2,
    "text": "Key content words that denote relationships, events, or actions\u2014mostly nouns or noun phrases\u2014are consistently highlighted as important.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.88197127978007,
    "similarity_var": 0.0011324796698070193,
    "score_fuzz": 0.775,
    "score_detection": 0.5,
    "score_embedding": 0.45562500000000006,
    "total_score": 0.5768749999999999,
    "x": 16.570018768310547,
    "y": 3.54959774017334,
    "cluster_id": -1
  },
  {
    "feature_id": 154,
    "explanation_index": 0,
    "text": "Prepositions and conjunctions, often used to connect clauses or phrases, and sometimes preceding or following a quotation mark, or used in a formal or technical context.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8485267162322998,
    "similarity_var": 0.00037869043322539636,
    "score_fuzz": 0.45,
    "score_detection": 0.4,
    "score_embedding": 0.3872,
    "total_score": 0.41240000000000004,
    "x": 12.137489318847656,
    "y": 0.13165491819381714,
    "cluster_id": 9
  },
  {
    "feature_id": 154,
    "explanation_index": 1,
    "text": "Common function words and morphological suffixes that appear in syntactic constructions involving comparison, direction, possession, or modification, often signaling grammatical relationships or semantic roles.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8485267162322998,
    "similarity_var": 0.00037869043322539636,
    "score_fuzz": 0.48,
    "score_detection": 0.37,
    "score_embedding": 0.5656250000000002,
    "total_score": 0.47187500000000004,
    "x": 10.591137886047363,
    "y": 1.4220623970031738,
    "cluster_id": 26
  },
  {
    "feature_id": 154,
    "explanation_index": 2,
    "text": "The highlighted tokens are typically short, high\u2011frequency function words or the core lexical items of common collocations and idioms, serving as the key elements that give a phrase its grammatical or semantic weight.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8485267162322998,
    "similarity_var": 0.00037869043322539636,
    "score_fuzz": 0.55,
    "score_detection": 0.25,
    "score_embedding": 0.60375,
    "total_score": 0.4679166666666667,
    "x": 14.107229232788086,
    "y": 3.771217107772827,
    "cluster_id": 67
  },
  {
    "feature_id": 155,
    "explanation_index": 0,
    "text": "Punctuation marks and common function words, often used to indicate negation, possession, or to begin a sentence.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8671135505040487,
    "similarity_var": 7.423788836844222e-05,
    "score_fuzz": 0.67,
    "score_detection": 0.81,
    "score_embedding": 0.4488,
    "total_score": 0.6429333333333332,
    "x": 7.860965728759766,
    "y": 6.665583610534668,
    "cluster_id": 32
  },
  {
    "feature_id": 155,
    "explanation_index": 1,
    "text": "The presence of negation markers (such as \\\"not\\\", \\\"n't\\\", \\\"non-\\\", \\\"no\\\") and pronouns (like \\\"I\\\", \\\"she\\\", \\\"it\\\") in close proximity to other grammatical or semantic elements, often signaling contrast, exclusion, or emphasis in context.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8671135505040487,
    "similarity_var": 7.423788836844222e-05,
    "score_fuzz": 0.75,
    "score_detection": 0.76,
    "score_embedding": 0.728125,
    "total_score": 0.7460416666666667,
    "x": 10.81498908996582,
    "y": 2.6886870861053467,
    "cluster_id": 46
  },
  {
    "feature_id": 155,
    "explanation_index": 2,
    "text": "the pattern: important tokens are function words, pronouns, conjunctions, prepositions, articles.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8671135505040487,
    "similarity_var": 7.423788836844222e-05,
    "score_fuzz": 0.75,
    "score_detection": 0.875,
    "score_embedding": 0.32562499999999994,
    "total_score": 0.6502083333333334,
    "x": 11.415966033935547,
    "y": 4.475631237030029,
    "cluster_id": 3
  },
  {
    "feature_id": 156,
    "explanation_index": 0,
    "text": "Adjectives and nouns that describe fundamental or essential concepts, often related to basic principles, core ideas, or elementary aspects of a subject, and sometimes used in academic or technical contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8892258207003275,
    "similarity_var": 0.0010754424091040783,
    "score_fuzz": 0.84,
    "score_detection": 0.56,
    "score_embedding": 0.6684,
    "total_score": 0.6894666666666667,
    "x": 8.43353271484375,
    "y": 0.791976273059845,
    "cluster_id": 54
  },
  {
    "feature_id": 156,
    "explanation_index": 1,
    "text": "The word \\\"basic\\\" and its variants (e.g., \\\"basics\\\", \\\"elementary\\\", \\\"essential\\\", \\\"core\\\", \\\"fundamental\\\") are frequently used to denote foundational or fundamental concepts, qualities, or components, often in educational, technical, or descriptive contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8892258207003275,
    "similarity_var": 0.0010754424091040783,
    "score_fuzz": 0.69,
    "score_detection": 0.62,
    "score_embedding": 0.73125,
    "total_score": 0.6804166666666666,
    "x": 10.005045890808105,
    "y": 2.515531063079834,
    "cluster_id": -1
  },
  {
    "feature_id": 156,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core nouns or adjectives that carry the main semantic load of each sentence\u2014often capitalized or part of a multi\u2011word phrase\u2014serving as the key concepts or terms that define the subject matter.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8892258207003275,
    "similarity_var": 0.0010754424091040783,
    "score_fuzz": 0.775,
    "score_detection": 0.525,
    "score_embedding": 0.673125,
    "total_score": 0.6577083333333333,
    "x": 15.066640853881836,
    "y": 3.973353624343872,
    "cluster_id": 22
  },
  {
    "feature_id": 157,
    "explanation_index": 0,
    "text": "Special characters, symbols, and keywords in programming languages and technical contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8883244395256042,
    "similarity_var": 0.00059879084112661,
    "score_fuzz": 0.37,
    "score_detection": 0.27,
    "score_embedding": 0.43479999999999996,
    "total_score": 0.3582666666666667,
    "x": 9.42699146270752,
    "y": 7.811375141143799,
    "cluster_id": 6
  },
  {
    "feature_id": 157,
    "explanation_index": 1,
    "text": "The presence of tokens that represent identifiers, delimiters, or syntactic elements in code or structured text, often appearing in contexts involving programming syntax, markup, or formatting.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8883244395256042,
    "similarity_var": 0.00059879084112661,
    "score_fuzz": 0.46,
    "score_detection": 0.3,
    "score_embedding": 0.56875,
    "total_score": 0.4429166666666666,
    "x": 10.70288372039795,
    "y": 6.298013210296631,
    "cluster_id": -1
  },
  {
    "feature_id": 157,
    "explanation_index": 2,
    "text": "The highlighted tokens are usually contiguous units that together form a meaningful phrase or code element\u2014idioms, comparative suffixes, nouns, identifiers, URLs, or other syntactic markers\u2014often bounded by whitespace or punctuation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8883244395256042,
    "similarity_var": 0.00059879084112661,
    "score_fuzz": 0.6,
    "score_detection": 0.4,
    "score_embedding": 0.625625,
    "total_score": 0.541875,
    "x": 14.83725643157959,
    "y": 4.702131271362305,
    "cluster_id": -1
  },
  {
    "feature_id": 159,
    "explanation_index": 0,
    "text": "Numerical values, often representing dates, times, or version numbers, and hexadecimal values.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.881453275680542,
    "similarity_var": 7.753106172240602e-05,
    "score_fuzz": 0.48,
    "score_detection": 0.4105263157894737,
    "score_embedding": 0.66,
    "total_score": 0.5168421052631579,
    "x": 6.953518390655518,
    "y": 8.73833179473877,
    "cluster_id": 29
  },
  {
    "feature_id": 159,
    "explanation_index": 1,
    "text": "The digit '0' and other digits frequently appear in numerical sequences, dates, identifiers, and code-related contexts, often as part of structured data, timestamps, or technical notation.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.881453275680542,
    "similarity_var": 7.753106172240602e-05,
    "score_fuzz": 0.45,
    "score_detection": 0.45,
    "score_embedding": 0.605625,
    "total_score": 0.501875,
    "x": 7.385071277618408,
    "y": 8.566579818725586,
    "cluster_id": 29
  },
  {
    "feature_id": 159,
    "explanation_index": 2,
    "text": "Numeric or alphanumeric tokens that encode identifiers, dates, times, or addresses.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.881453275680542,
    "similarity_var": 7.753106172240602e-05,
    "score_fuzz": 0.525,
    "score_detection": 0.35,
    "score_embedding": 0.64625,
    "total_score": 0.5070833333333333,
    "x": 7.610844135284424,
    "y": 8.419415473937988,
    "cluster_id": 29
  },
  {
    "feature_id": 160,
    "explanation_index": 0,
    "text": "Various programming-related terms and symbols, including function names, variable names, and operators, often used in the context of coding and software development.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8805000384648641,
    "similarity_var": 0.0005454469769535169,
    "score_fuzz": 0.55,
    "score_detection": 0.46,
    "score_embedding": 0.5548,
    "total_score": 0.5216,
    "x": 10.294731140136719,
    "y": 8.499910354614258,
    "cluster_id": -1
  },
  {
    "feature_id": 160,
    "explanation_index": 1,
    "text": "Common programming and markup syntax elements, including identifiers, operators, punctuation, and delimiters used in code contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8805000384648641,
    "similarity_var": 0.0005454469769535169,
    "score_fuzz": 0.51,
    "score_detection": 0.47,
    "score_embedding": 0.684375,
    "total_score": 0.5547916666666667,
    "x": 10.496574401855469,
    "y": 8.04417896270752,
    "cluster_id": -1
  },
  {
    "feature_id": 160,
    "explanation_index": 2,
    "text": "The highlighted tokens are code identifiers that refer to UI components or library functions, indicating that the important parts of the text are the names of functions or classes that perform UI actions.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8805000384648641,
    "similarity_var": 0.0005454469769535169,
    "score_fuzz": 0.5,
    "score_detection": 0.475,
    "score_embedding": 0.56,
    "total_score": 0.5116666666666667,
    "x": 13.798727989196777,
    "y": 6.530758380889893,
    "cluster_id": 8
  },
  {
    "feature_id": 161,
    "explanation_index": 0,
    "text": "Special characters and symbols used to denote parameters, return types, and other elements in programming documentation and code.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9086763064066569,
    "similarity_var": 0.00013177909450313841,
    "score_fuzz": 0.47,
    "score_detection": 0.5,
    "score_embedding": 0.4576,
    "total_score": 0.47586666666666666,
    "x": 9.604393005371094,
    "y": 7.771817207336426,
    "cluster_id": 6
  },
  {
    "feature_id": 161,
    "explanation_index": 1,
    "text": "The token sequences often represent code syntax elements such as parameter declarations, return types, and annotations in programming languages, with emphasis on identifiers, type names, and structural markers like brackets, colons, and special symbols.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9086763064066569,
    "similarity_var": 0.00013177909450313841,
    "score_fuzz": 0.41,
    "score_detection": 0.5,
    "score_embedding": 0.44125000000000003,
    "total_score": 0.45041666666666663,
    "x": 11.065380096435547,
    "y": 5.804262638092041,
    "cluster_id": -1
  },
  {
    "feature_id": 161,
    "explanation_index": 2,
    "text": "The highlighted words are code identifiers, parameter names, and language keywords that carry semantic weight in programming snippets, often surrounded by delimiters and preceded by whitespace or punctuation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9086763064066569,
    "similarity_var": 0.00013177909450313841,
    "score_fuzz": 0.425,
    "score_detection": 0.5,
    "score_embedding": 0.460625,
    "total_score": 0.46187500000000004,
    "x": 14.082552909851074,
    "y": 6.614899635314941,
    "cluster_id": -1
  },
  {
    "feature_id": 162,
    "explanation_index": 0,
    "text": "Indefinite and definite articles in various languages, often used to introduce a noun.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8329610427220663,
    "similarity_var": 0.0024006468518496466,
    "score_fuzz": 0.82,
    "score_detection": 0.46,
    "score_embedding": 0.6464000000000001,
    "total_score": 0.6421333333333333,
    "x": 12.808259963989258,
    "y": 0.5668939352035522,
    "cluster_id": 34
  },
  {
    "feature_id": 162,
    "explanation_index": 1,
    "text": "The use of indefinite articles (\\\"un\\\", \\\"une\\\", \\\"en\\\", \\\"ein\\\", \\\"a\\\", \\\"one\\\") or quantifiers (\\\"bir\\\", \\\"une\\\", \\\"deux\\\", \\\"un\\\", \\\"una\\\", \\\"um\\\") preceding nouns, often in contexts involving singular countable entities, abstract concepts, or general references, with high activation indicating their role in grammatical structure and semantic specificity.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8329610427220663,
    "similarity_var": 0.0024006468518496466,
    "score_fuzz": 0.92,
    "score_detection": 0.52,
    "score_embedding": 0.731875,
    "total_score": 0.7239583333333334,
    "x": 12.744022369384766,
    "y": 0.5860348343849182,
    "cluster_id": 34
  },
  {
    "feature_id": 162,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8329610427220663,
    "similarity_var": 0.0024006468518496466,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.6049999999999999,
    "total_score": 0.535,
    "x": -5.911647796630859,
    "y": 15.997121810913086,
    "cluster_id": 10
  },
  {
    "feature_id": 163,
    "explanation_index": 0,
    "text": "Punctuation marks and special characters used to separate or denote different sections, items, or formatting in text, often indicating a transition or a new element.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8415151238441467,
    "similarity_var": 0.003030614185085767,
    "score_fuzz": 0.5,
    "score_detection": 0.46,
    "score_embedding": 0.38520000000000004,
    "total_score": 0.44839999999999997,
    "x": 8.333114624023438,
    "y": 6.950176239013672,
    "cluster_id": 36
  },
  {
    "feature_id": 163,
    "explanation_index": 1,
    "text": "The presence of punctuation, delimiters, or formatting symbols (such as parentheses, brackets, quotation marks, or special characters) that mark structural or syntactic boundaries in text, often indicating formatting, mathematical expressions, or markup.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8415151238441467,
    "similarity_var": 0.003030614185085767,
    "score_fuzz": 0.38,
    "score_detection": 0.33,
    "score_embedding": 0.33374999999999994,
    "total_score": 0.34791666666666665,
    "x": 9.69241714477539,
    "y": 6.9070940017700195,
    "cluster_id": 21
  },
  {
    "feature_id": 163,
    "explanation_index": 2,
    "text": "the patterns in the given examples.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8415151238441467,
    "similarity_var": 0.003030614185085767,
    "score_fuzz": 0.425,
    "score_detection": 0.35,
    "score_embedding": 0.22312500000000002,
    "total_score": 0.33270833333333333,
    "x": 5.1576433181762695,
    "y": 9.953681945800781,
    "cluster_id": 58
  },
  {
    "feature_id": 164,
    "explanation_index": 0,
    "text": "Verbs that describe actions, often in a neutral or objective tone, and are frequently used in formal or informative writing.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8819414178530375,
    "similarity_var": 0.00020440901826251294,
    "score_fuzz": 0.84,
    "score_detection": 0.47,
    "score_embedding": 0.5988,
    "total_score": 0.6362666666666666,
    "x": 10.499656677246094,
    "y": -0.7733203768730164,
    "cluster_id": 14
  },
  {
    "feature_id": 164,
    "explanation_index": 1,
    "text": "Verbs indicating actions, states, or processes, often related to performing, causing, or experiencing an event, with high activation values when describing dynamic or causal relationships.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8819414178530375,
    "similarity_var": 0.00020440901826251294,
    "score_fuzz": 0.9,
    "score_detection": 0.66,
    "score_embedding": 0.57625,
    "total_score": 0.7120833333333333,
    "x": 10.605069160461426,
    "y": -0.9334549307823181,
    "cluster_id": 14
  },
  {
    "feature_id": 164,
    "explanation_index": 2,
    "text": "The highlighted words are the main verbs that carry the core action or state of each sentence, showing the model\u2019s focus on predicate words for semantic content.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8819414178530375,
    "similarity_var": 0.00020440901826251294,
    "score_fuzz": 0.925,
    "score_detection": 0.825,
    "score_embedding": 0.46875,
    "total_score": 0.7395833333333334,
    "x": 16.537967681884766,
    "y": 3.626948356628418,
    "cluster_id": 20
  },
  {
    "feature_id": 167,
    "explanation_index": 0,
    "text": "Prepositions, conjunctions, and adverbs, often used to connect words or phrases, and sometimes nouns or adjectives that convey a sense of comparison, measurement, or evaluation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8368263244628906,
    "similarity_var": 0.00274514033653143,
    "score_fuzz": 0.57,
    "score_detection": 0.54,
    "score_embedding": 0.354,
    "total_score": 0.488,
    "x": 12.109925270080566,
    "y": -0.06924981623888016,
    "cluster_id": 9
  },
  {
    "feature_id": 167,
    "explanation_index": 1,
    "text": "Common multi-word phrases involving prepositions (e.g., \\\"to\\\", \\\"with\\\", \\\"on\\\", \\\"at\\\", \\\"in\\\") or comparative structures (e.g., \\\"than\\\", \\\"more\\\", \\\"less\\\") that function as grammatical connectors or modifiers in evaluative or descriptive contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8368263244628906,
    "similarity_var": 0.00274514033653143,
    "score_fuzz": 0.51,
    "score_detection": 0.58,
    "score_embedding": 0.379375,
    "total_score": 0.4897916666666666,
    "x": 12.344236373901367,
    "y": -0.4861312210559845,
    "cluster_id": 63
  },
  {
    "feature_id": 167,
    "explanation_index": 2,
    "text": "The highlighted words are typically the main content words\u2014nouns, noun phrases, or key adjectives\u2014that carry the core semantic meaning of the sentence, often serving as subjects, objects, or central descriptors. They are the words the model deems most important for understanding the sentence.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8368263244628906,
    "similarity_var": 0.00274514033653143,
    "score_fuzz": 0.425,
    "score_detection": 0.55,
    "score_embedding": 0.38375,
    "total_score": 0.4529166666666667,
    "x": 16.69099235534668,
    "y": 3.6586270332336426,
    "cluster_id": 20
  },
  {
    "feature_id": 168,
    "explanation_index": 0,
    "text": "Verbs in various languages, often in the context of a sentence or phrase, sometimes with a focus on the verb's conjugation or tense.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8154305617014567,
    "similarity_var": 0.0017582378236235107,
    "score_fuzz": 0.73,
    "score_detection": 0.68,
    "score_embedding": 0.44079999999999997,
    "total_score": 0.6169333333333333,
    "x": 10.542508125305176,
    "y": -0.776738703250885,
    "cluster_id": 14
  },
  {
    "feature_id": 168,
    "explanation_index": 1,
    "text": "Common suffixes and function words in multi-lingual text, often part of verb conjugations, prepositions, or grammatical markers, with low individual token importance but high contextual relevance in morphological patterns.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8154305617014567,
    "similarity_var": 0.0017582378236235107,
    "score_fuzz": 0.68,
    "score_detection": 0.62,
    "score_embedding": 0.490625,
    "total_score": 0.5968749999999999,
    "x": 10.458124160766602,
    "y": 1.6760814189910889,
    "cluster_id": -1
  },
  {
    "feature_id": 168,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8154305617014567,
    "similarity_var": 0.0017582378236235107,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.5125,
    "total_score": 0.5041666666666667,
    "x": -7.9163079261779785,
    "y": 9.143745422363281,
    "cluster_id": 52
  },
  {
    "feature_id": 169,
    "explanation_index": 0,
    "text": "Verbs or phrases indicating assistance, support, or aid, often in the form of helping, assisting, or supporting someone or something.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9267432689666748,
    "similarity_var": 2.101350711095999e-05,
    "score_fuzz": 0.88,
    "score_detection": 0.75,
    "score_embedding": 0.5888,
    "total_score": 0.7395999999999999,
    "x": 10.650766372680664,
    "y": 0.03710891306400299,
    "cluster_id": -1
  },
  {
    "feature_id": 169,
    "explanation_index": 1,
    "text": "The word \\\"help\\\" and its variants frequently appear in contexts involving support, assistance, or enabling actions, often followed by a beneficiary (e.g., \\\"you\\\", \\\"them\\\", \\\"businesses\\\") or a purpose (e.g., \\\"to\\\", \\\"with\\\"), indicating a supportive or facilitative role.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9267432689666748,
    "similarity_var": 2.101350711095999e-05,
    "score_fuzz": 0.87,
    "score_detection": 0.84,
    "score_embedding": 0.6456249999999999,
    "total_score": 0.7852083333333333,
    "x": 10.69762897491455,
    "y": 0.19407714903354645,
    "cluster_id": -1
  },
  {
    "feature_id": 169,
    "explanation_index": 2,
    "text": "The text repeatedly uses the verb \u201chelp\u201d and its variants, often paired with prepositions or objects, to signal offering assistance or support.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9267432689666748,
    "similarity_var": 2.101350711095999e-05,
    "score_fuzz": 0.725,
    "score_detection": 0.7,
    "score_embedding": 0.6484375,
    "total_score": 0.6911458333333332,
    "x": 10.733248710632324,
    "y": 0.14500612020492554,
    "cluster_id": -1
  },
  {
    "feature_id": 170,
    "explanation_index": 0,
    "text": "Proper nouns and specialized terms, often related to military, government, or technical fields, and sometimes indicating a formal or official context.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8639349142710367,
    "similarity_var": 0.0008282551361568203,
    "score_fuzz": 0.68,
    "score_detection": 0.52,
    "score_embedding": 0.7415999999999998,
    "total_score": 0.6472,
    "x": 7.768651008605957,
    "y": -0.6258120536804199,
    "cluster_id": 16
  },
  {
    "feature_id": 170,
    "explanation_index": 1,
    "text": "Compound military or organizational terms, often consisting of two or more words, where the second word is a key identifier (e.g., \\\"Signal Regiment\\\", \\\"Air Force\\\", \\\"Intelligence\\\"), and frequently appear in contexts involving defense, security, or structured institutions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8639349142710367,
    "similarity_var": 0.0008282551361568203,
    "score_fuzz": 0.67,
    "score_detection": 0.65,
    "score_embedding": 0.714375,
    "total_score": 0.678125,
    "x": 8.721546173095703,
    "y": 0.484953373670578,
    "cluster_id": -1
  },
  {
    "feature_id": 170,
    "explanation_index": 2,
    "text": "The highlighted portions are domain\u2011specific noun phrases\u2014often proper nouns or technical terms\u2014that carry the main semantic load of the sentence, and the activations confirm that the tokens within these phrases are the most salient for the model\u2019s behavior.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8639349142710367,
    "similarity_var": 0.0008282551361568203,
    "score_fuzz": 0.725,
    "score_detection": 0.55,
    "score_embedding": 0.7987500000000001,
    "total_score": 0.69125,
    "x": 15.301319122314453,
    "y": 4.748263359069824,
    "cluster_id": -1
  },
  {
    "feature_id": 171,
    "explanation_index": 0,
    "text": "Special characters and symbols used for various purposes such as citations, labels, and formatting in academic and technical writing, often denoted by symbols like '@', '[', ']', ':', and '<'.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8783522645632426,
    "similarity_var": 0.0005781979670926615,
    "score_fuzz": 0.48,
    "score_detection": 0.49,
    "score_embedding": 0.6056,
    "total_score": 0.5252,
    "x": 8.723318099975586,
    "y": 7.426036357879639,
    "cluster_id": 4
  },
  {
    "feature_id": 171,
    "explanation_index": 1,
    "text": "Delimiters and special syntax markers used in code, documentation, and markup languages, often indicating structure, formatting, or references.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8783522645632426,
    "similarity_var": 0.0005781979670926615,
    "score_fuzz": 0.49,
    "score_detection": 0.48,
    "score_embedding": 0.416875,
    "total_score": 0.4622916666666666,
    "x": 9.90211296081543,
    "y": 7.155320167541504,
    "cluster_id": -1
  },
  {
    "feature_id": 171,
    "explanation_index": 2,
    "text": "The highlighted tokens are typically short identifiers or keywords that function as keys, labels, or delimiters in code, URLs, or markup, often appearing adjacent to punctuation or within paths.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8783522645632426,
    "similarity_var": 0.0005781979670926615,
    "score_fuzz": 0.525,
    "score_detection": 0.275,
    "score_embedding": 0.49749999999999994,
    "total_score": 0.43249999999999994,
    "x": 13.706703186035156,
    "y": 5.958011627197266,
    "cluster_id": -1
  },
  {
    "feature_id": 172,
    "explanation_index": 0,
    "text": "Phrases or words indicating movement or direction, often involving a reversal or return to a previous state or location.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9238813519477844,
    "similarity_var": 0.00011088403103324633,
    "score_fuzz": 0.95,
    "score_detection": 0.86,
    "score_embedding": 0.7632,
    "total_score": 0.8577333333333333,
    "x": 11.575397491455078,
    "y": -0.8776734471321106,
    "cluster_id": 13
  },
  {
    "feature_id": 172,
    "explanation_index": 1,
    "text": "The word \\\"back\\\" or related forms like \\\"returned\\\", \\\"returning\\\", \\\"backtrack\\\", or \\\"payback\\\" frequently appear in contexts involving movement, reversion, or reestablishment to a previous state, location, or condition, often paired with prepositions like \\\"to\\\" or \\\"into\\\".",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9238813519477844,
    "similarity_var": 0.00011088403103324633,
    "score_fuzz": 0.94,
    "score_detection": 0.92,
    "score_embedding": 0.900625,
    "total_score": 0.9202083333333334,
    "x": 11.7035551071167,
    "y": -0.8398523330688477,
    "cluster_id": 13
  },
  {
    "feature_id": 172,
    "explanation_index": 2,
    "text": "The text repeatedly uses the word \u201cback\u201d and its variants (return, backtracking, back up, etc.) to signal a return, reversal, or movement to a prior state, often appearing in prepositional phrases such as \u201cback to,\u201d \u201creturn to,\u201d or as part of compound verbs.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9238813519477844,
    "similarity_var": 0.00011088403103324633,
    "score_fuzz": 1.0,
    "score_detection": 0.925,
    "score_embedding": 0.845625,
    "total_score": 0.9235416666666666,
    "x": 11.61533260345459,
    "y": -0.9100778698921204,
    "cluster_id": 13
  },
  {
    "feature_id": 173,
    "explanation_index": 0,
    "text": "Tokens often representing titles, versions, or labels in academic, technical, or formal contexts, frequently accompanied by numbers, abbreviations, or special characters.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8798359235127767,
    "similarity_var": 0.00027400094586798533,
    "score_fuzz": 0.67,
    "score_detection": 0.77,
    "score_embedding": 0.6444,
    "total_score": 0.6948,
    "x": 10.19107723236084,
    "y": 4.775982856750488,
    "cluster_id": -1
  },
  {
    "feature_id": 173,
    "explanation_index": 1,
    "text": "Common patterns include identifiers for technical or formal entities such as software versions, document volumes, licenses, and file paths, often involving abbreviations, numerical suffixes, or structured naming conventions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8798359235127767,
    "similarity_var": 0.00027400094586798533,
    "score_fuzz": 0.6,
    "score_detection": 0.7,
    "score_embedding": 0.72125,
    "total_score": 0.67375,
    "x": 10.571820259094238,
    "y": 6.847051620483398,
    "cluster_id": -1
  },
  {
    "feature_id": 173,
    "explanation_index": 2,
    "text": "The highlighted words are formal reference terms or technical identifiers that appear in citations, code, or legal statements, and they carry high importance for the model\u2019s behavior.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8798359235127767,
    "similarity_var": 0.00027400094586798533,
    "score_fuzz": 0.5,
    "score_detection": 0.55,
    "score_embedding": 0.714375,
    "total_score": 0.588125,
    "x": 16.55967140197754,
    "y": 3.8344502449035645,
    "cluster_id": -1
  },
  {
    "feature_id": 174,
    "explanation_index": 0,
    "text": "Adjectives describing the inherent characteristics of something, often related to its natural state, origin, or composition.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8328783909479777,
    "similarity_var": 0.002201492527206818,
    "score_fuzz": 0.83,
    "score_detection": 0.59,
    "score_embedding": 0.5803999999999999,
    "total_score": 0.6668,
    "x": 8.714673042297363,
    "y": 1.0641800165176392,
    "cluster_id": -1
  },
  {
    "feature_id": 174,
    "explanation_index": 1,
    "text": "The term \\\"natural\\\" and its variants (e.g., \\\"natural\\\", \\\"nature\\\", \\\"naturally\\\") are frequently used to describe inherent, unaltered, or authentic qualities, often in contrast to artificial or human-made elements, and appear in contexts related to environment, biology, authenticity, and intrinsic properties.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8328783909479777,
    "similarity_var": 0.002201492527206818,
    "score_fuzz": 0.78,
    "score_detection": 0.76,
    "score_embedding": 0.7506249999999999,
    "total_score": 0.7635416666666667,
    "x": 8.588632583618164,
    "y": 1.100147008895874,
    "cluster_id": -1
  },
  {
    "feature_id": 174,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8328783909479777,
    "similarity_var": 0.002201492527206818,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.36000000000000004,
    "total_score": 0.45333333333333337,
    "x": -7.886962890625,
    "y": 9.172989845275879,
    "cluster_id": 52
  },
  {
    "feature_id": 175,
    "explanation_index": 0,
    "text": "Words related to spatial location, direction, or movement, including prepositions, adverbs, and nouns.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8395310441652933,
    "similarity_var": 0.00034194847059944143,
    "score_fuzz": 0.6,
    "score_detection": 0.6,
    "score_embedding": 0.4464,
    "total_score": 0.5488,
    "x": 11.88141918182373,
    "y": -0.5344412922859192,
    "cluster_id": -1
  },
  {
    "feature_id": 175,
    "explanation_index": 1,
    "text": "The word \\\"back\\\" and its derivatives (e.g., \\\"backed\\\", \\\"backlit\\\", \\\"backpacker\\\") frequently appear in contexts involving direction, return, or physical position, often as part of compound nouns or adjectives describing location, movement, or structure.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8395310441652933,
    "similarity_var": 0.00034194847059944143,
    "score_fuzz": 0.71,
    "score_detection": 0.66,
    "score_embedding": 0.6831250000000001,
    "total_score": 0.6843750000000001,
    "x": 11.70451545715332,
    "y": -0.8385970592498779,
    "cluster_id": 13
  },
  {
    "feature_id": 175,
    "explanation_index": 2,
    "text": "the highlighted tokens are typically short, highly polysemous words that can function as nouns, verbs, adjectives, or adverbs and appear across a wide range of contexts.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8395310441652933,
    "similarity_var": 0.00034194847059944143,
    "score_fuzz": 0.45,
    "score_detection": 0.35,
    "score_embedding": 0.23500000000000001,
    "total_score": 0.34500000000000003,
    "x": 14.941167831420898,
    "y": 3.8765487670898438,
    "cluster_id": -1
  },
  {
    "feature_id": 176,
    "explanation_index": 0,
    "text": "Special characters and symbols, often used as markers or indicators, such as hash signs, at signs, and greater-than or less-than symbols, which may serve various purposes like referencing, linking, or denoting specific sections or codes.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9110971490542094,
    "similarity_var": 8.934694935507854e-07,
    "score_fuzz": 0.57,
    "score_detection": 0.56,
    "score_embedding": 0.2316,
    "total_score": 0.45386666666666664,
    "x": 9.10944652557373,
    "y": 7.604611396789551,
    "cluster_id": 68
  },
  {
    "feature_id": 176,
    "explanation_index": 1,
    "text": "The symbol '#' and related patterns like '#', 'hash', 'HASH', '@#', and ' {#' are frequently used to denote identifiers, references, or metadata in code, documentation, or structured text, often indicating a location, label, or special token.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9110971490542094,
    "similarity_var": 8.934694935507854e-07,
    "score_fuzz": 0.84,
    "score_detection": 0.81,
    "score_embedding": 0.21062499999999998,
    "total_score": 0.6202083333333334,
    "x": 9.054594993591309,
    "y": 7.609795570373535,
    "cluster_id": 68
  },
  {
    "feature_id": 176,
    "explanation_index": 2,
    "text": "The highlighted tokens are typically symbols or identifiers that serve as markers or references in code, markup, or social\u2011media contexts\u2014hash symbols, API names, logging calls, and platform tags.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9110971490542094,
    "similarity_var": 8.934694935507854e-07,
    "score_fuzz": 0.65,
    "score_detection": 0.5,
    "score_embedding": 0.279375,
    "total_score": 0.47645833333333326,
    "x": 13.5905179977417,
    "y": 5.923260688781738,
    "cluster_id": -1
  },
  {
    "feature_id": 177,
    "explanation_index": 0,
    "text": "Punctuation marks and short function words that connect clauses or phrases, often used to indicate relationships between ideas or to provide additional information.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.849714994430542,
    "similarity_var": 0.00027858950671581323,
    "score_fuzz": 0.58,
    "score_detection": 0.68,
    "score_embedding": 0.33759999999999996,
    "total_score": 0.5325333333333333,
    "x": 7.831577301025391,
    "y": 6.511767387390137,
    "cluster_id": 32
  },
  {
    "feature_id": 177,
    "explanation_index": 1,
    "text": "Common linguistic patterns involving punctuation, abbreviations, compound terms, and contextual phrases that frequently appear in technical, legal, or structured text, often signaling specific syntactic or semantic roles such as emphasis, formatting, or reference.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.849714994430542,
    "similarity_var": 0.00027858950671581323,
    "score_fuzz": 0.33,
    "score_detection": 0.32,
    "score_embedding": 0.240625,
    "total_score": 0.296875,
    "x": 9.866406440734863,
    "y": 0.5567619204521179,
    "cluster_id": -1
  },
  {
    "feature_id": 177,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core lexical items of idiomatic or collocational phrases, often the main word in a multi\u2011word expression or a morphological marker that carries the key semantic content.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.849714994430542,
    "similarity_var": 0.00027858950671581323,
    "score_fuzz": 0.7,
    "score_detection": 0.825,
    "score_embedding": 0.26125000000000004,
    "total_score": 0.5954166666666666,
    "x": 15.031655311584473,
    "y": 4.1090240478515625,
    "cluster_id": 22
  },
  {
    "feature_id": 178,
    "explanation_index": 0,
    "text": "Special characters, symbols, and keywords used in programming languages, markup languages, and other technical contexts, often serving specific syntactic or semantic purposes.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9007788499196371,
    "similarity_var": 0.00011274098932369094,
    "score_fuzz": 0.53,
    "score_detection": 0.43,
    "score_embedding": 0.6076,
    "total_score": 0.5225333333333334,
    "x": 9.452580451965332,
    "y": 7.821432590484619,
    "cluster_id": 6
  },
  {
    "feature_id": 178,
    "explanation_index": 1,
    "text": "Patterns involving special characters, delimiters, or syntax elements in code, markup, or structured text, often indicating formatting, syntax highlighting, or structural boundaries.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9007788499196371,
    "similarity_var": 0.00011274098932369094,
    "score_fuzz": 0.63,
    "score_detection": 0.49,
    "score_embedding": 0.6806249999999999,
    "total_score": 0.6002083333333333,
    "x": 10.415626525878906,
    "y": 7.068846702575684,
    "cluster_id": 86
  },
  {
    "feature_id": 178,
    "explanation_index": 2,
    "text": "The highlighted tokens are short, keyword\u2011like or symbolic elements that belong to code or markup syntax\u2014such as language keywords, attribute names, or special symbols\u2014rather than ordinary natural\u2011language words. They are the syntactic units that directly influence program or document behavior.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9007788499196371,
    "similarity_var": 0.00011274098932369094,
    "score_fuzz": 0.45,
    "score_detection": 0.375,
    "score_embedding": 0.6531250000000001,
    "total_score": 0.4927083333333333,
    "x": 13.955367088317871,
    "y": 6.023723125457764,
    "cluster_id": -1
  },
  {
    "feature_id": 179,
    "explanation_index": 0,
    "text": "Various symbols and characters used in programming languages, mathematical expressions, and formatting, often serving as operators, delimiters, or indicators of specific functions or structures.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8623447418212891,
    "similarity_var": 0.0023169427491041006,
    "score_fuzz": 0.47,
    "score_detection": 0.58,
    "score_embedding": 0.4372,
    "total_score": 0.4957333333333333,
    "x": 9.519522666931152,
    "y": 7.945253372192383,
    "cluster_id": -1
  },
  {
    "feature_id": 179,
    "explanation_index": 1,
    "text": "The presence of special characters, symbols, or syntax elements used in programming, markup, or mathematical notation, often indicating structural or syntactic components in code, documentation, or formal expressions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8623447418212891,
    "similarity_var": 0.0023169427491041006,
    "score_fuzz": 0.46,
    "score_detection": 0.59,
    "score_embedding": 0.49375,
    "total_score": 0.5145833333333334,
    "x": 9.418889045715332,
    "y": 7.710389614105225,
    "cluster_id": 6
  },
  {
    "feature_id": 179,
    "explanation_index": 2,
    "text": "The highlighted tokens are contiguous sequences that together form a meaningful phrase or code fragment, often representing the core content of the sentence or snippet.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8623447418212891,
    "similarity_var": 0.0023169427491041006,
    "score_fuzz": 0.5,
    "score_detection": 0.325,
    "score_embedding": 0.4425,
    "total_score": 0.42250000000000004,
    "x": 14.04526424407959,
    "y": 5.8333306312561035,
    "cluster_id": -1
  },
  {
    "feature_id": 180,
    "explanation_index": 0,
    "text": "Special characters and symbols used in mathematical and scientific notation, often denoting subscripts, superscripts, or other typographical elements.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9147092501322428,
    "similarity_var": 0.00047751192123099726,
    "score_fuzz": 0.76,
    "score_detection": 0.71,
    "score_embedding": 0.6876000000000001,
    "total_score": 0.7192,
    "x": 9.0942964553833,
    "y": 8.015021324157715,
    "cluster_id": -1
  },
  {
    "feature_id": 180,
    "explanation_index": 1,
    "text": "Subscripts and superscripts in scientific notation, often denoting mathematical or physical variables, are frequently marked by special characters like \\\"sub\\\", \\\"sup\\\", \\\"^\\\", \\\"_\\\", or parentheses, and are typically associated with technical or mathematical expressions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9147092501322428,
    "similarity_var": 0.00047751192123099726,
    "score_fuzz": 0.73,
    "score_detection": 0.72,
    "score_embedding": 0.70875,
    "total_score": 0.7195833333333334,
    "x": 9.158476829528809,
    "y": 8.126660346984863,
    "cluster_id": 74
  },
  {
    "feature_id": 180,
    "explanation_index": 2,
    "text": "The highlighted tokens are components of domain\u2011specific phrases or symbols\u2014subscripts, degree signs, chemical symbols, mathematical notation, or noun phrases that name particular entities\u2014whose presence signals a technical or scientific context.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9147092501322428,
    "similarity_var": 0.00047751192123099726,
    "score_fuzz": 0.825,
    "score_detection": 0.525,
    "score_embedding": 0.6431250000000001,
    "total_score": 0.664375,
    "x": 13.648853302001953,
    "y": 4.687023639678955,
    "cluster_id": -1
  },
  {
    "feature_id": 181,
    "explanation_index": 0,
    "text": "Headings or titles of sections, often in a formal or informative text, such as guides, articles, or academic papers.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8782028754552206,
    "similarity_var": 8.207433100990456e-05,
    "score_fuzz": 0.85,
    "score_detection": 0.79,
    "score_embedding": 0.40480000000000005,
    "total_score": 0.6816000000000001,
    "x": 9.285510063171387,
    "y": 0.363923579454422,
    "cluster_id": -1
  },
  {
    "feature_id": 181,
    "explanation_index": 1,
    "text": "The token sequence \\\"<<\\\" followed by a title or section header, often indicating a thematic or structural division in the text, with the subsequent content typically introducing a new topic or subsection.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8782028754552206,
    "similarity_var": 8.207433100990456e-05,
    "score_fuzz": 0.8842105263157894,
    "score_detection": 0.71,
    "score_embedding": 0.306875,
    "total_score": 0.6336951754385965,
    "x": 9.458486557006836,
    "y": 6.432709693908691,
    "cluster_id": -1
  },
  {
    "feature_id": 181,
    "explanation_index": 2,
    "text": "The highlighted tokens are the main nouns or proper nouns that serve as section titles or headings, often capitalized and sometimes multi\u2011word, and they capture the core topic of each segment.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8782028754552206,
    "similarity_var": 8.207433100990456e-05,
    "score_fuzz": 0.75,
    "score_detection": 0.825,
    "score_embedding": 0.3675,
    "total_score": 0.6475,
    "x": 14.798768997192383,
    "y": 4.069045543670654,
    "cluster_id": -1
  },
  {
    "feature_id": 182,
    "explanation_index": 0,
    "text": "The word \\\"which\\\" is often used in comparative or interrogative contexts, typically to inquire about or distinguish between quantities, values, or options.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8752935330073038,
    "similarity_var": 0.0014376241234599102,
    "score_fuzz": 0.69,
    "score_detection": 0.59,
    "score_embedding": 0.23,
    "total_score": 0.5033333333333333,
    "x": 11.225483894348145,
    "y": 2.034715414047241,
    "cluster_id": 70
  },
  {
    "feature_id": 182,
    "explanation_index": 1,
    "text": "The word \\\"Which\\\" is frequently used in comparative questions involving numerical or quantitative values, often followed by \\\"is\\\" and a comparison operator, with high activation on \\\"Which\\\" and \\\"is\\\" when evaluating magnitude or proximity.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8752935330073038,
    "similarity_var": 0.0014376241234599102,
    "score_fuzz": 0.59,
    "score_detection": 0.54,
    "score_embedding": 0.15125,
    "total_score": 0.4270833333333333,
    "x": 11.219250679016113,
    "y": 2.2197442054748535,
    "cluster_id": -1
  },
  {
    "feature_id": 182,
    "explanation_index": 2,
    "text": "The highlighted tokens are usually key words that anchor the sentence\u2014often interrogative pronouns like \u201cWhich\u201d or \u201cwhich\u201d or specific nouns such as \u201cRoyal\u201d or objects/places that the sentence centers on.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8752935330073038,
    "similarity_var": 0.0014376241234599102,
    "score_fuzz": 0.6,
    "score_detection": 0.475,
    "score_embedding": 0.306875,
    "total_score": 0.460625,
    "x": 14.50052547454834,
    "y": 3.924135684967041,
    "cluster_id": 11
  },
  {
    "feature_id": 183,
    "explanation_index": 0,
    "text": "Verbs related to perception, appearance, or gaze, often in the form of present or past tense, sometimes used in idiomatic expressions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9006768067677816,
    "similarity_var": 0.0002730699585298011,
    "score_fuzz": 0.88,
    "score_detection": 0.77,
    "score_embedding": 0.5162,
    "total_score": 0.7220666666666666,
    "x": 10.41897964477539,
    "y": -1.243947148323059,
    "cluster_id": 23
  },
  {
    "feature_id": 183,
    "explanation_index": 1,
    "text": "The verb \\\"look\\\" and its inflections (e.g., \\\"looking\\\", \\\"looked\\\") are frequently activated when describing visual perception, appearance, or attention, often in contexts involving observation, evaluation, or anticipation.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9006768067677816,
    "similarity_var": 0.0002730699585298011,
    "score_fuzz": 0.72,
    "score_detection": 0.74,
    "score_embedding": 0.580625,
    "total_score": 0.6802083333333333,
    "x": 10.365612983703613,
    "y": -1.2938792705535889,
    "cluster_id": 23
  },
  {
    "feature_id": 183,
    "explanation_index": 2,
    "text": "The pattern: many words with \\\"look\\\" root.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9006768067677816,
    "similarity_var": 0.0002730699585298011,
    "score_fuzz": 0.7,
    "score_detection": 0.725,
    "score_embedding": 0.41937499999999994,
    "total_score": 0.6147916666666666,
    "x": 11.473477363586426,
    "y": 3.9813010692596436,
    "cluster_id": -1
  },
  {
    "feature_id": 184,
    "explanation_index": 0,
    "text": "Function words and common prepositions, conjunctions, and articles, often used to connect clauses or phrases, or to indicate relationships between entities.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9214374820391337,
    "similarity_var": 1.3801311437886297e-06,
    "score_fuzz": 0.59,
    "score_detection": 0.61,
    "score_embedding": 0.40559999999999996,
    "total_score": 0.5352,
    "x": 10.734575271606445,
    "y": 1.1768779754638672,
    "cluster_id": 26
  },
  {
    "feature_id": 184,
    "explanation_index": 1,
    "text": "Common function words and short phrases that serve grammatical or contextual\u8854\u63a5, such as prepositions, conjunctions, comparative markers, and discourse markers, often appear in high activation states when they connect ideas, modify meaning, or structure sentences.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9214374820391337,
    "similarity_var": 1.3801311437886297e-06,
    "score_fuzz": 0.57,
    "score_detection": 0.68,
    "score_embedding": 0.6206249999999999,
    "total_score": 0.6235416666666667,
    "x": 10.763727188110352,
    "y": 1.4489802122116089,
    "cluster_id": -1
  },
  {
    "feature_id": 184,
    "explanation_index": 2,
    "text": "The highlighted tokens are predominantly short, high\u2011frequency function words\u2014prepositions, conjunctions, determiners\u2014and a few key content words that signal grammatical relations or core semantic content; they serve as the connective tissue that links clauses and indicates relationships within the sentence.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9214374820391337,
    "similarity_var": 1.3801311437886297e-06,
    "score_fuzz": 0.625,
    "score_detection": 0.8,
    "score_embedding": 0.620625,
    "total_score": 0.6818750000000001,
    "x": 13.484044075012207,
    "y": 3.234741449356079,
    "cluster_id": 35
  },
  {
    "feature_id": 186,
    "explanation_index": 0,
    "text": "Adjectives and nouns describing scope, scale, or geography, often indicating something that is widespread, comprehensive, or related to the entire world.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8676853577295939,
    "similarity_var": 0.002784984673464268,
    "score_fuzz": 0.81,
    "score_detection": 0.78,
    "score_embedding": 0.7432,
    "total_score": 0.7777333333333334,
    "x": 8.361684799194336,
    "y": 0.15743321180343628,
    "cluster_id": 24
  },
  {
    "feature_id": 186,
    "explanation_index": 1,
    "text": "The word \\\"global\\\" and its variants (e.g., \\\"world\\\", \\\"global\\\", \\\"worldwide\\\") are frequently used to denote broad, widespread, or universal scope, often in contexts involving geography, scale, or systemic impact.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8676853577295939,
    "similarity_var": 0.002784984673464268,
    "score_fuzz": 0.78,
    "score_detection": 0.73,
    "score_embedding": 0.871875,
    "total_score": 0.7939583333333333,
    "x": 8.624777793884277,
    "y": 0.08081847429275513,
    "cluster_id": 24
  },
  {
    "feature_id": 186,
    "explanation_index": 2,
    "text": "The highlighted tokens are mainly nouns or adjectives that denote places, objects, or abstract concepts, often capitalized or part of proper names, and they serve as key semantic anchors across diverse contexts.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8676853577295939,
    "similarity_var": 0.002784984673464268,
    "score_fuzz": 0.7,
    "score_detection": 0.625,
    "score_embedding": 0.53,
    "total_score": 0.6183333333333333,
    "x": 14.492985725402832,
    "y": 4.094372749328613,
    "cluster_id": 11
  },
  {
    "feature_id": 187,
    "explanation_index": 0,
    "text": "Punctuation marks and quotation marks that indicate the start or end of a quotation, dialogue, or a spoken statement.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9097941120465597,
    "similarity_var": 0.00010196127044853002,
    "score_fuzz": 0.51,
    "score_detection": 0.41,
    "score_embedding": 0.45720000000000005,
    "total_score": 0.4590666666666667,
    "x": 8.256103515625,
    "y": 6.721872329711914,
    "cluster_id": 36
  },
  {
    "feature_id": 187,
    "explanation_index": 1,
    "text": "Frequent use of quotation marks, punctuation, and dialogue markers in conversational text, often indicating speech or direct quotes, with high activation on punctuation like \\\" and ? and structural elements like colons and quotation delimiters.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9097941120465597,
    "similarity_var": 0.00010196127044853002,
    "score_fuzz": 0.46,
    "score_detection": 0.44,
    "score_embedding": 0.61875,
    "total_score": 0.50625,
    "x": 8.394980430603027,
    "y": 6.645995140075684,
    "cluster_id": -1
  },
  {
    "feature_id": 187,
    "explanation_index": 2,
    "text": "The salient tokens are punctuation and quotation marks that delimit or emphasize speech, often appearing at the start or end of quoted text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9097941120465597,
    "similarity_var": 0.00010196127044853002,
    "score_fuzz": 0.575,
    "score_detection": 0.35,
    "score_embedding": 0.5956250000000001,
    "total_score": 0.506875,
    "x": 14.494123458862305,
    "y": 5.094669342041016,
    "cluster_id": -1
  },
  {
    "feature_id": 188,
    "explanation_index": 0,
    "text": "Proper nouns, names of people, places, and publications, as well as specific terms and phrases in academic and technical contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8658234675725301,
    "similarity_var": 0.0005651443035653693,
    "score_fuzz": 0.49,
    "score_detection": 0.43,
    "score_embedding": 0.5024000000000001,
    "total_score": 0.47413333333333335,
    "x": 7.532253265380859,
    "y": -0.8029995560646057,
    "cluster_id": 16
  },
  {
    "feature_id": 188,
    "explanation_index": 1,
    "text": "Common grammatical and structural elements in academic and formal text, including possessive markers, prepositions, punctuation, and proper nouns, often appearing in contextually specific or citation-related phrases.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8658234675725301,
    "similarity_var": 0.0005651443035653693,
    "score_fuzz": 0.58,
    "score_detection": 0.59,
    "score_embedding": 0.515625,
    "total_score": 0.561875,
    "x": 9.92943286895752,
    "y": 0.5350321531295776,
    "cluster_id": -1
  },
  {
    "feature_id": 188,
    "explanation_index": 2,
    "text": "The highlighted tokens are almost always the core lexical items of a named entity or a key noun phrase, or punctuation that signals a clause or phrase boundary. In other words, the model\u2019s activations concentrate on the words that carry the main semantic content of a phrase (often a proper name or a noun) and on the punctuation that separates or frames those phrases.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8658234675725301,
    "similarity_var": 0.0005651443035653693,
    "score_fuzz": 0.55,
    "score_detection": 0.45,
    "score_embedding": 0.62375,
    "total_score": 0.54125,
    "x": 14.986440658569336,
    "y": 4.752363204956055,
    "cluster_id": -1
  },
  {
    "feature_id": 189,
    "explanation_index": 0,
    "text": "Punctuation marks and short function words, often used to indicate a question, quotation, or a transition between clauses or sentences.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8548524777094523,
    "similarity_var": 0.00014362693558290907,
    "score_fuzz": 0.49,
    "score_detection": 0.78,
    "score_embedding": 0.19240000000000002,
    "total_score": 0.4874666666666667,
    "x": 7.8621296882629395,
    "y": 6.6080780029296875,
    "cluster_id": 32
  },
  {
    "feature_id": 189,
    "explanation_index": 1,
    "text": "Commonly activated tokens include words indicating negation, comparison, or evaluation (e.g., \\\"wrong\\\", \\\"not\\\", \\\"false\\\", \\\"mis\\\", \\\"deny\\\"), as well as pronouns and determiners (e.g., \\\"it\\\", \\\"the\\\", \\\"to\\\", \\\"I\\\") that serve grammatical or referential roles, often in contexts involving logical reasoning, correctness, or self-reference.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8548524777094523,
    "similarity_var": 0.00014362693558290907,
    "score_fuzz": 0.71,
    "score_detection": 0.78,
    "score_embedding": 0.19624999999999998,
    "total_score": 0.5620833333333334,
    "x": 10.364093780517578,
    "y": 3.141422748565674,
    "cluster_id": 50
  },
  {
    "feature_id": 189,
    "explanation_index": 2,
    "text": "The highlighted words are the core lexical items that anchor idiomatic expressions, comparative endings, or key nouns, and in broader contexts they are the function words that structure questions or statements.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8548524777094523,
    "similarity_var": 0.00014362693558290907,
    "score_fuzz": 0.75,
    "score_detection": 0.825,
    "score_embedding": 0.205625,
    "total_score": 0.5935416666666666,
    "x": 16.678180694580078,
    "y": 3.6259589195251465,
    "cluster_id": 20
  },
  {
    "feature_id": 190,
    "explanation_index": 0,
    "text": "Punctuation marks, mathematical symbols, and special characters, often used to denote specific formatting, mathematical operations, or to set off text.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8436278899510702,
    "similarity_var": 0.0015982057641047555,
    "score_fuzz": 0.3,
    "score_detection": 0.35,
    "score_embedding": 0.5544,
    "total_score": 0.40146666666666664,
    "x": 8.450655937194824,
    "y": 7.254644393920898,
    "cluster_id": 4
  },
  {
    "feature_id": 190,
    "explanation_index": 1,
    "text": "Common patterns include the use of delimiters, punctuation, and special symbols in technical or structured text, often surrounding identifiers, mathematical expressions, or markup elements, with frequent activation of tokens related to formatting, structure, or syntax.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8436278899510702,
    "similarity_var": 0.0015982057641047555,
    "score_fuzz": 0.36,
    "score_detection": 0.44,
    "score_embedding": 0.51625,
    "total_score": 0.43875000000000003,
    "x": 10.204671859741211,
    "y": 6.721524715423584,
    "cluster_id": 88
  },
  {
    "feature_id": 190,
    "explanation_index": 2,
    "text": "The highlighted fragments are the core content units that carry the main meaning of a phrase or code snippet\u2014typically contiguous words or symbols that form a coherent idiom, noun phrase, or functional element, while function words and extraneous tokens are omitted.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8436278899510702,
    "similarity_var": 0.0015982057641047555,
    "score_fuzz": 0.5,
    "score_detection": 0.35,
    "score_embedding": 0.62,
    "total_score": 0.49,
    "x": 15.598376274108887,
    "y": 7.333461761474609,
    "cluster_id": 19
  },
  {
    "feature_id": 192,
    "explanation_index": 0,
    "text": "Holiday-related terms and nouns, often including the names of holidays such as Christmas, Thanksgiving, and Halloween, as well as words associated with these holidays, like decorations, festivities, and traditions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9044555028279623,
    "similarity_var": 2.966759409004125e-05,
    "score_fuzz": 0.65,
    "score_detection": 0.6,
    "score_embedding": 0.35559999999999997,
    "total_score": 0.5352,
    "x": 8.110273361206055,
    "y": -0.22342193126678467,
    "cluster_id": -1
  },
  {
    "feature_id": 192,
    "explanation_index": 1,
    "text": "The word \\\"Christmas\\\" frequently appears in contexts related to holidays, celebrations, seasonal activities, and associated traditions, often linked to cultural, emotional, or commercial themes.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9044555028279623,
    "similarity_var": 2.966759409004125e-05,
    "score_fuzz": 0.66,
    "score_detection": 0.59,
    "score_embedding": 0.406875,
    "total_score": 0.5522916666666666,
    "x": 8.166062355041504,
    "y": -0.0667685717344284,
    "cluster_id": -1
  },
  {
    "feature_id": 192,
    "explanation_index": 2,
    "text": "The pattern: tokens like \\\"Christmas\\\", \\\"Christmas Day\\\", \\\"Christmas season\\\", \\\"Christmas holiday\\\", \\\"Christmas lights\\\", \\\"Christmas decorations\\\", etc.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9044555028279623,
    "similarity_var": 2.966759409004125e-05,
    "score_fuzz": 0.575,
    "score_detection": 0.55,
    "score_embedding": 0.460625,
    "total_score": 0.5285416666666667,
    "x": 11.39186954498291,
    "y": 4.391077995300293,
    "cluster_id": 3
  },
  {
    "feature_id": 193,
    "explanation_index": 0,
    "text": "Nouns representing concepts, objects, or processes, often in technical or scientific contexts, and sometimes part of a formal or specific terminology.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8711041609446207,
    "similarity_var": 0.0008407065080630916,
    "score_fuzz": 0.75,
    "score_detection": 0.76,
    "score_embedding": 0.6364,
    "total_score": 0.7154666666666666,
    "x": 8.073508262634277,
    "y": 0.35920849442481995,
    "cluster_id": 12
  },
  {
    "feature_id": 193,
    "explanation_index": 1,
    "text": "Common noun phrases or terms used in technical, medical, or academic contexts, often following prepositions like \\\"in the\\\" or \\\"during the,\\\" and frequently associated with specific domains such as biology, engineering, or social sciences.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8711041609446207,
    "similarity_var": 0.0008407065080630916,
    "score_fuzz": 0.76,
    "score_detection": 0.58,
    "score_embedding": 0.695625,
    "total_score": 0.6785416666666667,
    "x": 12.499950408935547,
    "y": -0.2856540381908417,
    "cluster_id": -1
  },
  {
    "feature_id": 193,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core nouns or noun phrases that carry the main semantic content of each sentence\u2014typically the subject, object, or key domain\u2011specific concept\u2014often a single word or a short phrase that is the focus of the clause.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8711041609446207,
    "similarity_var": 0.0008407065080630916,
    "score_fuzz": 0.75,
    "score_detection": 0.65,
    "score_embedding": 0.5843750000000001,
    "total_score": 0.6614583333333334,
    "x": 15.074499130249023,
    "y": 3.7072978019714355,
    "cluster_id": -1
  },
  {
    "feature_id": 195,
    "explanation_index": 0,
    "text": "Special characters or symbols used to denote items in a list, separate sections, or indicate specific formatting, often used in formal or technical writing.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9057353138923645,
    "similarity_var": 0.00047217248558932096,
    "score_fuzz": 0.82,
    "score_detection": 0.77,
    "score_embedding": 0.2112,
    "total_score": 0.6003999999999999,
    "x": 9.032876968383789,
    "y": 7.56780481338501,
    "cluster_id": 68
  },
  {
    "feature_id": 195,
    "explanation_index": 1,
    "text": "Special symbols and punctuation marks used as bullet points, section markers, or formatting indicators in structured text, often preceding or following content with semantic or typographic significance.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9057353138923645,
    "similarity_var": 0.00047217248558932096,
    "score_fuzz": 0.87,
    "score_detection": 0.79,
    "score_embedding": 0.31562500000000004,
    "total_score": 0.6585416666666667,
    "x": 8.394536972045898,
    "y": 7.04356050491333,
    "cluster_id": 37
  },
  {
    "feature_id": 195,
    "explanation_index": 2,
    "text": "The delimiters are used to flag key tokens or phrases across a variety of contexts\u2014bullet lists, code snippets, mathematical expressions, and prose. They typically appear immediately before or after the highlighted element and can be single symbols (e.g., \u201c\u2022\u201d, \u201c*\u201d, \u201c-\u201d) or short sequences (e.g., \u201c<<case>>\u201d, \u201c<<   >>\u201d). This pattern signals that the enclosed or adjacent text is of special importance or requires special handling.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9057353138923645,
    "similarity_var": 0.00047217248558932096,
    "score_fuzz": 0.7,
    "score_detection": 0.7,
    "score_embedding": 0.263125,
    "total_score": 0.554375,
    "x": 9.876967430114746,
    "y": 6.911235332489014,
    "cluster_id": 69
  },
  {
    "feature_id": 196,
    "explanation_index": 0,
    "text": "Verbs that express a relationship, action, or state, often in a formal or technical context, and frequently used in descriptive or explanatory writing.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8780169486999512,
    "similarity_var": 3.1360689177972745e-05,
    "score_fuzz": 0.85,
    "score_detection": 0.36,
    "score_embedding": 0.756,
    "total_score": 0.6553333333333333,
    "x": 10.590288162231445,
    "y": -0.7527201175689697,
    "cluster_id": 14
  },
  {
    "feature_id": 196,
    "explanation_index": 1,
    "text": "Verbs indicating actions, states, or processes, often related to decision-making, movement, or influence, with a focus on dynamic or consequential behavior.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8780169486999512,
    "similarity_var": 3.1360689177972745e-05,
    "score_fuzz": 0.87,
    "score_detection": 0.55,
    "score_embedding": 0.75625,
    "total_score": 0.7254166666666667,
    "x": 10.708192825317383,
    "y": -0.8568972945213318,
    "cluster_id": 14
  },
  {
    "feature_id": 196,
    "explanation_index": 2,
    "text": "The highlighted words are verbs or verb phrases that function as the main predicate of a clause, usually in present tense or gerund, and they appear across a wide range of contexts, often followed by an object or complement.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8780169486999512,
    "similarity_var": 3.1360689177972745e-05,
    "score_fuzz": 0.85,
    "score_detection": 0.525,
    "score_embedding": 0.6856249999999999,
    "total_score": 0.686875,
    "x": 16.502601623535156,
    "y": 3.6107559204101562,
    "cluster_id": -1
  },
  {
    "feature_id": 197,
    "explanation_index": 0,
    "text": "Various tokens including nouns, verbs, adjectives, and numbers, often representing specific objects, concepts, or quantities, and sometimes being part of a larger phrase or sentence.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8334406812985738,
    "similarity_var": 0.00017762404711242475,
    "score_fuzz": 0.47,
    "score_detection": 0.61,
    "score_embedding": 0.2136,
    "total_score": 0.4312,
    "x": 10.56753158569336,
    "y": 4.554328441619873,
    "cluster_id": 47
  },
  {
    "feature_id": 197,
    "explanation_index": 1,
    "text": "Common linguistic patterns involving compound nouns, technical terms, or phrases with specific structural or semantic roles, often appearing in academic, technical, or formal contexts, with emphasis on precise terminology, numerical values, or syntactic constructions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8334406812985738,
    "similarity_var": 0.00017762404711242475,
    "score_fuzz": 0.37,
    "score_detection": 0.32,
    "score_embedding": 0.3325,
    "total_score": 0.3408333333333333,
    "x": 9.569255828857422,
    "y": 0.3971291780471802,
    "cluster_id": -1
  },
  {
    "feature_id": 197,
    "explanation_index": 2,
    "text": "the patterns.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8334406812985738,
    "similarity_var": 0.00017762404711242475,
    "score_fuzz": 0.375,
    "score_detection": 0.325,
    "score_embedding": 0.3025,
    "total_score": 0.33416666666666667,
    "x": 5.140806674957275,
    "y": 9.966550827026367,
    "cluster_id": 58
  },
  {
    "feature_id": 198,
    "explanation_index": 0,
    "text": "Interrogative phrases, typically starting with \\\"what\\\", used to introduce a question or inquiry, often seeking information or clarification.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8865049481391907,
    "similarity_var": 0.0002273442815858099,
    "score_fuzz": 0.97,
    "score_detection": 0.95,
    "score_embedding": 0.734,
    "total_score": 0.8846666666666666,
    "x": 11.224580764770508,
    "y": 1.7624911069869995,
    "cluster_id": 73
  },
  {
    "feature_id": 198,
    "explanation_index": 1,
    "text": "The word \\\"What\\\" is frequently used to introduce questions about identity, definition, or value, often in contexts involving mathematical calculations, conceptual definitions, or inquiry into unknowns.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8865049481391907,
    "similarity_var": 0.0002273442815858099,
    "score_fuzz": 0.94,
    "score_detection": 0.92,
    "score_embedding": 0.664375,
    "total_score": 0.8414583333333333,
    "x": 11.232436180114746,
    "y": 1.9473248720169067,
    "cluster_id": 70
  },
  {
    "feature_id": 198,
    "explanation_index": 2,
    "text": "The text repeatedly marks the interrogative word \u201cWhat\u201d (or \u201cwhat\u201d) as a key token, most often at the beginning of a question and usually followed by \u201cis\u201d and a noun phrase, indicating a consistent pattern of question formation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8865049481391907,
    "similarity_var": 0.0002273442815858099,
    "score_fuzz": 1.0,
    "score_detection": 1.0,
    "score_embedding": 0.51875,
    "total_score": 0.8395833333333332,
    "x": 11.270535469055176,
    "y": 1.887927770614624,
    "cluster_id": 70
  },
  {
    "feature_id": 199,
    "explanation_index": 0,
    "text": "Tokens that are part of proper nouns, abbreviations, or specific terms, often denoting organizations, locations, concepts, or individuals.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9003265301386515,
    "similarity_var": 0.0005867572709337624,
    "score_fuzz": 0.66,
    "score_detection": 0.68,
    "score_embedding": 0.7436,
    "total_score": 0.6945333333333333,
    "x": 10.132575988769531,
    "y": 4.398421764373779,
    "cluster_id": 1
  },
  {
    "feature_id": 199,
    "explanation_index": 1,
    "text": "Tokens that form proper nouns, technical terms, or abbreviations, often appearing in scientific, medical, or institutional contexts, with high activation values when part of named entities or acronyms.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9003265301386515,
    "similarity_var": 0.0005867572709337624,
    "score_fuzz": 0.67,
    "score_detection": 0.7,
    "score_embedding": 0.6993750000000001,
    "total_score": 0.6897916666666667,
    "x": 10.082430839538574,
    "y": 4.145711898803711,
    "cluster_id": -1
  },
  {
    "feature_id": 199,
    "explanation_index": 2,
    "text": "The marked tokens are the core lexical units that form fixed expressions, morphological patterns, or named\u2011entity phrases, which the model activates to capture the meaning of the surrounding text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9003265301386515,
    "similarity_var": 0.0005867572709337624,
    "score_fuzz": 0.4,
    "score_detection": 0.6,
    "score_embedding": 0.6218750000000001,
    "total_score": 0.540625,
    "x": 15.418725967407227,
    "y": 4.3270487785339355,
    "cluster_id": -1
  },
  {
    "feature_id": 200,
    "explanation_index": 0,
    "text": "Tokens that are often used to indicate the beginning of a new section, quotation, or piece of information, including words that signal publication, posting, or redirection, as well as certain punctuation marks and special characters.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8993185559908549,
    "similarity_var": 0.0002922181588529169,
    "score_fuzz": 0.5,
    "score_detection": 0.28,
    "score_embedding": 0.182,
    "total_score": 0.32066666666666666,
    "x": 10.50492000579834,
    "y": 4.736093044281006,
    "cluster_id": -1
  },
  {
    "feature_id": 200,
    "explanation_index": 1,
    "text": "Common function words, punctuation, and proper nouns used in contextual markers for metadata, formatting, or grammatical structure.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8993185559908549,
    "similarity_var": 0.0002922181588529169,
    "score_fuzz": 0.49,
    "score_detection": 0.33,
    "score_embedding": 0.13937500000000003,
    "total_score": 0.3197916666666667,
    "x": 7.729288578033447,
    "y": 6.5252532958984375,
    "cluster_id": 32
  },
  {
    "feature_id": 200,
    "explanation_index": 2,
    "text": "The highlighted tokens are short, function\u2011like words or punctuation that serve as structural connectors or metadata markers, appearing across diverse contexts.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8993185559908549,
    "similarity_var": 0.0002922181588529169,
    "score_fuzz": 0.375,
    "score_detection": 0.35,
    "score_embedding": 0.1775,
    "total_score": 0.30083333333333334,
    "x": 13.893306732177734,
    "y": 4.227893829345703,
    "cluster_id": -1
  },
  {
    "feature_id": 203,
    "explanation_index": 0,
    "text": "Punctuation marks and common function words that serve to connect or separate clauses, phrases, or items in a list, often used in formal or written language.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8663453459739685,
    "similarity_var": 0.0007748144593217413,
    "score_fuzz": 0.51,
    "score_detection": 0.4,
    "score_embedding": 0.30319999999999997,
    "total_score": 0.40440000000000004,
    "x": 7.782942771911621,
    "y": 6.6213765144348145,
    "cluster_id": 32
  },
  {
    "feature_id": 203,
    "explanation_index": 1,
    "text": "Common linguistic patterns involving function words, punctuation, and compound terms that serve grammatical or structural roles in text, often appearing in contexts requiring clarity, emphasis, or syntactic completeness.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8663453459739685,
    "similarity_var": 0.0007748144593217413,
    "score_fuzz": 0.49,
    "score_detection": 0.42,
    "score_embedding": 0.35375,
    "total_score": 0.42124999999999996,
    "x": 10.389033317565918,
    "y": 1.1702736616134644,
    "cluster_id": -1
  },
  {
    "feature_id": 203,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core lexical items and connective words that form the main semantic units of the sentences, often nouns, adjectives, or fragments of longer words, and they signal the central ideas and relationships in the text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8663453459739685,
    "similarity_var": 0.0007748144593217413,
    "score_fuzz": 0.475,
    "score_detection": 0.475,
    "score_embedding": 0.366875,
    "total_score": 0.43895833333333334,
    "x": 15.090696334838867,
    "y": 4.238284587860107,
    "cluster_id": 91
  },
  {
    "feature_id": 204,
    "explanation_index": 0,
    "text": "Archaeological and historical terms, names of ancient civilizations, and words related to museums, artifacts, and historical sites.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8498671849568685,
    "similarity_var": 0.003802559345625727,
    "score_fuzz": 0.83,
    "score_detection": 0.91,
    "score_embedding": 0.8608,
    "total_score": 0.8669333333333333,
    "x": 7.738201141357422,
    "y": -0.683134138584137,
    "cluster_id": 16
  },
  {
    "feature_id": 204,
    "explanation_index": 1,
    "text": "Nouns and adjectives related to archaeological, historical, or prehistoric contexts, often describing sites, artifacts, or cultural periods, with frequent emphasis on specific time periods, materials, and geographical locations.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8498671849568685,
    "similarity_var": 0.003802559345625727,
    "score_fuzz": 0.86,
    "score_detection": 0.92,
    "score_embedding": 0.8981250000000001,
    "total_score": 0.8927083333333333,
    "x": 8.065311431884766,
    "y": -0.03606421500444412,
    "cluster_id": -1
  },
  {
    "feature_id": 204,
    "explanation_index": 2,
    "text": "the patterns in the examples.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8498671849568685,
    "similarity_var": 0.003802559345625727,
    "score_fuzz": 0.625,
    "score_detection": 0.525,
    "score_embedding": 0.38375,
    "total_score": 0.51125,
    "x": 5.193559169769287,
    "y": 9.923203468322754,
    "cluster_id": 58
  },
  {
    "feature_id": 205,
    "explanation_index": 0,
    "text": "Citations, references, and links to external sources, often denoted by a unique identifier or number, and sometimes accompanied by a brief description or title.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8829269011815389,
    "similarity_var": 0.0004238864293818602,
    "score_fuzz": 0.83,
    "score_detection": 0.82,
    "score_embedding": 0.6864,
    "total_score": 0.7787999999999999,
    "x": 8.899036407470703,
    "y": 4.59128999710083,
    "cluster_id": 75
  },
  {
    "feature_id": 205,
    "explanation_index": 1,
    "text": "The token sequence \\\"[@\\\" or \\\"[[\\\" is used to denote citations or references in academic or technical text, often preceding a bibliographic identifier or a label.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8829269011815389,
    "similarity_var": 0.0004238864293818602,
    "score_fuzz": 0.81,
    "score_detection": 0.77,
    "score_embedding": 0.6975,
    "total_score": 0.7591666666666667,
    "x": 8.850698471069336,
    "y": 7.15703821182251,
    "cluster_id": -1
  },
  {
    "feature_id": 205,
    "explanation_index": 2,
    "text": "The highlighted tokens are punctuation and bracket symbols that mark citations, references, code fences, or mathematical delimiters in scholarly or technical text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8829269011815389,
    "similarity_var": 0.0004238864293818602,
    "score_fuzz": 0.725,
    "score_detection": 0.625,
    "score_embedding": 0.6950000000000001,
    "total_score": 0.6816666666666666,
    "x": 13.561649322509766,
    "y": 5.829997539520264,
    "cluster_id": -1
  },
  {
    "feature_id": 206,
    "explanation_index": 0,
    "text": "LaTeX equation delimiters.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8974157770474752,
    "similarity_var": 4.552423609125198e-05,
    "score_fuzz": 0.59,
    "score_detection": 0.51,
    "score_embedding": 0.538,
    "total_score": 0.546,
    "x": 9.769767761230469,
    "y": 7.952231407165527,
    "cluster_id": -1
  },
  {
    "feature_id": 206,
    "explanation_index": 1,
    "text": "The token sequence \\\"<<\\\" followed by a newline and then \\\">>\\\" is used to delimit mathematical expressions or equation environments in LaTeX, often appearing around aligned equations, cases, or other structured math blocks.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8974157770474752,
    "similarity_var": 4.552423609125198e-05,
    "score_fuzz": 0.8,
    "score_detection": 0.6,
    "score_embedding": 0.6024999999999999,
    "total_score": 0.6675,
    "x": 9.565168380737305,
    "y": 6.657948017120361,
    "cluster_id": 61
  },
  {
    "feature_id": 206,
    "explanation_index": 2,
    "text": "The delimiters mark LaTeX math fragments, which in these cases are largely composed of whitespace or backslash characters.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8974157770474752,
    "similarity_var": 4.552423609125198e-05,
    "score_fuzz": 0.625,
    "score_detection": 0.475,
    "score_embedding": 0.6693749999999999,
    "total_score": 0.5897916666666667,
    "x": 9.739279747009277,
    "y": 7.051493167877197,
    "cluster_id": 21
  },
  {
    "feature_id": 207,
    "explanation_index": 0,
    "text": "Proper nouns, names of places, people, and organizations, as well as common nouns and adjectives that describe or characterize something.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8863052725791931,
    "similarity_var": 0.00023923235132154255,
    "score_fuzz": 0.67,
    "score_detection": 0.81,
    "score_embedding": 0.598,
    "total_score": 0.6926666666666667,
    "x": 7.502193450927734,
    "y": -0.9054937362670898,
    "cluster_id": 16
  },
  {
    "feature_id": 207,
    "explanation_index": 1,
    "text": "Common patterns include proper nouns, compound nouns, and phrases that denote locations, objects, or abstract concepts, often appearing in contexts involving names, descriptors, or specific terminology, with emphasis on lexical units that carry semantic weight in their respective contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8863052725791931,
    "similarity_var": 0.00023923235132154255,
    "score_fuzz": 0.72,
    "score_detection": 0.77,
    "score_embedding": 0.6987500000000001,
    "total_score": 0.7295833333333334,
    "x": 9.436731338500977,
    "y": 0.2640448808670044,
    "cluster_id": -1
  },
  {
    "feature_id": 207,
    "explanation_index": 2,
    "text": "The highlighted tokens are core noun phrases or key lexical items that denote places, objects, or concepts, often forming the subject or object of the sentence, and can be single words or multi\u2011word phrases.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8863052725791931,
    "similarity_var": 0.00023923235132154255,
    "score_fuzz": 0.75,
    "score_detection": 0.7,
    "score_embedding": 0.665625,
    "total_score": 0.7052083333333333,
    "x": 15.184481620788574,
    "y": 3.894639730453491,
    "cluster_id": 22
  },
  {
    "feature_id": 208,
    "explanation_index": 0,
    "text": "Abbreviations or words related to agreements, names, places, or objects, often used in formal or technical contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8518081506093343,
    "similarity_var": 0.001038575737918595,
    "score_fuzz": 0.74,
    "score_detection": 0.72,
    "score_embedding": 0.6859999999999999,
    "total_score": 0.7153333333333333,
    "x": 7.716985702514648,
    "y": 1.524940848350525,
    "cluster_id": -1
  },
  {
    "feature_id": 208,
    "explanation_index": 1,
    "text": "Partial or fragmented words, often derived from proper nouns or technical terms, that are contextually significant and frequently appear in compound or abbreviated forms.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8518081506093343,
    "similarity_var": 0.001038575737918595,
    "score_fuzz": 0.68,
    "score_detection": 0.68,
    "score_embedding": 0.534375,
    "total_score": 0.6314583333333333,
    "x": 7.1832356452941895,
    "y": 2.706897258758545,
    "cluster_id": 15
  },
  {
    "feature_id": 208,
    "explanation_index": 2,
    "text": "The pattern might be that the important tokens are words that start with \\\"gr\\\" or contain \\\"gr\\\" as a prefix or suffix? Many tokens: \\\"agreement\\\", \\\"gr\\\", \\\"gre\\\", \\\"GRASP\\\", \\\"grievances\\\", \\\"great\\\", \\\"grill\\\", \\\"grits\\\", \\\"grace\\\"? Also \\\"gr\\\" appears as a separate token \\\"gr\\\" in \\\"grater\\\" etc.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8518081506093343,
    "similarity_var": 0.001038575737918595,
    "score_fuzz": 0.675,
    "score_detection": 0.825,
    "score_embedding": 0.6612500000000001,
    "total_score": 0.7204166666666666,
    "x": 11.36142349243164,
    "y": 4.24415397644043,
    "cluster_id": 3
  },
  {
    "feature_id": 209,
    "explanation_index": 0,
    "text": "Numerical values, often representing time or quantity, embedded within text.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8204688628514608,
    "similarity_var": 0.0025191116132469277,
    "score_fuzz": 0.77,
    "score_detection": 0.7,
    "score_embedding": 0.8412000000000001,
    "total_score": 0.7704,
    "x": 6.8800883293151855,
    "y": 8.796672821044922,
    "cluster_id": 29
  },
  {
    "feature_id": 209,
    "explanation_index": 1,
    "text": "Numbers, both cardinal and ordinal, used to express time durations, counts, or quantities, often in contexts involving periods, measurements, or sequences.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8204688628514608,
    "similarity_var": 0.0025191116132469277,
    "score_fuzz": 0.85,
    "score_detection": 0.7,
    "score_embedding": 0.808125,
    "total_score": 0.7860416666666666,
    "x": 7.181770324707031,
    "y": 8.686229705810547,
    "cluster_id": 29
  },
  {
    "feature_id": 209,
    "explanation_index": 2,
    "text": "the patterns.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8204688628514608,
    "similarity_var": 0.0025191116132469277,
    "score_fuzz": 0.7,
    "score_detection": 0.425,
    "score_embedding": 0.7112499999999999,
    "total_score": 0.6120833333333333,
    "x": 5.115909576416016,
    "y": 9.991707801818848,
    "cluster_id": 58
  },
  {
    "feature_id": 210,
    "explanation_index": 0,
    "text": "Various programming language syntax elements, including object and method calls, function and variable declarations, conditional statements, loops, and error handling, often involving dot notation, arrow notation, and other operators.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8883136312166849,
    "similarity_var": 0.00039094005842659694,
    "score_fuzz": 0.52,
    "score_detection": 0.54,
    "score_embedding": 0.4968,
    "total_score": 0.5189333333333334,
    "x": 10.687700271606445,
    "y": 8.297414779663086,
    "cluster_id": 48
  },
  {
    "feature_id": 210,
    "explanation_index": 1,
    "text": "Frequent use of dot (.) and arrow (->) operators to access object properties or methods, often in programming contexts involving object-oriented syntax or method chaining.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8883136312166849,
    "similarity_var": 0.00039094005842659694,
    "score_fuzz": 0.58,
    "score_detection": 0.55,
    "score_embedding": 0.499375,
    "total_score": 0.543125,
    "x": 10.396685600280762,
    "y": 8.095832824707031,
    "cluster_id": -1
  },
  {
    "feature_id": 210,
    "explanation_index": 2,
    "text": "The highlighted tokens are syntactic elements of code\u2014punctuation, operators, and keywords that indicate structure, method/property access, and control flow.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8883136312166849,
    "similarity_var": 0.00039094005842659694,
    "score_fuzz": 0.525,
    "score_detection": 0.475,
    "score_embedding": 0.5125,
    "total_score": 0.5041666666666667,
    "x": 13.732370376586914,
    "y": 6.649599552154541,
    "cluster_id": 8
  },
  {
    "feature_id": 211,
    "explanation_index": 0,
    "text": "Pronouns and articles, often used as subjects or objects in sentences, sometimes in reported speech or dialogue.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.874159554640452,
    "similarity_var": 0.00013444663759858917,
    "score_fuzz": 0.77,
    "score_detection": 0.64,
    "score_embedding": 0.46040000000000003,
    "total_score": 0.6234666666666667,
    "x": 11.647909164428711,
    "y": 1.064388632774353,
    "cluster_id": 64
  },
  {
    "feature_id": 211,
    "explanation_index": 1,
    "text": "Pronouns and reflexive particles (like \\\"il\\\", \\\"elle\\\", \\\"se\\\", \\\"que\\\", \\\"non\\\", \\\"on\\\") are frequently activated in contexts involving self-reference, possession, or conditional clauses, often appearing in narrative or descriptive text with grammatical dependencies.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.874159554640452,
    "similarity_var": 0.00013444663759858917,
    "score_fuzz": 0.79,
    "score_detection": 0.65,
    "score_embedding": 0.41062499999999996,
    "total_score": 0.616875,
    "x": 11.691516876220703,
    "y": 1.3836017847061157,
    "cluster_id": 71
  },
  {
    "feature_id": 211,
    "explanation_index": 2,
    "text": "The highlighted tokens are short grammatical function words or suffixes\u2014pronouns, articles, prepositions, conjunctions, and comparative endings\u2014that signal syntactic relations rather than lexical content, and they recur across many languages.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.874159554640452,
    "similarity_var": 0.00013444663759858917,
    "score_fuzz": 0.6,
    "score_detection": 0.55,
    "score_embedding": 0.24375000000000002,
    "total_score": 0.4645833333333333,
    "x": 13.599430084228516,
    "y": 3.3250038623809814,
    "cluster_id": 35
  },
  {
    "feature_id": 213,
    "explanation_index": 0,
    "text": "Tokens that are part of a larger code or programming syntax, often including symbols, operators, and keywords, and sometimes numerical values or mathematical expressions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8946979840596517,
    "similarity_var": 0.00010731084064335365,
    "score_fuzz": 0.76,
    "score_detection": 0.81,
    "score_embedding": 0.7752,
    "total_score": 0.7817333333333334,
    "x": 10.713838577270508,
    "y": 5.94367790222168,
    "cluster_id": 18
  },
  {
    "feature_id": 213,
    "explanation_index": 1,
    "text": "The token sequences often represent grammatical or syntactic elements, numerical values, or identifiers in code, mathematical expressions, or structured text, with high activation on words that serve as connectors, modifiers, or markers of structure, such as prepositions, conjunctions, punctuation, or parts of compound terms.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8946979840596517,
    "similarity_var": 0.00010731084064335365,
    "score_fuzz": 0.69,
    "score_detection": 0.71,
    "score_embedding": 0.6306250000000001,
    "total_score": 0.676875,
    "x": 11.056342124938965,
    "y": 5.437633037567139,
    "cluster_id": 51
  },
  {
    "feature_id": 213,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core lexical or structural elements that carry the main semantic or syntactic weight of a phrase or code fragment, often the first token of a multi\u2011token phrase or a key punctuation or symbol that signals a concept or operation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8946979840596517,
    "similarity_var": 0.00010731084064335365,
    "score_fuzz": 0.65,
    "score_detection": 0.7,
    "score_embedding": 0.733125,
    "total_score": 0.694375,
    "x": 14.902063369750977,
    "y": 4.468168258666992,
    "cluster_id": -1
  },
  {
    "feature_id": 214,
    "explanation_index": 0,
    "text": "Numerical values, dates, and citations, often in a formal or technical context.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8555418848991394,
    "similarity_var": 0.0005034740360940759,
    "score_fuzz": 0.53,
    "score_detection": 0.52,
    "score_embedding": 0.4412,
    "total_score": 0.4970666666666667,
    "x": 6.935150623321533,
    "y": 8.76805305480957,
    "cluster_id": 29
  },
  {
    "feature_id": 214,
    "explanation_index": 1,
    "text": "Individual digits, particularly '9', '8', '7', '6', '5', '4', '3', '2', and '1', frequently appear in numerical sequences, dates, identifiers, or references, often within contexts involving years, page numbers, versioning, or technical specifications.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8555418848991394,
    "similarity_var": 0.0005034740360940759,
    "score_fuzz": 0.59,
    "score_detection": 0.53,
    "score_embedding": 0.37187500000000007,
    "total_score": 0.49729166666666674,
    "x": 7.2912187576293945,
    "y": 8.635930061340332,
    "cluster_id": 29
  },
  {
    "feature_id": 214,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core elements of a phrase or structural component\u2014idiomatic expressions, comparative suffixes, or citation fragments\u2014often consisting of punctuation or numeric markers that delineate the key part of the text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8555418848991394,
    "similarity_var": 0.0005034740360940759,
    "score_fuzz": 0.45,
    "score_detection": 0.45,
    "score_embedding": 0.376875,
    "total_score": 0.425625,
    "x": 15.028955459594727,
    "y": 4.399972915649414,
    "cluster_id": 72
  },
  {
    "feature_id": 215,
    "explanation_index": 0,
    "text": "Nouns or phrases representing inquiries, interrogations, or problems, often used in academic or formal contexts, sometimes appearing in titles or headings.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.81802370150884,
    "similarity_var": 0.0026952908484274315,
    "score_fuzz": 0.76,
    "score_detection": 0.78,
    "score_embedding": 0.7608,
    "total_score": 0.7669333333333334,
    "x": 8.532410621643066,
    "y": 0.2509067952632904,
    "cluster_id": 24
  },
  {
    "feature_id": 215,
    "explanation_index": 1,
    "text": "The word \\\"question\\\" and its variants frequently appear in contexts involving inquiry, assessment, or critical thinking, often associated with academic, evaluative, or reflective tasks.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.81802370150884,
    "similarity_var": 0.0026952908484274315,
    "score_fuzz": 0.7578947368421053,
    "score_detection": 0.76,
    "score_embedding": 0.8043750000000001,
    "total_score": 0.7740899122807017,
    "x": 11.260697364807129,
    "y": 1.8182225227355957,
    "cluster_id": 73
  },
  {
    "feature_id": 215,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.81802370150884,
    "similarity_var": 0.0026952908484274315,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.67625,
    "total_score": 0.55875,
    "x": -5.917695999145508,
    "y": 15.991056442260742,
    "cluster_id": 10
  },
  {
    "feature_id": 216,
    "explanation_index": 0,
    "text": "Scientific and technical terms, often referring to biological or chemical concepts, such as proteins, enzymes, acids, and molecules, as well as medical conditions and treatments.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8609145085016886,
    "similarity_var": 0.0008158065260354242,
    "score_fuzz": 0.68,
    "score_detection": 0.51,
    "score_embedding": 0.5204,
    "total_score": 0.5701333333333333,
    "x": 7.302248477935791,
    "y": 1.2161550521850586,
    "cluster_id": 25
  },
  {
    "feature_id": 216,
    "explanation_index": 1,
    "text": "Fragments of biological or chemical terms, often representing molecular components, structural motifs, or biochemical processes, are frequently activated when they appear in scientific text, particularly when part of compound terms or protein/nucleic acid names.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8609145085016886,
    "similarity_var": 0.0008158065260354242,
    "score_fuzz": 0.65,
    "score_detection": 0.5,
    "score_embedding": 0.531875,
    "total_score": 0.5606249999999999,
    "x": 7.440647125244141,
    "y": 2.399339199066162,
    "cluster_id": -1
  },
  {
    "feature_id": 216,
    "explanation_index": 2,
    "text": "The highlighted fragments are the semantic core of each phrase: key nouns, adjectives, or the essential sub\u2011word pieces of compound terms.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8609145085016886,
    "similarity_var": 0.0008158065260354242,
    "score_fuzz": 0.75,
    "score_detection": 0.45,
    "score_embedding": 0.5037499999999999,
    "total_score": 0.5679166666666666,
    "x": 15.803632736206055,
    "y": 7.377793788909912,
    "cluster_id": 19
  },
  {
    "feature_id": 217,
    "explanation_index": 0,
    "text": "Superscript notation for exponentiation, often used in mathematical expressions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8748330473899841,
    "similarity_var": 0.00031781128038232964,
    "score_fuzz": 0.78,
    "score_detection": 0.79,
    "score_embedding": 0.7128,
    "total_score": 0.7609333333333334,
    "x": 9.208944320678711,
    "y": 8.273787498474121,
    "cluster_id": 74
  },
  {
    "feature_id": 217,
    "explanation_index": 1,
    "text": "Mathematical expressions involving symbolic variables, exponents, and operators, with frequent use of special characters like ^, *, **, and parentheses, often in contexts of algebraic simplification or symbolic computation.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8748330473899841,
    "similarity_var": 0.00031781128038232964,
    "score_fuzz": 0.61,
    "score_detection": 0.57,
    "score_embedding": 0.649375,
    "total_score": 0.6097916666666666,
    "x": 9.424437522888184,
    "y": 8.493973731994629,
    "cluster_id": 65
  },
  {
    "feature_id": 217,
    "explanation_index": 2,
    "text": "The highlighted tokens are consistently short variable names, function identifiers, or mathematical operators that appear within LaTeX\u2011style expressions, often surrounded by punctuation or formatting symbols.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8748330473899841,
    "similarity_var": 0.00031781128038232964,
    "score_fuzz": 0.7,
    "score_detection": 0.55,
    "score_embedding": 0.49625,
    "total_score": 0.5820833333333334,
    "x": 13.364872932434082,
    "y": 5.930298805236816,
    "cluster_id": 30
  },
  {
    "feature_id": 218,
    "explanation_index": 0,
    "text": "Tokens representing code syntax elements, such as operators, symbols, and keywords, often used in programming languages, including C, C++, and others.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.881231963634491,
    "similarity_var": 0.0006282298343360063,
    "score_fuzz": 0.4,
    "score_detection": 0.43,
    "score_embedding": 0.5152,
    "total_score": 0.4484000000000001,
    "x": 10.862202644348145,
    "y": 5.995333671569824,
    "cluster_id": 18
  },
  {
    "feature_id": 218,
    "explanation_index": 1,
    "text": "Repeated numerical digits and symbols like \\\"4\\\", \\\"0\\\", and \\\",\\\" appear frequently in code contexts, often within hexadecimal values, array indices, or numeric literals, with high activation scores indicating their importance in syntactic or structural parsing.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.881231963634491,
    "similarity_var": 0.0006282298343360063,
    "score_fuzz": 0.62,
    "score_detection": 0.56,
    "score_embedding": 0.641875,
    "total_score": 0.6072916666666667,
    "x": 7.834242343902588,
    "y": 8.25232982635498,
    "cluster_id": -1
  },
  {
    "feature_id": 218,
    "explanation_index": 2,
    "text": "The highlighted elements are code tokens\u2014identifiers, keywords, or symbols\u2014that appear in function calls, variable names, or macro definitions, often containing underscores, numbers, or punctuation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.881231963634491,
    "similarity_var": 0.0006282298343360063,
    "score_fuzz": 0.525,
    "score_detection": 0.55,
    "score_embedding": 0.6331249999999999,
    "total_score": 0.5693750000000001,
    "x": 13.957779884338379,
    "y": 6.543064117431641,
    "cluster_id": 8
  },
  {
    "feature_id": 219,
    "explanation_index": 0,
    "text": "Tokens representing legal terminology, court names, and citations, often used in formal or technical contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.917818526426951,
    "similarity_var": 0.00040992484979638115,
    "score_fuzz": 0.43,
    "score_detection": 0.47,
    "score_embedding": 0.33280000000000004,
    "total_score": 0.4109333333333333,
    "x": 9.370007514953613,
    "y": 4.51151180267334,
    "cluster_id": -1
  },
  {
    "feature_id": 219,
    "explanation_index": 1,
    "text": "Legal citations and court references often include abbreviated court names, case identifiers, and structured formatting with periods, numbers, and parentheses, frequently surrounding key terms like \\\"Supreme Court,\\\" \\\"Appellate Court,\\\" \\\"cert. denied,\\\" and \\\"U.S.\\\"",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.917818526426951,
    "similarity_var": 0.00040992484979638115,
    "score_fuzz": 0.33,
    "score_detection": 0.41,
    "score_embedding": 0.37875000000000003,
    "total_score": 0.3729166666666666,
    "x": 8.890071868896484,
    "y": 4.461219310760498,
    "cluster_id": 75
  },
  {
    "feature_id": 219,
    "explanation_index": 2,
    "text": "The passages repeatedly employ legal citation conventions\u2014case names, court titles, and procedural phrases\u2014often abbreviated (e.g., U.S., S.Ct., L.Ed.) and punctuated in a Bluebook\u2011style format, with recurring terms such as \u201ccert. denied,\u201d \u201cSupreme Court,\u201d and \u201cAppellate Court.\u201d",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.917818526426951,
    "similarity_var": 0.00040992484979638115,
    "score_fuzz": 0.4,
    "score_detection": 0.375,
    "score_embedding": 0.365,
    "total_score": 0.38000000000000006,
    "x": 8.903112411499023,
    "y": 4.457316875457764,
    "cluster_id": 75
  },
  {
    "feature_id": 220,
    "explanation_index": 0,
    "text": "Citations, references, and quotes from legal documents, often including case numbers, court names, and specific sections of laws or regulations.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.902368446191152,
    "similarity_var": 0.00034964213777360296,
    "score_fuzz": 0.5,
    "score_detection": 0.46,
    "score_embedding": 0.5608,
    "total_score": 0.5069333333333333,
    "x": 8.87368392944336,
    "y": 4.471673488616943,
    "cluster_id": 75
  },
  {
    "feature_id": 220,
    "explanation_index": 1,
    "text": "Legal text containing case citations, procedural language, and formal legal terminology, with frequent use of numbered sections, court names, case references, and structured legal phrasing.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.902368446191152,
    "similarity_var": 0.00034964213777360296,
    "score_fuzz": 0.44,
    "score_detection": 0.42,
    "score_embedding": 0.395,
    "total_score": 0.4183333333333333,
    "x": 8.897660255432129,
    "y": 4.4410929679870605,
    "cluster_id": 75
  },
  {
    "feature_id": 220,
    "explanation_index": 2,
    "text": "The highlighted segments consistently mark legal references\u2014case names, statutes, citations, or key procedural phrases\u2014often single words or short phrases that carry legal significance. The pattern is that the markers surround tokens that are central to the legal context, such as specific case identifiers, statutory language, or pivotal procedural terms.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.902368446191152,
    "similarity_var": 0.00034964213777360296,
    "score_fuzz": 0.55,
    "score_detection": 0.5,
    "score_embedding": 0.47437499999999994,
    "total_score": 0.508125,
    "x": 8.989460945129395,
    "y": 4.4126811027526855,
    "cluster_id": 75
  },
  {
    "feature_id": 221,
    "explanation_index": 0,
    "text": "Punctuation and special characters, often used in mathematical expressions, coding, and formatting.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8545823295911154,
    "similarity_var": 0.0017923745766579046,
    "score_fuzz": 0.38,
    "score_detection": 0.32,
    "score_embedding": 0.27759999999999996,
    "total_score": 0.32586666666666664,
    "x": 8.668757438659668,
    "y": 7.366604328155518,
    "cluster_id": 4
  },
  {
    "feature_id": 221,
    "explanation_index": 1,
    "text": "Isolated digits and punctuation symbols frequently appear in mathematical, technical, or structured text formats, often within code-like or markup contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8545823295911154,
    "similarity_var": 0.0017923745766579046,
    "score_fuzz": 0.34,
    "score_detection": 0.34,
    "score_embedding": 0.3325,
    "total_score": 0.3375000000000001,
    "x": 7.7349395751953125,
    "y": 8.271910667419434,
    "cluster_id": 29
  },
  {
    "feature_id": 221,
    "explanation_index": 2,
    "text": "The highlighted tokens are consistently the core elements of a syntactic or semantic unit\u2014short words, punctuation, or symbols that together form a meaningful phrase, expression, or code fragment. They are the minimal building blocks that convey the main idea or function in each snippet.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8545823295911154,
    "similarity_var": 0.0017923745766579046,
    "score_fuzz": 0.35,
    "score_detection": 0.275,
    "score_embedding": 0.4175,
    "total_score": 0.3475,
    "x": 14.657544136047363,
    "y": 4.683117389678955,
    "cluster_id": -1
  },
  {
    "feature_id": 222,
    "explanation_index": 0,
    "text": "Words related to precipitation, weather, and time, often used in descriptive or informative contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8315404653549194,
    "similarity_var": 0.0022782704412520616,
    "score_fuzz": 0.69,
    "score_detection": 0.69,
    "score_embedding": 0.6951999999999999,
    "total_score": 0.6917333333333332,
    "x": 8.274574279785156,
    "y": 0.4835807681083679,
    "cluster_id": 12
  },
  {
    "feature_id": 222,
    "explanation_index": 1,
    "text": "The word \\\"rain\\\" and related forms (e.g., \\\"raining\\\", \\\"rainfall\\\") are frequently activated in contexts involving weather, environmental conditions, or metaphorical expressions tied to emotional or situational states, often associated with natural phenomena, time, or symbolic meaning.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8315404653549194,
    "similarity_var": 0.0022782704412520616,
    "score_fuzz": 0.64,
    "score_detection": 0.64,
    "score_embedding": 0.795625,
    "total_score": 0.691875,
    "x": 8.353693962097168,
    "y": 0.7174409031867981,
    "cluster_id": -1
  },
  {
    "feature_id": 222,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8315404653549194,
    "similarity_var": 0.0022782704412520616,
    "score_fuzz": 0.5,
    "score_detection": 0.425,
    "score_embedding": 0.7568750000000001,
    "total_score": 0.560625,
    "x": -5.941005229949951,
    "y": 15.967754364013672,
    "cluster_id": 10
  },
  {
    "feature_id": 223,
    "explanation_index": 0,
    "text": "Articles, pronouns, and other determiners that introduce or refer to nouns, often used to specify or clarify the noun they precede.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8765646616617838,
    "similarity_var": 0.0009081669827000699,
    "score_fuzz": 0.82,
    "score_detection": 0.55,
    "score_embedding": 0.19160000000000005,
    "total_score": 0.5205333333333334,
    "x": 12.745189666748047,
    "y": 0.4708785116672516,
    "cluster_id": 34
  },
  {
    "feature_id": 223,
    "explanation_index": 1,
    "text": "The frequent use of definite and indefinite articles (\\\"the\\\", \\\"a\\\", \\\"an\\\") and pronouns (\\\"it\\\", \\\"one\\\", \\\"each\\\", \\\"my\\\", \\\"this\\\", \\\"that\\\", \\\"these\\\", \\\"other\\\") to refer to previously mentioned or contextually implied entities, often preceding or following descriptive clauses or specific nouns.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8765646616617838,
    "similarity_var": 0.0009081669827000699,
    "score_fuzz": 0.68,
    "score_detection": 0.53,
    "score_embedding": 0.148125,
    "total_score": 0.4527083333333333,
    "x": 12.641341209411621,
    "y": 0.6815165281295776,
    "cluster_id": 34
  },
  {
    "feature_id": 223,
    "explanation_index": 2,
    "text": "The highlighted tokens are usually small function words\u2014articles, pronouns, prepositions, or conjunctions\u2014that begin a phrase or clause and receive high activation, signaling the start of an important linguistic unit.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8765646616617838,
    "similarity_var": 0.0009081669827000699,
    "score_fuzz": 0.8,
    "score_detection": 0.55,
    "score_embedding": 0.16125,
    "total_score": 0.50375,
    "x": 13.649042129516602,
    "y": 3.382373094558716,
    "cluster_id": 35
  },
  {
    "feature_id": 224,
    "explanation_index": 0,
    "text": "Words that describe shapes, directions, or physical properties, often used to provide spatial or visual context.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8030591011047363,
    "similarity_var": 0.0,
    "score_fuzz": 0.5,
    "score_detection": 0.16,
    "score_embedding": 0.3208,
    "total_score": 0.32693333333333335,
    "x": 7.954338550567627,
    "y": 0.32658815383911133,
    "cluster_id": -1
  },
  {
    "feature_id": 224,
    "explanation_index": 1,
    "text": "Words ending in common suffixes like -ed, -er, -ing, or -ly, often indicating past tense, comparative degree, or adverbial modification, are frequently activated in contextually specific linguistic patterns.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8030591011047363,
    "similarity_var": 0.0,
    "score_fuzz": 0.53,
    "score_detection": 0.43,
    "score_embedding": 0.463125,
    "total_score": 0.474375,
    "x": 8.734827995300293,
    "y": 2.2785065174102783,
    "cluster_id": -1
  },
  {
    "feature_id": 225,
    "explanation_index": 0,
    "text": "Nouns representing negative events, actions, or states, often with serious consequences.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9102639555931091,
    "similarity_var": 0.0007707002775489968,
    "score_fuzz": 0.75,
    "score_detection": 0.54,
    "score_embedding": 0.48960000000000004,
    "total_score": 0.5932000000000001,
    "x": 8.285740852355957,
    "y": 0.9043800234794617,
    "cluster_id": -1
  },
  {
    "feature_id": 225,
    "explanation_index": 1,
    "text": "Nouns denoting negative events or incidents, often related to harm, conflict, or legal/medical outcomes, frequently appearing in contexts involving consequences, damage, or formal proceedings.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9102639555931091,
    "similarity_var": 0.0007707002775489968,
    "score_fuzz": 0.78,
    "score_detection": 0.58,
    "score_embedding": 0.6074999999999999,
    "total_score": 0.6558333333333333,
    "x": 8.243595123291016,
    "y": 0.9876500368118286,
    "cluster_id": -1
  },
  {
    "feature_id": 225,
    "explanation_index": 2,
    "text": "The highlighted words are event\u2011oriented nouns (often violent or negative) that serve as key terms in news\u2011style text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9102639555931091,
    "similarity_var": 0.0007707002775489968,
    "score_fuzz": 0.825,
    "score_detection": 0.425,
    "score_embedding": 0.66875,
    "total_score": 0.6395833333333333,
    "x": 16.759475708007812,
    "y": 3.658526659011841,
    "cluster_id": 20
  },
  {
    "feature_id": 227,
    "explanation_index": 0,
    "text": "Symbols and operators used in programming languages, including comparison operators, arithmetic operators, and symbols for variables, functions, and data types.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8784003257751465,
    "similarity_var": 6.440146799491231e-05,
    "score_fuzz": 0.28,
    "score_detection": 0.36,
    "score_embedding": 0.1136,
    "total_score": 0.25120000000000003,
    "x": 9.758115768432617,
    "y": 8.21756362915039,
    "cluster_id": -1
  },
  {
    "feature_id": 227,
    "explanation_index": 1,
    "text": "Numeric tokens and symbols like digits, operators, and punctuation are frequently activated in code and mathematical expressions, often indicating syntactic structure, values, or comparisons.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8784003257751465,
    "similarity_var": 6.440146799491231e-05,
    "score_fuzz": 0.55,
    "score_detection": 0.51,
    "score_embedding": 0.42625,
    "total_score": 0.49541666666666667,
    "x": 7.82481575012207,
    "y": 8.231863021850586,
    "cluster_id": -1
  },
  {
    "feature_id": 227,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core syntax elements of code snippets\u2014keywords, identifiers, operators, numbers, and punctuation\u2014that define the structure and behavior of the program.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8784003257751465,
    "similarity_var": 6.440146799491231e-05,
    "score_fuzz": 0.325,
    "score_detection": 0.375,
    "score_embedding": 0.24187499999999995,
    "total_score": 0.3139583333333333,
    "x": 13.81686019897461,
    "y": 6.707468509674072,
    "cluster_id": 8
  },
  {
    "feature_id": 229,
    "explanation_index": 0,
    "text": "Prepositions, articles, and conjunctions, often used in phrases or sentences to connect ideas or show relationships between words, and sometimes nouns that represent objects or concepts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8496940533320109,
    "similarity_var": 0.0003109638173184079,
    "score_fuzz": 0.4,
    "score_detection": 0.44,
    "score_embedding": 0.3624,
    "total_score": 0.40080000000000005,
    "x": 12.533616065979004,
    "y": 0.11704183369874954,
    "cluster_id": -1
  },
  {
    "feature_id": 229,
    "explanation_index": 1,
    "text": "High activation on function words (e.g., \\\"to\\\", \\\"for\\\", \\\"in\\\", \\\"is\\\", \\\"a\\\", \\\"the\\\") and common morphological suffixes (e.g., \\\"er\\\", \\\"ing\\\", \\\"ly\\\") when they appear in syntactically or semantically pivotal positions, particularly in technical, formal, or structured text. These tokens often serve grammatical roles or form part of compound terms, especially in scientific, legal, or programming contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8496940533320109,
    "similarity_var": 0.0003109638173184079,
    "score_fuzz": 0.45,
    "score_detection": 0.36,
    "score_embedding": 0.529375,
    "total_score": 0.44645833333333335,
    "x": 10.207955360412598,
    "y": 2.9558582305908203,
    "cluster_id": -1
  },
  {
    "feature_id": 229,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core lexical units\u2014whole words or meaningful word fragments\u2014that together compose a phrase or a key part of a word, often including surrounding spaces or punctuation to mark word boundaries.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8496940533320109,
    "similarity_var": 0.0003109638173184079,
    "score_fuzz": 0.5,
    "score_detection": 0.425,
    "score_embedding": 0.52875,
    "total_score": 0.48458333333333337,
    "x": 15.183879852294922,
    "y": 4.461796760559082,
    "cluster_id": 72
  },
  {
    "feature_id": 230,
    "explanation_index": 0,
    "text": "Prepositions and articles often precede nouns, while adjectives and adverbs often precede or follow the nouns or verbs they modify, and mathematical or scientific terms often have specific symbols or formatting.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8489561875661215,
    "similarity_var": 0.0002850054680018212,
    "score_fuzz": 0.62,
    "score_detection": 0.55,
    "score_embedding": 0.374,
    "total_score": 0.5146666666666667,
    "x": 12.959538459777832,
    "y": 0.2379254251718521,
    "cluster_id": 43
  },
  {
    "feature_id": 230,
    "explanation_index": 1,
    "text": "The token \\\"the\\\" frequently appears in contexts involving mathematical or technical descriptions, often preceding nouns that denote abstract quantities, sets, or properties, and is commonly associated with formal or quantitative expressions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8489561875661215,
    "similarity_var": 0.0002850054680018212,
    "score_fuzz": 0.68,
    "score_detection": 0.52,
    "score_embedding": 0.518125,
    "total_score": 0.5727083333333334,
    "x": 10.937581062316895,
    "y": 2.661081314086914,
    "cluster_id": -1
  },
  {
    "feature_id": 230,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core words of quantitative or relational phrases\u2014common nouns, adjectives, or function words that form key expressions such as \u201cnumber of\u201d, \u201ctotal number\u201d, \u201ctime\u201d, \u201cvalue\u201d, \u201cfunction difference of\u201d, \u201cproduct of\u201d, \u201csum of\u201d, \u201camount of\u201d, \u201cpercentage\u201d, \u201crange\u201d, \u201clog\u201d, \u201cenergy\u201d, \u201caffine\u201d, \u201cradius\u201d, \u201cratio\u201d, \u201cspeed\u201d. These phrases convey measurements, relationships, or mathematical operations, and the model activates them as important.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8489561875661215,
    "similarity_var": 0.0002850054680018212,
    "score_fuzz": 0.6,
    "score_detection": 0.5,
    "score_embedding": 0.4325,
    "total_score": 0.5108333333333334,
    "x": 13.348724365234375,
    "y": 4.752790927886963,
    "cluster_id": -1
  },
  {
    "feature_id": 231,
    "explanation_index": 0,
    "text": "Biological terms, often referring to cells, tissues, or organs, and sometimes describing their functions or characteristics.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.886214554309845,
    "similarity_var": 3.8899704648542865e-06,
    "score_fuzz": 0.71,
    "score_detection": 0.51,
    "score_embedding": 0.7712,
    "total_score": 0.6637333333333334,
    "x": 7.270477771759033,
    "y": 1.4487831592559814,
    "cluster_id": 25
  },
  {
    "feature_id": 231,
    "explanation_index": 1,
    "text": "Biomedical terms composed of compound word parts, often describing cellular, molecular, or anatomical structures, with high activation on root or morphological components.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.886214554309845,
    "similarity_var": 3.8899704648542865e-06,
    "score_fuzz": 0.6736842105263158,
    "score_detection": 0.49,
    "score_embedding": 0.4618749999999999,
    "total_score": 0.5418530701754386,
    "x": 7.329655647277832,
    "y": 2.0420846939086914,
    "cluster_id": -1
  },
  {
    "feature_id": 231,
    "explanation_index": 2,
    "text": "Tokens that are biologically relevant nouns or adjectives\u2014often part of multi\u2011word phrases describing cell types, tissues, or processes\u2014are highlighted.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.886214554309845,
    "similarity_var": 3.8899704648542865e-06,
    "score_fuzz": 0.675,
    "score_detection": 0.55,
    "score_embedding": 0.455,
    "total_score": 0.56,
    "x": 15.184771537780762,
    "y": 4.040643215179443,
    "cluster_id": 22
  },
  {
    "feature_id": 233,
    "explanation_index": 0,
    "text": "Articles, prepositions, and conjunctions, often used to connect words or phrases, and sometimes nouns or noun phrases, especially those referring to locations or objects.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8717851837476095,
    "similarity_var": 5.634499811040743e-05,
    "score_fuzz": 0.49473684210526314,
    "score_detection": 0.55,
    "score_embedding": 0.5144,
    "total_score": 0.5197122807017543,
    "x": 12.646390914916992,
    "y": 0.18272022902965546,
    "cluster_id": 57
  },
  {
    "feature_id": 233,
    "explanation_index": 1,
    "text": "Common tokens include pronouns, prepositions, and function words that serve grammatical or structural roles, often appearing in sequences related to syntax, code, or natural language flow.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8717851837476095,
    "similarity_var": 5.634499811040743e-05,
    "score_fuzz": 0.54,
    "score_detection": 0.52,
    "score_embedding": 0.504375,
    "total_score": 0.5214583333333334,
    "x": 11.112699508666992,
    "y": 4.558658123016357,
    "cluster_id": -1
  },
  {
    "feature_id": 233,
    "explanation_index": 2,
    "text": "Tokens that belong to a semantically salient phrase, often a noun or verb phrase, sometimes spanning multiple words and including punctuation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8717851837476095,
    "similarity_var": 5.634499811040743e-05,
    "score_fuzz": 0.5,
    "score_detection": 0.35,
    "score_embedding": 0.521875,
    "total_score": 0.45729166666666665,
    "x": 10.503289222717285,
    "y": 4.618833065032959,
    "cluster_id": 47
  },
  {
    "feature_id": 234,
    "explanation_index": 0,
    "text": "Abstract nouns representing concepts that describe the influence, importance, or result of something, often used in academic or technical contexts to discuss the outcomes or consequences of a particular action, event, or situation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9411584337552389,
    "similarity_var": 3.063690389697942e-05,
    "score_fuzz": 0.94,
    "score_detection": 0.94,
    "score_embedding": 0.9564,
    "total_score": 0.9454666666666666,
    "x": 8.256333351135254,
    "y": 0.47764742374420166,
    "cluster_id": 12
  },
  {
    "feature_id": 234,
    "explanation_index": 1,
    "text": "Abstract nouns denoting measurable or theoretical outcomes, influences, or relationships in scientific contexts, often used to describe effects, roles, significance, or contributions of variables, interventions, or phenomena.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9411584337552389,
    "similarity_var": 3.063690389697942e-05,
    "score_fuzz": 0.96,
    "score_detection": 0.96,
    "score_embedding": 0.9675,
    "total_score": 0.9625,
    "x": 8.228344917297363,
    "y": 0.5594533085823059,
    "cluster_id": 12
  },
  {
    "feature_id": 234,
    "explanation_index": 2,
    "text": "The highlighted tokens are abstract nouns that denote influence, importance, or effect, typically used in academic or scientific contexts to describe the significance of a variable or phenomenon.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9411584337552389,
    "similarity_var": 3.063690389697942e-05,
    "score_fuzz": 0.925,
    "score_detection": 0.975,
    "score_embedding": 0.9562499999999999,
    "total_score": 0.9520833333333333,
    "x": 14.686866760253906,
    "y": 4.059357166290283,
    "cluster_id": 11
  },
  {
    "feature_id": 236,
    "explanation_index": 0,
    "text": "Various programming-related tokens, including variable names, function calls, and keywords, often in the context of code snippets or programming languages.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8128715554873148,
    "similarity_var": 0.002222216825592069,
    "score_fuzz": 0.49,
    "score_detection": 0.52,
    "score_embedding": 0.4572,
    "total_score": 0.4890666666666667,
    "x": 10.9268798828125,
    "y": 6.123945713043213,
    "cluster_id": 18
  },
  {
    "feature_id": 236,
    "explanation_index": 1,
    "text": "The token \\\"test\\\" frequently appears in contexts related to software development, particularly in identifiers, file paths, configuration, and code structure, often associated with testing frameworks, test cases, or test-related functionality.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8128715554873148,
    "similarity_var": 0.002222216825592069,
    "score_fuzz": 0.45,
    "score_detection": 0.45,
    "score_embedding": 0.544375,
    "total_score": 0.4814583333333333,
    "x": 10.877936363220215,
    "y": 6.1249775886535645,
    "cluster_id": 18
  },
  {
    "feature_id": 236,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8128715554873148,
    "similarity_var": 0.002222216825592069,
    "score_fuzz": 0.5,
    "score_detection": 0.525,
    "score_embedding": 0.468125,
    "total_score": 0.49770833333333336,
    "x": -5.964421272277832,
    "y": 15.94436264038086,
    "cluster_id": 10
  },
  {
    "feature_id": 237,
    "explanation_index": 0,
    "text": "Citations, references, and titles of laws, codes, and court cases, often including section numbers, years, and jurisdictions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9046252568562826,
    "similarity_var": 0.0010474279410491111,
    "score_fuzz": 0.55,
    "score_detection": 0.46,
    "score_embedding": 0.5436000000000001,
    "total_score": 0.5178666666666667,
    "x": 8.881690979003906,
    "y": 4.4723334312438965,
    "cluster_id": 75
  },
  {
    "feature_id": 237,
    "explanation_index": 1,
    "text": "Legal citations and references to statutes, codes, court cases, and legislative acts, often involving abbreviated state names, section numbers, court designations, and punctuation patterns typical of legal text.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9046252568562826,
    "similarity_var": 0.0010474279410491111,
    "score_fuzz": 0.53,
    "score_detection": 0.45,
    "score_embedding": 0.5731250000000001,
    "total_score": 0.5177083333333333,
    "x": 8.871657371520996,
    "y": 4.428886890411377,
    "cluster_id": 75
  },
  {
    "feature_id": 237,
    "explanation_index": 2,
    "text": "Tokens that belong to legal citation phrases\u2014jurisdiction abbreviations, section symbols, and related legal terms\u2014are highlighted as important.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9046252568562826,
    "similarity_var": 0.0010474279410491111,
    "score_fuzz": 0.525,
    "score_detection": 0.45,
    "score_embedding": 0.595625,
    "total_score": 0.5235416666666667,
    "x": 9.090810775756836,
    "y": 4.461981296539307,
    "cluster_id": -1
  },
  {
    "feature_id": 238,
    "explanation_index": 0,
    "text": "Mathematical expressions and equations, often involving variables, operators, and functions, with a focus on algebraic and calculus-related notation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8453298807144165,
    "similarity_var": 0.002435900811775582,
    "score_fuzz": 0.74,
    "score_detection": 0.72,
    "score_embedding": 0.6247999999999999,
    "total_score": 0.6949333333333333,
    "x": 9.402838706970215,
    "y": 8.49791145324707,
    "cluster_id": 65
  },
  {
    "feature_id": 238,
    "explanation_index": 1,
    "text": "The token sequences involving mathematical operators, parentheses, and symbolic notation often contain patterns of nested expressions, function applications, and symbolic variables, with high activation on delimiters, operators, and variable identifiers.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8453298807144165,
    "similarity_var": 0.002435900811775582,
    "score_fuzz": 0.63,
    "score_detection": 0.68,
    "score_embedding": 0.40499999999999997,
    "total_score": 0.5716666666666667,
    "x": 11.026310920715332,
    "y": 5.484500408172607,
    "cluster_id": 51
  },
  {
    "feature_id": 238,
    "explanation_index": 2,
    "text": "The patterns: the markers are used to isolate tokens that are important for the model's activation, often single tokens or short phrases.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8453298807144165,
    "similarity_var": 0.002435900811775582,
    "score_fuzz": 0.4,
    "score_detection": 0.35,
    "score_embedding": 0.391875,
    "total_score": 0.380625,
    "x": 14.389932632446289,
    "y": 5.112753868103027,
    "cluster_id": -1
  },
  {
    "feature_id": 239,
    "explanation_index": 0,
    "text": "Common nouns representing various concepts, objects, and actions, often in specific contexts such as travel, technology, and everyday life.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8854511976242065,
    "similarity_var": 0.00011711219662184173,
    "score_fuzz": 0.59,
    "score_detection": 0.21,
    "score_embedding": 0.484,
    "total_score": 0.42799999999999994,
    "x": 8.402737617492676,
    "y": -0.2698502838611603,
    "cluster_id": -1
  },
  {
    "feature_id": 239,
    "explanation_index": 1,
    "text": "Nouns and noun phrases denoting locations, transportation, or abstract concepts, often part of common collocations or technical terms, with high activation values when they appear in contextually specific or semantically rich phrases.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8854511976242065,
    "similarity_var": 0.00011711219662184173,
    "score_fuzz": 0.42,
    "score_detection": 0.29,
    "score_embedding": 0.5581250000000001,
    "total_score": 0.4227083333333333,
    "x": 8.796487808227539,
    "y": -0.1021597757935524,
    "cluster_id": -1
  },
  {
    "feature_id": 239,
    "explanation_index": 2,
    "text": "The highlighted tokens are primarily content words\u2014nouns or noun phrases that denote objects, events, or concepts\u2014often serving as the core semantic units of the sentence, with occasional key verbs or adjectives that carry the main action or property.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8854511976242065,
    "similarity_var": 0.00011711219662184173,
    "score_fuzz": 0.7,
    "score_detection": 0.375,
    "score_embedding": 0.7256250000000001,
    "total_score": 0.6002083333333333,
    "x": 15.34949779510498,
    "y": 3.9933676719665527,
    "cluster_id": 22
  },
  {
    "feature_id": 240,
    "explanation_index": 0,
    "text": "Titles or honorifics preceding names of individuals, often indicating positions of authority or prestige.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9297652244567871,
    "similarity_var": 7.156467748596167e-05,
    "score_fuzz": 0.79,
    "score_detection": 0.75,
    "score_embedding": 0.7924,
    "total_score": 0.7774666666666666,
    "x": 7.260011196136475,
    "y": -0.5695334672927856,
    "cluster_id": -1
  },
  {
    "feature_id": 240,
    "explanation_index": 1,
    "text": "Titles or honorifics (e.g., Sir, Admiral, President, Secretary) are frequently followed by personal names, and the most activated tokens are typically the title components and the associated proper names, with the title often serving as a key identifier for formal or official roles.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9297652244567871,
    "similarity_var": 7.156467748596167e-05,
    "score_fuzz": 0.81,
    "score_detection": 0.69,
    "score_embedding": 0.6712499999999999,
    "total_score": 0.7237499999999999,
    "x": 10.150714874267578,
    "y": 4.422332286834717,
    "cluster_id": 1
  },
  {
    "feature_id": 240,
    "explanation_index": 2,
    "text": "The highlighted tokens are titles or honorifics that precede names or positions, often capitalized and sometimes multi\u2011word, indicating rank, office, or formal address.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9297652244567871,
    "similarity_var": 7.156467748596167e-05,
    "score_fuzz": 0.8,
    "score_detection": 0.7,
    "score_embedding": 0.69125,
    "total_score": 0.7304166666666667,
    "x": 14.363279342651367,
    "y": 4.282747268676758,
    "cluster_id": -1
  },
  {
    "feature_id": 242,
    "explanation_index": 0,
    "text": "Auxiliary verbs and modal verbs used to express possibility, ability, permission, obligation, or future actions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9170535206794739,
    "similarity_var": 0.00025295538670159584,
    "score_fuzz": 0.9,
    "score_detection": 0.73,
    "score_embedding": 0.5616000000000001,
    "total_score": 0.7305333333333334,
    "x": 10.894688606262207,
    "y": -0.2595656216144562,
    "cluster_id": -1
  },
  {
    "feature_id": 242,
    "explanation_index": 1,
    "text": "Modal auxiliary verbs and their negated forms (e.g., can, could, may, might, will, shall, should, have, not, cannot) frequently appear in contexts involving possibility, necessity, or hypothetical conditions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9170535206794739,
    "similarity_var": 0.00025295538670159584,
    "score_fuzz": 0.86,
    "score_detection": 0.83,
    "score_embedding": 0.5275000000000001,
    "total_score": 0.7391666666666667,
    "x": 10.965384483337402,
    "y": -0.0767383724451065,
    "cluster_id": -1
  },
  {
    "feature_id": 242,
    "explanation_index": 2,
    "text": "The highlighted tokens are mainly modal or auxiliary verbs (can, could, will, have, may, should, not, to) and the short verb phrases they form (e.g., \u201ccan be\u201d, \u201cwill be\u201d, \u201chave been\u201d). These words signal possibility, ability, obligation, or future action, and are often the key elements that carry the sentence\u2019s meaning.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9170535206794739,
    "similarity_var": 0.00025295538670159584,
    "score_fuzz": 0.925,
    "score_detection": 0.775,
    "score_embedding": 0.49999999999999994,
    "total_score": 0.7333333333333334,
    "x": 14.050814628601074,
    "y": 3.5070972442626953,
    "cluster_id": 0
  },
  {
    "feature_id": 243,
    "explanation_index": 0,
    "text": "Various suffixes and prefixes, often indicating a change in state, location, or time, and sometimes used in technical or scientific contexts, or as part of a citation or reference.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8631115754445394,
    "similarity_var": 0.00039802470822615353,
    "score_fuzz": 0.5157894736842106,
    "score_detection": 0.26,
    "score_embedding": 0.46359999999999996,
    "total_score": 0.4131298245614035,
    "x": 8.34953784942627,
    "y": 2.181990385055542,
    "cluster_id": 44
  },
  {
    "feature_id": 243,
    "explanation_index": 1,
    "text": "The suffix \\\"-ate\\\" commonly appears in scientific and technical terms, often forming nouns or adjectives related to processes or states, and is frequently associated with chemical, biological, or engineering contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8631115754445394,
    "similarity_var": 0.00039802470822615353,
    "score_fuzz": 0.42,
    "score_detection": 0.16,
    "score_embedding": 0.5475,
    "total_score": 0.3758333333333333,
    "x": 8.626443862915039,
    "y": 2.3638834953308105,
    "cluster_id": 66
  },
  {
    "feature_id": 243,
    "explanation_index": 2,
    "text": "The highlighted fragments are typically short, high\u2011frequency English words or common suffixes that appear embedded within larger words or phrases\u2014such as \u201crate,\u201d \u201cgate,\u201d \u201cate,\u201d \u201cat,\u201d \u201clater,\u201d \u201cnote,\u201d \u201cstates,\u201d \u201cagent,\u201d and the \u201c@\u201d symbol. These tokens often function as connective or nominal elements in the surrounding context, indicating that the model flags frequent, functionally significant sub\u2011units rather than whole lexical items.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8631115754445394,
    "similarity_var": 0.00039802470822615353,
    "score_fuzz": 0.625,
    "score_detection": 0.425,
    "score_embedding": 0.5487500000000001,
    "total_score": 0.5329166666666667,
    "x": 14.912664413452148,
    "y": 5.2091450691223145,
    "cluster_id": 77
  },
  {
    "feature_id": 244,
    "explanation_index": 0,
    "text": "Articles, adjectives, adverbs, and nouns that provide additional information or context to the surrounding text, often indicating specificity, comparison, or possession.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8710655768712362,
    "similarity_var": 0.00030930474361983643,
    "score_fuzz": 0.64,
    "score_detection": 0.51,
    "score_embedding": 0.6696,
    "total_score": 0.6065333333333333,
    "x": 12.636754989624023,
    "y": 0.4722466468811035,
    "cluster_id": -1
  },
  {
    "feature_id": 244,
    "explanation_index": 1,
    "text": "Commonly used words and phrases that serve as grammatical or contextual connectors, often appearing in technical or descriptive text, with moderate activation values indicating their functional role in sentence structure and meaning.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8710655768712362,
    "similarity_var": 0.00030930474361983643,
    "score_fuzz": 0.53,
    "score_detection": 0.63,
    "score_embedding": 0.506875,
    "total_score": 0.555625,
    "x": 10.47732162475586,
    "y": 1.0757815837860107,
    "cluster_id": -1
  },
  {
    "feature_id": 244,
    "explanation_index": 2,
    "text": "The highlighted tokens are typically short, high\u2011frequency function words or domain\u2011specific terms that serve as core components of a phrase, often acting as connectors or descriptors that give the phrase its meaning.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8710655768712362,
    "similarity_var": 0.00030930474361983643,
    "score_fuzz": 0.55,
    "score_detection": 0.3,
    "score_embedding": 0.5387500000000001,
    "total_score": 0.4629166666666667,
    "x": 13.941625595092773,
    "y": 4.029516220092773,
    "cluster_id": 42
  },
  {
    "feature_id": 245,
    "explanation_index": 0,
    "text": "Various parts of speech, including nouns, verbs, adjectives, and adverbs, often functioning as significant elements in phrases or sentences, sometimes indicating a transition, comparison, or possession.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8628724614779154,
    "similarity_var": 0.0001260937153809828,
    "score_fuzz": 0.65,
    "score_detection": 0.54,
    "score_embedding": 0.4696,
    "total_score": 0.5532,
    "x": 9.481291770935059,
    "y": -0.068557009100914,
    "cluster_id": -1
  },
  {
    "feature_id": 245,
    "explanation_index": 1,
    "text": "Commonly activated tokens include function words (e.g., \\\"to\\\", \\\"of\\\", \\\"and\\\"), possessive or relational markers, and content words in compound nouns or phrases, often indicating relationships, locations, or grammatical structure.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8628724614779154,
    "similarity_var": 0.0001260937153809828,
    "score_fuzz": 0.59,
    "score_detection": 0.55,
    "score_embedding": 0.528125,
    "total_score": 0.5560416666666667,
    "x": 10.243330955505371,
    "y": 3.2839744091033936,
    "cluster_id": 50
  },
  {
    "feature_id": 245,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core lexical items that form the semantic nucleus of a phrase or name\u2014nouns, adjectives, verbs, and parts of proper names\u2014that carry the main meaning of the sentence.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8628724614779154,
    "similarity_var": 0.0001260937153809828,
    "score_fuzz": 0.575,
    "score_detection": 0.425,
    "score_embedding": 0.550625,
    "total_score": 0.5168750000000001,
    "x": 15.185510635375977,
    "y": 4.070674419403076,
    "cluster_id": 22
  },
  {
    "feature_id": 246,
    "explanation_index": 0,
    "text": "Numerical values, often in the form of codes, identifiers, or measurements, embedded within text.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8968719244003296,
    "similarity_var": 9.767841590502258e-05,
    "score_fuzz": 0.58,
    "score_detection": 0.46,
    "score_embedding": 0.2564,
    "total_score": 0.4321333333333333,
    "x": 6.850014686584473,
    "y": 8.807662963867188,
    "cluster_id": 29
  },
  {
    "feature_id": 246,
    "explanation_index": 1,
    "text": "The digit sequences within delimiters often represent identifiers, version numbers, or reference codes, with the most activated tokens typically being single digits or short numeric sequences embedded in structured text.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8968719244003296,
    "similarity_var": 9.767841590502258e-05,
    "score_fuzz": 0.61,
    "score_detection": 0.39,
    "score_embedding": 0.316875,
    "total_score": 0.43895833333333334,
    "x": 9.711030006408691,
    "y": 7.12443208694458,
    "cluster_id": -1
  },
  {
    "feature_id": 246,
    "explanation_index": 2,
    "text": "The highlighted fragments are typically short numeric or alphanumeric identifiers, code or math symbols that carry high informational weight.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8968719244003296,
    "similarity_var": 9.767841590502258e-05,
    "score_fuzz": 0.525,
    "score_detection": 0.475,
    "score_embedding": 0.28625,
    "total_score": 0.42874999999999996,
    "x": 15.414884567260742,
    "y": 7.316304683685303,
    "cluster_id": 56
  },
  {
    "feature_id": 248,
    "explanation_index": 0,
    "text": "Tokens often represent units of measurement, chemical names, or words with prefixes or suffixes, sometimes in scientific or technical contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8482370773951212,
    "similarity_var": 0.0014834591704071282,
    "score_fuzz": 0.73,
    "score_detection": 0.77,
    "score_embedding": 0.6892,
    "total_score": 0.7297333333333333,
    "x": 10.128006935119629,
    "y": 4.314208030700684,
    "cluster_id": 1
  },
  {
    "feature_id": 248,
    "explanation_index": 1,
    "text": "The model attends to partial or truncated words, often prefixes or suffixes of technical, scientific, or proper nouns, particularly in contexts involving abbreviations, units, chemical terms, or compound words. These fragments are typically part of larger lexical units and are activated when they appear in specific morphological or contextual patterns.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8482370773951212,
    "similarity_var": 0.0014834591704071282,
    "score_fuzz": 0.6,
    "score_detection": 0.7,
    "score_embedding": 0.565,
    "total_score": 0.6216666666666666,
    "x": 7.8336381912231445,
    "y": 3.0237739086151123,
    "cluster_id": -1
  },
  {
    "feature_id": 248,
    "explanation_index": 2,
    "text": "The pattern is that the important tokens are prefixes or substrings that start with \\\"met\\\" or \\\"meta\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" etc. Also \\\"m\\\" appears as a single letter. But many tokens are \\\"met\\\" or \\\"meta\\\" or \\\"met\\\" or \\\"met\\\". Also \\\"m\\\" appears as a single letter. But the main pattern is that the important tokens are substrings that start with \\\"met\\\" or \\\"meta\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\" or \\\"met\\\".",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8482370773951212,
    "similarity_var": 0.0014834591704071282,
    "score_fuzz": 0.7,
    "score_detection": 0.575,
    "score_embedding": 0.5912499999999999,
    "total_score": 0.6220833333333333,
    "x": 11.370433807373047,
    "y": 4.051029682159424,
    "cluster_id": -1
  },
  {
    "feature_id": 250,
    "explanation_index": 0,
    "text": "Tokens that are part of a word or phrase, often indicating a connection or continuation, and sometimes used to form a verb or adjective.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.884521504243215,
    "similarity_var": 0.0005021750990208161,
    "score_fuzz": 0.42,
    "score_detection": 0.45,
    "score_embedding": 0.6539999999999999,
    "total_score": 0.508,
    "x": 10.303778648376465,
    "y": 4.395907878875732,
    "cluster_id": 1
  },
  {
    "feature_id": 250,
    "explanation_index": 1,
    "text": "Fragments of words or multi-word phrases that are split across tokens, often due to morphological or orthographic boundaries, with high activation on partial or compound forms.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.884521504243215,
    "similarity_var": 0.0005021750990208161,
    "score_fuzz": 0.58,
    "score_detection": 0.5,
    "score_embedding": 0.550625,
    "total_score": 0.5435416666666667,
    "x": 6.987274169921875,
    "y": 2.756274461746216,
    "cluster_id": 2
  },
  {
    "feature_id": 250,
    "explanation_index": 2,
    "text": "The highlighted tokens are sub\u2011word pieces that together form a meaningful phrase or a larger word\u2014often idioms, proper nouns, or partially split words\u2014so the model\u2019s activations cluster on contiguous, semantically relevant fragments.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.884521504243215,
    "similarity_var": 0.0005021750990208161,
    "score_fuzz": 0.6,
    "score_detection": 0.425,
    "score_embedding": 0.60625,
    "total_score": 0.54375,
    "x": 14.948812484741211,
    "y": 4.918185710906982,
    "cluster_id": -1
  },
  {
    "feature_id": 251,
    "explanation_index": 0,
    "text": "Articles, auxiliary verbs, and other function words that provide grammatical context.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8787026007970175,
    "similarity_var": 0.0015469548752528163,
    "score_fuzz": 0.54,
    "score_detection": 0.43,
    "score_embedding": 0.306,
    "total_score": 0.42533333333333334,
    "x": 11.026571273803711,
    "y": 1.0875015258789062,
    "cluster_id": -1
  },
  {
    "feature_id": 251,
    "explanation_index": 1,
    "text": "Common function words and short content words that serve grammatical or structural roles in sentences, often appearing in contexts involving modality, possession, comparison, or reference.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8787026007970175,
    "similarity_var": 0.0015469548752528163,
    "score_fuzz": 0.59,
    "score_detection": 0.45,
    "score_embedding": 0.365625,
    "total_score": 0.4685416666666667,
    "x": 10.675701141357422,
    "y": 1.318406343460083,
    "cluster_id": 26
  },
  {
    "feature_id": 251,
    "explanation_index": 2,
    "text": "The highlighted tokens are typically single words or short phrases that form the core of a noun or verb phrase, often representing key concepts, actions, or modifiers within the sentence.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8787026007970175,
    "similarity_var": 0.0015469548752528163,
    "score_fuzz": 0.425,
    "score_detection": 0.55,
    "score_embedding": 0.3975,
    "total_score": 0.4575,
    "x": 14.600626945495605,
    "y": 3.834307909011841,
    "cluster_id": 11
  },
  {
    "feature_id": 252,
    "explanation_index": 0,
    "text": "Nouns or adjectives representing medical or biological terms, often related to diseases, body parts, or scientific concepts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8698761661847433,
    "similarity_var": 0.0011310634286879739,
    "score_fuzz": 0.64,
    "score_detection": 0.57,
    "score_embedding": 0.5952,
    "total_score": 0.6017333333333333,
    "x": 7.607428550720215,
    "y": 1.0753206014633179,
    "cluster_id": -1
  },
  {
    "feature_id": 252,
    "explanation_index": 1,
    "text": "Medical and biological terminology involving anatomical structures, pathological conditions, and physiological processes, often with compound or technical terms formed from root words and affixes.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8698761661847433,
    "similarity_var": 0.0011310634286879739,
    "score_fuzz": 0.62,
    "score_detection": 0.57,
    "score_embedding": 0.5906250000000001,
    "total_score": 0.5935416666666667,
    "x": 7.354585647583008,
    "y": 2.010417938232422,
    "cluster_id": -1
  },
  {
    "feature_id": 252,
    "explanation_index": 2,
    "text": "The model activates on subword fragments that compose domain\u2011specific terms or common phrases, especially in biomedical contexts, and also on frequent function words that appear in key positions.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8698761661847433,
    "similarity_var": 0.0011310634286879739,
    "score_fuzz": 0.575,
    "score_detection": 0.4,
    "score_embedding": 0.6175,
    "total_score": 0.5308333333333334,
    "x": 8.132519721984863,
    "y": 3.2494516372680664,
    "cluster_id": 76
  },
  {
    "feature_id": 253,
    "explanation_index": 0,
    "text": "Function words and nouns that are part of a phrase or sentence structure, often indicating possession, relation, or condition, and sometimes introducing a clause or quotation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8708314895629883,
    "similarity_var": 0.0005917333525099858,
    "score_fuzz": 0.55,
    "score_detection": 0.45,
    "score_embedding": 0.7208,
    "total_score": 0.5736,
    "x": 10.633830070495605,
    "y": 1.2151551246643066,
    "cluster_id": 26
  },
  {
    "feature_id": 253,
    "explanation_index": 1,
    "text": "Commonly activated tokens include pronouns (e.g., \\\"they\\\", \\\"them\\\", \\\"that\\\", \\\"which\\\"), possessive or relational nouns (e.g., \\\"body\\\", \\\"life\\\", \\\"city\\\", \\\"planet\\\"), and functional words (e.g., \\\"to\\\", \\\"can\\\", \\\"may\\\", \\\"that\\\") that serve grammatical or referential roles in contextually rich or semantically dense phrases.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8708314895629883,
    "similarity_var": 0.0005917333525099858,
    "score_fuzz": 0.66,
    "score_detection": 0.48,
    "score_embedding": 0.8525,
    "total_score": 0.6641666666666667,
    "x": 10.449198722839355,
    "y": 3.0697567462921143,
    "cluster_id": -1
  },
  {
    "feature_id": 253,
    "explanation_index": 2,
    "text": "The tokens are often words like \\\"world\\\", \\\"economy\\\", \\\"thereof\\\", \\\"area\\\", \\\"to\\\", \\\"body\\\", \\\"carriers\\\", \\\"features\\\", \\\"turnips\\\", \\\"genes\\\", \\\"that\\\", \\\"to\\\", \\\"can\\\", \\\"residues\\\", \\\"life\\\", \\\"city\\\", \\\"stocks\\\", \\\"planet\\\", \\\"file\\\", \\\"pets\\\", \\\"everything\\\", \\\"file\\\", \\\"that\\\", \\\"who\\\", \\\"may\\\", \\\"feet\\\", etc.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8708314895629883,
    "similarity_var": 0.0005917333525099858,
    "score_fuzz": 0.65,
    "score_detection": 0.75,
    "score_embedding": 0.91125,
    "total_score": 0.7704166666666666,
    "x": 10.885124206542969,
    "y": 3.363637924194336,
    "cluster_id": 27
  },
  {
    "feature_id": 255,
    "explanation_index": 0,
    "text": "Mathematical and programming expressions, often involving arithmetic operations, variables, and function calls, with a focus on syntax and notation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8887002468109131,
    "similarity_var": 0.00024313653399824867,
    "score_fuzz": 0.34,
    "score_detection": 0.36,
    "score_embedding": 0.6956,
    "total_score": 0.4652,
    "x": 9.464920043945312,
    "y": 8.492981910705566,
    "cluster_id": 65
  },
  {
    "feature_id": 255,
    "explanation_index": 1,
    "text": "The presence of isolated digits, mathematical operators, and symbolic notation in code-like contexts, often indicating numerical values, variables, or syntax elements in programming or mathematical expressions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8887002468109131,
    "similarity_var": 0.00024313653399824867,
    "score_fuzz": 0.45,
    "score_detection": 0.48,
    "score_embedding": 0.581875,
    "total_score": 0.5039583333333333,
    "x": 7.614358425140381,
    "y": 8.394067764282227,
    "cluster_id": 29
  },
  {
    "feature_id": 255,
    "explanation_index": 2,
    "text": "The highlighted segments are individual code tokens or short expressions that are deemed important for the behavior, such as variable names, operators, numbers, or small phrases, often appearing in code fragments.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8887002468109131,
    "similarity_var": 0.00024313653399824867,
    "score_fuzz": 0.475,
    "score_detection": 0.275,
    "score_embedding": 0.385,
    "total_score": 0.37833333333333335,
    "x": 14.770243644714355,
    "y": 6.863102436065674,
    "cluster_id": -1
  },
  {
    "feature_id": 256,
    "explanation_index": 0,
    "text": "Proper nouns, often representing names of places, organizations, or specific entities, and sometimes including words that are part of a title or a formal name.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8860635161399841,
    "similarity_var": 0.0002886385808835712,
    "score_fuzz": 0.74,
    "score_detection": 0.76,
    "score_embedding": 0.6252,
    "total_score": 0.7084,
    "x": 7.4885053634643555,
    "y": -0.8948513865470886,
    "cluster_id": 16
  },
  {
    "feature_id": 256,
    "explanation_index": 1,
    "text": "Proper nouns or compound terms often consisting of two or more capitalized words, frequently representing geographical locations, organizations, technical terms, or branded entities, with high activation on the constituent parts, especially when forming a recognized name or label.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8860635161399841,
    "similarity_var": 0.0002886385808835712,
    "score_fuzz": 0.74,
    "score_detection": 0.75,
    "score_embedding": 0.6112500000000001,
    "total_score": 0.7004166666666668,
    "x": 7.662109375,
    "y": -0.6930390000343323,
    "cluster_id": 16
  },
  {
    "feature_id": 256,
    "explanation_index": 2,
    "text": "The highlighted tokens are the semantic anchors of the text: they are either nouns or proper nouns that form part of named entities or idiomatic expressions, or morphological markers (e.g., comparative suffix \u201cer\u201d) that signal key relationships. They tend to be capitalized or appear in multi\u2011word phrases that convey a specific meaning.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8860635161399841,
    "similarity_var": 0.0002886385808835712,
    "score_fuzz": 0.75,
    "score_detection": 0.475,
    "score_embedding": 0.34249999999999997,
    "total_score": 0.5225000000000001,
    "x": 14.667439460754395,
    "y": 3.8831543922424316,
    "cluster_id": 11
  },
  {
    "feature_id": 257,
    "explanation_index": 0,
    "text": "Words related to heat, fire, or high temperature, often in contexts involving combustion, furnaces, or flames.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9348005652427673,
    "similarity_var": 5.782576147576416e-05,
    "score_fuzz": 0.57,
    "score_detection": 0.4,
    "score_embedding": 0.36600000000000005,
    "total_score": 0.44533333333333336,
    "x": 8.184703826904297,
    "y": 0.5986566543579102,
    "cluster_id": 12
  },
  {
    "feature_id": 257,
    "explanation_index": 1,
    "text": "The presence of words related to combustion, heat, fire, or high-temperature processes, often in technical or industrial contexts, with a focus on specific components or stages involving heat generation, transformation, or control.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9348005652427673,
    "similarity_var": 5.782576147576416e-05,
    "score_fuzz": 0.61,
    "score_detection": 0.47,
    "score_embedding": 0.341875,
    "total_score": 0.4739583333333333,
    "x": 8.181988716125488,
    "y": 0.5034374594688416,
    "cluster_id": 12
  },
  {
    "feature_id": 257,
    "explanation_index": 2,
    "text": "The highlighted tokens are all related to fire, heat, or combustion, often appearing as full words or as partial fragments of longer terms.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9348005652427673,
    "similarity_var": 5.782576147576416e-05,
    "score_fuzz": 0.725,
    "score_detection": 0.3,
    "score_embedding": 0.35625000000000007,
    "total_score": 0.4604166666666667,
    "x": 13.853625297546387,
    "y": 3.9725959300994873,
    "cluster_id": 42
  },
  {
    "feature_id": 258,
    "explanation_index": 0,
    "text": "Tokens representing various types of data, including numerical values, codes, and technical terms, often in a structured or formatted context, such as tables, lists, or programming code.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.883151650428772,
    "similarity_var": 0.000691160985271703,
    "score_fuzz": 0.34,
    "score_detection": 0.4,
    "score_embedding": 0.724,
    "total_score": 0.488,
    "x": 10.707945823669434,
    "y": 5.88162088394165,
    "cluster_id": 18
  },
  {
    "feature_id": 258,
    "explanation_index": 1,
    "text": "Patterns of sparse, non-semantic tokens and structural markers in formatted or code-like text, often representing whitespace, delimiters, or syntactic placeholders.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.883151650428772,
    "similarity_var": 0.000691160985271703,
    "score_fuzz": 0.45,
    "score_detection": 0.47,
    "score_embedding": 0.855625,
    "total_score": 0.5918749999999999,
    "x": 10.553894996643066,
    "y": 6.728143215179443,
    "cluster_id": -1
  },
  {
    "feature_id": 258,
    "explanation_index": 2,
    "text": "The passages repeatedly use paired delimiters to isolate segments, many of which contain only whitespace or code fragments, indicating a pattern of placeholder or formatting markers that separate content.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.883151650428772,
    "similarity_var": 0.000691160985271703,
    "score_fuzz": 0.525,
    "score_detection": 0.6,
    "score_embedding": 0.8424999999999999,
    "total_score": 0.6558333333333333,
    "x": 10.126853942871094,
    "y": 6.990421772003174,
    "cluster_id": -1
  },
  {
    "feature_id": 259,
    "explanation_index": 0,
    "text": "Adverbs or adjectives that describe manner, time, or degree, often ending in -ly, -al, or -ous, and typically modifying verbs, adjectives, or other adverbs.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8930373589197794,
    "similarity_var": 0.0003907285671813396,
    "score_fuzz": 0.86,
    "score_detection": 0.7,
    "score_embedding": 0.48319999999999996,
    "total_score": 0.6810666666666667,
    "x": 9.269953727722168,
    "y": 1.6046600341796875,
    "cluster_id": 89
  },
  {
    "feature_id": 259,
    "explanation_index": 1,
    "text": "Suffixes forming adverbs or adjectives that modify or describe the nature, degree, or manner of a preceding word, often indicating intensity, manner, or specificity.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8930373589197794,
    "similarity_var": 0.0003907285671813396,
    "score_fuzz": 0.94,
    "score_detection": 0.55,
    "score_embedding": 0.536875,
    "total_score": 0.675625,
    "x": 8.714261054992676,
    "y": 2.064450263977051,
    "cluster_id": -1
  },
  {
    "feature_id": 259,
    "explanation_index": 2,
    "text": "The pattern might be that the highlighted words are modifiers (adjectives/adverbs) that modify nouns or verbs.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8930373589197794,
    "similarity_var": 0.0003907285671813396,
    "score_fuzz": 0.9142857142857143,
    "score_detection": 0.65,
    "score_embedding": 0.385,
    "total_score": 0.6497619047619048,
    "x": 16.6564998626709,
    "y": 3.6519596576690674,
    "cluster_id": 20
  },
  {
    "feature_id": 260,
    "explanation_index": 0,
    "text": "Tokens that are often used as delimiters or separators, such as parentheses, brackets, and quotation marks, and sometimes numbers or special characters that are used to denote a specific value or code.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8800472617149353,
    "similarity_var": 0.0007354613990836848,
    "score_fuzz": 0.54,
    "score_detection": 0.52,
    "score_embedding": 0.3924,
    "total_score": 0.48413333333333336,
    "x": 10.640268325805664,
    "y": 5.893610954284668,
    "cluster_id": 18
  },
  {
    "feature_id": 260,
    "explanation_index": 1,
    "text": "Delimiters (<< >>) are used to mark specific tokens or sequences in text, often surrounding identifiers, code elements, or structural markers, with activation values indicating importance in context.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8800472617149353,
    "similarity_var": 0.0007354613990836848,
    "score_fuzz": 0.44,
    "score_detection": 0.52,
    "score_embedding": 0.31499999999999995,
    "total_score": 0.425,
    "x": 9.799556732177734,
    "y": 6.937891006469727,
    "cluster_id": 69
  },
  {
    "feature_id": 260,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core lexical units that carry the main semantic or syntactic role in the surrounding phrase or code, such as the noun or noun phrase in idioms, the comparative suffix, or a key identifier in code.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8800472617149353,
    "similarity_var": 0.0007354613990836848,
    "score_fuzz": 0.575,
    "score_detection": 0.75,
    "score_embedding": 0.294375,
    "total_score": 0.5397916666666667,
    "x": 14.874866485595703,
    "y": 4.56292724609375,
    "cluster_id": -1
  },
  {
    "feature_id": 261,
    "explanation_index": 0,
    "text": "Nouns representing events, occasions, or happenings, often used in formal or technical contexts, and sometimes used in conjunction with words like \\\"even\\\" or \\\"eventually\\\" to convey a sense of occurrence or timing.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8548942804336548,
    "similarity_var": 0.0012353816180805666,
    "score_fuzz": 0.76,
    "score_detection": 0.77,
    "score_embedding": 0.5704,
    "total_score": 0.7001333333333334,
    "x": 8.522754669189453,
    "y": 0.9351843595504761,
    "cluster_id": 54
  },
  {
    "feature_id": 261,
    "explanation_index": 1,
    "text": "The word \\\"event\\\" and its variants (e.g., \\\"events\\\", \\\"event\\\", \\\"incident\\\", \\\"episode\\\") are frequently used to denote specific occurrences, particularly in contexts involving schedules, activities, or notable happenings, often appearing in structured or formal descriptions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8548942804336548,
    "similarity_var": 0.0012353816180805666,
    "score_fuzz": 0.68,
    "score_detection": 0.7,
    "score_embedding": 0.51375,
    "total_score": 0.63125,
    "x": 8.535369873046875,
    "y": 1.018787145614624,
    "cluster_id": -1
  },
  {
    "feature_id": 261,
    "explanation_index": 2,
    "text": "The pattern seems to be that the important tokens are often nouns or words that are part of a larger phrase, sometimes with capitalization variations.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8548942804336548,
    "similarity_var": 0.0012353816180805666,
    "score_fuzz": 0.7,
    "score_detection": 0.725,
    "score_embedding": 0.42437500000000006,
    "total_score": 0.6164583333333332,
    "x": 11.37610912322998,
    "y": 4.364053726196289,
    "cluster_id": 3
  },
  {
    "feature_id": 262,
    "explanation_index": 0,
    "text": "Prepositions and special characters used in various programming contexts, including comparisons, function calls, and variable assignments, often serving to connect words, indicate relationships, or denote specific operations.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8706631263097128,
    "similarity_var": 0.0002573428398717523,
    "score_fuzz": 0.47,
    "score_detection": 0.56,
    "score_embedding": 0.45239999999999997,
    "total_score": 0.4941333333333333,
    "x": 9.611554145812988,
    "y": 7.948249816894531,
    "cluster_id": -1
  },
  {
    "feature_id": 262,
    "explanation_index": 1,
    "text": "Common prepositional phrases and punctuation sequences indicating location, method, or relationship, often involving \\\"in\\\", \\\"from\\\", \\\"using\\\", \\\"via\\\", \\\"by\\\", \\\"to\\\", \\\"of\\\", and special symbols like \\\"_\\\", \\\".\\\", \\\"/\\\", \\\">\\\", or \\\"-\\\".",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8706631263097128,
    "similarity_var": 0.0002573428398717523,
    "score_fuzz": 0.6631578947368421,
    "score_detection": 0.67,
    "score_embedding": 0.49687499999999996,
    "total_score": 0.6100109649122807,
    "x": 12.398381233215332,
    "y": -0.5712785124778748,
    "cluster_id": 63
  },
  {
    "feature_id": 262,
    "explanation_index": 2,
    "text": "The highlighted tokens are short, high\u2011frequency function words\u2014prepositions, articles, conjunctions, and brief verbs\u2014that serve as syntactic glue in both natural language and code\u2011related text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8706631263097128,
    "similarity_var": 0.0002573428398717523,
    "score_fuzz": 0.65,
    "score_detection": 0.525,
    "score_embedding": 0.41999999999999993,
    "total_score": 0.5316666666666666,
    "x": 13.550766944885254,
    "y": 3.2694008350372314,
    "cluster_id": 35
  },
  {
    "feature_id": 263,
    "explanation_index": 0,
    "text": "Prepositions \\\"to\\\" and \\\"for\\\" often used to indicate purpose, necessity, or direction, frequently preceding verbs or nouns in formal or technical contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9080472191174825,
    "similarity_var": 8.320644135611449e-05,
    "score_fuzz": 0.86,
    "score_detection": 0.62,
    "score_embedding": 0.7179999999999999,
    "total_score": 0.7326666666666667,
    "x": 11.608396530151367,
    "y": 0.03902836889028549,
    "cluster_id": 53
  },
  {
    "feature_id": 263,
    "explanation_index": 1,
    "text": "The word \\\"to\\\" frequently appears in infinitive verb constructions, often introducing purpose or necessity, and is highly activated in contexts involving goals, requirements, or conditions. The word \\\"for\\\" also appears in similar functional roles, particularly in expressions of purpose or necessity, though less frequently than \\\"to\\\".",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9080472191174825,
    "similarity_var": 8.320644135611449e-05,
    "score_fuzz": 0.85,
    "score_detection": 0.62,
    "score_embedding": 0.625625,
    "total_score": 0.6985416666666667,
    "x": 11.454618453979492,
    "y": 0.054090965539216995,
    "cluster_id": -1
  },
  {
    "feature_id": 263,
    "explanation_index": 2,
    "text": "The text repeatedly highlights the preposition \u201cto\u201d (and sometimes \u201cfor\u201d) as a highly activated, function\u2011word connector that introduces infinitives or prepositional phrases, signaling purpose or direction in the sentence structure.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9080472191174825,
    "similarity_var": 8.320644135611449e-05,
    "score_fuzz": 0.85,
    "score_detection": 0.575,
    "score_embedding": 0.603125,
    "total_score": 0.6760416666666665,
    "x": 11.550115585327148,
    "y": 0.0853581354022026,
    "cluster_id": 53
  },
  {
    "feature_id": 264,
    "explanation_index": 0,
    "text": "Function words that provide context, transition, or connection between ideas, including words that indicate location, sequence, or relationship, often used to introduce or link information.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8807286421457926,
    "similarity_var": 0.00027952523243928655,
    "score_fuzz": 0.87,
    "score_detection": 0.81,
    "score_embedding": 0.23959999999999998,
    "total_score": 0.6398666666666667,
    "x": 10.721582412719727,
    "y": 1.0673292875289917,
    "cluster_id": 26
  },
  {
    "feature_id": 264,
    "explanation_index": 1,
    "text": "Words indicating proximity in time, space, or reference, often used to point to upcoming or preceding content in technical or formal writing.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8807286421457926,
    "similarity_var": 0.00027952523243928655,
    "score_fuzz": 0.8421052631578947,
    "score_detection": 0.66,
    "score_embedding": 0.25812500000000005,
    "total_score": 0.5867434210526317,
    "x": 10.800004959106445,
    "y": 0.8212983012199402,
    "cluster_id": -1
  },
  {
    "feature_id": 264,
    "explanation_index": 2,
    "text": "The highlighted words are common English function words that act as connectors or modifiers\u2014often appearing with \u201cthe\u201d or as part of a phrase such as \u201cthe following,\u201d \u201cthe above,\u201d or \u201cthe surrounding.\u201d They are structural rather than content\u2011bearing tokens.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8807286421457926,
    "similarity_var": 0.00027952523243928655,
    "score_fuzz": 0.8,
    "score_detection": 0.8,
    "score_embedding": 0.19374999999999998,
    "total_score": 0.5979166666666668,
    "x": 13.879287719726562,
    "y": 3.9690279960632324,
    "cluster_id": 42
  },
  {
    "feature_id": 265,
    "explanation_index": 0,
    "text": "Adverbs or adverbial phrases used to convey a sense of simplicity, immediacy, or proximity, often indicating a straightforward or uncomplicated action or situation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8810042341550192,
    "similarity_var": 0.0011167141366791433,
    "score_fuzz": 0.93,
    "score_detection": 0.73,
    "score_embedding": 0.394,
    "total_score": 0.6846666666666668,
    "x": 9.387980461120605,
    "y": 1.5699442625045776,
    "cluster_id": 89
  },
  {
    "feature_id": 265,
    "explanation_index": 1,
    "text": "The word \\\"just\\\" frequently appears in contexts emphasizing immediacy, minimalism, or understatement, often modifying actions, states, or conditions with a sense of simplicity or nearness in time or degree.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8810042341550192,
    "similarity_var": 0.0011167141366791433,
    "score_fuzz": 0.86,
    "score_detection": 0.85,
    "score_embedding": 0.51,
    "total_score": 0.7399999999999999,
    "x": 11.837679862976074,
    "y": 2.5541927814483643,
    "cluster_id": -1
  },
  {
    "feature_id": 265,
    "explanation_index": 2,
    "text": "The highlighted token is the word \u201cjust\u201d (in any capitalization), repeatedly appearing as a standalone word or within brief phrases across many contexts, indicating it is a key lexical item of interest.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8810042341550192,
    "similarity_var": 0.0011167141366791433,
    "score_fuzz": 0.825,
    "score_detection": 0.825,
    "score_embedding": 0.27749999999999997,
    "total_score": 0.6425,
    "x": 14.497344970703125,
    "y": 4.307608127593994,
    "cluster_id": -1
  },
  {
    "feature_id": 266,
    "explanation_index": 0,
    "text": "A variety of tokens including contractions, prepositions, articles, and nouns, often functioning as part of a phrase or sentence, and sometimes indicating possession, location, or action.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8939125537872314,
    "similarity_var": 0.00011954853023136518,
    "score_fuzz": 0.52,
    "score_detection": 0.4,
    "score_embedding": 0.4164,
    "total_score": 0.4454666666666667,
    "x": 10.559954643249512,
    "y": 4.522854328155518,
    "cluster_id": 47
  },
  {
    "feature_id": 266,
    "explanation_index": 1,
    "text": "Commonly activated tokens include pronouns like \\\"I\\\", \\\"me\\\", \\\"m\\\", and \\\"my\\\", as well as function words like \\\"with\\\", \\\"the\\\", and \\\"and\\\", often appearing in personal expressions, conversational contexts, or grammatical structures involving possession, emotion, or description.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8939125537872314,
    "similarity_var": 0.00011954853023136518,
    "score_fuzz": 0.67,
    "score_detection": 0.68,
    "score_embedding": 0.608125,
    "total_score": 0.6527083333333333,
    "x": 10.788488388061523,
    "y": 2.561448812484741,
    "cluster_id": -1
  },
  {
    "feature_id": 266,
    "explanation_index": 2,
    "text": "Tokens that belong to a phrase carrying semantic weight\u2014often function words or key content words\u2014are highlighted; these can be single words (e.g., \u201cwith,\u201d \u201ctake,\u201d \u201cproud,\u201d \u201cShe,\u201d \u201cer\u201d) or multi\u2011word sequences (e.g., \u201csmoking area,\u201d \u201chouse,\u201d \u201ccolor\u201d), and they frequently appear as prepositions, verbs, adjectives, pronouns, nouns, or suffixes that shape the meaning of the surrounding text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8939125537872314,
    "similarity_var": 0.00011954853023136518,
    "score_fuzz": 0.6,
    "score_detection": 0.3,
    "score_embedding": 0.3712500000000001,
    "total_score": 0.42375,
    "x": 15.404417991638184,
    "y": 4.030468463897705,
    "cluster_id": 22
  },
  {
    "feature_id": 267,
    "explanation_index": 0,
    "text": "Special characters and symbols used in programming languages, such as operators, template and generic type declarations, and namespace separators.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8934178749720255,
    "similarity_var": 0.0005177719564062815,
    "score_fuzz": 0.4,
    "score_detection": 0.46,
    "score_embedding": 0.6764,
    "total_score": 0.5121333333333333,
    "x": 9.67056941986084,
    "y": 7.760146141052246,
    "cluster_id": 6
  },
  {
    "feature_id": 267,
    "explanation_index": 1,
    "text": "The token sequences often represent syntactic or structural elements in programming languages, such as keywords, type names, operators, or identifiers, frequently appearing in code contexts with specific formatting or naming conventions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8934178749720255,
    "similarity_var": 0.0005177719564062815,
    "score_fuzz": 0.61,
    "score_detection": 0.43,
    "score_embedding": 0.62125,
    "total_score": 0.55375,
    "x": 11.078813552856445,
    "y": 5.686004638671875,
    "cluster_id": -1
  },
  {
    "feature_id": 267,
    "explanation_index": 2,
    "text": "The highlighted tokens are code identifiers, keywords, or syntax symbols that mark significant parts of programming constructs.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8934178749720255,
    "similarity_var": 0.0005177719564062815,
    "score_fuzz": 0.5,
    "score_detection": 0.375,
    "score_embedding": 0.5975,
    "total_score": 0.4908333333333334,
    "x": 13.895477294921875,
    "y": 6.5481390953063965,
    "cluster_id": 8
  },
  {
    "feature_id": 269,
    "explanation_index": 0,
    "text": "Verbs or verb phrases, often in the form of auxiliary verbs or modal verbs, that express intention, ability, or possibility, and sometimes nouns that represent a distinct object or concept.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8572258154551188,
    "similarity_var": 0.0005861394016911781,
    "score_fuzz": 0.62,
    "score_detection": 0.57,
    "score_embedding": 0.3404,
    "total_score": 0.5101333333333333,
    "x": 10.727034568786621,
    "y": -0.45942962169647217,
    "cluster_id": 85
  },
  {
    "feature_id": 269,
    "explanation_index": 1,
    "text": "Common function words and short morphological fragments that appear in syntactic or semantic contexts involving conditionals, modality, possession, comparison, or nominalization, often signaling grammatical structure or subtle meaning shifts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8572258154551188,
    "similarity_var": 0.0005861394016911781,
    "score_fuzz": 0.54,
    "score_detection": 0.35,
    "score_embedding": 0.26125000000000004,
    "total_score": 0.38375000000000004,
    "x": 10.667619705200195,
    "y": 1.4169570207595825,
    "cluster_id": 26
  },
  {
    "feature_id": 269,
    "explanation_index": 2,
    "text": "The highlighted tokens are usually short, high\u2011frequency function words or the core lexical items that make up common idioms or collocations, often appearing at the boundaries of such expressions.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8572258154551188,
    "similarity_var": 0.0005861394016911781,
    "score_fuzz": 0.5,
    "score_detection": 0.525,
    "score_embedding": 0.25875000000000004,
    "total_score": 0.42791666666666667,
    "x": 13.993782043457031,
    "y": 3.8024585247039795,
    "cluster_id": -1
  },
  {
    "feature_id": 270,
    "explanation_index": 0,
    "text": "Angle brackets used to denote generic types or templates in programming languages, often in the context of object-oriented or functional programming.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9161055088043213,
    "similarity_var": 0.000319865576673332,
    "score_fuzz": 0.68,
    "score_detection": 0.76,
    "score_embedding": 0.6932000000000001,
    "total_score": 0.7110666666666666,
    "x": 10.119613647460938,
    "y": 7.582206726074219,
    "cluster_id": -1
  },
  {
    "feature_id": 270,
    "explanation_index": 1,
    "text": "Angular brackets (\\\"<\\\" and \\\">\\\") are used to denote generic type parameters in programming languages, often appearing in templates, type declarations, or container types. The pattern consistently involves nested or sequential use of \\\"<\\\" and \\\">\\\" to define or instantiate generic types, with frequent occurrence of \\\",\\\" as a separator within these constructs.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9161055088043213,
    "similarity_var": 0.000319865576673332,
    "score_fuzz": 0.74,
    "score_detection": 0.77,
    "score_embedding": 0.7306250000000001,
    "total_score": 0.7468750000000001,
    "x": 9.632682800292969,
    "y": 6.820086479187012,
    "cluster_id": -1
  },
  {
    "feature_id": 270,
    "explanation_index": 2,
    "text": "The text is dominated by code that repeatedly uses angle brackets to denote generic type parameters, template arguments, and shift operators, often nested within one another.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9161055088043213,
    "similarity_var": 0.000319865576673332,
    "score_fuzz": 0.5,
    "score_detection": 0.7,
    "score_embedding": 0.775625,
    "total_score": 0.6585416666666667,
    "x": 10.153279304504395,
    "y": 7.429370403289795,
    "cluster_id": -1
  },
  {
    "feature_id": 272,
    "explanation_index": 0,
    "text": "Names of television and radio networks, stations, and programs, often including abbreviations or call signs.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.901514450709025,
    "similarity_var": 0.0010056269413741207,
    "score_fuzz": 0.76,
    "score_detection": 0.77,
    "score_embedding": 0.6991999999999999,
    "total_score": 0.7430666666666667,
    "x": 7.544031143188477,
    "y": -0.0555911511182785,
    "cluster_id": -1
  },
  {
    "feature_id": 272,
    "explanation_index": 1,
    "text": "Proper nouns and abbreviations representing television networks, stations, or media brands, often appearing in contexts related to broadcasting, programming, or media distribution.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.901514450709025,
    "similarity_var": 0.0010056269413741207,
    "score_fuzz": 0.7473684210526316,
    "score_detection": 0.75,
    "score_embedding": 0.7431249999999999,
    "total_score": 0.7468311403508773,
    "x": 7.576193332672119,
    "y": -0.42615577578544617,
    "cluster_id": -1
  },
  {
    "feature_id": 272,
    "explanation_index": 2,
    "text": "The highlighted tokens are typically proper nouns or brand names that denote media outlets, shows, or channels, often capitalized and used as key identifiers within the text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.901514450709025,
    "similarity_var": 0.0010056269413741207,
    "score_fuzz": 0.825,
    "score_detection": 0.8,
    "score_embedding": 0.610625,
    "total_score": 0.7452083333333333,
    "x": 14.185686111450195,
    "y": 4.3652873039245605,
    "cluster_id": -1
  },
  {
    "feature_id": 273,
    "explanation_index": 0,
    "text": "Control flow keywords and operators, including conditional statements, loops, and logical operators, often used in programming languages.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9307210048039755,
    "similarity_var": 7.307311961173784e-05,
    "score_fuzz": 0.8,
    "score_detection": 0.61,
    "score_embedding": 0.5688,
    "total_score": 0.6596000000000001,
    "x": 10.895635604858398,
    "y": 8.35957145690918,
    "cluster_id": -1
  },
  {
    "feature_id": 273,
    "explanation_index": 1,
    "text": "Conditional and loop control structures in programming code, with frequent use of keywords like \\\"if\\\", \\\"while\\\", and \\\"for\\\", often accompanied by punctuation such as parentheses, braces, and logical operators.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9307210048039755,
    "similarity_var": 7.307311961173784e-05,
    "score_fuzz": 0.77,
    "score_detection": 0.7,
    "score_embedding": 0.6699999999999999,
    "total_score": 0.7133333333333333,
    "x": 10.965306282043457,
    "y": 8.208979606628418,
    "cluster_id": -1
  },
  {
    "feature_id": 273,
    "explanation_index": 2,
    "text": "The highlighted tokens are control\u2011flow keywords or operators that introduce a conditional or loop, typically followed by parentheses and a block of code.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9307210048039755,
    "similarity_var": 7.307311961173784e-05,
    "score_fuzz": 0.825,
    "score_detection": 0.8,
    "score_embedding": 0.645,
    "total_score": 0.7566666666666667,
    "x": 13.638352394104004,
    "y": 6.555662631988525,
    "cluster_id": 8
  },
  {
    "feature_id": 274,
    "explanation_index": 0,
    "text": "Specialized nouns representing various fields of study, concepts, or objects, often denoting a specific domain or area of expertise.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8887034257253011,
    "similarity_var": 0.0005253046659948129,
    "score_fuzz": 0.7,
    "score_detection": 0.32,
    "score_embedding": 0.14479999999999998,
    "total_score": 0.3882666666666667,
    "x": 7.912392616271973,
    "y": 0.4396778643131256,
    "cluster_id": -1
  },
  {
    "feature_id": 274,
    "explanation_index": 1,
    "text": "Nouns or adjectives that form compound terms commonly used in academic, technical, or specialized contexts, often describing fields, conditions, or systems.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8887034257253011,
    "similarity_var": 0.0005253046659948129,
    "score_fuzz": 0.7,
    "score_detection": 0.34,
    "score_embedding": 0.169375,
    "total_score": 0.403125,
    "x": 8.247154235839844,
    "y": 0.6837117075920105,
    "cluster_id": 12
  },
  {
    "feature_id": 274,
    "explanation_index": 2,
    "text": "The highlighted tokens are typically nouns or noun phrases that denote the central concept or entity in the sentence, often domain\u2011specific terms that carry the main semantic weight.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8887034257253011,
    "similarity_var": 0.0005253046659948129,
    "score_fuzz": 0.825,
    "score_detection": 0.275,
    "score_embedding": 0.15812500000000002,
    "total_score": 0.41937500000000005,
    "x": 14.772842407226562,
    "y": 3.8179144859313965,
    "cluster_id": -1
  },
  {
    "feature_id": 275,
    "explanation_index": 0,
    "text": "Names of individuals, often with a first name or an initial, sometimes followed by a surname.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8999152779579163,
    "similarity_var": 0.0010068759459353298,
    "score_fuzz": 0.78,
    "score_detection": 0.56,
    "score_embedding": 0.7048,
    "total_score": 0.6816,
    "x": 7.199044227600098,
    "y": -0.5964034199714661,
    "cluster_id": -1
  },
  {
    "feature_id": 275,
    "explanation_index": 1,
    "text": "First names and last names of individuals, often appearing in contexts involving personal identification, credits, or attributions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8999152779579163,
    "similarity_var": 0.0010068759459353298,
    "score_fuzz": 0.78,
    "score_detection": 0.56,
    "score_embedding": 0.6725000000000001,
    "total_score": 0.6708333333333334,
    "x": 7.17552375793457,
    "y": -0.6288386583328247,
    "cluster_id": -1
  },
  {
    "feature_id": 275,
    "explanation_index": 2,
    "text": "The highlighted tokens are the words that together make up a named entity\u2014most often a person\u2019s name, sometimes a place or title\u2014along with any punctuation that is part of that entity (e.g., periods in initials).",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8999152779579163,
    "similarity_var": 0.0010068759459353298,
    "score_fuzz": 0.825,
    "score_detection": 0.575,
    "score_embedding": 0.626875,
    "total_score": 0.675625,
    "x": 14.136565208435059,
    "y": 4.392589569091797,
    "cluster_id": -1
  },
  {
    "feature_id": 276,
    "explanation_index": 0,
    "text": "A prefix or suffix of a word, often indicating a grammatical function or a word root.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.877469519774119,
    "similarity_var": 0.0014395939695701387,
    "score_fuzz": 0.76,
    "score_detection": 0.59,
    "score_embedding": 0.7612,
    "total_score": 0.7037333333333334,
    "x": 8.248834609985352,
    "y": 2.1211133003234863,
    "cluster_id": 44
  },
  {
    "feature_id": 276,
    "explanation_index": 1,
    "text": "Partial word fragments at the end of tokens, often representing parts of proper nouns, technical terms, or common words, with high activation values indicating their importance in context.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.877469519774119,
    "similarity_var": 0.0014395939695701387,
    "score_fuzz": 0.88,
    "score_detection": 0.72,
    "score_embedding": 0.793125,
    "total_score": 0.7977083333333334,
    "x": 7.061056137084961,
    "y": 2.9462335109710693,
    "cluster_id": 59
  },
  {
    "feature_id": 276,
    "explanation_index": 2,
    "text": "The highlighted tokens are sub\u2011word fragments that capture the semantic core of a word\u2014often a root, prefix, or suffix\u2014rather than full words. These fragments, whether part of a common noun, a proper name, or a technical term, are the pieces the model deems most informative for activation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.877469519774119,
    "similarity_var": 0.0014395939695701387,
    "score_fuzz": 0.825,
    "score_detection": 0.675,
    "score_embedding": 0.8250000000000001,
    "total_score": 0.775,
    "x": 14.877638816833496,
    "y": 5.127769947052002,
    "cluster_id": 77
  },
  {
    "feature_id": 277,
    "explanation_index": 0,
    "text": "LaTeX and programming syntax elements, including mathematical expressions, equations, and code snippets, often denoted by special symbols and formatting.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9160006046295166,
    "similarity_var": 1.3635385130328359e-05,
    "score_fuzz": 0.57,
    "score_detection": 0.51,
    "score_embedding": 0.2812,
    "total_score": 0.4537333333333334,
    "x": 10.09882640838623,
    "y": 8.036871910095215,
    "cluster_id": -1
  },
  {
    "feature_id": 277,
    "explanation_index": 1,
    "text": "Patterns in mathematical and LaTeX-formatted text involving delimiters, alignment symbols, and structural markers used in equation environments.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9160006046295166,
    "similarity_var": 1.3635385130328359e-05,
    "score_fuzz": 0.76,
    "score_detection": 0.69,
    "score_embedding": 0.30875,
    "total_score": 0.58625,
    "x": 9.79513168334961,
    "y": 7.968435764312744,
    "cluster_id": -1
  },
  {
    "feature_id": 277,
    "explanation_index": 2,
    "text": "The highlighted tokens are LaTeX commands and math delimiters that structure mathematical expressions.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9160006046295166,
    "similarity_var": 1.3635385130328359e-05,
    "score_fuzz": 0.65,
    "score_detection": 0.575,
    "score_embedding": 0.22062500000000002,
    "total_score": 0.48187500000000005,
    "x": 13.173175811767578,
    "y": 6.13942289352417,
    "cluster_id": -1
  },
  {
    "feature_id": 278,
    "explanation_index": 0,
    "text": "Proper nouns, names of people, places, organizations, and specific events, often related to historical events, particularly World War II.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8507773876190186,
    "similarity_var": 0.002168817972931928,
    "score_fuzz": 0.71,
    "score_detection": 0.73,
    "score_embedding": 0.6540000000000001,
    "total_score": 0.6980000000000001,
    "x": 7.576844215393066,
    "y": -0.8697357773780823,
    "cluster_id": 16
  },
  {
    "feature_id": 278,
    "explanation_index": 1,
    "text": "Historical events, dates, and proper nouns related to World War II and mid-20th century history are frequently highlighted, particularly when associated with military operations, political figures, or significant dates.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8507773876190186,
    "similarity_var": 0.002168817972931928,
    "score_fuzz": 0.82,
    "score_detection": 0.92,
    "score_embedding": 0.6725,
    "total_score": 0.8041666666666667,
    "x": 7.688835144042969,
    "y": -0.7256993651390076,
    "cluster_id": 16
  },
  {
    "feature_id": 278,
    "explanation_index": 2,
    "text": "The patterns: The tokens inside << >> are often phrases or words that are important.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8507773876190186,
    "similarity_var": 0.002168817972931928,
    "score_fuzz": 0.575,
    "score_detection": 0.45,
    "score_embedding": 0.155,
    "total_score": 0.3933333333333333,
    "x": 11.316086769104004,
    "y": 4.416531562805176,
    "cluster_id": 3
  },
  {
    "feature_id": 279,
    "explanation_index": 0,
    "text": "Conditional statements, primarily \\\"if\\\" statements, used for decision-making and control flow in programming languages.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8809716502825419,
    "similarity_var": 0.0019820221317472272,
    "score_fuzz": 0.97,
    "score_detection": 0.95,
    "score_embedding": 0.6764000000000001,
    "total_score": 0.8654666666666667,
    "x": 11.004080772399902,
    "y": 8.260560035705566,
    "cluster_id": -1
  },
  {
    "feature_id": 279,
    "explanation_index": 1,
    "text": "The word \\\"if\\\" is frequently used in conditional statements within programming code to control flow based on boolean expressions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8809716502825419,
    "similarity_var": 0.0019820221317472272,
    "score_fuzz": 0.96,
    "score_detection": 0.93,
    "score_embedding": 0.60125,
    "total_score": 0.8304166666666667,
    "x": 10.984051704406738,
    "y": 8.274730682373047,
    "cluster_id": -1
  },
  {
    "feature_id": 279,
    "explanation_index": 2,
    "text": "The highlighted tokens are function words or keywords that signal grammatical or structural roles, such as prepositions, conjunctions, or programming conditionals.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8809716502825419,
    "similarity_var": 0.0019820221317472272,
    "score_fuzz": 0.95,
    "score_detection": 0.8,
    "score_embedding": 0.24375000000000002,
    "total_score": 0.6645833333333333,
    "x": 13.770503997802734,
    "y": 3.371016263961792,
    "cluster_id": 35
  },
  {
    "feature_id": 281,
    "explanation_index": 0,
    "text": "Commands, programming languages, and technical terms often used in software development and coding.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.899995764096578,
    "similarity_var": 0.00013166681959909788,
    "score_fuzz": 0.56,
    "score_detection": 0.45,
    "score_embedding": 0.4224,
    "total_score": 0.47746666666666665,
    "x": 10.386422157287598,
    "y": 8.512812614440918,
    "cluster_id": 80
  },
  {
    "feature_id": 281,
    "explanation_index": 1,
    "text": "Sequences of tokens representing command-line tools, system commands, or programming language constructs, often appearing in technical or scripting contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.899995764096578,
    "similarity_var": 0.00013166681959909788,
    "score_fuzz": 0.61,
    "score_detection": 0.41,
    "score_embedding": 0.41312499999999996,
    "total_score": 0.47770833333333335,
    "x": 11.090963363647461,
    "y": 5.923856735229492,
    "cluster_id": -1
  },
  {
    "feature_id": 281,
    "explanation_index": 2,
    "text": "The highlighted tokens are code\u2011related identifiers\u2014command names, file names, function or method names, and language keywords\u2014that appear within shell commands, scripts, or source code snippets.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.899995764096578,
    "similarity_var": 0.00013166681959909788,
    "score_fuzz": 0.55,
    "score_detection": 0.475,
    "score_embedding": 0.3975,
    "total_score": 0.4741666666666666,
    "x": 13.801965713500977,
    "y": 6.480307579040527,
    "cluster_id": 8
  },
  {
    "feature_id": 282,
    "explanation_index": 0,
    "text": "Tokens from low-level programming languages, including assembly, C, and C-derived languages, often representing keywords, operators, and symbols.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9028793573379517,
    "similarity_var": 0.0002469702129583122,
    "score_fuzz": 0.78,
    "score_detection": 0.89,
    "score_embedding": 0.7116,
    "total_score": 0.7938666666666666,
    "x": 10.92396354675293,
    "y": 6.006800174713135,
    "cluster_id": 18
  },
  {
    "feature_id": 282,
    "explanation_index": 1,
    "text": "Patterns in low-level code syntax, including assembly instructions, preprocessor directives, C/C++ declarations, and structured code blocks, often involving identifiers, special tokens, and syntactic markers like brackets, colons, and keywords.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9028793573379517,
    "similarity_var": 0.0002469702129583122,
    "score_fuzz": 0.81,
    "score_detection": 0.88,
    "score_embedding": 0.6843750000000001,
    "total_score": 0.7914583333333334,
    "x": 10.7008695602417,
    "y": 7.382425785064697,
    "cluster_id": 7
  },
  {
    "feature_id": 282,
    "explanation_index": 2,
    "text": "The patterns: markers around code tokens, often around identifiers, keywords, symbols.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9028793573379517,
    "similarity_var": 0.0002469702129583122,
    "score_fuzz": 0.475,
    "score_detection": 0.7,
    "score_embedding": 0.5487500000000001,
    "total_score": 0.5745833333333333,
    "x": 10.800248146057129,
    "y": 6.979982376098633,
    "cluster_id": -1
  },
  {
    "feature_id": 283,
    "explanation_index": 0,
    "text": "Special characters, mathematical symbols, and units of measurement, often used in scientific or technical contexts, and sometimes used to separate values or indicate a range.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8530120054880778,
    "similarity_var": 0.0020515283654331837,
    "score_fuzz": 0.42,
    "score_detection": 0.35,
    "score_embedding": 0.15960000000000002,
    "total_score": 0.3098666666666667,
    "x": 9.054173469543457,
    "y": 7.8140339851379395,
    "cluster_id": -1
  },
  {
    "feature_id": 283,
    "explanation_index": 1,
    "text": "The presence of non-alphabetic symbols, numerical digits, and special formatting elements such as subscripts, superscripts, and mathematical notation, often in scientific or technical contexts, with high activation on punctuation, spacing, and symbol clusters.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8530120054880778,
    "similarity_var": 0.0020515283654331837,
    "score_fuzz": 0.37,
    "score_detection": 0.38,
    "score_embedding": 0.13875,
    "total_score": 0.29625,
    "x": 9.159070014953613,
    "y": 8.009787559509277,
    "cluster_id": -1
  },
  {
    "feature_id": 283,
    "explanation_index": 2,
    "text": "The highlighted tokens are almost always content words that form a core phrase\u2014nouns, adjectives, or numbers\u2014often preceded by an article or preposition, and occasionally punctuation that marks a clause boundary. The pattern shows the model focusing on the semantic \u201cbuilding blocks\u201d of a phrase rather than on function words alone.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8530120054880778,
    "similarity_var": 0.0020515283654331837,
    "score_fuzz": 0.575,
    "score_detection": 0.45,
    "score_embedding": 0.21625,
    "total_score": 0.41375,
    "x": 15.397575378417969,
    "y": 4.162885665893555,
    "cluster_id": 22
  },
  {
    "feature_id": 284,
    "explanation_index": 0,
    "text": "Tokens that are part of a proper noun, often representing names of people, places, organizations, or titles.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8356477419535319,
    "similarity_var": 0.00015289623564819344,
    "score_fuzz": 0.53,
    "score_detection": 0.69,
    "score_embedding": 0.3216,
    "total_score": 0.5138666666666666,
    "x": 10.115828514099121,
    "y": 4.423980712890625,
    "cluster_id": 1
  },
  {
    "feature_id": 284,
    "explanation_index": 1,
    "text": "Frequent activation of tokens related to technical, mathematical, or structured formatting, including subscripts, superscripts, special symbols, and compound terms in academic or programming contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8356477419535319,
    "similarity_var": 0.00015289623564819344,
    "score_fuzz": 0.14,
    "score_detection": 0.21,
    "score_embedding": 0.50875,
    "total_score": 0.28625,
    "x": 10.620244979858398,
    "y": 6.149080753326416,
    "cluster_id": -1
  },
  {
    "feature_id": 284,
    "explanation_index": 2,
    "text": "The highlighted tokens are always contiguous sequences that together form a single semantic unit\u2014typically a noun phrase, idiom, or morphological marker\u2014so the model treats them as a single entity rather than separate words.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8356477419535319,
    "similarity_var": 0.00015289623564819344,
    "score_fuzz": 0.575,
    "score_detection": 0.65,
    "score_embedding": 0.38999999999999996,
    "total_score": 0.5383333333333333,
    "x": 15.021949768066406,
    "y": 4.8332624435424805,
    "cluster_id": 55
  },
  {
    "feature_id": 286,
    "explanation_index": 0,
    "text": "Mathematical expressions and equations, often with a formal or technical tone, and sometimes including a brief explanation or justification.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8691794276237488,
    "similarity_var": 0.0011251743764830735,
    "score_fuzz": 0.37,
    "score_detection": 0.44,
    "score_embedding": 0.5344,
    "total_score": 0.44813333333333333,
    "x": 9.430140495300293,
    "y": 8.49921989440918,
    "cluster_id": 65
  },
  {
    "feature_id": 286,
    "explanation_index": 1,
    "text": "The text contains mathematical expressions and formal notation, with frequent use of LaTeX-style syntax, symbolic variables, and structured equations. Important tokens often include mathematical symbols, function names, and structural markers like parentheses, brackets, and equation delimiters, indicating a formal mathematical or technical context.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8691794276237488,
    "similarity_var": 0.0011251743764830735,
    "score_fuzz": 0.34,
    "score_detection": 0.44,
    "score_embedding": 0.33999999999999997,
    "total_score": 0.37333333333333335,
    "x": 10.31787395477295,
    "y": 6.200308322906494,
    "cluster_id": -1
  },
  {
    "feature_id": 286,
    "explanation_index": 2,
    "text": "Important tokens are usually punctuation or math symbols that close a phrase or expression, often following a space, and they delineate key semantic units.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8691794276237488,
    "similarity_var": 0.0011251743764830735,
    "score_fuzz": 0.45,
    "score_detection": 0.625,
    "score_embedding": 0.34625000000000006,
    "total_score": 0.47375000000000006,
    "x": 11.3955717086792,
    "y": 4.780568599700928,
    "cluster_id": -1
  },
  {
    "feature_id": 287,
    "explanation_index": 0,
    "text": "Prepositions and conjunctions, often used to connect words, phrases, or clauses in a sentence, and mathematical or programming operators and symbols.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8781607945760092,
    "similarity_var": 2.593056108047954e-05,
    "score_fuzz": 0.51,
    "score_detection": 0.35,
    "score_embedding": 0.27799999999999997,
    "total_score": 0.3793333333333333,
    "x": 12.124448776245117,
    "y": 0.04779540002346039,
    "cluster_id": 9
  },
  {
    "feature_id": 287,
    "explanation_index": 1,
    "text": "Common syntactic and semantic patterns involving comparative, relational, or conditional constructs in code and technical text, often centered around operators, logical conditions, or structural markers like \\\"if\\\", \\\"to\\\", \\\"of\\\", \\\"than\\\", \\\"that\\\", and punctuation sequences.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8781607945760092,
    "similarity_var": 2.593056108047954e-05,
    "score_fuzz": 0.48,
    "score_detection": 0.48,
    "score_embedding": 0.270625,
    "total_score": 0.4102083333333333,
    "x": 10.299300193786621,
    "y": 7.066793918609619,
    "cluster_id": 86
  },
  {
    "feature_id": 287,
    "explanation_index": 2,
    "text": "The highlighted tokens are the short, high\u2011frequency function words and code keywords that act as the grammatical or syntactic glue in a sentence or program. They include prepositions, conjunctions, articles, and control\u2011flow operators, as well as punctuation that signals a clause boundary.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8781607945760092,
    "similarity_var": 2.593056108047954e-05,
    "score_fuzz": 0.675,
    "score_detection": 0.65,
    "score_embedding": 0.25375,
    "total_score": 0.52625,
    "x": 13.701353073120117,
    "y": 3.420135021209717,
    "cluster_id": 35
  },
  {
    "feature_id": 288,
    "explanation_index": 0,
    "text": "Articles, prepositions, and conjunctions, often used to connect phrases or clauses, and sometimes nouns representing specific objects or concepts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8588492075602213,
    "similarity_var": 0.00014701956998979744,
    "score_fuzz": 0.46,
    "score_detection": 0.6,
    "score_embedding": 0.3504,
    "total_score": 0.47013333333333335,
    "x": 12.628564834594727,
    "y": 0.1887873411178589,
    "cluster_id": 57
  },
  {
    "feature_id": 288,
    "explanation_index": 1,
    "text": "Common noun phrases and functional words that appear in legal, financial, or procedural contexts, often surrounding specific terms like \\\"benefits,\\\" \\\"registration,\\\" \\\"security,\\\" \\\"discount,\\\" \\\"pass,\\\" \\\"death,\\\" \\\"senior,\\\" and \\\"with,\\\" typically indicating formal conditions, qualifications, or descriptors.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8588492075602213,
    "similarity_var": 0.00014701956998979744,
    "score_fuzz": 0.43,
    "score_detection": 0.42,
    "score_embedding": 0.299375,
    "total_score": 0.383125,
    "x": 10.08582878112793,
    "y": 3.054899215698242,
    "cluster_id": -1
  },
  {
    "feature_id": 288,
    "explanation_index": 2,
    "text": "The highlighted tokens are usually short, common function words or modifiers that sit inside a larger phrase being emphasized; they often act as connectors or determiners within that phrase.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8588492075602213,
    "similarity_var": 0.00014701956998979744,
    "score_fuzz": 0.575,
    "score_detection": 0.6,
    "score_embedding": 0.3425,
    "total_score": 0.5058333333333332,
    "x": 14.097667694091797,
    "y": 4.061488151550293,
    "cluster_id": -1
  },
  {
    "feature_id": 289,
    "explanation_index": 0,
    "text": "Various nouns, adjectives, and proper nouns, often representing specific objects, concepts, or names, that are being highlighted or emphasized in the given text.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.868054211139679,
    "similarity_var": 0.00017424140696912596,
    "score_fuzz": 0.6,
    "score_detection": 0.55,
    "score_embedding": 0.38920000000000005,
    "total_score": 0.5130666666666667,
    "x": 8.619911193847656,
    "y": -0.031673505902290344,
    "cluster_id": -1
  },
  {
    "feature_id": 289,
    "explanation_index": 1,
    "text": "Fragments of words, proper nouns, or technical terms that appear in isolation or as part of compound identifiers, often indicating a specific concept, entity, or linguistic construction.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.868054211139679,
    "similarity_var": 0.00017424140696912596,
    "score_fuzz": 0.58,
    "score_detection": 0.46,
    "score_embedding": 0.2475,
    "total_score": 0.4291666666666667,
    "x": 7.070749282836914,
    "y": 2.5604653358459473,
    "cluster_id": 2
  },
  {
    "feature_id": 289,
    "explanation_index": 2,
    "text": "The marked tokens are the content words that form the semantic core of each phrase\u2014nouns, adjectives, verbs, or names that carry the main meaning, rather than function words.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.868054211139679,
    "similarity_var": 0.00017424140696912596,
    "score_fuzz": 0.525,
    "score_detection": 0.45,
    "score_embedding": 0.36000000000000004,
    "total_score": 0.44500000000000006,
    "x": 15.448877334594727,
    "y": 4.142389297485352,
    "cluster_id": 22
  },
  {
    "feature_id": 290,
    "explanation_index": 0,
    "text": "Special characters, abbreviations, and short words or phrases often used in technical, scientific, or programming contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8846657673517863,
    "similarity_var": 0.0006723891563409109,
    "score_fuzz": 0.55,
    "score_detection": 0.48,
    "score_embedding": 0.418,
    "total_score": 0.48266666666666663,
    "x": 9.136305809020996,
    "y": 7.6971588134765625,
    "cluster_id": 68
  },
  {
    "feature_id": 290,
    "explanation_index": 1,
    "text": "Short, often capitalized or hyphenated sequences of characters (e.g., acronyms, code identifiers, chemical symbols, or technical abbreviations) frequently appear in technical or scientific text, especially within code, mathematical notation, or specialized domains, and are typically highlighted by high activation values due to their structural or semantic specificity.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8846657673517863,
    "similarity_var": 0.0006723891563409109,
    "score_fuzz": 0.54,
    "score_detection": 0.46,
    "score_embedding": 0.3375,
    "total_score": 0.4458333333333333,
    "x": 7.650693416595459,
    "y": 2.0824437141418457,
    "cluster_id": -1
  },
  {
    "feature_id": 290,
    "explanation_index": 2,
    "text": "The highlighted fragments are the smallest contiguous pieces that together form a meaningful unit\u2014idioms, noun phrases, technical terms, or code snippets. They often include suffixes or prefixes that modify a base word or are part of a larger token split across delimiters, and they carry the core semantic content of the surrounding context.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8846657673517863,
    "similarity_var": 0.0006723891563409109,
    "score_fuzz": 0.6,
    "score_detection": 0.5,
    "score_embedding": 0.343125,
    "total_score": 0.48104166666666676,
    "x": 15.583813667297363,
    "y": 7.303173542022705,
    "cluster_id": 19
  },
  {
    "feature_id": 291,
    "explanation_index": 0,
    "text": "Punctuation marks and special characters, often used to denote abbreviations, citations, or mathematical operations, and sometimes preceding or following a word or phrase that is being emphasized or defined.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8520609736442566,
    "similarity_var": 0.0003938649286467921,
    "score_fuzz": 0.5789473684210527,
    "score_detection": 0.51,
    "score_embedding": 0.6159999999999999,
    "total_score": 0.5683157894736842,
    "x": 8.355416297912598,
    "y": 7.16836404800415,
    "cluster_id": 37
  },
  {
    "feature_id": 291,
    "explanation_index": 1,
    "text": "Fragments of words, abbreviations, or symbols that appear in technical, mathematical, or formatted text, often representing parts of identifiers, equations, or structured data.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8520609736442566,
    "similarity_var": 0.0003938649286467921,
    "score_fuzz": 0.5894736842105263,
    "score_detection": 0.69,
    "score_embedding": 0.7324999999999999,
    "total_score": 0.6706578947368421,
    "x": 9.9228515625,
    "y": 6.093685150146484,
    "cluster_id": -1
  },
  {
    "feature_id": 291,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core lexical items or sub\u2011word fragments that carry the main semantic content of a phrase\u2014often the head of a noun phrase or a key part of a multi\u2011token expression, including suffixes, prefixes, abbreviations, or named\u2011entity components.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8520609736442566,
    "similarity_var": 0.0003938649286467921,
    "score_fuzz": 0.625,
    "score_detection": 0.325,
    "score_embedding": 0.553125,
    "total_score": 0.5010416666666666,
    "x": 15.127132415771484,
    "y": 4.405411243438721,
    "cluster_id": 72
  },
  {
    "feature_id": 292,
    "explanation_index": 0,
    "text": "Prepositions and articles often precede nouns, and sometimes adjectives or adverbs, that are crucial for understanding the context of a sentence, often in scientific or technical writing.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9008945425351461,
    "similarity_var": 0.0010985705872322959,
    "score_fuzz": 0.71,
    "score_detection": 0.63,
    "score_embedding": 0.37600000000000006,
    "total_score": 0.572,
    "x": 12.812697410583496,
    "y": 0.17558085918426514,
    "cluster_id": 57
  },
  {
    "feature_id": 292,
    "explanation_index": 1,
    "text": "Prepositions and articles (such as \\\"of\\\", \\\"in\\\", \\\"the\\\", \\\"to\\\", \\\"and\\\") frequently appear in context with scientific terminology, often forming part of compound terms or modifying nouns in technical descriptions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9008945425351461,
    "similarity_var": 0.0010985705872322959,
    "score_fuzz": 0.63,
    "score_detection": 0.61,
    "score_embedding": 0.35750000000000004,
    "total_score": 0.5325000000000001,
    "x": 12.631467819213867,
    "y": -0.037233661860227585,
    "cluster_id": -1
  },
  {
    "feature_id": 292,
    "explanation_index": 2,
    "text": "The highlighted tokens are mainly short function words and domain\u2011specific nouns that form common multi\u2011word expressions (e.g., prepositional phrases, article\u2011noun pairs, and technical terms) which the model deems salient for contextual understanding.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9008945425351461,
    "similarity_var": 0.0010985705872322959,
    "score_fuzz": 0.625,
    "score_detection": 0.6,
    "score_embedding": 0.25687499999999996,
    "total_score": 0.49395833333333333,
    "x": 14.32221508026123,
    "y": 4.027743339538574,
    "cluster_id": -1
  },
  {
    "feature_id": 294,
    "explanation_index": 0,
    "text": "Ellipses or other symbols used to indicate omission, continuation, or separation in text, often in formal or technical writing, mathematical notation, or programming code.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8809008995691935,
    "similarity_var": 6.52126793580818e-05,
    "score_fuzz": 0.89,
    "score_detection": 0.84,
    "score_embedding": 0.8124,
    "total_score": 0.8474666666666666,
    "x": 8.382403373718262,
    "y": 6.992319583892822,
    "cluster_id": 37
  },
  {
    "feature_id": 294,
    "explanation_index": 1,
    "text": "The token sequences \\\"...\\\" and similar ellipsis-like patterns (e.g., \\\"....\\\", \\\"....\\\", \\\"\u22ef\\\", \\\"\u2013\\\", \\\"\u00a0\\\", \\\"\u2009\\\", \\\">>\\\", \\\"<<\\\", \\\" \\\\\\\\\\\", \\\" **\\\", \\\" --\\\", \\\" \u22c5\\\", \\\" !\\\", \\\" *:\\\", \\\" *\\\", \\\" **\\\", \\\" ---\\\", \\\" \u2026\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\\\\\\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\" \\\\<<\\\", \\\" \\\\>>\\\", \\\"",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8809008995691935,
    "similarity_var": 6.52126793580818e-05,
    "score_fuzz": 0.72,
    "score_detection": 0.7,
    "score_embedding": 0.84875,
    "total_score": 0.75625,
    "x": 11.030278205871582,
    "y": 3.3878493309020996,
    "cluster_id": 27
  },
  {
    "feature_id": 294,
    "explanation_index": 2,
    "text": "The highlighted tokens consistently serve as placeholders or markers for omitted, variable, or context\u2011dependent content\u2014often expressed with ellipses, special symbols, or code\u2011style delimiters\u2014across diverse textual settings.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8809008995691935,
    "similarity_var": 6.52126793580818e-05,
    "score_fuzz": 0.9,
    "score_detection": 0.925,
    "score_embedding": 0.783125,
    "total_score": 0.8693750000000001,
    "x": 13.715909004211426,
    "y": 5.875051021575928,
    "cluster_id": -1
  },
  {
    "feature_id": 295,
    "explanation_index": 0,
    "text": "Punctuation marks, often used to denote separation, grouping, or special formatting in text, such as periods, commas, parentheses, and colons.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8568899234135946,
    "similarity_var": 0.001552529793633381,
    "score_fuzz": 0.73,
    "score_detection": 0.51,
    "score_embedding": 0.7011999999999999,
    "total_score": 0.6470666666666666,
    "x": 8.195168495178223,
    "y": 6.770920276641846,
    "cluster_id": 36
  },
  {
    "feature_id": 295,
    "explanation_index": 1,
    "text": "The token sequences often represent punctuation marks, delimiters, or syntactic elements used in code, markup, or formatting, such as parentheses, brackets, dots, quotes, and special symbols, which are frequently used to structure or separate components in technical or structured text.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8568899234135946,
    "similarity_var": 0.001552529793633381,
    "score_fuzz": 0.75,
    "score_detection": 0.71,
    "score_embedding": 0.791875,
    "total_score": 0.750625,
    "x": 10.966377258300781,
    "y": 5.502476692199707,
    "cluster_id": 51
  },
  {
    "feature_id": 295,
    "explanation_index": 2,
    "text": "The highlighted fragments are the minimal substrings that carry the semantic or syntactic core of a word, identifier, or symbol, often split across larger tokens, and they serve as the key units for the model\u2019s activation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8568899234135946,
    "similarity_var": 0.001552529793633381,
    "score_fuzz": 0.7,
    "score_detection": 0.65,
    "score_embedding": 0.795625,
    "total_score": 0.7152083333333333,
    "x": 15.45907974243164,
    "y": 7.213856220245361,
    "cluster_id": 19
  },
  {
    "feature_id": 296,
    "explanation_index": 0,
    "text": "Nouns representing a setting, situation, or context, often describing a scene, atmosphere, or environment, and sometimes related to visual or artistic depictions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9023877183596293,
    "similarity_var": 0.000681098634947672,
    "score_fuzz": 0.5,
    "score_detection": 0.33,
    "score_embedding": 0.43359999999999993,
    "total_score": 0.4212,
    "x": 8.199780464172363,
    "y": 0.2660127878189087,
    "cluster_id": 24
  },
  {
    "feature_id": 296,
    "explanation_index": 1,
    "text": "Nouns denoting physical or abstract locations, settings, or environments, often associated with visual or experiential context, and frequently linked to perception or observation verbs like \\\"seen,\\\" \\\"depicted,\\\" or \\\"witnessed.\\\"",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9023877183596293,
    "similarity_var": 0.000681098634947672,
    "score_fuzz": 0.43,
    "score_detection": 0.42,
    "score_embedding": 0.536875,
    "total_score": 0.4622916666666666,
    "x": 8.482556343078613,
    "y": 0.17285440862178802,
    "cluster_id": 24
  },
  {
    "feature_id": 296,
    "explanation_index": 2,
    "text": "Tokens that denote a setting or context\u2014often used as nouns or adjectives in descriptive phrases and usually preceded by a determiner or preposition.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9023877183596293,
    "similarity_var": 0.000681098634947672,
    "score_fuzz": 0.55,
    "score_detection": 0.35,
    "score_embedding": 0.6837500000000001,
    "total_score": 0.5279166666666667,
    "x": 10.35827350616455,
    "y": 4.3977227210998535,
    "cluster_id": 1
  },
  {
    "feature_id": 298,
    "explanation_index": 0,
    "text": "Punctuation marks, particularly commas, parentheses, and colons, often used to separate or group items in code, data structures, and mathematical expressions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.860262413819631,
    "similarity_var": 3.573580600462694e-05,
    "score_fuzz": 0.65,
    "score_detection": 0.58,
    "score_embedding": 0.5504000000000001,
    "total_score": 0.5934666666666667,
    "x": 8.645729064941406,
    "y": 6.867109775543213,
    "cluster_id": -1
  },
  {
    "feature_id": 298,
    "explanation_index": 1,
    "text": "Closing punctuation marks such as parentheses, braces, or brackets are frequently activated when they appear at the end of syntactic or structural elements in code or markup, often signaling the end of a block, function, or expression.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.860262413819631,
    "similarity_var": 3.573580600462694e-05,
    "score_fuzz": 0.65,
    "score_detection": 0.68,
    "score_embedding": 0.709375,
    "total_score": 0.6797916666666667,
    "x": 9.393950462341309,
    "y": 6.741514682769775,
    "cluster_id": -1
  },
  {
    "feature_id": 298,
    "explanation_index": 2,
    "text": "The highlighted tokens are code identifiers, keywords, and punctuation that form syntactic constructs in programming languages, such as function calls, class definitions, and API parameters.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.860262413819631,
    "similarity_var": 3.573580600462694e-05,
    "score_fuzz": 0.55,
    "score_detection": 0.4,
    "score_embedding": 0.5249999999999999,
    "total_score": 0.4916666666666667,
    "x": 13.785472869873047,
    "y": 6.5637922286987305,
    "cluster_id": 8
  },
  {
    "feature_id": 299,
    "explanation_index": 0,
    "text": "Punctuation marks and symbols, often used to denote units of currency, percentages, or mathematical operations, and sometimes used to set off parenthetical information or indicate a range.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8743255734443665,
    "similarity_var": 0.000453093642145556,
    "score_fuzz": 0.62,
    "score_detection": 0.57,
    "score_embedding": 0.5664,
    "total_score": 0.5854666666666667,
    "x": 8.307377815246582,
    "y": 7.190202713012695,
    "cluster_id": 37
  },
  {
    "feature_id": 299,
    "explanation_index": 1,
    "text": "Empty or whitespace-separated tokens surrounded by delimiters, often used to mark spacing, formatting, or structural breaks in text, particularly in contexts involving numerical data, citations, or layout formatting.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8743255734443665,
    "similarity_var": 0.000453093642145556,
    "score_fuzz": 0.65,
    "score_detection": 0.61,
    "score_embedding": 0.4925,
    "total_score": 0.5841666666666666,
    "x": 11.223560333251953,
    "y": 7.176161289215088,
    "cluster_id": -1
  },
  {
    "feature_id": 299,
    "explanation_index": 2,
    "text": "The important tokens are non\u2011alphabetic symbols that act as delimiters or markers for numeric or structural information, such as percentages, currency signs, parentheses, brackets, arrows, and other punctuation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8743255734443665,
    "similarity_var": 0.000453093642145556,
    "score_fuzz": 0.475,
    "score_detection": 0.575,
    "score_embedding": 0.47437500000000005,
    "total_score": 0.5081249999999999,
    "x": 11.315254211425781,
    "y": 4.9300665855407715,
    "cluster_id": -1
  },
  {
    "feature_id": 300,
    "explanation_index": 0,
    "text": "Common nouns, proper nouns, and words that are part of a larger phrase or sentence, often indicating a specific object, location, or concept, and sometimes used to initiate or conclude a quotation or statement.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.889035145441691,
    "similarity_var": 0.0003402431248302504,
    "score_fuzz": 0.6,
    "score_detection": 0.25,
    "score_embedding": 0.3616,
    "total_score": 0.40386666666666665,
    "x": 8.672863960266113,
    "y": -0.4681349992752075,
    "cluster_id": 79
  },
  {
    "feature_id": 300,
    "explanation_index": 1,
    "text": "Common nouns, proper nouns, and function words that appear in contextually significant positions, often marking key entities, locations, or grammatical structures, with higher activation values typically indicating more semantically central or contextually distinct terms.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.889035145441691,
    "similarity_var": 0.0003402431248302504,
    "score_fuzz": 0.5,
    "score_detection": 0.29,
    "score_embedding": 0.50125,
    "total_score": 0.43041666666666667,
    "x": 8.777812004089355,
    "y": -0.27187851071357727,
    "cluster_id": -1
  },
  {
    "feature_id": 300,
    "explanation_index": 2,
    "text": "The highlighted tokens are consistently the content words that carry the core semantic load of a sentence\u2014nouns, adjectives, and key phrases, often part of named entities or idiomatic expressions. They are the words that define the main idea or emphasize a specific concept, whether they appear as single words or short multi\u2011word units.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.889035145441691,
    "similarity_var": 0.0003402431248302504,
    "score_fuzz": 0.575,
    "score_detection": 0.425,
    "score_embedding": 0.596875,
    "total_score": 0.5322916666666667,
    "x": 15.252413749694824,
    "y": 4.033962726593018,
    "cluster_id": 22
  },
  {
    "feature_id": 301,
    "explanation_index": 0,
    "text": "Punctuation marks and conjunctions that connect clauses or phrases, often used to introduce contrasting or additional information.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8968526919682821,
    "similarity_var": 4.1678551564277524e-05,
    "score_fuzz": 0.83,
    "score_detection": 0.68,
    "score_embedding": 0.3136,
    "total_score": 0.6078666666666667,
    "x": 7.837531089782715,
    "y": 6.415773868560791,
    "cluster_id": 5
  },
  {
    "feature_id": 301,
    "explanation_index": 1,
    "text": "The tokens \\\"and\\\", \\\"but\\\", \\\",\\\", \\\".\\\", and \\\"not\\\" are frequently activated in contexts involving logical or contrastive conjunctions, punctuation marking sentence boundaries, or transitions between clauses, often signaling relationships such as addition, contrast, or temporal sequence.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8968526919682821,
    "similarity_var": 4.1678551564277524e-05,
    "score_fuzz": 0.79,
    "score_detection": 0.7,
    "score_embedding": 0.266875,
    "total_score": 0.585625,
    "x": 10.946944236755371,
    "y": 2.8135316371917725,
    "cluster_id": -1
  },
  {
    "feature_id": 301,
    "explanation_index": 2,
    "text": "The model identifies coordinating conjunctions and punctuation as key tokens that mark syntactic or discourse connections between clauses.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8968526919682821,
    "similarity_var": 4.1678551564277524e-05,
    "score_fuzz": 0.925,
    "score_detection": 0.65,
    "score_embedding": 0.3125,
    "total_score": 0.6291666666666668,
    "x": 13.2958984375,
    "y": 5.18607234954834,
    "cluster_id": -1
  },
  {
    "feature_id": 302,
    "explanation_index": 0,
    "text": "Special characters and symbols used in academic citations, mathematical expressions, and programming code.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8855594595273336,
    "similarity_var": 5.102459513118952e-05,
    "score_fuzz": 0.44,
    "score_detection": 0.44,
    "score_embedding": 0.5424000000000001,
    "total_score": 0.47413333333333335,
    "x": 8.970370292663574,
    "y": 7.809158802032471,
    "cluster_id": -1
  },
  {
    "feature_id": 302,
    "explanation_index": 1,
    "text": "The pattern involves the use of citation markers in academic or technical text, typically appearing as [@...] or [^...], often preceding or following references, with frequent activation of the \\\"@\\\" symbol and surrounding brackets or special characters.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8855594595273336,
    "similarity_var": 5.102459513118952e-05,
    "score_fuzz": 0.75,
    "score_detection": 0.71,
    "score_embedding": 0.6356250000000001,
    "total_score": 0.6985416666666667,
    "x": 8.681885719299316,
    "y": 7.322812557220459,
    "cluster_id": 4
  },
  {
    "feature_id": 302,
    "explanation_index": 2,
    "text": "The highlighted tokens are non\u2011alphanumeric symbols that serve as delimiters or markers in code, markup, or citation syntax.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8855594595273336,
    "similarity_var": 5.102459513118952e-05,
    "score_fuzz": 0.45,
    "score_detection": 0.5,
    "score_embedding": 0.49374999999999997,
    "total_score": 0.48124999999999996,
    "x": 13.503959655761719,
    "y": 5.951915264129639,
    "cluster_id": -1
  },
  {
    "feature_id": 303,
    "explanation_index": 0,
    "text": "Special characters used in programming languages to denote scope, namespace, or access to classes, methods, or variables.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9051344990730286,
    "similarity_var": 5.130406812507241e-05,
    "score_fuzz": 0.73,
    "score_detection": 0.57,
    "score_embedding": 0.46080000000000004,
    "total_score": 0.5869333333333333,
    "x": 9.572548866271973,
    "y": 7.8290696144104,
    "cluster_id": 6
  },
  {
    "feature_id": 303,
    "explanation_index": 1,
    "text": "The dot (.) and double colon (::) operators are used to denote hierarchical or namespace-based access in programming languages, often indicating method calls, class members, or namespace qualifiers.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9051344990730286,
    "similarity_var": 5.130406812507241e-05,
    "score_fuzz": 0.84,
    "score_detection": 0.57,
    "score_embedding": 0.5337500000000001,
    "total_score": 0.6479166666666667,
    "x": 10.286519050598145,
    "y": 8.021316528320312,
    "cluster_id": -1
  },
  {
    "feature_id": 303,
    "explanation_index": 2,
    "text": "The highlighted tokens are punctuation symbols that serve as syntactic separators in programming languages, indicating member access, namespace resolution, type annotations, dictionary keys, and other structural elements.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9051344990730286,
    "similarity_var": 5.130406812507241e-05,
    "score_fuzz": 0.7,
    "score_detection": 0.475,
    "score_embedding": 0.5431250000000001,
    "total_score": 0.5727083333333333,
    "x": 13.608610153198242,
    "y": 6.253540992736816,
    "cluster_id": -1
  },
  {
    "feature_id": 306,
    "explanation_index": 0,
    "text": "Verbs or nouns related to summarizing, describing, or encapsulating information, often used in academic or formal writing.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8956120212872823,
    "similarity_var": 0.00017820921023393847,
    "score_fuzz": 0.8,
    "score_detection": 0.71,
    "score_embedding": 0.6543999999999999,
    "total_score": 0.7214666666666666,
    "x": 10.446427345275879,
    "y": -0.8205311298370361,
    "cluster_id": 14
  },
  {
    "feature_id": 306,
    "explanation_index": 1,
    "text": "Commonly activated tokens are partial or full forms of words related to summarizing, reviewing, or briefly presenting information, often appearing in academic or technical contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8956120212872823,
    "similarity_var": 0.00017820921023393847,
    "score_fuzz": 0.79,
    "score_detection": 0.71,
    "score_embedding": 0.578125,
    "total_score": 0.6927083333333334,
    "x": 10.216513633728027,
    "y": 3.8253233432769775,
    "cluster_id": -1
  },
  {
    "feature_id": 306,
    "explanation_index": 2,
    "text": "the pattern: tokens that indicate summarization or summarizing content.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8956120212872823,
    "similarity_var": 0.00017820921023393847,
    "score_fuzz": 0.85,
    "score_detection": 0.7,
    "score_embedding": 0.6849999999999999,
    "total_score": 0.745,
    "x": 11.171123504638672,
    "y": 4.520334720611572,
    "cluster_id": -1
  },
  {
    "feature_id": 307,
    "explanation_index": 0,
    "text": "Verbs or nouns representing physical actions, body parts, or objects that people interact with, often in a descriptive or narrative context.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8686060309410095,
    "similarity_var": 0.0020120849279005406,
    "score_fuzz": 0.78,
    "score_detection": 0.51,
    "score_embedding": 0.5864,
    "total_score": 0.6254666666666667,
    "x": 10.587316513061523,
    "y": -0.8571163415908813,
    "cluster_id": 14
  },
  {
    "feature_id": 307,
    "explanation_index": 1,
    "text": "Body parts and physical locations are frequently activated when describing physical actions, positions, or interactions, often in contexts involving movement, posture, or sensory experience.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8686060309410095,
    "similarity_var": 0.0020120849279005406,
    "score_fuzz": 0.74,
    "score_detection": 0.51,
    "score_embedding": 0.565625,
    "total_score": 0.6052083333333333,
    "x": 10.746386528015137,
    "y": -1.034144639968872,
    "cluster_id": -1
  },
  {
    "feature_id": 307,
    "explanation_index": 2,
    "text": "The highlighted tokens consistently capture the core lexical items that carry the main semantic content of each clause\u2014usually the noun or pronoun that is the subject or object, the verb that expresses the action, or the adjective or preposition that completes the phrase.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8686060309410095,
    "similarity_var": 0.0020120849279005406,
    "score_fuzz": 0.625,
    "score_detection": 0.575,
    "score_embedding": 0.5925,
    "total_score": 0.5975,
    "x": 15.067062377929688,
    "y": 3.590465784072876,
    "cluster_id": -1
  },
  {
    "feature_id": 308,
    "explanation_index": 0,
    "text": "The verb \\\"to be\\\" in various forms, often used in phrases or idiomatic expressions, such as \\\"to be certain\\\", \\\"to be honest\\\", \\\"to be a\\\", or \\\"being\\\" in a state or condition, frequently indicating a state of existence, truth, or identity.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9047979712486267,
    "similarity_var": 0.00022413176182804287,
    "score_fuzz": 0.92,
    "score_detection": 0.78,
    "score_embedding": 0.43039999999999995,
    "total_score": 0.7101333333333334,
    "x": 11.462462425231934,
    "y": 2.254746198654175,
    "cluster_id": -1
  },
  {
    "feature_id": 308,
    "explanation_index": 1,
    "text": "The verb \\\"be\\\" and its inflected forms (\\\"being\\\", \\\"been\\\") are frequently used in passive constructions, existential statements, or to express states of being, often in contexts involving identity, possibility, or condition.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9047979712486267,
    "similarity_var": 0.00022413176182804287,
    "score_fuzz": 0.94,
    "score_detection": 0.72,
    "score_embedding": 0.46499999999999997,
    "total_score": 0.7083333333333334,
    "x": 11.49875545501709,
    "y": 2.2383310794830322,
    "cluster_id": -1
  },
  {
    "feature_id": 308,
    "explanation_index": 2,
    "text": "The token \u201cbe\u201d (and its continuous form \u201cbeing\u201d) is repeatedly highlighted across a wide range of contexts, underscoring its role as a core linking or auxiliary verb that signals state, existence, or identity.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9047979712486267,
    "similarity_var": 0.00022413176182804287,
    "score_fuzz": 1.0,
    "score_detection": 0.875,
    "score_embedding": 0.4931249999999999,
    "total_score": 0.789375,
    "x": 11.730680465698242,
    "y": 2.312614679336548,
    "cluster_id": 38
  },
  {
    "feature_id": 309,
    "explanation_index": 0,
    "text": "Prepositions, conjunctions, and adverbs often function as important tokens, particularly when used in phrases or idiomatic expressions, and sometimes when used to connect clauses or phrases.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8785580197970072,
    "similarity_var": 2.2798787086565473e-05,
    "score_fuzz": 0.63,
    "score_detection": 0.51,
    "score_embedding": 0.2864,
    "total_score": 0.4754666666666667,
    "x": 12.173095703125,
    "y": 0.04259144142270088,
    "cluster_id": 9
  },
  {
    "feature_id": 309,
    "explanation_index": 1,
    "text": "The token \\\"of\\\" frequently appears in prepositional phrases indicating possession, quantity, or duration, often preceding nouns that denote abstract or measurable concepts. Other common tokens include \\\"and\\\", \\\"or\\\", \\\"more\\\", \\\"much\\\", \\\"less\\\", and comparative suffixes like \\\"-er\\\", which appear in contexts involving comparison, addition, or degree. Additionally, hyphenated compounds and adjectives describing quality or intensity are often activated, suggesting attention to linguistic structures expressing gradation, inclusion, or modification.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8785580197970072,
    "similarity_var": 2.2798787086565473e-05,
    "score_fuzz": 0.74,
    "score_detection": 0.56,
    "score_embedding": 0.41375000000000006,
    "total_score": 0.57125,
    "x": 10.31769847869873,
    "y": 3.1297481060028076,
    "cluster_id": 50
  },
  {
    "feature_id": 309,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core function words or suffixes that assemble into familiar multi\u2011word expressions\u2014idioms, comparative endings, or container nouns\u2014providing the connective or descriptive glue that gives the phrase its meaning.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8785580197970072,
    "similarity_var": 2.2798787086565473e-05,
    "score_fuzz": 0.55,
    "score_detection": 0.4,
    "score_embedding": 0.303125,
    "total_score": 0.41770833333333335,
    "x": 14.33961296081543,
    "y": 3.832542657852173,
    "cluster_id": -1
  },
  {
    "feature_id": 310,
    "explanation_index": 0,
    "text": "Nouns representing food, ingredients, or dishes, often in the context of menus, recipes, or culinary descriptions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9192903439203898,
    "similarity_var": 1.597483683073935e-05,
    "score_fuzz": 0.81,
    "score_detection": 0.78,
    "score_embedding": 0.8380000000000001,
    "total_score": 0.8093333333333333,
    "x": 8.697671890258789,
    "y": 0.40500715374946594,
    "cluster_id": -1
  },
  {
    "feature_id": 310,
    "explanation_index": 1,
    "text": "Words related to food, particularly vegetables, plant-based ingredients, and meal components, often appear in contexts describing menus, recipes, or dietary choices, with high activation on specific food items and related terms.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9192903439203898,
    "similarity_var": 1.597483683073935e-05,
    "score_fuzz": 0.83,
    "score_detection": 0.8,
    "score_embedding": 0.864375,
    "total_score": 0.8314583333333333,
    "x": 8.824997901916504,
    "y": 0.40392711758613586,
    "cluster_id": -1
  },
  {
    "feature_id": 310,
    "explanation_index": 2,
    "text": "The highlighted tokens are food\u2011related nouns and adjectives\u2014especially vegetables, produce, and menu items\u2014that appear repeatedly in culinary descriptions.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9192903439203898,
    "similarity_var": 1.597483683073935e-05,
    "score_fuzz": 0.85,
    "score_detection": 0.8,
    "score_embedding": 0.8725,
    "total_score": 0.8408333333333333,
    "x": 15.084817886352539,
    "y": 3.852081298828125,
    "cluster_id": 22
  },
  {
    "feature_id": 312,
    "explanation_index": 0,
    "text": "Punctuation marks, often used to denote the start or end of a quotation, section, or other distinct part of a text, and sometimes used to indicate a break or transition in the text.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8693617383639017,
    "similarity_var": 3.745238784426243e-05,
    "score_fuzz": 0.69,
    "score_detection": 0.77,
    "score_embedding": 0.29599999999999993,
    "total_score": 0.5853333333333333,
    "x": 8.2339506149292,
    "y": 6.791594505310059,
    "cluster_id": 36
  },
  {
    "feature_id": 312,
    "explanation_index": 1,
    "text": "The token \\\"<<\\\" is used to mark the beginning of a structural or formatting element in the text, often preceding or following punctuation, quotation marks, or section breaks, and is frequently associated with document layout, citations, or metadata.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8693617383639017,
    "similarity_var": 3.745238784426243e-05,
    "score_fuzz": 0.69,
    "score_detection": 0.59,
    "score_embedding": 0.254375,
    "total_score": 0.5114583333333332,
    "x": 9.52683162689209,
    "y": 6.541611671447754,
    "cluster_id": 61
  },
  {
    "feature_id": 312,
    "explanation_index": 2,
    "text": "The highlighted tokens are typically short, boundary\u2011marking words or punctuation that signal the start or end of a phrase or clause, showing a focus on structural and key lexical cues.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8693617383639017,
    "similarity_var": 3.745238784426243e-05,
    "score_fuzz": 0.65,
    "score_detection": 0.75,
    "score_embedding": 0.314375,
    "total_score": 0.5714583333333333,
    "x": 14.036229133605957,
    "y": 4.9976654052734375,
    "cluster_id": -1
  },
  {
    "feature_id": 313,
    "explanation_index": 0,
    "text": "Various programming language syntax elements, including assignment operators, comparison operators, logical operators, function calls, array and object access, and control flow statements.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9199392398198446,
    "similarity_var": 9.88715892218137e-05,
    "score_fuzz": 0.64,
    "score_detection": 0.57,
    "score_embedding": 0.4768,
    "total_score": 0.5622666666666666,
    "x": 10.70999526977539,
    "y": 8.351143836975098,
    "cluster_id": 48
  },
  {
    "feature_id": 313,
    "explanation_index": 1,
    "text": "Patterns in code syntax involving assignment operators, parentheses, brackets, and comparison or logical operators, often indicating variable assignments, function calls, or conditional logic.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9199392398198446,
    "similarity_var": 9.88715892218137e-05,
    "score_fuzz": 0.74,
    "score_detection": 0.56,
    "score_embedding": 0.45625000000000004,
    "total_score": 0.5854166666666667,
    "x": 10.726106643676758,
    "y": 7.646988391876221,
    "cluster_id": -1
  },
  {
    "feature_id": 313,
    "explanation_index": 2,
    "text": "The highlighted tokens are syntactic operators and delimiters that define code structure, control flow, and function calls across multiple programming languages.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9199392398198446,
    "similarity_var": 9.88715892218137e-05,
    "score_fuzz": 0.725,
    "score_detection": 0.5,
    "score_embedding": 0.36625,
    "total_score": 0.5304166666666666,
    "x": 13.601668357849121,
    "y": 6.640168190002441,
    "cluster_id": 8
  },
  {
    "feature_id": 314,
    "explanation_index": 0,
    "text": "Articles, prepositions, and conjunctions, often preceding or following proper nouns, names, or specific entities.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.828013002872467,
    "similarity_var": 0.0019924070462877808,
    "score_fuzz": 0.53,
    "score_detection": 0.49,
    "score_embedding": 0.5944,
    "total_score": 0.5381333333333334,
    "x": 12.757505416870117,
    "y": 0.3151043653488159,
    "cluster_id": -1
  },
  {
    "feature_id": 314,
    "explanation_index": 1,
    "text": "Common patterns include proper nouns, compound nouns, and phrases involving possessive or descriptive relationships, often appearing in contexts of location, ownership, or institutional naming, with frequent use of \\\"the\\\", \\\"of\\\", \\\"in\\\", and \\\"a\\\" as structural connectors.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.828013002872467,
    "similarity_var": 0.0019924070462877808,
    "score_fuzz": 0.62,
    "score_detection": 0.57,
    "score_embedding": 0.686875,
    "total_score": 0.625625,
    "x": 9.792065620422363,
    "y": 0.49615776538848877,
    "cluster_id": -1
  },
  {
    "feature_id": 314,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.828013002872467,
    "similarity_var": 0.0019924070462877808,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.4675,
    "total_score": 0.4891666666666667,
    "x": -5.915904521942139,
    "y": 15.992903709411621,
    "cluster_id": 10
  },
  {
    "feature_id": 315,
    "explanation_index": 0,
    "text": "Nouns representing various concepts, objects, or entities, often denoting a specific place, object, or idea, such as channels, bands, stations, ports, pathways, and mechanisms.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8801204760869344,
    "similarity_var": 0.00013485598502506317,
    "score_fuzz": 0.76,
    "score_detection": 0.59,
    "score_embedding": 0.7592,
    "total_score": 0.7030666666666666,
    "x": 8.116667747497559,
    "y": 0.18628615140914917,
    "cluster_id": 24
  },
  {
    "feature_id": 315,
    "explanation_index": 1,
    "text": "Nouns denoting physical locations, containers, or abstract categories, often part of compound terms or technical terminology, with high activation when they appear in contextually specific or domain-relevant phrases.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8801204760869344,
    "similarity_var": 0.00013485598502506317,
    "score_fuzz": 0.7,
    "score_detection": 0.24,
    "score_embedding": 0.761875,
    "total_score": 0.5672916666666666,
    "x": 8.380237579345703,
    "y": 0.3123900592327118,
    "cluster_id": -1
  },
  {
    "feature_id": 315,
    "explanation_index": 2,
    "text": "The highlighted tokens are primarily nouns or noun phrases that serve as the central referents or topics in each sentence, acting as semantic anchors for the meaning.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8801204760869344,
    "similarity_var": 0.00013485598502506317,
    "score_fuzz": 0.65,
    "score_detection": 0.25,
    "score_embedding": 0.6975,
    "total_score": 0.5325000000000001,
    "x": 14.882060050964355,
    "y": 3.7405588626861572,
    "cluster_id": -1
  },
  {
    "feature_id": 316,
    "explanation_index": 0,
    "text": "Verbs or verb phrases expressing necessity, obligation, or requirement, often in the form of modal verbs or auxiliary verbs.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.921806534131368,
    "similarity_var": 0.00018647709447666076,
    "score_fuzz": 0.91,
    "score_detection": 0.75,
    "score_embedding": 0.6432000000000001,
    "total_score": 0.7677333333333335,
    "x": 10.82021713256836,
    "y": -0.28886470198631287,
    "cluster_id": -1
  },
  {
    "feature_id": 316,
    "explanation_index": 1,
    "text": "The word \\\"need\\\" and its inflected forms (needs, needed, needing) are frequently used to express necessity or requirement, often in contexts involving obligations, conditions, or essential requirements.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.921806534131368,
    "similarity_var": 0.00018647709447666076,
    "score_fuzz": 0.84,
    "score_detection": 0.8,
    "score_embedding": 0.6081249999999999,
    "total_score": 0.749375,
    "x": 10.843562126159668,
    "y": 0.058970559388399124,
    "cluster_id": -1
  },
  {
    "feature_id": 316,
    "explanation_index": 2,
    "text": "The highlighted words are all forms of \u201cneed\u201d or related necessity terms, signaling that the text is describing a requirement or obligation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.921806534131368,
    "similarity_var": 0.00018647709447666076,
    "score_fuzz": 0.875,
    "score_detection": 0.7,
    "score_embedding": 0.58,
    "total_score": 0.7183333333333333,
    "x": 10.793296813964844,
    "y": 0.07785957306623459,
    "cluster_id": -1
  },
  {
    "feature_id": 318,
    "explanation_index": 0,
    "text": "Suffixes of words that form nouns, often representing concepts, actions, or states, and sometimes indicating a process or a condition.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8771287600199381,
    "similarity_var": 0.0003121952899607866,
    "score_fuzz": 0.72,
    "score_detection": 0.59,
    "score_embedding": 0.6123999999999999,
    "total_score": 0.6408,
    "x": 8.520578384399414,
    "y": 2.2510323524475098,
    "cluster_id": 66
  },
  {
    "feature_id": 318,
    "explanation_index": 1,
    "text": "Suffixes and root forms of words related to abstract concepts, transformations, or technical processes, often appearing in academic or formal contexts, with high activation on morphological endings like -ize, -ation, -tion, -al, -ing, and -ism.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8771287600199381,
    "similarity_var": 0.0003121952899607866,
    "score_fuzz": 0.8,
    "score_detection": 0.64,
    "score_embedding": 0.57625,
    "total_score": 0.6720833333333333,
    "x": 8.537405014038086,
    "y": 2.345390796661377,
    "cluster_id": 66
  },
  {
    "feature_id": 318,
    "explanation_index": 2,
    "text": "The highlighted fragments are subword units that form parts of larger words, often suffixes or prefixes, indicating the model\u2019s focus on morphological components rather than whole words.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8771287600199381,
    "similarity_var": 0.0003121952899607866,
    "score_fuzz": 0.775,
    "score_detection": 0.6,
    "score_embedding": 0.629375,
    "total_score": 0.668125,
    "x": 15.678329467773438,
    "y": 7.0894389152526855,
    "cluster_id": 19
  },
  {
    "feature_id": 319,
    "explanation_index": 0,
    "text": "Various nouns, adjectives, and verbs that convey a sense of scope, breadth, or extent, often describing objects, concepts, or ideas that are comprehensive, wide-ranging, or all-encompassing.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8528649210929871,
    "similarity_var": 4.983306692688908e-05,
    "score_fuzz": 0.7,
    "score_detection": 0.63,
    "score_embedding": 0.7128000000000001,
    "total_score": 0.6809333333333334,
    "x": 8.487112998962402,
    "y": 0.18488366901874542,
    "cluster_id": 24
  },
  {
    "feature_id": 319,
    "explanation_index": 1,
    "text": "Commonly activated tokens include function words (e.g., \\\"the\\\", \\\"to\\\", \\\"is\\\", \\\"and\\\"), suffixes like \\\"er\\\", \\\"ing\\\", \\\"ly\\\", and content words related to abstract concepts (e.g., \\\"function\\\", \\\"capacity\\\", \\\"openness\\\", \\\"theory\\\"), spatial or quantitative terms (e.g., \\\"mile\\\", \\\"wide\\\", \\\"broad\\\"), and nominal phrases denoting categories, systems, or attributes (e.g., \\\"invention\\\", \\\"coverage\\\", \\\"interests\\\", \\\"aspect\\\"), often appearing in academic or technical contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8528649210929871,
    "similarity_var": 4.983306692688908e-05,
    "score_fuzz": 0.72,
    "score_detection": 0.72,
    "score_embedding": 0.835,
    "total_score": 0.7583333333333333,
    "x": 10.078120231628418,
    "y": 3.22165846824646,
    "cluster_id": 33
  },
  {
    "feature_id": 319,
    "explanation_index": 2,
    "text": "The tokens are often words like \\\"broad\\\", \\\"broadly\\\", \\\"broadband\\\", \\\"broad\\\", \\\"broadly regarded\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\", \\\"broad\\\" .",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8528649210929871,
    "similarity_var": 4.983306692688908e-05,
    "score_fuzz": 0.55,
    "score_detection": 0.625,
    "score_embedding": 0.7325,
    "total_score": 0.6358333333333334,
    "x": 10.950096130371094,
    "y": 3.3792073726654053,
    "cluster_id": 27
  },
  {
    "feature_id": 320,
    "explanation_index": 0,
    "text": "Special characters and punctuation marks, often used in mathematical or scientific notation, or as part of a reference or citation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8424387375513712,
    "similarity_var": 0.0014646849549401332,
    "score_fuzz": 0.49,
    "score_detection": 0.47,
    "score_embedding": 0.5984,
    "total_score": 0.5194666666666666,
    "x": 8.637394905090332,
    "y": 7.464780330657959,
    "cluster_id": 4
  },
  {
    "feature_id": 320,
    "explanation_index": 1,
    "text": "Numbers, symbols, and punctuation within delimiters often represent identifiers, indices, or formatting markers in technical or structured text, such as mathematical expressions, file references, or labeled sections.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8424387375513712,
    "similarity_var": 0.0014646849549401332,
    "score_fuzz": 0.46,
    "score_detection": 0.41,
    "score_embedding": 0.6056250000000001,
    "total_score": 0.491875,
    "x": 9.636555671691895,
    "y": 7.011208534240723,
    "cluster_id": 21
  },
  {
    "feature_id": 320,
    "explanation_index": 2,
    "text": "The highlighted fragments are the short, core units that carry the main semantic load in each phrase\u2014suffixes that complete a word, key nouns, or symbolic tokens (numbers, punctuation, operators). They are typically the minimal element that, when isolated, still conveys the essential meaning of the surrounding text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8424387375513712,
    "similarity_var": 0.0014646849549401332,
    "score_fuzz": 0.5,
    "score_detection": 0.425,
    "score_embedding": 0.5875000000000001,
    "total_score": 0.5041666666666668,
    "x": 15.703435897827148,
    "y": 7.307348251342773,
    "cluster_id": 19
  },
  {
    "feature_id": 321,
    "explanation_index": 0,
    "text": "The token is often a semicolon, a newline character, or a closing bracket, indicating the end of a statement or a block of code in a programming context.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9083051880200704,
    "similarity_var": 7.10962538721876e-05,
    "score_fuzz": 0.78,
    "score_detection": 0.67,
    "score_embedding": 0.6796,
    "total_score": 0.7098666666666666,
    "x": 10.753954887390137,
    "y": 5.985588550567627,
    "cluster_id": 18
  },
  {
    "feature_id": 321,
    "explanation_index": 1,
    "text": "The token sequence \\\"<<\\\" followed by a closing \\\">>\\\" often encloses code fragments or syntax elements, with high activation on punctuation and structural tokens like semicolons and newlines, indicating syntactic boundaries in programming code.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9083051880200704,
    "similarity_var": 7.10962538721876e-05,
    "score_fuzz": 0.61,
    "score_detection": 0.52,
    "score_embedding": 0.6106250000000001,
    "total_score": 0.5802083333333333,
    "x": 9.556403160095215,
    "y": 6.580805778503418,
    "cluster_id": 61
  },
  {
    "feature_id": 321,
    "explanation_index": 2,
    "text": "The highlighted tokens are syntactic markers that delineate code structure\u2014punctuation such as semicolons, braces, parentheses, and language\u2011specific keywords like end, which signal the boundaries of statements, blocks, or functions.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9083051880200704,
    "similarity_var": 7.10962538721876e-05,
    "score_fuzz": 0.625,
    "score_detection": 0.475,
    "score_embedding": 0.639375,
    "total_score": 0.5797916666666667,
    "x": 13.728494644165039,
    "y": 6.334527969360352,
    "cluster_id": -1
  },
  {
    "feature_id": 322,
    "explanation_index": 0,
    "text": "Words related to actions, interactions, and relationships between entities, often describing dynamic processes or connections.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.856145958105723,
    "similarity_var": 5.832557991504296e-05,
    "score_fuzz": 0.74,
    "score_detection": 0.56,
    "score_embedding": 0.7648,
    "total_score": 0.6882666666666667,
    "x": 9.034953117370605,
    "y": 0.33493220806121826,
    "cluster_id": -1
  },
  {
    "feature_id": 322,
    "explanation_index": 1,
    "text": "The suffix \\\"-ation\\\" is frequently used to form abstract nouns from verbs, often denoting processes or states, and is commonly activated in contexts involving actions, interactions, or systemic processes.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.856145958105723,
    "similarity_var": 5.832557991504296e-05,
    "score_fuzz": 0.72,
    "score_detection": 0.6,
    "score_embedding": 0.6706249999999999,
    "total_score": 0.6635416666666666,
    "x": 8.597850799560547,
    "y": 2.340909957885742,
    "cluster_id": 66
  },
  {
    "feature_id": 322,
    "explanation_index": 2,
    "text": "The examples reveal a consistent focus on words that share a common morphological root\u2014particularly the prefix \u201cinter-\u201d (and its counterpart \u201cintra-\u201d)\u2014which signals relationships or internal states. The activations cluster around these prefixes and their derivations, indicating that the model is attuned to the semantic family of interaction, integration, and internality.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.856145958105723,
    "similarity_var": 5.832557991504296e-05,
    "score_fuzz": 0.75,
    "score_detection": 0.725,
    "score_embedding": 0.73625,
    "total_score": 0.7370833333333334,
    "x": 8.371269226074219,
    "y": 2.790419340133667,
    "cluster_id": -1
  },
  {
    "feature_id": 323,
    "explanation_index": 0,
    "text": "A delimiter or separator often used to indicate the start or end of a code snippet, comment, or a specific section in a programming context, and sometimes used to separate items or indicate a break in a non-programming context.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8830605943997701,
    "similarity_var": 0.00016884228927535917,
    "score_fuzz": 0.57,
    "score_detection": 0.35,
    "score_embedding": 0.41759999999999997,
    "total_score": 0.44586666666666663,
    "x": 10.015307426452637,
    "y": 6.988768577575684,
    "cluster_id": -1
  },
  {
    "feature_id": 323,
    "explanation_index": 1,
    "text": "Patterns in the text involve structural or syntactic elements such as line breaks, punctuation, and code or markup delimiters, often indicating formatting, code structure, or document boundaries.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8830605943997701,
    "similarity_var": 0.00016884228927535917,
    "score_fuzz": 0.59,
    "score_detection": 0.54,
    "score_embedding": 0.5299999999999998,
    "total_score": 0.5533333333333332,
    "x": 10.200181007385254,
    "y": 6.854373455047607,
    "cluster_id": 88
  },
  {
    "feature_id": 323,
    "explanation_index": 2,
    "text": "The highlighted tokens are usually structural delimiters or boundary markers that separate code or text segments, often appearing at the start or end of a phrase.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8830605943997701,
    "similarity_var": 0.00016884228927535917,
    "score_fuzz": 0.725,
    "score_detection": 0.45,
    "score_embedding": 0.5012500000000001,
    "total_score": 0.55875,
    "x": 13.845931053161621,
    "y": 5.693734645843506,
    "cluster_id": -1
  },
  {
    "feature_id": 324,
    "explanation_index": 0,
    "text": "Prepositions and articles often precede nouns, and commas are used to separate items in lists.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8500757813453674,
    "similarity_var": 0.00011368581238713205,
    "score_fuzz": 0.64,
    "score_detection": 0.34,
    "score_embedding": 0.452,
    "total_score": 0.47733333333333333,
    "x": 12.621609687805176,
    "y": 0.1837187111377716,
    "cluster_id": 57
  },
  {
    "feature_id": 324,
    "explanation_index": 1,
    "text": "Common prepositional phrases and articles (like \\\"at\\\", \\\"in\\\", \\\"on\\\", \\\"the\\\", \\\"a\\\", \\\"and\\\", \\\"of\\\") used to link locations, objects, or concepts in descriptive or spatial contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8500757813453674,
    "similarity_var": 0.00011368581238713205,
    "score_fuzz": 0.55,
    "score_detection": 0.39,
    "score_embedding": 0.369375,
    "total_score": 0.4364583333333334,
    "x": 12.43698787689209,
    "y": -0.4521189033985138,
    "cluster_id": 63
  },
  {
    "feature_id": 324,
    "explanation_index": 2,
    "text": "The highlighted tokens are almost always very short, high\u2011frequency function words or punctuation marks that act as grammatical glue (articles, prepositions, conjunctions, commas, question marks, etc.), with a few short nouns or noun phrases that anchor the meaning of a clause.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8500757813453674,
    "similarity_var": 0.00011368581238713205,
    "score_fuzz": 0.75,
    "score_detection": 0.625,
    "score_embedding": 0.34437500000000004,
    "total_score": 0.573125,
    "x": 13.715439796447754,
    "y": 3.4433696269989014,
    "cluster_id": 35
  },
  {
    "feature_id": 325,
    "explanation_index": 0,
    "text": "Punctuation marks and special characters used in programming languages, often denoting the end of a statement, separation of elements, or indicating a specific operation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.885567327340444,
    "similarity_var": 0.0008942508789391785,
    "score_fuzz": 0.38,
    "score_detection": 0.36,
    "score_embedding": 0.35,
    "total_score": 0.3633333333333333,
    "x": 8.503744125366211,
    "y": 7.051210403442383,
    "cluster_id": 37
  },
  {
    "feature_id": 325,
    "explanation_index": 1,
    "text": "The presence of special characters, punctuation, or symbols (such as parentheses, brackets, braces, semicolons, commas, and operators) in code or structured text, often indicating syntactic or structural boundaries.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.885567327340444,
    "similarity_var": 0.0008942508789391785,
    "score_fuzz": 0.43,
    "score_detection": 0.42,
    "score_embedding": 0.4675,
    "total_score": 0.43916666666666665,
    "x": 10.13647174835205,
    "y": 7.0658111572265625,
    "cluster_id": -1
  },
  {
    "feature_id": 325,
    "explanation_index": 2,
    "text": "Tokens that form a contiguous, semantically or syntactically significant phrase or code construct\u2014such as idiomatic expressions or key identifiers and punctuation\u2014are highlighted as important.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.885567327340444,
    "similarity_var": 0.0008942508789391785,
    "score_fuzz": 0.425,
    "score_detection": 0.325,
    "score_embedding": 0.46937500000000004,
    "total_score": 0.40645833333333337,
    "x": 14.76513385772705,
    "y": 4.586182117462158,
    "cluster_id": -1
  },
  {
    "feature_id": 326,
    "explanation_index": 0,
    "text": "Function words and nouns that are part of formal or technical language, often used in academic, legal, or scientific contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8567101160685221,
    "similarity_var": 0.00021425501362968028,
    "score_fuzz": 0.54,
    "score_detection": 0.48,
    "score_embedding": 0.15880000000000002,
    "total_score": 0.39293333333333336,
    "x": 10.659822463989258,
    "y": 1.1656951904296875,
    "cluster_id": 26
  },
  {
    "feature_id": 326,
    "explanation_index": 1,
    "text": "The word \\\"applies\\\" and its variants are frequently used in legal and technical contexts to indicate the relevance or enforcement of rules, conditions, or principles under specific circumstances.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8567101160685221,
    "similarity_var": 0.00021425501362968028,
    "score_fuzz": 0.53,
    "score_detection": 0.44,
    "score_embedding": 0.186875,
    "total_score": 0.38562499999999994,
    "x": 9.058363914489746,
    "y": 4.2892889976501465,
    "cluster_id": -1
  },
  {
    "feature_id": 326,
    "explanation_index": 2,
    "text": "The activations focus on short, high\u2011frequency function words and domain\u2011specific nouns that form fixed legal or technical phrases, suggesting the model treats these as key tokens for contextual understanding.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8567101160685221,
    "similarity_var": 0.00021425501362968028,
    "score_fuzz": 0.5,
    "score_detection": 0.3,
    "score_embedding": 0.375625,
    "total_score": 0.39187500000000003,
    "x": 8.768290519714355,
    "y": 3.6462342739105225,
    "cluster_id": -1
  },
  {
    "feature_id": 327,
    "explanation_index": 0,
    "text": "Conjunctions, articles, and auxiliary verbs, often used to connect clauses or phrases, and sometimes preceding or following a quotation mark, or used in idiomatic expressions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8641842802365621,
    "similarity_var": 0.000584272927540831,
    "score_fuzz": 0.53,
    "score_detection": 0.5,
    "score_embedding": 0.39239999999999997,
    "total_score": 0.47413333333333335,
    "x": 12.145237922668457,
    "y": 0.30364710092544556,
    "cluster_id": -1
  },
  {
    "feature_id": 327,
    "explanation_index": 1,
    "text": "The word \\\"and\\\" frequently appears in lists or compound structures, often connecting elements in a sequence or contrasting ideas, with consistent activation strength across contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8641842802365621,
    "similarity_var": 0.000584272927540831,
    "score_fuzz": 0.53,
    "score_detection": 0.52,
    "score_embedding": 0.244375,
    "total_score": 0.43145833333333333,
    "x": 11.742509841918945,
    "y": 2.265235424041748,
    "cluster_id": 38
  },
  {
    "feature_id": 327,
    "explanation_index": 2,
    "text": "The highlighted tokens are predominantly short, high\u2011frequency function words (conjunctions, articles, pronouns, auxiliary verbs) that serve as grammatical glue, occasionally including key nouns that anchor a phrase.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8641842802365621,
    "similarity_var": 0.000584272927540831,
    "score_fuzz": 0.625,
    "score_detection": 0.375,
    "score_embedding": 0.275625,
    "total_score": 0.42520833333333335,
    "x": 13.656339645385742,
    "y": 3.3685927391052246,
    "cluster_id": 35
  },
  {
    "feature_id": 328,
    "explanation_index": 0,
    "text": "Words related to shopping, delivery, and shipping, including names of stores and services.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8276837865511576,
    "similarity_var": 0.0033374241823725336,
    "score_fuzz": 0.85,
    "score_detection": 0.81,
    "score_embedding": 0.7996000000000001,
    "total_score": 0.8198666666666666,
    "x": 8.294698715209961,
    "y": -0.34904614090919495,
    "cluster_id": -1
  },
  {
    "feature_id": 328,
    "explanation_index": 1,
    "text": "The word \\\"shipping\\\" and related terms like \\\"delivery,\\\" \\\"package,\\\" \\\"freight,\\\" and \\\"courier\\\" are frequently activated in contexts involving e-commerce, logistics, and product fulfillment, often tied to purchase incentives, thresholds, or delivery processes.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8276837865511576,
    "similarity_var": 0.0033374241823725336,
    "score_fuzz": 0.7,
    "score_detection": 0.71,
    "score_embedding": 0.6075,
    "total_score": 0.6725,
    "x": 9.909825325012207,
    "y": 3.1468677520751953,
    "cluster_id": -1
  },
  {
    "feature_id": 328,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8276837865511576,
    "similarity_var": 0.0033374241823725336,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.11875000000000001,
    "total_score": 0.3729166666666666,
    "x": -5.8964362144470215,
    "y": 16.012283325195312,
    "cluster_id": 10
  },
  {
    "feature_id": 329,
    "explanation_index": 0,
    "text": "Function words and nouns that are part of phrases or sentences that express purpose, ability, or permission, often used in formal or technical contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8469550609588623,
    "similarity_var": 0.0005098842400907225,
    "score_fuzz": 0.66,
    "score_detection": 0.51,
    "score_embedding": 0.5252,
    "total_score": 0.5650666666666666,
    "x": 10.637393951416016,
    "y": 1.1908142566680908,
    "cluster_id": 26
  },
  {
    "feature_id": 329,
    "explanation_index": 1,
    "text": "The word \\\"to\\\" frequently appears in infinitive verb constructions, often following verbs of purpose or ability, and is commonly activated in contexts involving intention, capability, or functional purpose.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8469550609588623,
    "similarity_var": 0.0005098842400907225,
    "score_fuzz": 0.6,
    "score_detection": 0.56,
    "score_embedding": 0.3975,
    "total_score": 0.5191666666666667,
    "x": 11.399033546447754,
    "y": 0.00937744416296482,
    "cluster_id": -1
  },
  {
    "feature_id": 329,
    "explanation_index": 2,
    "text": "The important tokens are typically short, high\u2011frequency function words or key content words that serve as the core of a phrase, often forming common collocations or idiomatic expressions.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8469550609588623,
    "similarity_var": 0.0005098842400907225,
    "score_fuzz": 0.75,
    "score_detection": 0.5,
    "score_embedding": 0.42437499999999995,
    "total_score": 0.558125,
    "x": 11.503320693969727,
    "y": 4.661215305328369,
    "cluster_id": 78
  },
  {
    "feature_id": 330,
    "explanation_index": 0,
    "text": "Various nouns representing concepts, objects, or entities, often in a technical, scientific, or formal context.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8785215616226196,
    "similarity_var": 0.00045216420427844167,
    "score_fuzz": 0.78,
    "score_detection": 0.65,
    "score_embedding": 0.4748,
    "total_score": 0.6349333333333335,
    "x": 8.085853576660156,
    "y": 0.3709551990032196,
    "cluster_id": 12
  },
  {
    "feature_id": 330,
    "explanation_index": 1,
    "text": "The token \\\"data\\\" and related terms (e.g., \\\"information\\\", \\\"evidence\\\", \\\"documents\\\", \\\"files\\\") are frequently activated in contexts involving structured or processed content, often in technical, academic, or data-handling domains.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8785215616226196,
    "similarity_var": 0.00045216420427844167,
    "score_fuzz": 0.73,
    "score_detection": 0.67,
    "score_embedding": 0.61375,
    "total_score": 0.67125,
    "x": 10.599526405334473,
    "y": 3.5359537601470947,
    "cluster_id": -1
  },
  {
    "feature_id": 330,
    "explanation_index": 2,
    "text": "The highlighted tokens are nouns or noun phrases that serve as key concepts or objects in the sentence, often capitalized or part of a technical term, and sometimes preceded by articles or embedded in code.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8785215616226196,
    "similarity_var": 0.00045216420427844167,
    "score_fuzz": 0.775,
    "score_detection": 0.825,
    "score_embedding": 0.5306249999999999,
    "total_score": 0.7102083333333334,
    "x": 14.624724388122559,
    "y": 4.00152063369751,
    "cluster_id": 11
  },
  {
    "feature_id": 332,
    "explanation_index": 0,
    "text": "Function words and common grammatical elements, including articles, conjunctions, prepositions, auxiliary verbs, and modal verbs, often used to connect clauses or phrases, or to indicate relationships between entities or actions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8723228375116984,
    "similarity_var": 0.00020621386547345667,
    "score_fuzz": 0.55,
    "score_detection": 0.47,
    "score_embedding": 0.6688,
    "total_score": 0.5629333333333334,
    "x": 10.701213836669922,
    "y": 1.2077891826629639,
    "cluster_id": 26
  },
  {
    "feature_id": 332,
    "explanation_index": 1,
    "text": "Common function words and grammatical particles used in conditional, comparative, or contrastive constructions, often appearing in syntactic contexts involving negation, comparison, or logical relationships.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8723228375116984,
    "similarity_var": 0.00020621386547345667,
    "score_fuzz": 0.59,
    "score_detection": 0.58,
    "score_embedding": 0.805,
    "total_score": 0.6583333333333333,
    "x": 10.688213348388672,
    "y": 1.3683668375015259,
    "cluster_id": 26
  },
  {
    "feature_id": 332,
    "explanation_index": 2,
    "text": "The highlighted tokens are typically short, high\u2011frequency function words or morphological markers that signal grammatical structure or common collocations, such as \u201cthe\u201d, \u201cis\u201d, \u201cor\u201d, \u201cbut\u201d, \u201cbe\u201d, \u201cof\u201d, \u201cand\u201d, \u201creturn\u201d, \u201csuccess\u201d, or comparative suffixes like \u201c\u2011er\u201d. These words often serve as anchors in idiomatic phrases or grammatical constructions, making them salient in the model\u2019s activations.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8723228375116984,
    "similarity_var": 0.00020621386547345667,
    "score_fuzz": 0.725,
    "score_detection": 0.375,
    "score_embedding": 0.7287500000000001,
    "total_score": 0.6095833333333335,
    "x": 13.760326385498047,
    "y": 3.590538740158081,
    "cluster_id": -1
  },
  {
    "feature_id": 333,
    "explanation_index": 0,
    "text": "Punctuation and symbols used in programming languages, mathematical notation, and other technical contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8895675738652548,
    "similarity_var": 0.0003609528277440038,
    "score_fuzz": 0.51,
    "score_detection": 0.51,
    "score_embedding": 0.51,
    "total_score": 0.51,
    "x": 8.592707633972168,
    "y": 7.381077766418457,
    "cluster_id": 4
  },
  {
    "feature_id": 333,
    "explanation_index": 1,
    "text": "Specialized syntax tokens in programming, markup, or mathematical notation, often used to denote structure, types, or operations, with high activation in code-like or formal language contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8895675738652548,
    "similarity_var": 0.0003609528277440038,
    "score_fuzz": 0.51,
    "score_detection": 0.53,
    "score_embedding": 0.4375,
    "total_score": 0.4925,
    "x": 10.798980712890625,
    "y": 6.058501720428467,
    "cluster_id": 18
  },
  {
    "feature_id": 333,
    "explanation_index": 2,
    "text": "The highlighted fragments are the syntactic elements that drive the structure of code\u2014keywords, operators, punctuation, and key identifiers that mark the start or end of statements, function calls, or type declarations.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8895675738652548,
    "similarity_var": 0.0003609528277440038,
    "score_fuzz": 0.525,
    "score_detection": 0.4,
    "score_embedding": 0.32875000000000004,
    "total_score": 0.4179166666666667,
    "x": 15.111040115356445,
    "y": 7.23488712310791,
    "cluster_id": -1
  },
  {
    "feature_id": 334,
    "explanation_index": 0,
    "text": "Various linguistic and symbolic elements, including mathematical and scientific notation, programming syntax, and special characters, often used in specific contexts such as academic or technical writing, computer code, and data representation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8630399902661642,
    "similarity_var": 0.0004774122097101794,
    "score_fuzz": 0.24,
    "score_detection": 0.22,
    "score_embedding": 0.3176,
    "total_score": 0.2592,
    "x": 9.368221282958984,
    "y": 7.850732326507568,
    "cluster_id": 6
  },
  {
    "feature_id": 334,
    "explanation_index": 1,
    "text": "High activation in tokens that represent structural or syntactic elements in text, including punctuation, spacing, formatting markers, and symbolic notation, often indicating boundaries, references, or formatting in code, mathematical expressions, or document markup.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8630399902661642,
    "similarity_var": 0.0004774122097101794,
    "score_fuzz": 0.31,
    "score_detection": 0.27,
    "score_embedding": 0.359375,
    "total_score": 0.31312500000000004,
    "x": 10.497893333435059,
    "y": 6.351238250732422,
    "cluster_id": -1
  },
  {
    "feature_id": 334,
    "explanation_index": 2,
    "text": "The highlighted segments are the model\u2019s focus on semantically salient words or phrases\u2014idiomatic expressions, comparative adjectives, key nouns, technical terms, or code tokens\u2014whose activation values indicate their importance for the model\u2019s processing.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8630399902661642,
    "similarity_var": 0.0004774122097101794,
    "score_fuzz": 0.15,
    "score_detection": 0.325,
    "score_embedding": 0.35375,
    "total_score": 0.27625,
    "x": 15.251629829406738,
    "y": 4.931023597717285,
    "cluster_id": -1
  },
  {
    "feature_id": 336,
    "explanation_index": 0,
    "text": "Tokens related to ordering, sorting, or arranging items in a specific manner, often in ascending or descending order.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9136345386505127,
    "similarity_var": 0.00022035742236425904,
    "score_fuzz": 0.71,
    "score_detection": 0.73,
    "score_embedding": 0.654,
    "total_score": 0.698,
    "x": 11.26984691619873,
    "y": 5.522027492523193,
    "cluster_id": -1
  },
  {
    "feature_id": 336,
    "explanation_index": 1,
    "text": "The word \\\"sort\\\" or \\\"sort\\\" variants (e.g., \\\"sorted\\\", \\\"sorting\\\") often appear in contexts related to ordering or organizing data, frequently paired with terms like \\\"by\\\", \\\"in\\\", or \\\"ascending/descending\\\", indicating a sorting operation or comparison.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9136345386505127,
    "similarity_var": 0.00022035742236425904,
    "score_fuzz": 0.69,
    "score_detection": 0.73,
    "score_embedding": 0.55375,
    "total_score": 0.6579166666666666,
    "x": 11.451553344726562,
    "y": 5.624006271362305,
    "cluster_id": -1
  },
  {
    "feature_id": 336,
    "explanation_index": 2,
    "text": "The highlighted tokens are all components of sorting or ordering syntax\u2014keywords like \u201csort,\u201d \u201corder,\u201d \u201cby,\u201d and modifiers such as \u201cascending,\u201d \u201cdescending,\u201d \u201casc,\u201d \u201cdesc,\u201d or \u201csortfield.\u201d",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9136345386505127,
    "similarity_var": 0.00022035742236425904,
    "score_fuzz": 0.65,
    "score_detection": 0.75,
    "score_embedding": 0.54,
    "total_score": 0.6466666666666666,
    "x": 13.45750904083252,
    "y": 6.135370254516602,
    "cluster_id": -1
  },
  {
    "feature_id": 337,
    "explanation_index": 0,
    "text": "Punctuation marks and common suffixes or prefixes in nouns, often related to technology, science, or formal writing.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8627888162930807,
    "similarity_var": 0.00032774498691247165,
    "score_fuzz": 0.59,
    "score_detection": 0.31,
    "score_embedding": 0.2428,
    "total_score": 0.3809333333333333,
    "x": 7.849249839782715,
    "y": 6.820350170135498,
    "cluster_id": -1
  },
  {
    "feature_id": 337,
    "explanation_index": 1,
    "text": "Common patterns include compound nouns, technical terms, and multi-word phrases where individual components are activated in sequence, often indicating domain-specific terminology, proper nouns, or structural elements in code or scientific writing.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8627888162930807,
    "similarity_var": 0.00032774498691247165,
    "score_fuzz": 0.65,
    "score_detection": 0.35,
    "score_embedding": 0.13937500000000003,
    "total_score": 0.3797916666666667,
    "x": 9.388239860534668,
    "y": 0.29992398619651794,
    "cluster_id": -1
  },
  {
    "feature_id": 337,
    "explanation_index": 2,
    "text": "The highlighted tokens are fragments or whole words that belong to a phrase being marked, often appearing at word boundaries or with punctuation, and may include partial word pieces or punctuation marks.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8627888162930807,
    "similarity_var": 0.00032774498691247165,
    "score_fuzz": 0.625,
    "score_detection": 0.1,
    "score_embedding": 0.15125,
    "total_score": 0.2920833333333333,
    "x": 14.159449577331543,
    "y": 5.04051399230957,
    "cluster_id": -1
  },
  {
    "feature_id": 338,
    "explanation_index": 0,
    "text": "Verbs related to investigation, analysis, and examination, often used in formal or academic contexts, and prepositions indicating direction or relation, often used in phrases describing actions or states.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9160644213358561,
    "similarity_var": 0.0007371057777124041,
    "score_fuzz": 0.85,
    "score_detection": 0.55,
    "score_embedding": 0.7884,
    "total_score": 0.7294666666666666,
    "x": 10.960023880004883,
    "y": -0.8071891665458679,
    "cluster_id": -1
  },
  {
    "feature_id": 338,
    "explanation_index": 1,
    "text": "Verbs related to investigation, analysis, or examination of a subject, often followed by a prepositional phrase indicating the object of study, with high activation on the verb and surrounding prepositions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9160644213358561,
    "similarity_var": 0.0007371057777124041,
    "score_fuzz": 0.84,
    "score_detection": 0.59,
    "score_embedding": 0.835,
    "total_score": 0.7549999999999999,
    "x": 11.13485336303711,
    "y": -0.6651520729064941,
    "cluster_id": -1
  },
  {
    "feature_id": 338,
    "explanation_index": 2,
    "text": "The highlighted tokens are usually verbs or prepositions that form a phrase indicating an action or relationship, often used in academic or descriptive contexts.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9160644213358561,
    "similarity_var": 0.0007371057777124041,
    "score_fuzz": 0.825,
    "score_detection": 0.5,
    "score_embedding": 0.860625,
    "total_score": 0.7285416666666666,
    "x": 14.496097564697266,
    "y": 3.439699411392212,
    "cluster_id": -1
  },
  {
    "feature_id": 339,
    "explanation_index": 0,
    "text": "Technical terms and phrases commonly used in scientific and laboratory settings, particularly in the fields of molecular biology, biochemistry, and immunology.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8664759794871012,
    "similarity_var": 0.0016191869859514755,
    "score_fuzz": 0.63,
    "score_detection": 0.51,
    "score_embedding": 0.5676,
    "total_score": 0.5692,
    "x": 7.242207050323486,
    "y": 1.1806650161743164,
    "cluster_id": 25
  },
  {
    "feature_id": 339,
    "explanation_index": 1,
    "text": "Technical terms and compound words commonly found in scientific and laboratory protocols, often involving equipment, reagents, or experimental procedures, with frequent use of abbreviations, units, and specialized terminology.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8664759794871012,
    "similarity_var": 0.0016191869859514755,
    "score_fuzz": 0.58,
    "score_detection": 0.53,
    "score_embedding": 0.533125,
    "total_score": 0.5477083333333334,
    "x": 7.2785444259643555,
    "y": 1.1772143840789795,
    "cluster_id": 25
  },
  {
    "feature_id": 339,
    "explanation_index": 2,
    "text": "The activations consistently target sub\u2011word units that carry morphological or domain\u2011specific meaning\u2014whole words, prefixes, suffixes, or split scientific terms\u2014showing the model relies on these sub\u2011word components to encode and process specialized terminology.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8664759794871012,
    "similarity_var": 0.0016191869859514755,
    "score_fuzz": 0.675,
    "score_detection": 0.525,
    "score_embedding": 0.374375,
    "total_score": 0.5247916666666668,
    "x": 8.038566589355469,
    "y": 3.1456918716430664,
    "cluster_id": 76
  },
  {
    "feature_id": 340,
    "explanation_index": 0,
    "text": "Various parts of speech, including nouns, verbs, adjectives, and adverbs, often representing objects, actions, or descriptions, and sometimes being part of idiomatic expressions or technical terms.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8650908668835958,
    "similarity_var": 4.833535459722624e-05,
    "score_fuzz": 0.64,
    "score_detection": 0.43,
    "score_embedding": 0.5672,
    "total_score": 0.5457333333333333,
    "x": 9.492583274841309,
    "y": -0.09513410925865173,
    "cluster_id": -1
  },
  {
    "feature_id": 340,
    "explanation_index": 1,
    "text": "Commonly activated tokens include suffixes forming comparative or past-tense verbs, proper nouns, and nouns denoting physical objects or locations, often appearing in contexts involving description, measurement, or identity.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8650908668835958,
    "similarity_var": 4.833535459722624e-05,
    "score_fuzz": 0.49,
    "score_detection": 0.36,
    "score_embedding": 0.61,
    "total_score": 0.48666666666666664,
    "x": 10.165794372558594,
    "y": 3.6354169845581055,
    "cluster_id": 41
  },
  {
    "feature_id": 340,
    "explanation_index": 2,
    "text": "The highlighted fragments are usually suffixes or word pieces that belong to a larger word, or whole words that form part of a phrase, often appearing at the end of a word or as a grammatical marker, and occasionally include punctuation or special symbols.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8650908668835958,
    "similarity_var": 4.833535459722624e-05,
    "score_fuzz": 0.4,
    "score_detection": 0.7,
    "score_embedding": 0.51375,
    "total_score": 0.5379166666666667,
    "x": 15.683414459228516,
    "y": 7.2755961418151855,
    "cluster_id": 19
  },
  {
    "feature_id": 341,
    "explanation_index": 0,
    "text": "Mathematical notation and symbols, often used in equations and formulas, including subscripts, superscripts, and special characters.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9087153673171997,
    "similarity_var": 0.00018092290943864478,
    "score_fuzz": 0.46,
    "score_detection": 0.45,
    "score_embedding": 0.602,
    "total_score": 0.504,
    "x": 9.223925590515137,
    "y": 8.239401817321777,
    "cluster_id": 74
  },
  {
    "feature_id": 341,
    "explanation_index": 1,
    "text": "Mathematical notation involving subscripts, summations, and indexed variables, often within LaTeX-formatted expressions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9087153673171997,
    "similarity_var": 0.00018092290943864478,
    "score_fuzz": 0.47,
    "score_detection": 0.43,
    "score_embedding": 0.63125,
    "total_score": 0.5104166666666666,
    "x": 9.277621269226074,
    "y": 8.302543640136719,
    "cluster_id": 74
  },
  {
    "feature_id": 341,
    "explanation_index": 2,
    "text": "The highlighted tokens are the building blocks of LaTeX mathematical notation\u2014Greek letters, variable names, subscripts, superscripts, operators, and structural delimiters\u2014used to compose complex formulas.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9087153673171997,
    "similarity_var": 0.00018092290943864478,
    "score_fuzz": 0.375,
    "score_detection": 0.5,
    "score_embedding": 0.5937499999999999,
    "total_score": 0.4895833333333333,
    "x": 13.029540061950684,
    "y": 6.076913356781006,
    "cluster_id": -1
  },
  {
    "feature_id": 343,
    "explanation_index": 0,
    "text": "Tokens that mark the end of a code block, mathematical expression, or a specific section in a document, often used in programming languages, LaTeX, or other markup languages.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8900176882743835,
    "similarity_var": 0.0008794559163973759,
    "score_fuzz": 0.99,
    "score_detection": 0.93,
    "score_embedding": 0.988,
    "total_score": 0.9693333333333333,
    "x": 10.668956756591797,
    "y": 5.929617881774902,
    "cluster_id": 18
  },
  {
    "feature_id": 343,
    "explanation_index": 1,
    "text": "Closing delimiters such as \\\"}\\\", \\\"*/\\\", \\\"}\\\", and \\\"```\\\" that mark the end of code blocks, comments, or mathematical environments, often appearing in structured or formatted text.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8900176882743835,
    "similarity_var": 0.0008794559163973759,
    "score_fuzz": 0.99,
    "score_detection": 0.95,
    "score_embedding": 0.9450000000000001,
    "total_score": 0.9616666666666666,
    "x": 9.562579154968262,
    "y": 6.6828293800354,
    "cluster_id": 61
  },
  {
    "feature_id": 343,
    "explanation_index": 2,
    "text": "Tokens that mark structural boundaries or key elements in code or LaTeX\u2014such as environment names, punctuation, or short keywords\u2014are highlighted as important.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8900176882743835,
    "similarity_var": 0.0008794559163973759,
    "score_fuzz": 1.0,
    "score_detection": 0.975,
    "score_embedding": 0.9724999999999999,
    "total_score": 0.9824999999999999,
    "x": 14.013174057006836,
    "y": 5.909601211547852,
    "cluster_id": -1
  },
  {
    "feature_id": 344,
    "explanation_index": 0,
    "text": "Adjectives describing states of being active or occupied, often used to convey a sense of activity or busyness, and various numerical values and codes.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8447310328483582,
    "similarity_var": 0.0007505598586898069,
    "score_fuzz": 0.66,
    "score_detection": 0.55,
    "score_embedding": 0.352,
    "total_score": 0.5206666666666666,
    "x": 8.930456161499023,
    "y": 1.0246602296829224,
    "cluster_id": -1
  },
  {
    "feature_id": 344,
    "explanation_index": 1,
    "text": "The word \\\"busy\\\" and its variants (e.g., \\\"busiest\\\", \\\"busy\\\" in compound terms) are frequently activated in contexts describing high activity, congestion, or intense schedules, often in relation to locations, times, or people.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8447310328483582,
    "similarity_var": 0.0007505598586898069,
    "score_fuzz": 0.72,
    "score_detection": 0.74,
    "score_embedding": 0.7981250000000001,
    "total_score": 0.7527083333333334,
    "x": 8.993145942687988,
    "y": 1.0917888879776,
    "cluster_id": 45
  },
  {
    "feature_id": 344,
    "explanation_index": 2,
    "text": "The highlighted tokens consistently function as the core lexical elements of idiomatic or collocational expressions\u2014often indicating state, comparison, or location\u2014and they tend to be high\u2011frequency words that carry the main semantic load in the surrounding phrase.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8447310328483582,
    "similarity_var": 0.0007505598586898069,
    "score_fuzz": 0.625,
    "score_detection": 0.725,
    "score_embedding": 0.548125,
    "total_score": 0.6327083333333333,
    "x": 14.44067096710205,
    "y": 3.8811471462249756,
    "cluster_id": 11
  },
  {
    "feature_id": 346,
    "explanation_index": 0,
    "text": "Special characters used as delimiters or markers in code, often indicating the start or end of a section, comment, or block of code.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9341350197792053,
    "similarity_var": 0.0002179179894952199,
    "score_fuzz": 0.62,
    "score_detection": 0.44,
    "score_embedding": 0.648,
    "total_score": 0.5693333333333334,
    "x": 9.363848686218262,
    "y": 7.480685234069824,
    "cluster_id": -1
  },
  {
    "feature_id": 346,
    "explanation_index": 1,
    "text": "Special symbols and delimiters used in code syntax, documentation, or markup languages, often indicating structure, comments, formatting, or mathematical notation.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9341350197792053,
    "similarity_var": 0.0002179179894952199,
    "score_fuzz": 0.63,
    "score_detection": 0.48,
    "score_embedding": 0.7581249999999999,
    "total_score": 0.6227083333333333,
    "x": 9.555657386779785,
    "y": 7.450695037841797,
    "cluster_id": -1
  },
  {
    "feature_id": 346,
    "explanation_index": 2,
    "text": "The highlighted tokens are symbols that mark code structure or syntax\u2014comment delimiters, code fences, preprocessor directives, and other language\u2011specific punctuation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9341350197792053,
    "similarity_var": 0.0002179179894952199,
    "score_fuzz": 0.675,
    "score_detection": 0.325,
    "score_embedding": 0.6681250000000001,
    "total_score": 0.5560416666666667,
    "x": 13.658084869384766,
    "y": 6.25075101852417,
    "cluster_id": -1
  },
  {
    "feature_id": 347,
    "explanation_index": 0,
    "text": "Empty or whitespace strings often used as delimiters or placeholders in code, sometimes indicating the start or end of a section or block.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8338204423586527,
    "similarity_var": 0.0014670854983983696,
    "score_fuzz": 0.84,
    "score_detection": 0.58,
    "score_embedding": 0.8635999999999999,
    "total_score": 0.7612,
    "x": 11.261652946472168,
    "y": 7.2678351402282715,
    "cluster_id": -1
  },
  {
    "feature_id": 347,
    "explanation_index": 1,
    "text": "The token sequence \\\"<<\\\" followed by a newline and then \\\">>\\\" often marks the boundary of a code block, comment, or structured content segment, with high activation on the newline character and surrounding whitespace, indicating structural parsing or tokenization boundaries in code or markup contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8338204423586527,
    "similarity_var": 0.0014670854983983696,
    "score_fuzz": 0.82,
    "score_detection": 0.63,
    "score_embedding": 0.886875,
    "total_score": 0.7789583333333333,
    "x": 9.533018112182617,
    "y": 6.5553131103515625,
    "cluster_id": 61
  },
  {
    "feature_id": 347,
    "explanation_index": 2,
    "text": "The highlighted tokens are almost always the last element of a phrase or clause\u2014typically a noun or a suffix that completes a word\u2014so they carry the key semantic or syntactic weight of the surrounding text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8338204423586527,
    "similarity_var": 0.0014670854983983696,
    "score_fuzz": 0.2,
    "score_detection": 0.425,
    "score_embedding": 0.855625,
    "total_score": 0.4935416666666666,
    "x": 14.592464447021484,
    "y": 3.791480779647827,
    "cluster_id": 11
  },
  {
    "feature_id": 349,
    "explanation_index": 0,
    "text": "Common nouns, proper nouns, and words that indicate possession or relation, often used to specify a location, organization, or entity.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8742403388023376,
    "similarity_var": 0.0017209176234610861,
    "score_fuzz": 0.38,
    "score_detection": 0.2,
    "score_embedding": 0.27040000000000003,
    "total_score": 0.2834666666666667,
    "x": 8.610276222229004,
    "y": -0.5052857995033264,
    "cluster_id": 79
  },
  {
    "feature_id": 349,
    "explanation_index": 1,
    "text": "Common nouns or noun phrases representing specific locations, abstract concepts, or possessive pronouns, often appearing in contexts involving possession, location, or descriptive attributes.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8742403388023376,
    "similarity_var": 0.0017209176234610861,
    "score_fuzz": 0.41,
    "score_detection": 0.19,
    "score_embedding": 0.26687500000000003,
    "total_score": 0.2889583333333334,
    "x": 8.764429092407227,
    "y": -0.33871203660964966,
    "cluster_id": -1
  },
  {
    "feature_id": 349,
    "explanation_index": 2,
    "text": "The highlighted words consistently make up the core of a meaningful phrase\u2014typically a noun or prepositional phrase that conveys a key concept or named entity\u2014so the important tokens are those that together form a coherent semantic unit, including both content words and the necessary function words that bind them.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8742403388023376,
    "similarity_var": 0.0017209176234610861,
    "score_fuzz": 0.525,
    "score_detection": 0.325,
    "score_embedding": 0.549375,
    "total_score": 0.46645833333333336,
    "x": 15.486227035522461,
    "y": 4.142375469207764,
    "cluster_id": 22
  },
  {
    "feature_id": 350,
    "explanation_index": 0,
    "text": "Punctuation marks and whitespace characters, often used to denote the end or beginning of a sentence, quotation, or code block.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8656797210375468,
    "similarity_var": 8.744660442832558e-05,
    "score_fuzz": 0.73,
    "score_detection": 0.62,
    "score_embedding": 0.7056,
    "total_score": 0.6852,
    "x": 8.364459037780762,
    "y": 6.853795051574707,
    "cluster_id": 36
  },
  {
    "feature_id": 350,
    "explanation_index": 1,
    "text": "Empty or whitespace-only tokens, often representing structural or formatting elements in code, markup, or document layout, are frequently activated when contextually adjacent to meaningful content.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8656797210375468,
    "similarity_var": 8.744660442832558e-05,
    "score_fuzz": 0.83,
    "score_detection": 0.63,
    "score_embedding": 0.706875,
    "total_score": 0.7222916666666667,
    "x": 11.240715026855469,
    "y": 7.127373695373535,
    "cluster_id": -1
  },
  {
    "feature_id": 350,
    "explanation_index": 2,
    "text": "The highlighted tokens are usually nouns or noun phrases that identify key objects or concepts, often preceded by articles or adjectives, and occasionally punctuation or code elements that are essential to the meaning or structure of the sentence or snippet.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8656797210375468,
    "similarity_var": 8.744660442832558e-05,
    "score_fuzz": 0.325,
    "score_detection": 0.5,
    "score_embedding": 0.733125,
    "total_score": 0.519375,
    "x": 14.64065933227539,
    "y": 3.8984439373016357,
    "cluster_id": 11
  },
  {
    "feature_id": 351,
    "explanation_index": 0,
    "text": "Numerical digits, often representing quantities, measurements, or identifiers, frequently appearing in scientific, mathematical, or technical contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8967497944831848,
    "similarity_var": 4.8720768944576776e-05,
    "score_fuzz": 0.6,
    "score_detection": 0.48,
    "score_embedding": 0.21719999999999998,
    "total_score": 0.43240000000000006,
    "x": 7.045266151428223,
    "y": 8.708891868591309,
    "cluster_id": 29
  },
  {
    "feature_id": 351,
    "explanation_index": 1,
    "text": "Digits that appear immediately after a delimiter symbol, often indicating precision, indexing, or numerical annotation in scientific, technical, or formatted text.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8967497944831848,
    "similarity_var": 4.8720768944576776e-05,
    "score_fuzz": 0.65,
    "score_detection": 0.43,
    "score_embedding": 0.215,
    "total_score": 0.4316666666666667,
    "x": 7.165834426879883,
    "y": 8.644143104553223,
    "cluster_id": 29
  },
  {
    "feature_id": 351,
    "explanation_index": 2,
    "text": "The highlighted tokens are numeric components\u2014individual digits or numeric substrings that together compose numbers, decimal values, timestamps, or identifiers.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8967497944831848,
    "similarity_var": 4.8720768944576776e-05,
    "score_fuzz": 0.675,
    "score_detection": 0.45,
    "score_embedding": 0.18,
    "total_score": 0.435,
    "x": 13.142729759216309,
    "y": 5.8590593338012695,
    "cluster_id": 30
  },
  {
    "feature_id": 352,
    "explanation_index": 0,
    "text": "Code blocks or snippets, often in various programming languages, that are separated by a delimiter, typically indicating the end of a statement, block, or function.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8232950568199158,
    "similarity_var": 0.0019286134168391793,
    "score_fuzz": 0.62,
    "score_detection": 0.5,
    "score_embedding": 0.416,
    "total_score": 0.512,
    "x": 11.17073917388916,
    "y": 8.23958969116211,
    "cluster_id": -1
  },
  {
    "feature_id": 352,
    "explanation_index": 1,
    "text": "Patterns in code syntax involving balanced braces, parentheses, and brackets, with frequent use of newline characters and closing symbols like \\\"}\\\" and \\\")\\\" in structured programming constructs.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8232950568199158,
    "similarity_var": 0.0019286134168391793,
    "score_fuzz": 0.56,
    "score_detection": 0.45,
    "score_embedding": 0.23875000000000002,
    "total_score": 0.41625,
    "x": 10.59390926361084,
    "y": 7.41867733001709,
    "cluster_id": 7
  },
  {
    "feature_id": 352,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8232950568199158,
    "similarity_var": 0.0019286134168391793,
    "score_fuzz": 0.5,
    "score_detection": 0.525,
    "score_embedding": 0.5268750000000001,
    "total_score": 0.5172916666666666,
    "x": -5.864222526550293,
    "y": 16.044448852539062,
    "cluster_id": 10
  },
  {
    "feature_id": 354,
    "explanation_index": 0,
    "text": "A prefix or suffix of a word, often related to medical or biological terms, or a word that is part of a phrase or sentence that is being described or analyzed.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8838985761006674,
    "similarity_var": 0.000296055099639937,
    "score_fuzz": 0.57,
    "score_detection": 0.41,
    "score_embedding": 0.3504,
    "total_score": 0.4434666666666667,
    "x": 8.191951751708984,
    "y": 2.1165404319763184,
    "cluster_id": 44
  },
  {
    "feature_id": 354,
    "explanation_index": 1,
    "text": "Fragments of anatomical or physiological terms, often part of compound words, that are frequently activated in medical or biological contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8838985761006674,
    "similarity_var": 0.000296055099639937,
    "score_fuzz": 0.63,
    "score_detection": 0.41,
    "score_embedding": 0.275625,
    "total_score": 0.43854166666666666,
    "x": 7.289580345153809,
    "y": 2.122357130050659,
    "cluster_id": -1
  },
  {
    "feature_id": 354,
    "explanation_index": 2,
    "text": "The activations consistently point to sub\u2011word fragments that compose longer words\u2014common suffixes, prefixes, and stems\u2014especially within domain\u2011specific terminology, showing the model\u2019s reliance on sub\u2011word tokenization to capture morphological structure.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8838985761006674,
    "similarity_var": 0.000296055099639937,
    "score_fuzz": 0.45,
    "score_detection": 0.35,
    "score_embedding": 0.256875,
    "total_score": 0.35229166666666667,
    "x": 8.028229713439941,
    "y": 3.176063060760498,
    "cluster_id": 76
  },
  {
    "feature_id": 355,
    "explanation_index": 0,
    "text": "Citations, references, and legal terminology, often including numbers, abbreviations, and specific formatting.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9345860282580057,
    "similarity_var": 7.992541678289753e-05,
    "score_fuzz": 0.65,
    "score_detection": 0.57,
    "score_embedding": 0.5339999999999999,
    "total_score": 0.5846666666666667,
    "x": 8.860608100891113,
    "y": 4.5204339027404785,
    "cluster_id": 75
  },
  {
    "feature_id": 355,
    "explanation_index": 1,
    "text": "The text contains legal citations and references with structured formatting, including numerical codes, abbreviations (e.g., \\\"F.3d\\\", \\\"S. Ct.\\\"), section symbols (\u00a7), parentheses, and spacing patterns, often surrounding specific legal provisions, case names, or statutory references.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9345860282580057,
    "similarity_var": 7.992541678289753e-05,
    "score_fuzz": 0.66,
    "score_detection": 0.6,
    "score_embedding": 0.558125,
    "total_score": 0.6060416666666667,
    "x": 8.885080337524414,
    "y": 4.454402446746826,
    "cluster_id": 75
  },
  {
    "feature_id": 355,
    "explanation_index": 2,
    "text": "The text repeatedly uses legal citation conventions\u2014numerical identifiers, abbreviations for courts and statutes, and punctuation such as parentheses, hyphens, and section symbols\u2014to reference cases, rules, and statutory provisions.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9345860282580057,
    "similarity_var": 7.992541678289753e-05,
    "score_fuzz": 0.6,
    "score_detection": 0.55,
    "score_embedding": 0.549375,
    "total_score": 0.5664583333333333,
    "x": 8.91828727722168,
    "y": 4.430027484893799,
    "cluster_id": 75
  },
  {
    "feature_id": 356,
    "explanation_index": 0,
    "text": "Special keywords, function names, and variable names in programming languages, often denoting specific actions, properties, or configurations.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8938974539438883,
    "similarity_var": 1.2534732210017159e-05,
    "score_fuzz": 0.72,
    "score_detection": 0.67,
    "score_embedding": 0.4136,
    "total_score": 0.6012000000000001,
    "x": 10.440088272094727,
    "y": 8.60938549041748,
    "cluster_id": 80
  },
  {
    "feature_id": 356,
    "explanation_index": 1,
    "text": "Tokens enclosed within double angle brackets often represent identifiers, types, or keywords in programming contexts, frequently appearing in code syntax such as class names, method calls, configuration settings, or language-specific constructs.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8938974539438883,
    "similarity_var": 1.2534732210017159e-05,
    "score_fuzz": 0.63,
    "score_detection": 0.55,
    "score_embedding": 0.31875000000000003,
    "total_score": 0.49958333333333343,
    "x": 10.861599922180176,
    "y": 6.126134395599365,
    "cluster_id": 18
  },
  {
    "feature_id": 356,
    "explanation_index": 2,
    "text": "The highlighted tokens are consistently identifiers or operators that are central to the syntax or semantics of the code, such as class names, method names, property names, or control operators.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8938974539438883,
    "similarity_var": 1.2534732210017159e-05,
    "score_fuzz": 0.75,
    "score_detection": 0.675,
    "score_embedding": 0.285625,
    "total_score": 0.5702083333333333,
    "x": 13.898216247558594,
    "y": 6.613193988800049,
    "cluster_id": 8
  },
  {
    "feature_id": 358,
    "explanation_index": 0,
    "text": "Conjunctions and subordinating conjunctions introducing clauses, often indicating a condition, reason, or consequence, and sometimes used in formal or technical writing.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8822147846221924,
    "similarity_var": 0.00028765444290712594,
    "score_fuzz": 0.92,
    "score_detection": 0.78,
    "score_embedding": 0.3408,
    "total_score": 0.6802666666666667,
    "x": 12.074396133422852,
    "y": 0.25875768065452576,
    "cluster_id": -1
  },
  {
    "feature_id": 358,
    "explanation_index": 1,
    "text": "The word \\\"that\\\" frequently introduces a subordinate clause expressing a fact, result, or condition, often following verbs like \\\"demonstrate,\\\" \\\"show,\\\" or \\\"indicate,\\\" and is commonly used in formal or technical writing to convey logical relationships.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8822147846221924,
    "similarity_var": 0.00028765444290712594,
    "score_fuzz": 0.75,
    "score_detection": 0.75,
    "score_embedding": 0.335625,
    "total_score": 0.6118750000000001,
    "x": 11.40371322631836,
    "y": 2.295863151550293,
    "cluster_id": -1
  },
  {
    "feature_id": 358,
    "explanation_index": 2,
    "text": "The highlighted tokens are common function words and punctuation that serve to link clauses, signal conditions, reasons, or relationships within sentences.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8822147846221924,
    "similarity_var": 0.00028765444290712594,
    "score_fuzz": 0.95,
    "score_detection": 0.75,
    "score_embedding": 0.296875,
    "total_score": 0.665625,
    "x": 13.643935203552246,
    "y": 3.480274200439453,
    "cluster_id": 35
  },
  {
    "feature_id": 359,
    "explanation_index": 0,
    "text": "Punctuation marks and special characters, often used to denote the end of a sentence, quotation, or mathematical expression, or to indicate a transition between ideas or sections.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8116581837336222,
    "similarity_var": 0.00033705285624405527,
    "score_fuzz": 0.56,
    "score_detection": 0.32,
    "score_embedding": 0.4456,
    "total_score": 0.4418666666666667,
    "x": 8.21384048461914,
    "y": 6.836000442504883,
    "cluster_id": 36
  },
  {
    "feature_id": 359,
    "explanation_index": 1,
    "text": "The token \\\"er\\\" appears in comparative forms of adjectives, often indicating a higher degree of a quality, and is frequently associated with linguistic comparisons involving size, intensity, or degree.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8116581837336222,
    "similarity_var": 0.00033705285624405527,
    "score_fuzz": 0.53,
    "score_detection": 0.64,
    "score_embedding": 0.4575,
    "total_score": 0.5425,
    "x": 11.842766761779785,
    "y": 3.417825222015381,
    "cluster_id": 60
  },
  {
    "feature_id": 359,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core lexical items that carry the main semantic content of a phrase\u2014typically nouns, key modifiers, or technical terms\u2014and occasionally punctuation that marks phrase boundaries.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8116581837336222,
    "similarity_var": 0.00033705285624405527,
    "score_fuzz": 0.625,
    "score_detection": 0.775,
    "score_embedding": 0.365625,
    "total_score": 0.5885416666666666,
    "x": 15.084016799926758,
    "y": 4.288889408111572,
    "cluster_id": 91
  },
  {
    "feature_id": 361,
    "explanation_index": 0,
    "text": "Prepositions and adverbs indicating movement or direction, often used in idiomatic expressions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8477723002433777,
    "similarity_var": 0.0015228110626447726,
    "score_fuzz": 0.96,
    "score_detection": 0.79,
    "score_embedding": 0.4948,
    "total_score": 0.7482666666666667,
    "x": 11.85409164428711,
    "y": -0.5164834856987,
    "cluster_id": -1
  },
  {
    "feature_id": 361,
    "explanation_index": 1,
    "text": "Common directional or locative phrasal verbs (e.g., \\\"down,\\\" \\\"up,\\\" \\\"back,\\\" \\\"out,\\\" \\\"forward,\\\" \\\"around,\\\" \\\"through,\\\" \\\"over,\\\" \\\"away\\\") used to describe movement, change, or progression in space or time.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8477723002433777,
    "similarity_var": 0.0015228110626447726,
    "score_fuzz": 0.98,
    "score_detection": 0.83,
    "score_embedding": 0.7474999999999999,
    "total_score": 0.8525,
    "x": 11.618375778198242,
    "y": -0.8459916114807129,
    "cluster_id": 13
  },
  {
    "feature_id": 361,
    "explanation_index": 2,
    "text": "the patterns in the examples.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8477723002433777,
    "similarity_var": 0.0015228110626447726,
    "score_fuzz": 0.825,
    "score_detection": 0.475,
    "score_embedding": 0.393125,
    "total_score": 0.564375,
    "x": 5.211014747619629,
    "y": 9.905943870544434,
    "cluster_id": 58
  },
  {
    "feature_id": 362,
    "explanation_index": 0,
    "text": "Function words that connect clauses, phrases, or ideas, including prepositions, conjunctions, and auxiliary verbs, often used to introduce or link elements in a sentence.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9140169421831766,
    "similarity_var": 0.0003345713275856434,
    "score_fuzz": 0.8,
    "score_detection": 0.67,
    "score_embedding": 0.4236,
    "total_score": 0.6312000000000001,
    "x": 10.627936363220215,
    "y": 1.183030605316162,
    "cluster_id": 26
  },
  {
    "feature_id": 362,
    "explanation_index": 1,
    "text": "Common function words and phrases used to connect clauses, express conditions, or introduce additional information, particularly in formal or technical contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9140169421831766,
    "similarity_var": 0.0003345713275856434,
    "score_fuzz": 0.81,
    "score_detection": 0.57,
    "score_embedding": 0.378125,
    "total_score": 0.5860416666666667,
    "x": 10.680097579956055,
    "y": 1.2257856130599976,
    "cluster_id": 26
  },
  {
    "feature_id": 362,
    "explanation_index": 2,
    "text": "The highlighted tokens are short, function words that act as grammatical glue\u2014conjunctions, prepositions, auxiliary verbs, and punctuation\u2014linking clauses, indicating relationships, or marking structure.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9140169421831766,
    "similarity_var": 0.0003345713275856434,
    "score_fuzz": 0.8,
    "score_detection": 0.625,
    "score_embedding": 0.42812500000000003,
    "total_score": 0.6177083333333334,
    "x": 13.69915771484375,
    "y": 3.3531129360198975,
    "cluster_id": 35
  },
  {
    "feature_id": 363,
    "explanation_index": 0,
    "text": "Common nouns representing various objects, vehicles, and devices.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9452486236890157,
    "similarity_var": 1.2318655645376313e-05,
    "score_fuzz": 0.85,
    "score_detection": 0.5,
    "score_embedding": 0.6315999999999999,
    "total_score": 0.6605333333333333,
    "x": 8.441299438476562,
    "y": -0.14386829733848572,
    "cluster_id": -1
  },
  {
    "feature_id": 363,
    "explanation_index": 1,
    "text": "Nouns representing physical objects, vehicles, or devices, often associated with transportation, technology, or everyday items, frequently appearing in contexts involving functionality, movement, or specific use cases.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9452486236890157,
    "similarity_var": 1.2318655645376313e-05,
    "score_fuzz": 0.82,
    "score_detection": 0.58,
    "score_embedding": 0.6687500000000001,
    "total_score": 0.6895833333333333,
    "x": 8.276398658752441,
    "y": 0.0879201665520668,
    "cluster_id": 24
  },
  {
    "feature_id": 363,
    "explanation_index": 2,
    "text": "Common nouns that denote concrete objects or entities, frequently appearing in contexts of transportation, technology, biology, or everyday life.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9452486236890157,
    "similarity_var": 1.2318655645376313e-05,
    "score_fuzz": 0.8,
    "score_detection": 0.425,
    "score_embedding": 0.6649999999999999,
    "total_score": 0.63,
    "x": 8.378173828125,
    "y": -0.11392766237258911,
    "cluster_id": -1
  },
  {
    "feature_id": 364,
    "explanation_index": 0,
    "text": "Special characters and LaTeX/mathematical notation, often used in programming and academic contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8117571274439493,
    "similarity_var": 0.002022905265878055,
    "score_fuzz": 0.57,
    "score_detection": 0.53,
    "score_embedding": 0.6295999999999999,
    "total_score": 0.5765333333333333,
    "x": 9.168957710266113,
    "y": 7.83250617980957,
    "cluster_id": -1
  },
  {
    "feature_id": 364,
    "explanation_index": 1,
    "text": "Single-letter tokens, often used as variables, identifiers, or placeholders in code, mathematical expressions, or markup, are highly activated, particularly when they appear in contexts involving syntax, programming, or formal notation.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8117571274439493,
    "similarity_var": 0.002022905265878055,
    "score_fuzz": 0.59,
    "score_detection": 0.48,
    "score_embedding": 0.6056250000000001,
    "total_score": 0.5585416666666666,
    "x": 10.638224601745605,
    "y": 6.249340057373047,
    "cluster_id": -1
  },
  {
    "feature_id": 364,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8117571274439493,
    "similarity_var": 0.002022905265878055,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.5387500000000001,
    "total_score": 0.5129166666666667,
    "x": -5.937502384185791,
    "y": 15.971253395080566,
    "cluster_id": 10
  },
  {
    "feature_id": 365,
    "explanation_index": 0,
    "text": "Code snippets in various programming languages, often including function calls, variable declarations, and control structures, with a focus on system programming and low-level operations.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8767011165618896,
    "similarity_var": 0.00024663910804415917,
    "score_fuzz": 0.44,
    "score_detection": 0.44,
    "score_embedding": 0.5648,
    "total_score": 0.4816,
    "x": 11.222686767578125,
    "y": 8.721070289611816,
    "cluster_id": 17
  },
  {
    "feature_id": 365,
    "explanation_index": 1,
    "text": "Patterns in code syntax involving underscores, identifiers, and structural tokens in programming languages, particularly in C, Go, and related systems code.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8767011165618896,
    "similarity_var": 0.00024663910804415917,
    "score_fuzz": 0.43,
    "score_detection": 0.44,
    "score_embedding": 0.555625,
    "total_score": 0.4752083333333334,
    "x": 10.702966690063477,
    "y": 7.4148993492126465,
    "cluster_id": 7
  },
  {
    "feature_id": 365,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core syntactic and semantic elements of code\u2014identifiers, keywords, operators, and punctuation\u2014that form the building blocks of the program.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8767011165618896,
    "similarity_var": 0.00024663910804415917,
    "score_fuzz": 0.375,
    "score_detection": 0.475,
    "score_embedding": 0.499375,
    "total_score": 0.44979166666666665,
    "x": 13.780030250549316,
    "y": 6.793694972991943,
    "cluster_id": 8
  },
  {
    "feature_id": 366,
    "explanation_index": 0,
    "text": "Adjectives and adverbs often have suffixes added to their base form, such as -al, -ic, -ful, -ive, -ly, and -er, to convey various meanings and functions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8086798588434855,
    "similarity_var": 0.003826418433794585,
    "score_fuzz": 0.72,
    "score_detection": 0.49,
    "score_embedding": 0.43600000000000005,
    "total_score": 0.5486666666666666,
    "x": 8.626869201660156,
    "y": 2.2128968238830566,
    "cluster_id": 66
  },
  {
    "feature_id": 366,
    "explanation_index": 1,
    "text": "Suffixes and compound words forming adjectives or nouns, often related to technical, academic, or descriptive contexts, with a focus on morphological patterns like \\\"-al\\\", \\\"-er\\\", \\\"-ful\\\", \\\"-ous\\\", and \\\"-ative\\\", frequently appearing in scientific, formal, or specialized language.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8086798588434855,
    "similarity_var": 0.003826418433794585,
    "score_fuzz": 0.67,
    "score_detection": 0.27,
    "score_embedding": 0.27625,
    "total_score": 0.4054166666666667,
    "x": 8.627312660217285,
    "y": 2.305922746658325,
    "cluster_id": 66
  },
  {
    "feature_id": 366,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8086798588434855,
    "similarity_var": 0.003826418433794585,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.361875,
    "total_score": 0.4539583333333333,
    "x": -5.932892799377441,
    "y": 15.97591781616211,
    "cluster_id": 10
  },
  {
    "feature_id": 368,
    "explanation_index": 0,
    "text": "Nouns representing various concepts, objects, and activities, often related to everyday life, technology, health, and leisure.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8567550778388977,
    "similarity_var": 6.816630779364156e-05,
    "score_fuzz": 0.67,
    "score_detection": 0.4,
    "score_embedding": 0.37920000000000004,
    "total_score": 0.4830666666666667,
    "x": 8.23340129852295,
    "y": -0.09184788167476654,
    "cluster_id": -1
  },
  {
    "feature_id": 368,
    "explanation_index": 1,
    "text": "Compound nouns or noun phrases where the second word is a common modifier or descriptor, often forming a specific category or type, with high activation on the second word.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8567550778388977,
    "similarity_var": 6.816630779364156e-05,
    "score_fuzz": 0.7473684210526316,
    "score_detection": 0.43,
    "score_embedding": 0.47375,
    "total_score": 0.5503728070175439,
    "x": 8.773380279541016,
    "y": 0.37686559557914734,
    "cluster_id": -1
  },
  {
    "feature_id": 368,
    "explanation_index": 2,
    "text": "The highlighted tokens are the words or phrases that carry the main semantic content of the sentence, typically nouns, noun phrases, or key adjectives\u2014including idiomatic expressions and domain\u2011specific terms\u2014that represent the core concepts or entities around which the sentence is built.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8567550778388977,
    "similarity_var": 6.816630779364156e-05,
    "score_fuzz": 0.75,
    "score_detection": 0.375,
    "score_embedding": 0.405625,
    "total_score": 0.5102083333333334,
    "x": 14.968588829040527,
    "y": 3.8271243572235107,
    "cluster_id": -1
  },
  {
    "feature_id": 369,
    "explanation_index": 0,
    "text": "Decimal points in numerical values, often used in scientific or technical contexts to represent precise measurements or data.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9019199013710022,
    "similarity_var": 0.0009632049867202378,
    "score_fuzz": 0.71,
    "score_detection": 0.59,
    "score_embedding": 0.36600000000000005,
    "total_score": 0.5553333333333333,
    "x": 6.773759365081787,
    "y": 8.737325668334961,
    "cluster_id": 29
  },
  {
    "feature_id": 369,
    "explanation_index": 1,
    "text": "The period character \\\".\\\" is frequently used as a decimal separator in numerical values, particularly in scientific, statistical, or technical contexts, and is often associated with precise measurements, probabilities, or formatted data.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9019199013710022,
    "similarity_var": 0.0009632049867202378,
    "score_fuzz": 0.67,
    "score_detection": 0.61,
    "score_embedding": 0.5175,
    "total_score": 0.5991666666666666,
    "x": 8.26359748840332,
    "y": 7.217319011688232,
    "cluster_id": 37
  },
  {
    "feature_id": 369,
    "explanation_index": 2,
    "text": "The decimal point token is consistently highlighted in numeric expressions, indicating its importance in representing fractional values.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9019199013710022,
    "similarity_var": 0.0009632049867202378,
    "score_fuzz": 0.825,
    "score_detection": 0.625,
    "score_embedding": 0.46249999999999997,
    "total_score": 0.6375,
    "x": 13.138310432434082,
    "y": 5.897983551025391,
    "cluster_id": 30
  },
  {
    "feature_id": 370,
    "explanation_index": 0,
    "text": "URLs, website addresses, and domain names, often including top-level domains and subdomains, as well as specific web-related terms and protocols.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8811564246813456,
    "similarity_var": 0.0014008767236606762,
    "score_fuzz": 0.8,
    "score_detection": 0.86,
    "score_embedding": 0.898,
    "total_score": 0.8526666666666668,
    "x": 9.397747993469238,
    "y": 3.2969915866851807,
    "cluster_id": -1
  },
  {
    "feature_id": 370,
    "explanation_index": 1,
    "text": "Patterns involving domain names, URLs, and web-related identifiers, including subdomains, top-level domains (like .uk, .org, .co), protocol prefixes (http://, https://), and common web structures (www, @, .com, .net), often appearing in contexts related to online resources, links, or digital infrastructure.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8811564246813456,
    "similarity_var": 0.0014008767236606762,
    "score_fuzz": 0.77,
    "score_detection": 0.82,
    "score_embedding": 0.9043749999999999,
    "total_score": 0.8314583333333333,
    "x": 9.455340385437012,
    "y": 3.3258140087127686,
    "cluster_id": -1
  },
  {
    "feature_id": 370,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core lexical pieces that give a phrase or a URL its meaning\u2014typically nouns, adjectives, or key prepositions that form idiomatic expressions or domain identifiers. They usually appear surrounded by spaces or punctuation and serve as the building blocks of the phrase or web address.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8811564246813456,
    "similarity_var": 0.0014008767236606762,
    "score_fuzz": 0.675,
    "score_detection": 0.575,
    "score_embedding": 0.8425,
    "total_score": 0.6975000000000001,
    "x": 14.908966064453125,
    "y": 4.011608123779297,
    "cluster_id": 22
  },
  {
    "feature_id": 371,
    "explanation_index": 0,
    "text": "Tokens related to revision, review, and reform, often in academic or formal contexts, as well as words associated with rivers, evolution, and revelation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.864879826704661,
    "similarity_var": 0.00019731268143472237,
    "score_fuzz": 0.72,
    "score_detection": 0.69,
    "score_embedding": 0.2376,
    "total_score": 0.5492,
    "x": 10.190166473388672,
    "y": 4.286310195922852,
    "cluster_id": 1
  },
  {
    "feature_id": 371,
    "explanation_index": 1,
    "text": "The text contains a recurring pattern of morphological variants of root words (e.g., \\\"revise\\\", \\\"revelation\\\", \\\"revolution\\\", \\\"reform\\\", \\\"revenue\\\", \\\"reversible\\\", \\\"relevance\\\", \\\"river\\\", \\\"reward\\\", \\\"recovery\\\", \\\"renewal\\\", \\\"reversal\\\", \\\"revolver\\\", \\\"revisit\\\", \\\"renew\\\", \\\"reinforce\\\", \\\"reinstate\\\", \\\"reiterate\\\", \\\"reinvent\\\", \\\"rein\\\", \\\"reinforce\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"rein\\\", \\\"re",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.864879826704661,
    "similarity_var": 0.00019731268143472237,
    "score_fuzz": 0.76,
    "score_detection": 0.66,
    "score_embedding": 0.34125,
    "total_score": 0.5870833333333333,
    "x": 9.174593925476074,
    "y": 2.9257006645202637,
    "cluster_id": -1
  },
  {
    "feature_id": 371,
    "explanation_index": 2,
    "text": "The highlighted fragments are all substrings that appear inside larger words, most of them beginning with the letters \u201cre\u201d, \u201crev\u201d, or \u201criv\u201d, showing a focus on shared prefixes or root fragments across diverse lexical items.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.864879826704661,
    "similarity_var": 0.00019731268143472237,
    "score_fuzz": 0.775,
    "score_detection": 0.725,
    "score_embedding": 0.34875,
    "total_score": 0.61625,
    "x": 15.528438568115234,
    "y": 7.250728130340576,
    "cluster_id": 19
  },
  {
    "feature_id": 372,
    "explanation_index": 0,
    "text": "Prepositions and conjunctions, often used to connect words, phrases, or clauses in a sentence, and sometimes preceding or following a quotation mark or a comma.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8988182147343954,
    "similarity_var": 0.0001430115337023431,
    "score_fuzz": 0.7111111111111111,
    "score_detection": 0.46,
    "score_embedding": 0.5952,
    "total_score": 0.5887703703703704,
    "x": 12.183686256408691,
    "y": 0.04907859489321709,
    "cluster_id": 9
  },
  {
    "feature_id": 372,
    "explanation_index": 1,
    "text": "Common conjunctions and prepositions used to connect clauses, items in lists, or modify relationships between entities, often appearing in structured or formal text.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8988182147343954,
    "similarity_var": 0.0001430115337023431,
    "score_fuzz": 0.74,
    "score_detection": 0.48,
    "score_embedding": 0.655,
    "total_score": 0.625,
    "x": 12.137558937072754,
    "y": 0.1341981440782547,
    "cluster_id": 9
  },
  {
    "feature_id": 372,
    "explanation_index": 2,
    "text": "The highlighted tokens are primarily function words\u2014conjunctions, prepositions, articles, and pronouns\u2014that act as syntactic glue, frequently appearing between clauses or phrases across the examples.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8988182147343954,
    "similarity_var": 0.0001430115337023431,
    "score_fuzz": 0.65,
    "score_detection": 0.4,
    "score_embedding": 0.665,
    "total_score": 0.5716666666666667,
    "x": 13.629914283752441,
    "y": 3.325485944747925,
    "cluster_id": 35
  },
  {
    "feature_id": 374,
    "explanation_index": 0,
    "text": "The token \\\"out\\\" often indicates movement or direction away from a location, or something being visible, apparent, or made known, while \\\"up\\\" is often associated with increase, improvement, or regulation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8741013010342916,
    "similarity_var": 0.00018749910953235686,
    "score_fuzz": 0.88,
    "score_detection": 0.87,
    "score_embedding": 0.8156,
    "total_score": 0.8552,
    "x": 11.941864967346191,
    "y": -0.7339308857917786,
    "cluster_id": -1
  },
  {
    "feature_id": 374,
    "explanation_index": 1,
    "text": "The word \\\"out\\\" frequently appears in phrasal verbs indicating emergence, departure, or release, often associated with physical or metaphorical exit, completion, or disclosure.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8741013010342916,
    "similarity_var": 0.00018749910953235686,
    "score_fuzz": 0.87,
    "score_detection": 0.87,
    "score_embedding": 0.8712500000000001,
    "total_score": 0.8704166666666667,
    "x": 11.923995971679688,
    "y": -0.7149563431739807,
    "cluster_id": -1
  },
  {
    "feature_id": 374,
    "explanation_index": 2,
    "text": "The highlighted fragments are short, often directional or state\u2011changing words (or parts of words) that signal movement, transition, or position\u2014such as \u201cout,\u201d \u201cup,\u201d \u201cdown,\u201d \u201coff,\u201d \u201caway,\u201d or a fragment like \u201cAud.\u201d They appear as prepositions or suffixes within larger words or phrases, marking a shift or location.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8741013010342916,
    "similarity_var": 0.00018749910953235686,
    "score_fuzz": 0.875,
    "score_detection": 0.9,
    "score_embedding": 0.80125,
    "total_score": 0.85875,
    "x": 15.67922592163086,
    "y": 7.200594425201416,
    "cluster_id": 19
  },
  {
    "feature_id": 376,
    "explanation_index": 0,
    "text": "Code snippets in various programming languages, often including function calls, variable declarations, and control structures.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8842443823814392,
    "similarity_var": 0.00021008845254044672,
    "score_fuzz": 0.4,
    "score_detection": 0.4,
    "score_embedding": 0.6028,
    "total_score": 0.4676,
    "x": 11.190573692321777,
    "y": 8.70078182220459,
    "cluster_id": 17
  },
  {
    "feature_id": 376,
    "explanation_index": 1,
    "text": "The text contains programming syntax, identifiers, and structural elements such as parentheses, brackets, colons, and special tokens like `@`, `<<`, `>>`, and `nil`, often associated with code constructs, function definitions, type declarations, and language-specific syntax in languages like Swift, Objective-C, JavaScript, and Ruby.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8842443823814392,
    "similarity_var": 0.00021008845254044672,
    "score_fuzz": 0.37,
    "score_detection": 0.43,
    "score_embedding": 0.486875,
    "total_score": 0.42895833333333333,
    "x": 10.615134239196777,
    "y": 8.276268005371094,
    "cluster_id": 48
  },
  {
    "feature_id": 376,
    "explanation_index": 2,
    "text": "The highlighted tokens are identifiers and keywords that denote functions, methods, classes, variables, or properties in code, often part of method calls or property accesses, and are crucial for the behavior of the code.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8842443823814392,
    "similarity_var": 0.00021008845254044672,
    "score_fuzz": 0.35,
    "score_detection": 0.375,
    "score_embedding": 0.5275,
    "total_score": 0.4175,
    "x": 13.762675285339355,
    "y": 6.635488986968994,
    "cluster_id": 8
  },
  {
    "feature_id": 377,
    "explanation_index": 0,
    "text": "Verbs and nouns related to games, sports, and leisure activities.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8492916623751322,
    "similarity_var": 0.001814349102044193,
    "score_fuzz": 0.77,
    "score_detection": 0.67,
    "score_embedding": 0.6844,
    "total_score": 0.7081333333333334,
    "x": 8.377730369567871,
    "y": -0.41946107149124146,
    "cluster_id": -1
  },
  {
    "feature_id": 377,
    "explanation_index": 1,
    "text": "The token \\\"play\\\" and its variants (e.g., playing, played, play it) are frequently activated in contexts involving games, sports, or interactive activities, often indicating participation or engagement in a structured or recreational activity.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8492916623751322,
    "similarity_var": 0.001814349102044193,
    "score_fuzz": 0.68,
    "score_detection": 0.71,
    "score_embedding": 0.8062500000000001,
    "total_score": 0.7320833333333333,
    "x": 10.405293464660645,
    "y": 4.226170063018799,
    "cluster_id": -1
  },
  {
    "feature_id": 377,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8492916623751322,
    "similarity_var": 0.001814349102044193,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.69625,
    "total_score": 0.5654166666666667,
    "x": -5.932358264923096,
    "y": 15.976490020751953,
    "cluster_id": 10
  },
  {
    "feature_id": 378,
    "explanation_index": 0,
    "text": "Tokens that are part of a larger unit, such as a word, phrase, or sentence, often with a specific grammatical or semantic function, and sometimes indicating a transition or connection between ideas.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8712067802747091,
    "similarity_var": 4.197536663102457e-05,
    "score_fuzz": 0.57,
    "score_detection": 0.84,
    "score_embedding": 0.474,
    "total_score": 0.628,
    "x": 10.434439659118652,
    "y": 4.5455708503723145,
    "cluster_id": -1
  },
  {
    "feature_id": 378,
    "explanation_index": 1,
    "text": "Fragments of words, abbreviations, or technical terms that appear in isolation or are split across tokens, often representing parts of compound words, identifiers, or symbolic notation.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8712067802747091,
    "similarity_var": 4.197536663102457e-05,
    "score_fuzz": 0.18,
    "score_detection": 0.17,
    "score_embedding": 0.734375,
    "total_score": 0.3614583333333334,
    "x": 7.1545257568359375,
    "y": 2.7235336303710938,
    "cluster_id": 15
  },
  {
    "feature_id": 378,
    "explanation_index": 2,
    "text": "Important tokens are contiguous character sequences\u2014often partial words, full words, or short phrases\u2014selected for activation, sometimes including punctuation or numbers, reflecting the model\u2019s focus on semantically or syntactically salient fragments.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8712067802747091,
    "similarity_var": 4.197536663102457e-05,
    "score_fuzz": 0.5,
    "score_detection": 0.6,
    "score_embedding": 0.6775000000000001,
    "total_score": 0.5925000000000001,
    "x": 11.472452163696289,
    "y": 4.637814998626709,
    "cluster_id": 78
  },
  {
    "feature_id": 379,
    "explanation_index": 0,
    "text": "Punctuation and special characters, often used to denote code, mathematical expressions, or formatting, and sometimes preceding or following specific words or phrases.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8513204455375671,
    "similarity_var": 0.0004609245944517208,
    "score_fuzz": 0.44,
    "score_detection": 0.41,
    "score_embedding": 0.4719999999999999,
    "total_score": 0.4406666666666666,
    "x": 8.532732963562012,
    "y": 7.237494468688965,
    "cluster_id": 4
  },
  {
    "feature_id": 379,
    "explanation_index": 1,
    "text": "The presence of tokens that form compound words, abbreviations, or technical terms, often separated by underscores, hyphens, or special characters, with high activation values indicating structural or semantic significance in context.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8513204455375671,
    "similarity_var": 0.0004609245944517208,
    "score_fuzz": 0.54,
    "score_detection": 0.44,
    "score_embedding": 0.7024999999999999,
    "total_score": 0.5608333333333333,
    "x": 9.952249526977539,
    "y": 3.8854799270629883,
    "cluster_id": -1
  },
  {
    "feature_id": 379,
    "explanation_index": 2,
    "text": "The highlighted tokens consistently form coherent units\u2014phrases, idioms, or code fragments\u2014that carry the core meaning or function of the surrounding text. These units are usually made up of nouns, verbs, adjectives, or structural punctuation, and the importance scores reflect how central each element is to that unit.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8513204455375671,
    "similarity_var": 0.0004609245944517208,
    "score_fuzz": 0.5,
    "score_detection": 0.2,
    "score_embedding": 0.555625,
    "total_score": 0.41854166666666665,
    "x": 15.370887756347656,
    "y": 4.547181606292725,
    "cluster_id": 31
  },
  {
    "feature_id": 380,
    "explanation_index": 0,
    "text": "Verbs or nouns related to representation, replication, or presentation of information, concepts, or objects, often in a formal or technical context.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8856931130091349,
    "similarity_var": 0.000481049231420943,
    "score_fuzz": 0.6,
    "score_detection": 0.42,
    "score_embedding": 0.292,
    "total_score": 0.43733333333333335,
    "x": 10.494745254516602,
    "y": -0.7446200251579285,
    "cluster_id": 14
  },
  {
    "feature_id": 380,
    "explanation_index": 1,
    "text": "The word \\\"representation\\\" and its variants (e.g., \\\"represents\\\", \\\"represented\\\", \\\"representing\\\") are frequently used in contexts involving abstract modeling, data visualization, or symbolic depiction, often in technical, academic, or descriptive writing.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8856931130091349,
    "similarity_var": 0.000481049231420943,
    "score_fuzz": 0.63,
    "score_detection": 0.59,
    "score_embedding": 0.266875,
    "total_score": 0.495625,
    "x": 9.37208366394043,
    "y": 7.652992248535156,
    "cluster_id": -1
  },
  {
    "feature_id": 380,
    "explanation_index": 2,
    "text": "The tokens include \\\"representation\\\", \\\"represents\\\", \\\"replication\\\", \\\"repent\\\", \\\"repressive\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\", \\\"represents\\\".",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8856931130091349,
    "similarity_var": 0.000481049231420943,
    "score_fuzz": 0.65,
    "score_detection": 0.65,
    "score_embedding": 0.423125,
    "total_score": 0.574375,
    "x": 11.025328636169434,
    "y": 3.3714778423309326,
    "cluster_id": 27
  },
  {
    "feature_id": 381,
    "explanation_index": 0,
    "text": "Mathematical expressions and equations, often containing Greek letters, subscripts, and superscripts, typically in the context of quantum mechanics and theoretical physics.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.89143834511439,
    "similarity_var": 6.610636481793917e-05,
    "score_fuzz": 0.56,
    "score_detection": 0.54,
    "score_embedding": 0.40080000000000005,
    "total_score": 0.5002666666666667,
    "x": 9.286152839660645,
    "y": 8.38694953918457,
    "cluster_id": 74
  },
  {
    "feature_id": 381,
    "explanation_index": 1,
    "text": "Mathematical and physical terminology involving specialized concepts such as renormalization, gauge invariance, wavefunctions, and quantum operators, often appearing in formal theoretical physics contexts with structured symbolic notation.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.89143834511439,
    "similarity_var": 6.610636481793917e-05,
    "score_fuzz": 0.59,
    "score_detection": 0.5,
    "score_embedding": 0.498125,
    "total_score": 0.5293749999999999,
    "x": 9.275683403015137,
    "y": 8.319025993347168,
    "cluster_id": 74
  },
  {
    "feature_id": 381,
    "explanation_index": 2,
    "text": "The highlighted tokens are consistently domain\u2011specific technical terms and LaTeX mathematical symbols that appear in scientific writing, especially physics and chemistry, often within equations or math mode. They are nouns or adjectives describing physical concepts and are usually part of LaTeX commands or mathematical expressions.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.89143834511439,
    "similarity_var": 6.610636481793917e-05,
    "score_fuzz": 0.525,
    "score_detection": 0.5,
    "score_embedding": 0.5706249999999999,
    "total_score": 0.531875,
    "x": 13.25020980834961,
    "y": 5.547224521636963,
    "cluster_id": -1
  },
  {
    "feature_id": 383,
    "explanation_index": 0,
    "text": "Special characters and symbols used in various contexts such as programming, mathematics, and web development, often serving as operators, delimiters, or markers.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8047016263008118,
    "similarity_var": 0.0004078936329463545,
    "score_fuzz": 0.59,
    "score_detection": 0.48,
    "score_embedding": 0.3416,
    "total_score": 0.4705333333333333,
    "x": 9.305331230163574,
    "y": 7.70639181137085,
    "cluster_id": -1
  },
  {
    "feature_id": 383,
    "explanation_index": 1,
    "text": "The token \\\"er\\\" at the end of a comparative adjective describing size.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8047016263008118,
    "similarity_var": 0.0004078936329463545,
    "score_fuzz": 0.49,
    "score_detection": 0.51,
    "score_embedding": 0.33,
    "total_score": 0.44333333333333336,
    "x": 11.837145805358887,
    "y": 3.408853054046631,
    "cluster_id": 60
  },
  {
    "feature_id": 383,
    "explanation_index": 2,
    "text": "The selected tokens are the core lexical or syntactic elements that identify a specific concept or function in the text, such as nouns, domain names, attribute names, or punctuation that delimit a key component.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8047016263008118,
    "similarity_var": 0.0004078936329463545,
    "score_fuzz": 0.6,
    "score_detection": 0.525,
    "score_embedding": 0.42625,
    "total_score": 0.5170833333333333,
    "x": 15.053099632263184,
    "y": 4.408098220825195,
    "cluster_id": 72
  },
  {
    "feature_id": 386,
    "explanation_index": 0,
    "text": "Prefixes or parts of words, often indicating a relationship or a characteristic, such as size, location, or function.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8881070812543234,
    "similarity_var": 0.0004423483916140311,
    "score_fuzz": 0.75,
    "score_detection": 0.59,
    "score_embedding": 0.4292,
    "total_score": 0.5897333333333333,
    "x": 8.212051391601562,
    "y": 2.1063880920410156,
    "cluster_id": 44
  },
  {
    "feature_id": 386,
    "explanation_index": 1,
    "text": "Subword units derived from scientific and technical terminology, often representing prefixes, roots, or suffixes in compound terms, with high activation in specialized domains.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8881070812543234,
    "similarity_var": 0.0004423483916140311,
    "score_fuzz": 0.76,
    "score_detection": 0.44,
    "score_embedding": 0.41437500000000005,
    "total_score": 0.538125,
    "x": 7.96523380279541,
    "y": 2.8656110763549805,
    "cluster_id": -1
  },
  {
    "feature_id": 386,
    "explanation_index": 2,
    "text": "The highlighted fragments are sub\u2011word units that line up with meaningful morphemes\u2014prefixes, suffixes, or stems\u2014found in scientific terminology. They show that the model\u2019s activations focus on these sub\u2011word pieces, using them to encode semantic content rather than whole words.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8881070812543234,
    "similarity_var": 0.0004423483916140311,
    "score_fuzz": 0.725,
    "score_detection": 0.425,
    "score_embedding": 0.48,
    "total_score": 0.5433333333333333,
    "x": 15.644721984863281,
    "y": 6.987248420715332,
    "cluster_id": 19
  },
  {
    "feature_id": 387,
    "explanation_index": 0,
    "text": "Nouns representing various concepts, objects, or ideas, often in specific contexts or situations, such as physical locations, abstract ideas, or technical terms.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8450542688369751,
    "similarity_var": 0.00276081659507336,
    "score_fuzz": 0.67,
    "score_detection": 0.43,
    "score_embedding": 0.35800000000000004,
    "total_score": 0.48600000000000004,
    "x": 8.244837760925293,
    "y": 0.22005575895309448,
    "cluster_id": 24
  },
  {
    "feature_id": 387,
    "explanation_index": 1,
    "text": "Nouns or noun phrases representing physical or abstract locations, containers, or spatial relationships, often following prepositions like \\\"in,\\\" \\\"on,\\\" or \\\"at,\\\" and frequently associated with contextually specific or metaphorical spaces.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8450542688369751,
    "similarity_var": 0.00276081659507336,
    "score_fuzz": 0.57,
    "score_detection": 0.43,
    "score_embedding": 0.19875000000000004,
    "total_score": 0.39958333333333335,
    "x": 12.363428115844727,
    "y": -0.5668129920959473,
    "cluster_id": 63
  },
  {
    "feature_id": 387,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8450542688369751,
    "similarity_var": 0.00276081659507336,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.359375,
    "total_score": 0.453125,
    "x": -5.899898052215576,
    "y": 16.00884437561035,
    "cluster_id": 10
  },
  {
    "feature_id": 389,
    "explanation_index": 0,
    "text": "Indentation, spacing, and punctuation marks, often used to denote code blocks, function calls, conditional statements, and variable declarations in programming languages.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8953103820482889,
    "similarity_var": 0.0003301299887215552,
    "score_fuzz": 0.45,
    "score_detection": 0.4,
    "score_embedding": 0.3256,
    "total_score": 0.39186666666666675,
    "x": 11.243037223815918,
    "y": 7.7838568687438965,
    "cluster_id": 81
  },
  {
    "feature_id": 389,
    "explanation_index": 1,
    "text": "The model attends to syntactic and structural elements in code, such as braces, parentheses, semicolons, and keywords, with higher activation on tokens that define code structure, control flow, or function boundaries.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8953103820482889,
    "similarity_var": 0.0003301299887215552,
    "score_fuzz": 0.38,
    "score_detection": 0.37,
    "score_embedding": 0.314375,
    "total_score": 0.35479166666666667,
    "x": 10.525406837463379,
    "y": 7.377107620239258,
    "cluster_id": 7
  },
  {
    "feature_id": 389,
    "explanation_index": 2,
    "text": "The highlighted tokens are the syntactic elements that delimit and control the flow of code\u2014whitespace, braces, parentheses, semicolons, and keywords such as if, else, return, while, for, and function names. These tokens are the building blocks that determine how the program is parsed and executed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8953103820482889,
    "similarity_var": 0.0003301299887215552,
    "score_fuzz": 0.475,
    "score_detection": 0.375,
    "score_embedding": 0.27375,
    "total_score": 0.3745833333333333,
    "x": 13.575454711914062,
    "y": 6.544483184814453,
    "cluster_id": 8
  },
  {
    "feature_id": 390,
    "explanation_index": 0,
    "text": "Punctuation marks, often used to denote the end of a sentence, quotation, or code block, and sometimes used in conjunction with other symbols to indicate a specific formatting or syntax.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8628196517626444,
    "similarity_var": 0.0005753519880195135,
    "score_fuzz": 0.89,
    "score_detection": 0.71,
    "score_embedding": 0.7048,
    "total_score": 0.7682666666666668,
    "x": 8.24550724029541,
    "y": 6.796697616577148,
    "cluster_id": 36
  },
  {
    "feature_id": 390,
    "explanation_index": 1,
    "text": "Closing punctuation and bracketing symbols, particularly quotation marks, brackets, and braces, are frequently activated when they appear at the end of a sequence, often signaling the end of a quoted or structured text segment.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8628196517626444,
    "similarity_var": 0.0005753519880195135,
    "score_fuzz": 0.83,
    "score_detection": 0.91,
    "score_embedding": 0.5256250000000001,
    "total_score": 0.7552083333333334,
    "x": 9.205085754394531,
    "y": 6.734382629394531,
    "cluster_id": -1
  },
  {
    "feature_id": 390,
    "explanation_index": 2,
    "text": "The markers isolate contiguous groups of tokens that are semantically or syntactically significant\u2014often idiomatic phrases, comparative adjectives, or code\u2011style fragments\u2014whose individual words or punctuation are highlighted by the activation list.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8628196517626444,
    "similarity_var": 0.0005753519880195135,
    "score_fuzz": 0.425,
    "score_detection": 0.275,
    "score_embedding": 0.6287499999999999,
    "total_score": 0.4429166666666666,
    "x": 14.61160659790039,
    "y": 4.930077075958252,
    "cluster_id": -1
  },
  {
    "feature_id": 391,
    "explanation_index": 0,
    "text": "Indentation spaces in code, often used to denote block-level structure.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9243696928024292,
    "similarity_var": 0.0002899105455066812,
    "score_fuzz": 0.78,
    "score_detection": 0.53,
    "score_embedding": 0.5552,
    "total_score": 0.6217333333333334,
    "x": 11.34040641784668,
    "y": 7.778777599334717,
    "cluster_id": 81
  },
  {
    "feature_id": 391,
    "explanation_index": 1,
    "text": "Patterns of whitespace indentation in code, particularly spaces used for structural alignment and code block formatting.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9243696928024292,
    "similarity_var": 0.0002899105455066812,
    "score_fuzz": 0.78,
    "score_detection": 0.55,
    "score_embedding": 0.593125,
    "total_score": 0.6410416666666667,
    "x": 11.364007949829102,
    "y": 7.713703155517578,
    "cluster_id": 81
  },
  {
    "feature_id": 391,
    "explanation_index": 2,
    "text": "The highlighted tokens are sequences of whitespace characters that represent indentation levels in code.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9243696928024292,
    "similarity_var": 0.0002899105455066812,
    "score_fuzz": 0.85,
    "score_detection": 0.6,
    "score_embedding": 0.6487499999999999,
    "total_score": 0.6995833333333333,
    "x": 13.625170707702637,
    "y": 6.425103664398193,
    "cluster_id": 8
  },
  {
    "feature_id": 392,
    "explanation_index": 0,
    "text": "Verbs that convey the idea of discovery, understanding, or making something known, often used in formal or academic contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9244483113288879,
    "similarity_var": 1.1855088539884187e-05,
    "score_fuzz": 0.82,
    "score_detection": 0.75,
    "score_embedding": 0.6488,
    "total_score": 0.7395999999999999,
    "x": 10.35189151763916,
    "y": -1.0554471015930176,
    "cluster_id": -1
  },
  {
    "feature_id": 392,
    "explanation_index": 1,
    "text": "Verbs and nouns related to uncovering, revealing, or understanding hidden information, often in contexts involving discovery, investigation, or insight.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9244483113288879,
    "similarity_var": 1.1855088539884187e-05,
    "score_fuzz": 0.87,
    "score_detection": 0.79,
    "score_embedding": 0.57875,
    "total_score": 0.74625,
    "x": 10.43415355682373,
    "y": -1.1524940729141235,
    "cluster_id": 23
  },
  {
    "feature_id": 392,
    "explanation_index": 2,
    "text": "The highlighted tokens are action words that signal the act of making something known or understood\u2014verbs or nouns such as \u201crevealed,\u201d \u201cunravel,\u201d \u201cdiscover,\u201d \u201celucidate,\u201d \u201cuncover,\u201d \u201cdecode,\u201d etc.\u2014used in contexts of research, investigation, or narrative to indicate that new information is being disclosed or clarified.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9244483113288879,
    "similarity_var": 1.1855088539884187e-05,
    "score_fuzz": 0.875,
    "score_detection": 0.825,
    "score_embedding": 0.63375,
    "total_score": 0.7779166666666667,
    "x": 14.767946243286133,
    "y": 3.966472864151001,
    "cluster_id": -1
  },
  {
    "feature_id": 394,
    "explanation_index": 0,
    "text": "Punctuation and prepositions that connect clauses, phrases, or items in a list, often indicating a transition or a relationship between them.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8473960558573405,
    "similarity_var": 8.693746675289858e-05,
    "score_fuzz": 0.59,
    "score_detection": 0.56,
    "score_embedding": 0.3944,
    "total_score": 0.5148,
    "x": 7.77125358581543,
    "y": 6.329554557800293,
    "cluster_id": -1
  },
  {
    "feature_id": 394,
    "explanation_index": 1,
    "text": "Common syntactic and structural tokens used in mathematical, scientific, and technical writing, particularly around references, equations, and logical connectors.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8473960558573405,
    "similarity_var": 8.693746675289858e-05,
    "score_fuzz": 0.44,
    "score_detection": 0.27,
    "score_embedding": 0.265625,
    "total_score": 0.3252083333333333,
    "x": 10.2520170211792,
    "y": 5.976737976074219,
    "cluster_id": -1
  },
  {
    "feature_id": 394,
    "explanation_index": 2,
    "text": "The model consistently flags short, high\u2011frequency function words that serve as connectors or prepositions within key phrases or clauses.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8473960558573405,
    "similarity_var": 8.693746675289858e-05,
    "score_fuzz": 0.55,
    "score_detection": 0.475,
    "score_embedding": 0.29000000000000004,
    "total_score": 0.4383333333333333,
    "x": 12.933768272399902,
    "y": 3.2625186443328857,
    "cluster_id": 82
  },
  {
    "feature_id": 395,
    "explanation_index": 0,
    "text": "Common conjunctions and prepositions, often used to connect words, phrases, or clauses, and sometimes nouns representing objects or locations.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8178073366483053,
    "similarity_var": 0.00033493083688145795,
    "score_fuzz": 0.64,
    "score_detection": 0.35,
    "score_embedding": 0.8475999999999999,
    "total_score": 0.6125333333333333,
    "x": 12.126604080200195,
    "y": 0.06564512103796005,
    "cluster_id": 9
  },
  {
    "feature_id": 395,
    "explanation_index": 1,
    "text": "Fragments of words or common conjunctions like \\\"and\\\", \\\"end\\\", \\\"ind\\\", \\\"ond\\\", \\\"pandas\\\", \\\"sandy\\\", \\\"landrind\\\", \\\"DN\\\", \\\"ends\\\", \\\"dor\\\", \\\"Nanda\\\", \\\"andra\\\", \\\"candles\\\", \\\"pond\\\", \\\"way\\\", \\\"house\\\", \\\"box\\\", \\\"area\\\", \\\"cund\\\", \\\"indi\\\", \\\"&&\\\", \\\"end\\\", \\\"sandy\\\", \\\"landrind\\\", \\\"DN\\\", \\\"ends\\\", \\\"pandas\\\", \\\"indi\\\", \\\"and\\\", \\\"&&\\\", \\\"end\\\", \\\"candles\\\", \\\"pond\\\", \\\"way\\\", \\\"house\\\", \\\"box\\\", \\\"area\\\", \\\"cund\\\", \\\"indi\\\", \\\"andra\\\", \\\"candles\\\", \\\"pond\\\", \\\"way\\\", \\\"house\\\", \\\"box\\\", \\\"area\\\", \\\"cund\\\", \\\"indi\\\", \\\"andra\\\", \\\"candles\\\", \\\"pond\\\", \\\"way\\\", \\\"house\\\", \\\"box\\\", \\\"area\\\", \\\"cund\\\", \\\"indi\\\", \\\"andra\\\", \\\"candles\\\", \\\"pond\\\", \\\"way\\\", \\\"house\\\", \\\"box\\\", \\\"area\\\", \\\"cund\\\", \\\"indi\\\", \\\"andra\\\", \\\"candles\\\", \\\"pond\\\", \\\"way\\\", \\\"house\\\", \\\"box\\\", \\\"area\\\", \\\"cund\\\", \\\"indi\\\", \\\"andra\\\", \\\"candles\\\", \\\"pond\\\", \\\"way\\\", \\\"house\\\", \\\"box\\\", \\\"area\\\", \\\"cund\\\", \\\"indi\\\", \\\"andra\\\", \\\"candles\\\", \\\"pond\\\", \\\"way\\\", \\\"house\\\", \\\"box\\\", \\\"area\\\", \\\"cund\\\", \\\"indi\\\", \\\"andra\\\", \\\"candles\\\", \\\"pond\\\", \\\"way\\\", \\\"house\\\", \\\"box\\\", \\\"area\\\", \\\"cund\\\", \\\"indi\\\", \\\"andra\\\", \\\"candles\\\", \\\"pond\\\", \\\"way\\\", \\\"house\\\", \\\"box\\\", \\\"area\\\", \\\"cund\\\", \\\"indi\\\", \\\"andra\\\", \\\"candles\\\", \\\"pond\\\", \\\"way\\\", \\\"house\\\", \\\"box\\\", \\\"area\\\", \\\"cund\\\", \\\"indi\\\", \\\"andra\\\", \\\"candles\\\", \\\"pond\\\", \\\"way\\\", \\\"house\\\", \\\"box\\\", \\\"area\\\", \\\"cund\\\", \\\"indi\\\", \\\"andra\\\", \\\"candles\\\", \\\"pond\\\", \\\"way\\\", \\\"house\\\", \\\"box\\\", \\\"area\\\", \\\"cund\\\", \\\"indi\\\", \\\"andra\\\", \\\"candles\\\", \\\"pond\\\", \\\"way\\\", \\\"house\\\", \\\"box\\\", \\\"area\\\", \\\"cund\\\", \\\"indi\\\", \\\"andra\\\", \\\"candles\\\",",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8178073366483053,
    "similarity_var": 0.00033493083688145795,
    "score_fuzz": 0.82,
    "score_detection": 0.5263157894736842,
    "score_embedding": 0.886875,
    "total_score": 0.7443969298245614,
    "x": 11.045511245727539,
    "y": 3.24169659614563,
    "cluster_id": -1
  },
  {
    "feature_id": 395,
    "explanation_index": 2,
    "text": "The highlighted tokens are almost always very short, high\u2011frequency function words or common suffixes that appear in many contexts, often as part of larger words. They serve a structural role rather than conveying specific content, and their repeated appearance across examples indicates a pattern of the model focusing on these ubiquitous linguistic elements.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8178073366483053,
    "similarity_var": 0.00033493083688145795,
    "score_fuzz": 0.725,
    "score_detection": 0.475,
    "score_embedding": 0.790625,
    "total_score": 0.6635416666666667,
    "x": 13.748507499694824,
    "y": 3.7480037212371826,
    "cluster_id": -1
  },
  {
    "feature_id": 396,
    "explanation_index": 0,
    "text": "Verbs or verb phrases indicating movement, transition, or action, often in a physical or spatial sense, and sometimes in a more abstract sense, such as changing state or status.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8855279684066772,
    "similarity_var": 0.0016442061573584965,
    "score_fuzz": 0.7789473684210526,
    "score_detection": 0.46,
    "score_embedding": 0.6136,
    "total_score": 0.6175157894736842,
    "x": 10.91186809539795,
    "y": -0.9654854536056519,
    "cluster_id": -1
  },
  {
    "feature_id": 396,
    "explanation_index": 1,
    "text": "Common verb phrases indicating movement, transition, or completion, often involving directional or positional change.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8855279684066772,
    "similarity_var": 0.0016442061573584965,
    "score_fuzz": 0.75,
    "score_detection": 0.53,
    "score_embedding": 0.47750000000000004,
    "total_score": 0.5858333333333333,
    "x": 11.237420082092285,
    "y": -0.9553472399711609,
    "cluster_id": -1
  },
  {
    "feature_id": 396,
    "explanation_index": 2,
    "text": "The highlighted tokens are consistently verbs or verb\u2011phrases that carry the main action or state of the sentence, often forming a core clause and usually appearing amid quotation marks or punctuation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8855279684066772,
    "similarity_var": 0.0016442061573584965,
    "score_fuzz": 0.675,
    "score_detection": 0.55,
    "score_embedding": 0.51,
    "total_score": 0.5783333333333334,
    "x": 14.630392074584961,
    "y": 3.4058597087860107,
    "cluster_id": -1
  },
  {
    "feature_id": 397,
    "explanation_index": 0,
    "text": "Punctuation marks, often commas or periods, used to separate clauses or sentences, sometimes indicating a pause or a shift in thought.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.899026095867157,
    "similarity_var": 0.00031146524792073177,
    "score_fuzz": 0.86,
    "score_detection": 0.55,
    "score_embedding": 0.22840000000000002,
    "total_score": 0.5461333333333334,
    "x": 8.025172233581543,
    "y": 6.487705707550049,
    "cluster_id": 5
  },
  {
    "feature_id": 397,
    "explanation_index": 1,
    "text": "Commas and punctuation marks frequently appear in proximity to discourse markers, parenthetical expressions, or transitional phrases, often signaling pauses, interruptions, or shifts in thought, particularly in conversational or narrative text.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.899026095867157,
    "similarity_var": 0.00031146524792073177,
    "score_fuzz": 0.86,
    "score_detection": 0.86,
    "score_embedding": 0.21000000000000002,
    "total_score": 0.6433333333333333,
    "x": 8.044449806213379,
    "y": 6.406312942504883,
    "cluster_id": 5
  },
  {
    "feature_id": 397,
    "explanation_index": 2,
    "text": "The highlighted fragments are usually brief function words or punctuation that signal clause boundaries, connect ideas, or introduce quoted material, often appearing at the start or end of a phrase.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.899026095867157,
    "similarity_var": 0.00031146524792073177,
    "score_fuzz": 0.75,
    "score_detection": 0.8,
    "score_embedding": 0.15375,
    "total_score": 0.5679166666666667,
    "x": 15.730688095092773,
    "y": 7.339259147644043,
    "cluster_id": 19
  },
  {
    "feature_id": 398,
    "explanation_index": 0,
    "text": "Technical and scientific terms, often representing specific concepts, objects, or processes, in various fields such as neuroscience, medicine, and physics.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8670950134595236,
    "similarity_var": 0.0013739468378170096,
    "score_fuzz": 0.7,
    "score_detection": 0.49,
    "score_embedding": 0.31679999999999997,
    "total_score": 0.5022666666666666,
    "x": 7.359350204467773,
    "y": 1.1398149728775024,
    "cluster_id": 25
  },
  {
    "feature_id": 398,
    "explanation_index": 1,
    "text": "Fragments of scientific and technical terms, often derived from compound words or abbreviations, where partial tokens (e.g., \\\"substantia\\\", \\\"temporal\\\", \\\"connectivity\\\", \\\"imaging\\\") are activated due to their role in specialized vocabulary, particularly in neuroscience, medicine, and physics.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8670950134595236,
    "similarity_var": 0.0013739468378170096,
    "score_fuzz": 0.7,
    "score_detection": 0.49,
    "score_embedding": 0.23125,
    "total_score": 0.47374999999999995,
    "x": 7.680837154388428,
    "y": 2.640197992324829,
    "cluster_id": -1
  },
  {
    "feature_id": 398,
    "explanation_index": 2,
    "text": "The highlighted fragments are the core lexical units that carry the main semantic content of each sentence\u2014typically nouns, adjectives, or verb stems (sometimes in partial form). Their activation scores reflect how strongly each unit contributes to the overall meaning.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8670950134595236,
    "similarity_var": 0.0013739468378170096,
    "score_fuzz": 0.5,
    "score_detection": 0.475,
    "score_embedding": 0.25875000000000004,
    "total_score": 0.41125000000000006,
    "x": 15.796621322631836,
    "y": 7.375293254852295,
    "cluster_id": 19
  },
  {
    "feature_id": 400,
    "explanation_index": 0,
    "text": "Specialized terms and identifiers in programming languages, often denoting variables, functions, or constants, and sometimes referencing external libraries or frameworks.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9016588926315308,
    "similarity_var": 0.0007383598072365771,
    "score_fuzz": 0.51,
    "score_detection": 0.52,
    "score_embedding": 0.6135999999999999,
    "total_score": 0.5478666666666666,
    "x": 10.410926818847656,
    "y": 8.553885459899902,
    "cluster_id": 80
  },
  {
    "feature_id": 400,
    "explanation_index": 1,
    "text": "Common patterns in code include identifiers with underscores separating words, repeated use of capitalized terms like SHADOW, OpenGL, UnityEngine, and fragment, often in context of graphics programming, shader code, or software development, with frequent activation of tokens related to structure, naming conventions, and technical components.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9016588926315308,
    "similarity_var": 0.0007383598072365771,
    "score_fuzz": 0.47,
    "score_detection": 0.47,
    "score_embedding": 0.41250000000000003,
    "total_score": 0.45083333333333336,
    "x": 10.766901969909668,
    "y": 7.167034149169922,
    "cluster_id": -1
  },
  {
    "feature_id": 400,
    "explanation_index": 2,
    "text": "The highlighted tokens are consistently parts of programming identifiers\u2014often uppercase, underscore\u2011separated names or key graphics/shader terms such as \u201cSHADOW\u201d, \u201cSOFT\u201d, \u201cfragment\u201d, \u201ctexture\u201d, \u201cbuffer\u201d, \u201cvertex\u201d, \u201cOpenGL\u201d, \u201cGLSL\u201d, \u201cUnityEngine\u201d, etc. They appear within code snippets and represent variables, constants, or function names tied to rendering or shader logic.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9016588926315308,
    "similarity_var": 0.0007383598072365771,
    "score_fuzz": 0.375,
    "score_detection": 0.25,
    "score_embedding": 0.38625000000000004,
    "total_score": 0.33708333333333335,
    "x": 13.835225105285645,
    "y": 6.622840881347656,
    "cluster_id": 8
  },
  {
    "feature_id": 402,
    "explanation_index": 0,
    "text": "Verbs or verb phrases that convey the idea of managing, addressing, or resolving a problem, issue, or situation, often in a context of improvement, solution, or progress.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9227678577105204,
    "similarity_var": 0.00019643429071278557,
    "score_fuzz": 0.88,
    "score_detection": 0.74,
    "score_embedding": 0.608,
    "total_score": 0.7426666666666667,
    "x": 10.71336841583252,
    "y": -0.5783675312995911,
    "cluster_id": 85
  },
  {
    "feature_id": 402,
    "explanation_index": 1,
    "text": "Verbs and verb phrases expressing resolution, handling, or addressing a problem, often paired with prepositions like \\\"to,\\\" \\\"of,\\\" \\\"against,\\\" or \\\"out,\\\" and frequently associated with abstract or practical challenges.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9227678577105204,
    "similarity_var": 0.00019643429071278557,
    "score_fuzz": 0.93,
    "score_detection": 0.77,
    "score_embedding": 0.61875,
    "total_score": 0.7729166666666667,
    "x": 11.462607383728027,
    "y": -0.35429683327674866,
    "cluster_id": -1
  },
  {
    "feature_id": 402,
    "explanation_index": 2,
    "text": "The highlighted tokens are action verbs\u2014often in infinitive form\u2014that signal problem\u2011solving or addressing a situation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9227678577105204,
    "similarity_var": 0.00019643429071278557,
    "score_fuzz": 0.825,
    "score_detection": 0.65,
    "score_embedding": 0.371875,
    "total_score": 0.615625,
    "x": 14.544502258300781,
    "y": 3.3249318599700928,
    "cluster_id": -1
  },
  {
    "feature_id": 405,
    "explanation_index": 0,
    "text": "Common nouns representing various objects, places, concepts, and names.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8754228949546814,
    "similarity_var": 0.00029060191929157025,
    "score_fuzz": 0.72,
    "score_detection": 0.36,
    "score_embedding": 0.5632,
    "total_score": 0.5477333333333334,
    "x": 8.423323631286621,
    "y": -0.3828493654727936,
    "cluster_id": -1
  },
  {
    "feature_id": 405,
    "explanation_index": 1,
    "text": "Common nouns or proper nouns forming compound terms, often representing specific places, objects, or concepts, with high activation values when part of established phrases or named entities.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8754228949546814,
    "similarity_var": 0.00029060191929157025,
    "score_fuzz": 0.63,
    "score_detection": 0.2,
    "score_embedding": 0.51,
    "total_score": 0.4466666666666667,
    "x": 8.779095649719238,
    "y": -0.22947846353054047,
    "cluster_id": -1
  },
  {
    "feature_id": 405,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core lexical items that carry semantic content in a phrase, usually nouns or content words, often part of named entities or common nouns, rather than function words.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8754228949546814,
    "similarity_var": 0.00029060191929157025,
    "score_fuzz": 0.925,
    "score_detection": 0.375,
    "score_embedding": 0.65375,
    "total_score": 0.65125,
    "x": 15.18763542175293,
    "y": 4.1838765144348145,
    "cluster_id": 91
  },
  {
    "feature_id": 406,
    "explanation_index": 0,
    "text": "Tokens that are part of a larger sequence or phrase, often including punctuation, and may be related to various concepts such as programming, mathematics, or everyday language.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8821335037549337,
    "similarity_var": 0.00021385333143165834,
    "score_fuzz": 0.46,
    "score_detection": 0.37,
    "score_embedding": 0.612,
    "total_score": 0.48066666666666674,
    "x": 10.773452758789062,
    "y": 5.075771808624268,
    "cluster_id": -1
  },
  {
    "feature_id": 406,
    "explanation_index": 1,
    "text": "Fragments of text containing technical, mathematical, or structured syntax elements, often with embedded identifiers, symbols, or formatting markers, where important tokens are typically short, context-specific, and frequently appear in sequences related to code, equations, citations, or markup.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8821335037549337,
    "similarity_var": 0.00021385333143165834,
    "score_fuzz": 0.58,
    "score_detection": 0.68,
    "score_embedding": 0.695,
    "total_score": 0.6516666666666667,
    "x": 10.110611915588379,
    "y": 6.2943434715271,
    "cluster_id": -1
  },
  {
    "feature_id": 406,
    "explanation_index": 2,
    "text": "The highlighted fragments are contiguous character sequences that belong to larger lexical items\u2014often the final part of a word or a component of a multi\u2011word expression. They can be whole words (e.g., \u201chouse\u201d, \u201cbox\u201d) or partial stems (e.g., \u201cer\u201d from \u201cwider\u201d, \u201cer\u201d from \u201ctaller\u201d). These fragments are extracted for analysis, regardless of whether they form a complete word, a noun phrase, or a compound term.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8821335037549337,
    "similarity_var": 0.00021385333143165834,
    "score_fuzz": 0.5,
    "score_detection": 0.325,
    "score_embedding": 0.6137499999999999,
    "total_score": 0.47958333333333325,
    "x": 15.655168533325195,
    "y": 7.234228610992432,
    "cluster_id": 19
  },
  {
    "feature_id": 407,
    "explanation_index": 0,
    "text": "Punctuation marks and special characters, often used to denote the end of a statement, separate code blocks, or indicate the start of a new line.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9011157751083374,
    "similarity_var": 0.00027417666773269883,
    "score_fuzz": 0.63,
    "score_detection": 0.65,
    "score_embedding": 0.5864,
    "total_score": 0.6221333333333333,
    "x": 8.61828899383545,
    "y": 6.919116020202637,
    "cluster_id": -1
  },
  {
    "feature_id": 407,
    "explanation_index": 1,
    "text": "The presence of special tokens or symbols (like punctuation, delimiters, or structural markers) that often appear in code, markup, or formatted text, frequently associated with syntax, structure, or tokenization boundaries.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9011157751083374,
    "similarity_var": 0.00027417666773269883,
    "score_fuzz": 0.59,
    "score_detection": 0.61,
    "score_embedding": 0.6125,
    "total_score": 0.6041666666666666,
    "x": 10.359519004821777,
    "y": 6.506890296936035,
    "cluster_id": -1
  },
  {
    "feature_id": 407,
    "explanation_index": 2,
    "text": "The highlighted tokens are the syntactic delimiters and key identifiers that define the structure of code fragments\u2014punctuation, braces, semicolons, parentheses, and language keywords or variable names that mark boundaries or essential elements.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9011157751083374,
    "similarity_var": 0.00027417666773269883,
    "score_fuzz": 0.675,
    "score_detection": 0.6,
    "score_embedding": 0.633125,
    "total_score": 0.6360416666666667,
    "x": 13.845564842224121,
    "y": 6.394672870635986,
    "cluster_id": 8
  },
  {
    "feature_id": 408,
    "explanation_index": 0,
    "text": "Prepositions, particularly \\\"from\\\", often used to indicate origin, source, or removal, and sometimes preceding or following a quotation mark, or used in phrases that describe a change or a transition.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8605889280637106,
    "similarity_var": 0.0010038426209327946,
    "score_fuzz": 0.62,
    "score_detection": 0.62,
    "score_embedding": 0.5312,
    "total_score": 0.5903999999999999,
    "x": 12.255127906799316,
    "y": -0.37732458114624023,
    "cluster_id": -1
  },
  {
    "feature_id": 408,
    "explanation_index": 1,
    "text": "The preposition \\\"from\\\" frequently appears in contexts indicating origin, source, or derivation, often preceding a noun or noun phrase that specifies what is being derived or originated.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8605889280637106,
    "similarity_var": 0.0010038426209327946,
    "score_fuzz": 0.66,
    "score_detection": 0.57,
    "score_embedding": 0.51625,
    "total_score": 0.5820833333333333,
    "x": 12.333999633789062,
    "y": -0.4312615990638733,
    "cluster_id": 63
  },
  {
    "feature_id": 408,
    "explanation_index": 2,
    "text": "the pattern might be that the important tokens are often prepositions or articles that are part of common phrases.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8605889280637106,
    "similarity_var": 0.0010038426209327946,
    "score_fuzz": 0.525,
    "score_detection": 0.4,
    "score_embedding": 0.555,
    "total_score": 0.49333333333333335,
    "x": 11.340339660644531,
    "y": 4.464993000030518,
    "cluster_id": 3
  },
  {
    "feature_id": 409,
    "explanation_index": 0,
    "text": "Various programming-related terms and concepts, including variable names, function calls, and keywords, often in the context of web development, authentication, and error handling.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.889009932676951,
    "similarity_var": 0.000319579135389208,
    "score_fuzz": 0.67,
    "score_detection": 0.63,
    "score_embedding": 0.5008,
    "total_score": 0.6002666666666667,
    "x": 10.414981842041016,
    "y": 8.594827651977539,
    "cluster_id": 80
  },
  {
    "feature_id": 409,
    "explanation_index": 1,
    "text": "Common patterns in code include method calls, object properties, and identifiers with specific naming conventions, often involving abbreviations, acronyms, or compound terms, where the most important tokens are typically part of a technical or syntactic structure.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.889009932676951,
    "similarity_var": 0.000319579135389208,
    "score_fuzz": 0.74,
    "score_detection": 0.68,
    "score_embedding": 0.439375,
    "total_score": 0.6197916666666666,
    "x": 10.738787651062012,
    "y": 7.009934425354004,
    "cluster_id": -1
  },
  {
    "feature_id": 409,
    "explanation_index": 2,
    "text": "The highlighted tokens are code identifiers\u2014methods, classes, variables, or API names\u2014that appear in member\u2011access or function\u2011call contexts, often preceded by punctuation such as a dot or arrow, indicating their importance to the code\u2019s behavior.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.889009932676951,
    "similarity_var": 0.000319579135389208,
    "score_fuzz": 0.675,
    "score_detection": 0.625,
    "score_embedding": 0.44625,
    "total_score": 0.5820833333333334,
    "x": 13.764873504638672,
    "y": 6.743675231933594,
    "cluster_id": 8
  },
  {
    "feature_id": 411,
    "explanation_index": 0,
    "text": "Words or phrases that are often function words, or words that are part of a larger phrase or idiom, and sometimes words that are being used to describe or show something.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8169335921605428,
    "similarity_var": 0.0001600998740569379,
    "score_fuzz": 0.56,
    "score_detection": 0.5,
    "score_embedding": 0.5336,
    "total_score": 0.5312,
    "x": 10.577300071716309,
    "y": 0.9978622794151306,
    "cluster_id": -1
  },
  {
    "feature_id": 411,
    "explanation_index": 1,
    "text": "Partial or truncated proper nouns, often names of people, places, or brands, where the activation is concentrated on the latter part of the name or a phonetic fragment, suggesting the model identifies incomplete or partially masked identifiers.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8169335921605428,
    "similarity_var": 0.0001600998740569379,
    "score_fuzz": 0.58,
    "score_detection": 0.34,
    "score_embedding": 0.58,
    "total_score": 0.5,
    "x": 7.293307304382324,
    "y": 2.8058416843414307,
    "cluster_id": 15
  },
  {
    "feature_id": 411,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8169335921605428,
    "similarity_var": 0.0001600998740569379,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.44,
    "total_score": 0.48,
    "x": -5.883564472198486,
    "y": 16.02521324157715,
    "cluster_id": 10
  },
  {
    "feature_id": 412,
    "explanation_index": 0,
    "text": "Code snippets from various programming languages, often containing method calls, variable assignments, and mathematical operations, with a focus on graphical and visual elements.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9052254756291708,
    "similarity_var": 0.0002861581004991207,
    "score_fuzz": 0.47,
    "score_detection": 0.5,
    "score_embedding": 0.542,
    "total_score": 0.504,
    "x": 11.20994758605957,
    "y": 8.729283332824707,
    "cluster_id": 17
  },
  {
    "feature_id": 412,
    "explanation_index": 1,
    "text": "The presence of identifiers, method calls, and syntax elements in programming code, particularly those involving object-oriented or functional constructs, with high activation on tokens that denote structure, access, or operations.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9052254756291708,
    "similarity_var": 0.0002861581004991207,
    "score_fuzz": 0.43,
    "score_detection": 0.44,
    "score_embedding": 0.495625,
    "total_score": 0.4552083333333334,
    "x": 10.66669750213623,
    "y": 7.4150285720825195,
    "cluster_id": 7
  },
  {
    "feature_id": 412,
    "explanation_index": 2,
    "text": "The highlighted tokens are code elements that form syntactic units in programming languages, such as identifiers, operators, punctuation, and literals, often grouped into contiguous sequences that represent function calls, method invocations, or expressions.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9052254756291708,
    "similarity_var": 0.0002861581004991207,
    "score_fuzz": 0.375,
    "score_detection": 0.475,
    "score_embedding": 0.5349999999999999,
    "total_score": 0.4616666666666666,
    "x": 13.931443214416504,
    "y": 6.50828742980957,
    "cluster_id": 8
  },
  {
    "feature_id": 413,
    "explanation_index": 0,
    "text": "Prepositions, particularly \\\"to\\\", \\\"at\\\", and \\\"from\\\", often used in phrases to indicate direction, location, or comparison, and possessive pronouns \\\"its\\\" and \\\"their\\\" used to describe something belonging to a noun or entity.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8969357411066691,
    "similarity_var": 0.0007041078428744957,
    "score_fuzz": 0.82,
    "score_detection": 0.57,
    "score_embedding": 0.29600000000000004,
    "total_score": 0.5619999999999999,
    "x": 12.394986152648926,
    "y": -0.5536349415779114,
    "cluster_id": 63
  },
  {
    "feature_id": 413,
    "explanation_index": 1,
    "text": "The phrases \\\"at its\\\", \\\"to its\\\", and \\\"from its\\\" are frequently used to express a state, extent, or origin related to a possessive or referential entity, often describing a condition, location, or degree.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8969357411066691,
    "similarity_var": 0.0007041078428744957,
    "score_fuzz": 0.73,
    "score_detection": 0.73,
    "score_embedding": 0.5343749999999999,
    "total_score": 0.6647916666666666,
    "x": 12.394522666931152,
    "y": -0.5808435082435608,
    "cluster_id": 63
  },
  {
    "feature_id": 413,
    "explanation_index": 2,
    "text": "The highlighted tokens are short function words\u2014prepositions and possessive pronouns\u2014that act as grammatical glue, linking phrases and indicating relationships such as location, direction, or possession across varied contexts.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8969357411066691,
    "similarity_var": 0.0007041078428744957,
    "score_fuzz": 0.825,
    "score_detection": 0.575,
    "score_embedding": 0.35374999999999995,
    "total_score": 0.5845833333333333,
    "x": 13.78865909576416,
    "y": 3.440422773361206,
    "cluster_id": 35
  },
  {
    "feature_id": 415,
    "explanation_index": 0,
    "text": "Punctuation marks and common function words, often used in formal or technical writing, such as company names, scientific terminology, and citations.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8765721718470255,
    "similarity_var": 0.0002927154308080857,
    "score_fuzz": 0.45,
    "score_detection": 0.45,
    "score_embedding": 0.3556,
    "total_score": 0.41853333333333337,
    "x": 7.850826263427734,
    "y": 6.713206768035889,
    "cluster_id": 32
  },
  {
    "feature_id": 415,
    "explanation_index": 1,
    "text": "Partial word fragments or compound terms often appear in technical or scientific contexts, especially within product names, brand references, or specialized terminology, where parts of words are split across tokens, frequently in conjunction with punctuation or abbreviations.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8765721718470255,
    "similarity_var": 0.0002927154308080857,
    "score_fuzz": 0.51,
    "score_detection": 0.35,
    "score_embedding": 0.295625,
    "total_score": 0.3852083333333334,
    "x": 7.141687393188477,
    "y": 2.797058582305908,
    "cluster_id": 15
  },
  {
    "feature_id": 415,
    "explanation_index": 2,
    "text": "The highlighted tokens are typically short, high\u2011frequency words or punctuation that serve as syntactic boundaries or connectors, or they are brand/product names that anchor a phrase.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8765721718470255,
    "similarity_var": 0.0002927154308080857,
    "score_fuzz": 0.625,
    "score_detection": 0.6,
    "score_embedding": 0.34437500000000004,
    "total_score": 0.5231250000000001,
    "x": 14.059094429016113,
    "y": 4.419801712036133,
    "cluster_id": -1
  },
  {
    "feature_id": 416,
    "explanation_index": 0,
    "text": "Punctuation marks, often used to denote the end of a sentence or to separate items in a list, and sometimes used in conjunction with other symbols or formatting to indicate specific types of content, such as code or citations.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9091261625289917,
    "similarity_var": 0.00019409404021786258,
    "score_fuzz": 0.81,
    "score_detection": 0.52,
    "score_embedding": 0.9087999999999999,
    "total_score": 0.7462666666666666,
    "x": 8.107446670532227,
    "y": 6.75130558013916,
    "cluster_id": 36
  },
  {
    "feature_id": 416,
    "explanation_index": 1,
    "text": "Punctuation and delimiter tokens such as parentheses, brackets, quotation marks, and commas are frequently activated in structured or formatted text, often surrounding or separating syntactic elements like citations, code blocks, or metadata.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9091261625289917,
    "similarity_var": 0.00019409404021786258,
    "score_fuzz": 0.85,
    "score_detection": 0.72,
    "score_embedding": 0.7987500000000001,
    "total_score": 0.7895833333333333,
    "x": 9.309426307678223,
    "y": 6.866775989532471,
    "cluster_id": -1
  },
  {
    "feature_id": 416,
    "explanation_index": 2,
    "text": "The highlighted tokens are mainly punctuation and structural delimiters\u2014commas, periods, parentheses, brackets, braces, quotation marks, and similar symbols\u2014that serve to separate, group, or otherwise delineate clauses, lists, or code fragments in the text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9091261625289917,
    "similarity_var": 0.00019409404021786258,
    "score_fuzz": 0.825,
    "score_detection": 0.6,
    "score_embedding": 0.8200000000000001,
    "total_score": 0.7483333333333334,
    "x": 13.666823387145996,
    "y": 5.71776819229126,
    "cluster_id": -1
  },
  {
    "feature_id": 417,
    "explanation_index": 0,
    "text": "Mathematical expressions, equations, and operations, often involving variables, constants, and arithmetic operators, and sometimes including function definitions, derivatives, and simplifications.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8676055272420248,
    "similarity_var": 0.0010262677584296713,
    "score_fuzz": 0.27,
    "score_detection": 0.38,
    "score_embedding": 0.5044000000000001,
    "total_score": 0.38480000000000003,
    "x": 9.438722610473633,
    "y": 8.5305814743042,
    "cluster_id": 65
  },
  {
    "feature_id": 417,
    "explanation_index": 1,
    "text": "Mathematical operations and symbols, particularly those involving comparison, arithmetic, and symbolic notation, are frequently highlighted in contexts involving algebraic expressions, equations, and formal mathematical reasoning.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8676055272420248,
    "similarity_var": 0.0010262677584296713,
    "score_fuzz": 0.46,
    "score_detection": 0.43,
    "score_embedding": 0.384375,
    "total_score": 0.4247916666666667,
    "x": 9.41459846496582,
    "y": 8.521437644958496,
    "cluster_id": 65
  },
  {
    "feature_id": 417,
    "explanation_index": 2,
    "text": "The highlighted tokens are typically short, high\u2011frequency function words or operators that act as syntactic glue in mathematical or programming expressions, often forming part of multi\u2011word phrases such as \u201cdivided by\u201d, \u201cmultiplying\u201d, \u201cunion all\u201d, \u201cpostfix\u201d, \u201cSuppose\u201d, \u201cClosing\u201d, \u201cMinus\u201d, \u201cPlus sign\u201d, \u201cderivative\u201d, etc. They are not content words but structural elements that convey the core meaning of the phrase.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8676055272420248,
    "similarity_var": 0.0010262677584296713,
    "score_fuzz": 0.7,
    "score_detection": 0.725,
    "score_embedding": 0.19187500000000002,
    "total_score": 0.5389583333333333,
    "x": 14.0073823928833,
    "y": 3.8936305046081543,
    "cluster_id": -1
  },
  {
    "feature_id": 418,
    "explanation_index": 0,
    "text": "Scientific and technical terms, often representing specific concepts, species, or biological processes, typically in the fields of genetics, biology, and medicine.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8916012247403463,
    "similarity_var": 0.00013284036713025042,
    "score_fuzz": 0.66,
    "score_detection": 0.47,
    "score_embedding": 0.354,
    "total_score": 0.49466666666666664,
    "x": 7.312148571014404,
    "y": 1.164646029472351,
    "cluster_id": 25
  },
  {
    "feature_id": 418,
    "explanation_index": 1,
    "text": "Fragments of scientific terminology, particularly genetic, biological, and molecular biology terms, often appear as partial tokens (e.g., \\\"hetero\\\", \\\"zyg\\\", \\\"phenotyp\\\", \\\"genetic\\\") and are frequently associated with comparative, structural, or functional descriptions in academic text.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8916012247403463,
    "similarity_var": 0.00013284036713025042,
    "score_fuzz": 0.64,
    "score_detection": 0.5,
    "score_embedding": 0.34125,
    "total_score": 0.4937500000000001,
    "x": 7.493378639221191,
    "y": 2.6350343227386475,
    "cluster_id": -1
  },
  {
    "feature_id": 418,
    "explanation_index": 2,
    "text": "The highlighted tokens are sub\u2011word fragments that belong to domain\u2011specific biological terminology (e.g., \u201chomo\u201d, \u201chetero\u201d, \u201callele\u201d, \u201cgene\u201d, \u201cgenome\u201d, \u201cwild\u201d, \u201casymmetric\u201d, \u201ccoding\u201d, \u201cphenotyp\u201d), showing that the model focuses on biologically meaningful sub\u2011word units rather than whole words.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8916012247403463,
    "similarity_var": 0.00013284036713025042,
    "score_fuzz": 0.725,
    "score_detection": 0.575,
    "score_embedding": 0.32375000000000004,
    "total_score": 0.5412499999999999,
    "x": 7.9440436363220215,
    "y": 3.0456206798553467,
    "cluster_id": -1
  },
  {
    "feature_id": 419,
    "explanation_index": 0,
    "text": "Technical terms and words related to optics, vision, and microscopy, often describing specific parts or properties of lenses, light, and visual systems.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8177616198857626,
    "similarity_var": 0.0015475537299880987,
    "score_fuzz": 0.64,
    "score_detection": 0.4,
    "score_embedding": 0.39239999999999997,
    "total_score": 0.47746666666666665,
    "x": 7.898007869720459,
    "y": 0.5897359251976013,
    "cluster_id": -1
  },
  {
    "feature_id": 419,
    "explanation_index": 1,
    "text": "Partial word fragments at the end of tokens, often representing scientific or technical terms, with high activation values on suffixes like \\\"er\\\", \\\"al\\\", \\\"ic\\\", \\\"ion\\\", \\\"t\\\", \\\"ref\\\", \\\"opto\\\", \\\"lens\\\", \\\"micro\\\", \\\"crystal\\\", \\\"bire\\\", \\\"focal\\\", \\\"scanning\\\", \\\"phano\\\", \\\"phenomena\\\", \\\"progressive\\\", \\\"spher\\\", \\\"refractive\\\", \\\"contact\\\", \\\"objective\\\", \\\"magnification\\\", \\\"thickness\\\", \\\"catal\\\", \\\"ophthal\\\", \\\"trifoc\\\", \\\"bifoc\\\", \\\"neofluar\\\", \\\"OD\\\", \\\"MLA\\\", \\\"rotatable\\\", \\\"elevate\\\", \\\"by\\\", \\\"with\\\", \\\"and\\\", \\\"in\\\", \\\"of\\\", \\\"to\\\", \\\"for\\\", \\\"on\\\", \\\"at\\\", \\\"from\\\", \\\"up\\\", \\\"down\\\", \\\"left\\\", \\\"right\\\", \\\"center\\\", \\\"central\\\", \\\"anterior\\\", \\\"posterior\\\", \\\"internal\\\", \\\"external\\\", \\\"transmitted\\\", \\\"reflected\\\", \\\"high\\\", \\\"low\\\", \\\"power\\\", \\\"light\\\", \\\"beam\\\", \\\"focus\\\", \\\"point\\\", \\\"channel\\\", \\\"flow\\\", \\\"array\\\", \\\"spiral\\\", \\\"closely\\\", \\\"spaced\\\", \\\"microtubules\\\", \\\"neurofilaments\\\", \\\"axoplasm\\\", \\\"nerve\\\", \\\"fibers\\\", \\\"lacuna\\\", \\\"double\\\", \\\"arrow\\\", \\\"density\\\", \\\"variability\\\", \\\"shape\\\", \\\"laminae\\\", \\\"reveals\\\", \\\"varying\\\", \\\"birefringence\\\", \\\"orientation\\\", \\\"bone\\\", \\\"fiber\\\", \\\"polymer\\\", \\\"liquid\\\", \\\"crystal\\\", \\\"scattering\\\", \\\"boundary\\\", \\\"motion\\\", \\\"artifacts\\\", \\\"residual\\\", \\\"contamination\\\", \\\"minimize\\\", \\\"superpositioning\\\", \\\"difference\\\", \\\"index\\\", \\\"refractive\\\", \\\"independent\\\", \\\"solvent\\\", \\\"slow\\\", \\\"crystallisation\\\", \\\"amount\\\", \\\"water\\\", \\\"coater\\\", \\\"examined\\\", \\\"under\\\", \\\"scanning\\\", \\\"electron\\\", \\\"microscope\\\", \\\"S-2300\\\", \\\"high\\\", \\\"powered\\\", \\\"internal\\\", \\\"source\\\", \\\"illumination\\\", \\\"transmitted\\\", \\\"reflected\\\", \\\"magnification\\\", \\\"provides\\\", \\\"cohesive\\\", \\\"sheath\\\", \\\"irregular\\\", \\\"profile\\\", \\\"large\\\", \\\"contained\\\", \\\"axon\\\",",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8177616198857626,
    "similarity_var": 0.0015475537299880987,
    "score_fuzz": 0.79,
    "score_detection": 0.47,
    "score_embedding": 0.539375,
    "total_score": 0.5997916666666666,
    "x": 7.355095863342285,
    "y": 3.0332958698272705,
    "cluster_id": -1
  },
  {
    "feature_id": 419,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8177616198857626,
    "similarity_var": 0.0015475537299880987,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.47875,
    "total_score": 0.49291666666666667,
    "x": -5.995246887207031,
    "y": 15.913597106933594,
    "cluster_id": 10
  },
  {
    "feature_id": 420,
    "explanation_index": 0,
    "text": "Special characters and common programming syntax elements, such as operators, access modifiers, and data types, often used in code snippets.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8877370754877726,
    "similarity_var": 0.00040167380058243727,
    "score_fuzz": 0.43,
    "score_detection": 0.38,
    "score_embedding": 0.12320000000000002,
    "total_score": 0.31106666666666666,
    "x": 10.035258293151855,
    "y": 7.87830114364624,
    "cluster_id": -1
  },
  {
    "feature_id": 420,
    "explanation_index": 1,
    "text": "The presence of tokens that form technical or syntactic constructs in programming languages, such as identifiers, operators, type names, and structural symbols, often indicating code structure, variable names, or function calls.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8877370754877726,
    "similarity_var": 0.00040167380058243727,
    "score_fuzz": 0.39,
    "score_detection": 0.39,
    "score_embedding": 0.20687499999999998,
    "total_score": 0.3289583333333333,
    "x": 11.00369644165039,
    "y": 6.120058059692383,
    "cluster_id": 18
  },
  {
    "feature_id": 420,
    "explanation_index": 2,
    "text": "The highlighted tokens are the semantically or syntactically significant elements that drive the meaning or behavior of the text, such as idiomatic phrases, comparative adjectives, or code keywords and identifiers.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8877370754877726,
    "similarity_var": 0.00040167380058243727,
    "score_fuzz": 0.425,
    "score_detection": 0.425,
    "score_embedding": 0.21375,
    "total_score": 0.3545833333333333,
    "x": 14.70950698852539,
    "y": 4.288078784942627,
    "cluster_id": -1
  },
  {
    "feature_id": 422,
    "explanation_index": 0,
    "text": "Tokens that are often abbreviations, proper nouns, or words that are part of a title, name, or label, and are typically capitalized or set apart from the rest of the text.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8309218287467957,
    "similarity_var": 0.0038766508794362644,
    "score_fuzz": 0.71,
    "score_detection": 0.58,
    "score_embedding": 0.4396,
    "total_score": 0.5765333333333333,
    "x": 10.149452209472656,
    "y": 4.403732776641846,
    "cluster_id": 1
  },
  {
    "feature_id": 422,
    "explanation_index": 1,
    "text": "Capitalized or proper noun tokens often represent specific entities, locations, organizations, or named concepts, frequently appearing in contexts involving titles, institutions, geographical places, or technical terms.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8309218287467957,
    "similarity_var": 0.0038766508794362644,
    "score_fuzz": 0.63,
    "score_detection": 0.58,
    "score_embedding": 0.36437499999999995,
    "total_score": 0.5247916666666667,
    "x": 10.182394981384277,
    "y": 4.343353271484375,
    "cluster_id": 1
  },
  {
    "feature_id": 422,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8309218287467957,
    "similarity_var": 0.0038766508794362644,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.42874999999999996,
    "total_score": 0.47625,
    "x": -5.891387939453125,
    "y": 16.017417907714844,
    "cluster_id": 10
  },
  {
    "feature_id": 423,
    "explanation_index": 0,
    "text": "Code blocks or snippets, often containing function or method definitions, variable declarations, or control structures, typically in a variety of programming languages.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8662204742431641,
    "similarity_var": 0.00048061278087629944,
    "score_fuzz": 0.56,
    "score_detection": 0.52,
    "score_embedding": 0.7532,
    "total_score": 0.6110666666666668,
    "x": 11.236906051635742,
    "y": 8.542492866516113,
    "cluster_id": -1
  },
  {
    "feature_id": 423,
    "explanation_index": 1,
    "text": "Line breaks and structural tokens in code or markup that separate logical blocks or syntax elements, often preceding or following code constructs, comments, or nested structures.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8662204742431641,
    "similarity_var": 0.00048061278087629944,
    "score_fuzz": 0.67,
    "score_detection": 0.59,
    "score_embedding": 0.691875,
    "total_score": 0.650625,
    "x": 10.369915008544922,
    "y": 6.98864221572876,
    "cluster_id": 86
  },
  {
    "feature_id": 423,
    "explanation_index": 2,
    "text": "The highlighted tokens are mainly syntactic markers that delineate code structure\u2014newlines, braces, parentheses, semicolons, and occasionally language keywords\u2014rather than semantic content.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8662204742431641,
    "similarity_var": 0.00048061278087629944,
    "score_fuzz": 0.525,
    "score_detection": 0.525,
    "score_embedding": 0.7293750000000001,
    "total_score": 0.593125,
    "x": 13.827284812927246,
    "y": 6.404870986938477,
    "cluster_id": 8
  },
  {
    "feature_id": 425,
    "explanation_index": 0,
    "text": "Geographic locations, often cities or towns, and sometimes states or countries, which are typically proper nouns.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8788900574048361,
    "similarity_var": 0.00022348201633882862,
    "score_fuzz": 0.57,
    "score_detection": 0.52,
    "score_embedding": 0.5452,
    "total_score": 0.5450666666666666,
    "x": 7.2645673751831055,
    "y": -1.1138423681259155,
    "cluster_id": -1
  },
  {
    "feature_id": 425,
    "explanation_index": 1,
    "text": "Proper nouns, particularly place names, are frequently activated when they appear in context, often accompanied by common prepositions, punctuation, or abbreviations that signal geographical or locational references.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8788900574048361,
    "similarity_var": 0.00022348201633882862,
    "score_fuzz": 0.6,
    "score_detection": 0.48,
    "score_embedding": 0.4975,
    "total_score": 0.5258333333333334,
    "x": 7.124801158905029,
    "y": -1.1126823425292969,
    "cluster_id": 40
  },
  {
    "feature_id": 425,
    "explanation_index": 2,
    "text": "The highlighted tokens are typically proper nouns or key descriptors that identify places, organizations, or other important entities, often forming part of multi\u2011word expressions; occasionally function words or punctuation that serve as connectors in those expressions are also highlighted.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8788900574048361,
    "similarity_var": 0.00022348201633882862,
    "score_fuzz": 0.55,
    "score_detection": 0.575,
    "score_embedding": 0.46749999999999997,
    "total_score": 0.5308333333333334,
    "x": 14.602420806884766,
    "y": 4.008382320404053,
    "cluster_id": 11
  },
  {
    "feature_id": 426,
    "explanation_index": 0,
    "text": "Pronouns and auxiliary verbs often used in formal or written contexts, typically in a declarative or informative tone.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8222884138425192,
    "similarity_var": 0.0014879880103922322,
    "score_fuzz": 0.64,
    "score_detection": 0.4,
    "score_embedding": 0.6888,
    "total_score": 0.5762666666666667,
    "x": 11.516456604003906,
    "y": 1.0396714210510254,
    "cluster_id": 64
  },
  {
    "feature_id": 426,
    "explanation_index": 1,
    "text": "Pronouns and determiners referring to previously mentioned entities, often used in legal, academic, or narrative texts to maintain coherence and reference continuity.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8222884138425192,
    "similarity_var": 0.0014879880103922322,
    "score_fuzz": 0.62,
    "score_detection": 0.41,
    "score_embedding": 0.41812499999999997,
    "total_score": 0.48270833333333335,
    "x": 11.574592590332031,
    "y": 1.056897759437561,
    "cluster_id": 64
  },
  {
    "feature_id": 426,
    "explanation_index": 2,
    "text": "the patterns.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8222884138425192,
    "similarity_var": 0.0014879880103922322,
    "score_fuzz": 0.6,
    "score_detection": 0.275,
    "score_embedding": 0.6375,
    "total_score": 0.5041666666666667,
    "x": 5.139217853546143,
    "y": 9.968600273132324,
    "cluster_id": 58
  },
  {
    "feature_id": 430,
    "explanation_index": 0,
    "text": "Medical imaging techniques and terms, often related to radiology, used in various medical contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8179511427879333,
    "similarity_var": 0.0060222531014086185,
    "score_fuzz": 0.64,
    "score_detection": 0.54,
    "score_embedding": 0.5048,
    "total_score": 0.5616,
    "x": 7.333745956420898,
    "y": 1.3974100351333618,
    "cluster_id": 25
  },
  {
    "feature_id": 430,
    "explanation_index": 1,
    "text": "Medical imaging modalities and related technical terms, often composed of root words like \\\"radio\\\", \\\"scan\\\", \\\"tomography\\\", \\\"imaging\\\", \\\"fluor\\\", \\\"x-ray\\\", and \\\"cardiac\\\", frequently appear in clinical and radiological contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8179511427879333,
    "similarity_var": 0.0060222531014086185,
    "score_fuzz": 0.68,
    "score_detection": 0.65,
    "score_embedding": 0.610625,
    "total_score": 0.646875,
    "x": 7.387897968292236,
    "y": 1.8802238702774048,
    "cluster_id": -1
  },
  {
    "feature_id": 430,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8179511427879333,
    "similarity_var": 0.0060222531014086185,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.65875,
    "total_score": 0.5529166666666666,
    "x": -5.999575614929199,
    "y": 15.909289360046387,
    "cluster_id": 10
  },
  {
    "feature_id": 431,
    "explanation_index": 0,
    "text": "Various tokens that appear to be part of a programming or coding context, including keywords, symbols, and identifiers, often used in a specific syntax or structure.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8576589028040568,
    "similarity_var": 0.0010051112756938906,
    "score_fuzz": 0.28,
    "score_detection": 0.35,
    "score_embedding": 0.18360000000000004,
    "total_score": 0.27120000000000005,
    "x": 10.89088249206543,
    "y": 6.140817165374756,
    "cluster_id": 18
  },
  {
    "feature_id": 431,
    "explanation_index": 1,
    "text": "Common linguistic patterns involving prepositions, possessives, and compound terms, often appearing in technical or descriptive contexts, with frequent emphasis on spatial, structural, or functional relationships.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8576589028040568,
    "similarity_var": 0.0010051112756938906,
    "score_fuzz": 0.65,
    "score_detection": 0.66,
    "score_embedding": 0.23500000000000004,
    "total_score": 0.515,
    "x": 9.928709030151367,
    "y": 0.40132957696914673,
    "cluster_id": -1
  },
  {
    "feature_id": 431,
    "explanation_index": 2,
    "text": "The highlighted tokens are typically short, single words that serve as code identifiers or common English words embedded in markup or source code.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8576589028040568,
    "similarity_var": 0.0010051112756938906,
    "score_fuzz": 0.375,
    "score_detection": 0.275,
    "score_embedding": 0.125625,
    "total_score": 0.25854166666666667,
    "x": 13.915404319763184,
    "y": 6.087936878204346,
    "cluster_id": -1
  },
  {
    "feature_id": 432,
    "explanation_index": 0,
    "text": "Common nouns, adjectives, and verbs that are often used in formal or technical writing, including words related to sports, science, and law, as well as words that indicate time, place, and quantity.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8406275510787964,
    "similarity_var": 0.0006907737704887987,
    "score_fuzz": 0.76,
    "score_detection": 0.47,
    "score_embedding": 0.6487999999999999,
    "total_score": 0.6262666666666666,
    "x": 8.54139518737793,
    "y": -0.48814260959625244,
    "cluster_id": 79
  },
  {
    "feature_id": 432,
    "explanation_index": 1,
    "text": "Nouns and noun phrases denoting locations, events, or abstract concepts, often appearing in contexts involving categories, measurements, or descriptive attributes.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8406275510787964,
    "similarity_var": 0.0006907737704887987,
    "score_fuzz": 0.55,
    "score_detection": 0.48,
    "score_embedding": 0.6768750000000001,
    "total_score": 0.5689583333333333,
    "x": 8.448663711547852,
    "y": 0.18172277510166168,
    "cluster_id": 24
  },
  {
    "feature_id": 432,
    "explanation_index": 2,
    "text": "The tokens are various words: \\\"statements\\\", \\\"athy\\\", \\\"Es\\\", \\\"patient\\\", \\\"year\\\", \\\"winning\\\", \\\"first\\\", \\\"6\\\", \\\"3\\\", \\\"in\\\", \\\"season\\\", \\\"th\\\", \\\"second\\\", \\\"six\\\", \\\"categories\\\", \\\"aged\\\", \\\"City\\\", \\\"Swansea\\\", \\\"was\\\", \\\"lower\\\", \\\"Bowl\\\", \\\"specimens\\\", \\\"supporting\\\", \\\"\u2019\\\", \\\"season\\\", \\\"them\\\", \\\"everyone\\\", \\\"matches\\\", \\\"race\\\", \\\"activation\\\", \\\"English\\\", \\\"activity\\\", \\\"levels\\\", \\\"reaction\\\", \\\"since\\\", \\\"festival\\\", \\\"and\\\", \\\"Clinton\\\", \\\"added\\\", \\\"fire\\\", \\\"participants\\\", \\\"won\\\", \\\"service\\\", \\\"every\\\", \\\"song\\\", \\\"hit\\\", \\\"Challenges\\\", \\\"also\\\", \\\"proceeded\\\", \\\"fans\\\", \\\"crimes\\\", \\\"employed\\\".",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8406275510787964,
    "similarity_var": 0.0006907737704887987,
    "score_fuzz": 0.55,
    "score_detection": 0.4,
    "score_embedding": 0.49125,
    "total_score": 0.4804166666666667,
    "x": 11.045989036560059,
    "y": 3.358572244644165,
    "cluster_id": 27
  },
  {
    "feature_id": 433,
    "explanation_index": 0,
    "text": "Prepositions indicating location or direction, often used in various languages.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8279479742050171,
    "similarity_var": 0.002270464982987145,
    "score_fuzz": 0.83,
    "score_detection": 0.56,
    "score_embedding": 0.7068,
    "total_score": 0.6989333333333333,
    "x": 12.009943008422852,
    "y": -0.4131721556186676,
    "cluster_id": 39
  },
  {
    "feature_id": 433,
    "explanation_index": 1,
    "text": "Common prepositions and their contracted forms (e.g., \\\"\u043d\u0430\\\", \\\"auf\\\", \\\"on\\\", \\\"sur\\\", \\\"p\u00e5\\\", \\\"ang\\\", \\\"op\\\", \\\"au\\\") frequently appear in context with spatial, temporal, or abstract relationships, often preceding or following key nouns or verbs in phrases involving location, transition, or action.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8279479742050171,
    "similarity_var": 0.002270464982987145,
    "score_fuzz": 0.82,
    "score_detection": 0.71,
    "score_embedding": 0.6425,
    "total_score": 0.7241666666666666,
    "x": 12.396895408630371,
    "y": -0.5636313557624817,
    "cluster_id": 63
  },
  {
    "feature_id": 433,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8279479742050171,
    "similarity_var": 0.002270464982987145,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.5843750000000001,
    "total_score": 0.5281250000000001,
    "x": -5.885819435119629,
    "y": 16.02301597595215,
    "cluster_id": 10
  },
  {
    "feature_id": 434,
    "explanation_index": 0,
    "text": "The linking verb \\\"is\\\" or \\\"was\\\" connecting a subject to a predicate, often used to introduce a reason, explanation, or description.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8859924077987671,
    "similarity_var": 0.0008280205252925535,
    "score_fuzz": 0.97,
    "score_detection": 0.8,
    "score_embedding": 0.6012,
    "total_score": 0.7904,
    "x": 11.454476356506348,
    "y": 2.1381418704986572,
    "cluster_id": -1
  },
  {
    "feature_id": 434,
    "explanation_index": 1,
    "text": "The words \\\"is\\\", \\\"was\\\", or \\\"are\\\" frequently appear in contexts introducing definitions, explanations, or clarifications, often following a noun or clause that sets up a statement of fact or purpose.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8859924077987671,
    "similarity_var": 0.0008280205252925535,
    "score_fuzz": 0.92,
    "score_detection": 0.8,
    "score_embedding": 0.651875,
    "total_score": 0.790625,
    "x": 11.35970401763916,
    "y": 2.2271647453308105,
    "cluster_id": -1
  },
  {
    "feature_id": 434,
    "explanation_index": 2,
    "text": "The highlighted token is a linking verb that connects a subject to its complement.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8859924077987671,
    "similarity_var": 0.0008280205252925535,
    "score_fuzz": 0.95,
    "score_detection": 0.55,
    "score_embedding": 0.691875,
    "total_score": 0.730625,
    "x": 14.372252464294434,
    "y": 3.4344754219055176,
    "cluster_id": -1
  },
  {
    "feature_id": 435,
    "explanation_index": 0,
    "text": "Various words and phrases, often nouns or verbs, that appear to be significant in the context of the surrounding text, including proper nouns, technical terms, and words with specific meanings or connotations.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8207858006159464,
    "similarity_var": 0.0020246800285319308,
    "score_fuzz": 0.55,
    "score_detection": 0.48,
    "score_embedding": 0.3424,
    "total_score": 0.4574666666666667,
    "x": 8.968140602111816,
    "y": -0.0679544135928154,
    "cluster_id": 83
  },
  {
    "feature_id": 435,
    "explanation_index": 1,
    "text": "Fragments of words or proper nouns that are part of compound terms, technical names, or common phrases, often appearing in contexts involving technical, legal, or domain-specific terminology.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8207858006159464,
    "similarity_var": 0.0020246800285319308,
    "score_fuzz": 0.54,
    "score_detection": 0.32,
    "score_embedding": 0.44375000000000003,
    "total_score": 0.4345833333333334,
    "x": 7.035588264465332,
    "y": 2.5427186489105225,
    "cluster_id": 2
  },
  {
    "feature_id": 435,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8207858006159464,
    "similarity_var": 0.0020246800285319308,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.454375,
    "total_score": 0.4847916666666667,
    "x": -5.927722454071045,
    "y": 15.98117733001709,
    "cluster_id": 10
  },
  {
    "feature_id": 437,
    "explanation_index": 0,
    "text": "Names of people, places, and objects, often including surnames, locations, and nouns representing entities, as well as words related to family relationships and professions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8194393118222555,
    "similarity_var": 0.00011732758842539524,
    "score_fuzz": 0.53,
    "score_detection": 0.43,
    "score_embedding": 0.6684,
    "total_score": 0.5428000000000001,
    "x": 7.597794055938721,
    "y": -0.7318377494812012,
    "cluster_id": 16
  },
  {
    "feature_id": 437,
    "explanation_index": 1,
    "text": "Partial word fragments at the end of tokens, often representing proper nouns or compound words, with varying activation levels depending on context and completeness.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8194393118222555,
    "similarity_var": 0.00011732758842539524,
    "score_fuzz": 0.64,
    "score_detection": 0.55,
    "score_embedding": 0.7281250000000001,
    "total_score": 0.639375,
    "x": 7.076570510864258,
    "y": 2.927328109741211,
    "cluster_id": 59
  },
  {
    "feature_id": 437,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8194393118222555,
    "similarity_var": 0.00011732758842539524,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.859375,
    "total_score": 0.6197916666666666,
    "x": -5.941677093505859,
    "y": 15.967172622680664,
    "cluster_id": 10
  },
  {
    "feature_id": 438,
    "explanation_index": 0,
    "text": "Indentation and whitespace characters, often used to denote code blocks, comments, or formatting in programming languages.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8243644634882609,
    "similarity_var": 0.0034139607137299143,
    "score_fuzz": 0.74,
    "score_detection": 0.51,
    "score_embedding": 0.5824,
    "total_score": 0.6108,
    "x": 11.3371000289917,
    "y": 7.705845355987549,
    "cluster_id": 81
  },
  {
    "feature_id": 438,
    "explanation_index": 1,
    "text": "Patterns in code syntax and structure, including indentation, comment markers, and token sequences that reflect programming language constructs and formatting conventions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8243644634882609,
    "similarity_var": 0.0034139607137299143,
    "score_fuzz": 0.55,
    "score_detection": 0.48,
    "score_embedding": 0.7450000000000001,
    "total_score": 0.5916666666666667,
    "x": 10.732407569885254,
    "y": 7.459833145141602,
    "cluster_id": 7
  },
  {
    "feature_id": 438,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8243644634882609,
    "similarity_var": 0.0034139607137299143,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.5025,
    "total_score": 0.5008333333333334,
    "x": -5.9740166664123535,
    "y": 15.934826850891113,
    "cluster_id": 10
  },
  {
    "feature_id": 439,
    "explanation_index": 0,
    "text": "Geographic locations, including states, countries, and regions, often used to specify the origin or location of something or someone.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8968661030133566,
    "similarity_var": 8.105791395330975e-06,
    "score_fuzz": 0.94,
    "score_detection": 0.81,
    "score_embedding": 0.7172,
    "total_score": 0.8224,
    "x": 7.325048923492432,
    "y": -1.1125568151474,
    "cluster_id": -1
  },
  {
    "feature_id": 439,
    "explanation_index": 1,
    "text": "Geographic locations, particularly states, provinces, and regions, are frequently referenced in text, often with high activation values on the proper noun itself and sometimes on associated abbreviations or modifiers.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8968661030133566,
    "similarity_var": 8.105791395330975e-06,
    "score_fuzz": 0.98,
    "score_detection": 0.85,
    "score_embedding": 0.8056249999999999,
    "total_score": 0.8785416666666667,
    "x": 7.210044860839844,
    "y": -1.1743474006652832,
    "cluster_id": 40
  },
  {
    "feature_id": 439,
    "explanation_index": 2,
    "text": "Tokens that are geographic place names\u2014state or city names, often with a preceding space, sometimes followed by a possessive or abbreviation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8968661030133566,
    "similarity_var": 8.105791395330975e-06,
    "score_fuzz": 0.95,
    "score_detection": 0.725,
    "score_embedding": 0.7425,
    "total_score": 0.8058333333333333,
    "x": 10.16522216796875,
    "y": 4.361207485198975,
    "cluster_id": 1
  },
  {
    "feature_id": 440,
    "explanation_index": 0,
    "text": "Prepositions and conjunctions, often used to indicate location, direction, or relationship, as well as adjectives and nouns that describe or modify a place, object, or concept.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8792007366816202,
    "similarity_var": 0.0008875784428007527,
    "score_fuzz": 0.6,
    "score_detection": 0.5,
    "score_embedding": 0.39239999999999997,
    "total_score": 0.49746666666666667,
    "x": 12.105305671691895,
    "y": -0.06509245187044144,
    "cluster_id": 9
  },
  {
    "feature_id": 440,
    "explanation_index": 1,
    "text": "Prepositions and related words (such as \\\"at\\\", \\\"in\\\", \\\"on\\\", \\\"of\\\", \\\"to\\\", \\\"from\\\", \\\"into\\\", \\\"within\\\", \\\"for\\\", \\\"via\\\", \\\"and\\\", \\\",\\\") frequently appear in context with spatial, directional, or relational descriptions, often linking locations, actions, or entities in a structured way.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8792007366816202,
    "similarity_var": 0.0008875784428007527,
    "score_fuzz": 0.57,
    "score_detection": 0.48,
    "score_embedding": 0.38625,
    "total_score": 0.47874999999999995,
    "x": 12.364175796508789,
    "y": -0.5450147390365601,
    "cluster_id": 63
  },
  {
    "feature_id": 440,
    "explanation_index": 2,
    "text": "The highlighted segments are typically function words or morphological endings that serve as connectors or modifiers within larger idiomatic, comparative, or container\u2011type expressions.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8792007366816202,
    "similarity_var": 0.0008875784428007527,
    "score_fuzz": 0.625,
    "score_detection": 0.375,
    "score_embedding": 0.283125,
    "total_score": 0.42770833333333336,
    "x": 15.506047248840332,
    "y": 6.892619609832764,
    "cluster_id": -1
  },
  {
    "feature_id": 441,
    "explanation_index": 0,
    "text": "Commas used for punctuation in various contexts, including separating items in lists, setting off nonessential clauses, and indicating pauses in sentences.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9212760329246521,
    "similarity_var": 0.00044472543852928464,
    "score_fuzz": 0.92,
    "score_detection": 0.78,
    "score_embedding": 0.5724,
    "total_score": 0.7574666666666667,
    "x": 8.017239570617676,
    "y": 6.4529242515563965,
    "cluster_id": 5
  },
  {
    "feature_id": 441,
    "explanation_index": 1,
    "text": "The comma (\\\",\\\") is frequently used to separate items in a list, introduce clauses, or mark pauses in complex sentences, often appearing in sequences of related elements or after introductory phrases.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9212760329246521,
    "similarity_var": 0.00044472543852928464,
    "score_fuzz": 0.98,
    "score_detection": 0.79,
    "score_embedding": 0.45812499999999995,
    "total_score": 0.7427083333333333,
    "x": 8.027366638183594,
    "y": 6.415149688720703,
    "cluster_id": 5
  },
  {
    "feature_id": 441,
    "explanation_index": 2,
    "text": "The recurring important token is the comma, a punctuation mark that separates clauses, items, or phrases within a sentence.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9212760329246521,
    "similarity_var": 0.00044472543852928464,
    "score_fuzz": 1.0,
    "score_detection": 0.875,
    "score_embedding": 0.34687500000000004,
    "total_score": 0.740625,
    "x": 11.340853691101074,
    "y": 4.696455955505371,
    "cluster_id": 78
  },
  {
    "feature_id": 442,
    "explanation_index": 0,
    "text": "Punctuation marks, often used to denote quotation, separation, or emphasis, and sometimes preceding or following proper nouns, titles, or specific phrases.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8678483168284098,
    "similarity_var": 0.0003592569102990082,
    "score_fuzz": 0.66,
    "score_detection": 0.53,
    "score_embedding": 0.45879999999999993,
    "total_score": 0.5496,
    "x": 8.140497207641602,
    "y": 6.7410759925842285,
    "cluster_id": 36
  },
  {
    "feature_id": 442,
    "explanation_index": 1,
    "text": "Frequent use of quotation marks, punctuation, and special characters surrounding text, often indicating dialogue, titles, or formatting in structured or coded text.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8678483168284098,
    "similarity_var": 0.0003592569102990082,
    "score_fuzz": 0.6,
    "score_detection": 0.56,
    "score_embedding": 0.33625000000000005,
    "total_score": 0.4987500000000001,
    "x": 8.478178024291992,
    "y": 6.760495185852051,
    "cluster_id": -1
  },
  {
    "feature_id": 442,
    "explanation_index": 2,
    "text": "The highlighted tokens are the most semantically salient words in a phrase\u2014typically nouns, adjectives, or named\u2011entity components\u2014and often include punctuation that marks a boundary or a syntactic break.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8678483168284098,
    "similarity_var": 0.0003592569102990082,
    "score_fuzz": 0.525,
    "score_detection": 0.45,
    "score_embedding": 0.32,
    "total_score": 0.4316666666666667,
    "x": 15.057700157165527,
    "y": 4.214505672454834,
    "cluster_id": -1
  },
  {
    "feature_id": 443,
    "explanation_index": 0,
    "text": "Punctuation marks, particularly periods and commas, often used to end sentences or separate items in lists, and sometimes category labels.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.884763220945994,
    "similarity_var": 0.000144816579209185,
    "score_fuzz": 0.81,
    "score_detection": 0.46,
    "score_embedding": 0.4956,
    "total_score": 0.5885333333333334,
    "x": 8.002888679504395,
    "y": 6.640566825866699,
    "cluster_id": -1
  },
  {
    "feature_id": 443,
    "explanation_index": 1,
    "text": "Terminal punctuation marks (like periods and commas) and adjacent content often signal the end of a descriptive clause or list, particularly in travel or review-style text, with high activation on closing punctuation and surrounding words.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.884763220945994,
    "similarity_var": 0.000144816579209185,
    "score_fuzz": 0.78,
    "score_detection": 0.48,
    "score_embedding": 0.36875,
    "total_score": 0.5429166666666667,
    "x": 8.006429672241211,
    "y": 6.638810157775879,
    "cluster_id": -1
  },
  {
    "feature_id": 443,
    "explanation_index": 2,
    "text": "The highlighted tokens are mainly punctuation marks and very common stop\u2011words (e.g., \u201c.\u201d, \u201c,\u201d, \u201cand\u201d, \u201cthe\u201d, \u201cCategory\u201d) that act as structural glue in the text, marking phrase or sentence boundaries and linking clauses.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.884763220945994,
    "similarity_var": 0.000144816579209185,
    "score_fuzz": 0.675,
    "score_detection": 0.45,
    "score_embedding": 0.52,
    "total_score": 0.5483333333333333,
    "x": 13.916667938232422,
    "y": 5.1151442527771,
    "cluster_id": -1
  },
  {
    "feature_id": 445,
    "explanation_index": 0,
    "text": "Adjectives describing various qualities, characteristics, or states, often with a neutral or evaluative tone.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8559423883756002,
    "similarity_var": 0.004384372157683774,
    "score_fuzz": 0.92,
    "score_detection": 0.52,
    "score_embedding": 0.5439999999999999,
    "total_score": 0.6613333333333333,
    "x": 8.957537651062012,
    "y": 1.230114221572876,
    "cluster_id": 45
  },
  {
    "feature_id": 445,
    "explanation_index": 1,
    "text": "Adjectives and adjectival forms describing qualities, states, or conditions, often used to evaluate or characterize entities, processes, or experiences.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8559423883756002,
    "similarity_var": 0.004384372157683774,
    "score_fuzz": 0.89,
    "score_detection": 0.49,
    "score_embedding": 0.45562499999999995,
    "total_score": 0.611875,
    "x": 8.900540351867676,
    "y": 1.1399309635162354,
    "cluster_id": 45
  },
  {
    "feature_id": 445,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8559423883756002,
    "similarity_var": 0.004384372157683774,
    "score_fuzz": 0.6,
    "score_detection": 0.45,
    "score_embedding": 0.39312500000000006,
    "total_score": 0.48104166666666676,
    "x": -5.9078264236450195,
    "y": 16.001115798950195,
    "cluster_id": 10
  },
  {
    "feature_id": 446,
    "explanation_index": 0,
    "text": "Definite articles, possessive forms, and prepositions often precede nouns, and sometimes appear in phrases indicating permission, accompaniment, or association.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8755991657574972,
    "similarity_var": 0.0003831656530345463,
    "score_fuzz": 0.8,
    "score_detection": 0.65,
    "score_embedding": 0.4232,
    "total_score": 0.6244000000000001,
    "x": 12.920985221862793,
    "y": 0.40241020917892456,
    "cluster_id": -1
  },
  {
    "feature_id": 446,
    "explanation_index": 1,
    "text": "Prepositional phrases involving \\\"with,\\\" \\\"without,\\\" \\\"the,\\\" and possessive markers like \\\"s\\\" are frequently activated when describing conditions, permissions, or relationships involving entities, actions, or dependencies.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8755991657574972,
    "similarity_var": 0.0003831656530345463,
    "score_fuzz": 0.82,
    "score_detection": 0.77,
    "score_embedding": 0.399375,
    "total_score": 0.663125,
    "x": 12.401981353759766,
    "y": -0.5316994190216064,
    "cluster_id": 63
  },
  {
    "feature_id": 446,
    "explanation_index": 2,
    "text": "The highlighted tokens are predominantly short, high\u2011frequency function words or morphological markers\u2014such as determiners, prepositions, possessives, comparative suffixes, and abbreviations\u2014that carry essential grammatical information and shape the meaning of the surrounding text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8755991657574972,
    "similarity_var": 0.0003831656530345463,
    "score_fuzz": 0.75,
    "score_detection": 0.55,
    "score_embedding": 0.216875,
    "total_score": 0.505625,
    "x": 13.70159912109375,
    "y": 3.508192539215088,
    "cluster_id": 35
  },
  {
    "feature_id": 447,
    "explanation_index": 0,
    "text": "Mathematical expressions and equations, often involving derivatives, integrals, and fractions, typically in the context of physics or engineering.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8262569705645243,
    "similarity_var": 0.004166369853695389,
    "score_fuzz": 0.9,
    "score_detection": 0.93,
    "score_embedding": 0.972,
    "total_score": 0.934,
    "x": 9.459673881530762,
    "y": 8.531609535217285,
    "cluster_id": 65
  },
  {
    "feature_id": 447,
    "explanation_index": 1,
    "text": "Mathematical expressions involving partial derivatives, fractions, and symbolic notation, often with contextual markers like \\\"frac\\\", \\\"partial\\\", and parentheses, indicating formal mathematical syntax.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8262569705645243,
    "similarity_var": 0.004166369853695389,
    "score_fuzz": 0.92,
    "score_detection": 0.91,
    "score_embedding": 0.98125,
    "total_score": 0.9370833333333334,
    "x": 9.444318771362305,
    "y": 8.413939476013184,
    "cluster_id": 65
  },
  {
    "feature_id": 447,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8262569705645243,
    "similarity_var": 0.004166369853695389,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.6368750000000001,
    "total_score": 0.545625,
    "x": -7.887650012969971,
    "y": 9.172566413879395,
    "cluster_id": 52
  },
  {
    "feature_id": 448,
    "explanation_index": 0,
    "text": "Indentation and line breaks often precede a function or method definition, conditional statement, or a switch case statement, and sometimes follow a function or method call.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9005147218704224,
    "similarity_var": 0.00023756092685545127,
    "score_fuzz": 0.62,
    "score_detection": 0.54,
    "score_embedding": 0.45599999999999996,
    "total_score": 0.5386666666666667,
    "x": 11.243219375610352,
    "y": 7.624711036682129,
    "cluster_id": -1
  },
  {
    "feature_id": 448,
    "explanation_index": 1,
    "text": "Patterns of code structure and syntax, particularly around line breaks, indentation, and token placement in programming language constructs such as conditionals, loops, function definitions, and control flow.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9005147218704224,
    "similarity_var": 0.00023756092685545127,
    "score_fuzz": 0.6,
    "score_detection": 0.45,
    "score_embedding": 0.5062500000000001,
    "total_score": 0.51875,
    "x": 10.786783218383789,
    "y": 7.666032791137695,
    "cluster_id": -1
  },
  {
    "feature_id": 448,
    "explanation_index": 2,
    "text": "The highlighted portions are syntactically significant code fragments\u2014often whole lines or blocks\u2014that include structural elements like indentation, line breaks, and control\u2011flow or definition tokens.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9005147218704224,
    "similarity_var": 0.00023756092685545127,
    "score_fuzz": 0.55,
    "score_detection": 0.45,
    "score_embedding": 0.490625,
    "total_score": 0.496875,
    "x": 14.717447280883789,
    "y": 6.994909286499023,
    "cluster_id": -1
  },
  {
    "feature_id": 449,
    "explanation_index": 0,
    "text": "Verbs or nouns expressing necessity, desire, or importance, often in the context of human needs, wants, or obligations.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8645570278167725,
    "similarity_var": 0.0025506863792159606,
    "score_fuzz": 0.87,
    "score_detection": 0.7,
    "score_embedding": 0.7303999999999999,
    "total_score": 0.7667999999999999,
    "x": 10.719828605651855,
    "y": -0.27628836035728455,
    "cluster_id": -1
  },
  {
    "feature_id": 449,
    "explanation_index": 1,
    "text": "The word \\\"need\\\" and its variants (e.g., \\\"needed\\\", \\\"want\\\", \\\"must\\\", \\\"should\\\") frequently appear in contexts expressing necessity, desire, or obligation, often preceding or following key actions or conditions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8645570278167725,
    "similarity_var": 0.0025506863792159606,
    "score_fuzz": 0.78,
    "score_detection": 0.72,
    "score_embedding": 0.8043750000000001,
    "total_score": 0.7681250000000001,
    "x": 10.845748901367188,
    "y": 0.09354650974273682,
    "cluster_id": -1
  },
  {
    "feature_id": 449,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core content words that carry the main semantic load of each sentence\u2014typically nouns, verbs, or adjectives that serve as the key subject, object, or predicate. They are the words the model deems most important for understanding or generating the sentence, and they are not ordinary function words.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8645570278167725,
    "similarity_var": 0.0025506863792159606,
    "score_fuzz": 0.675,
    "score_detection": 0.45,
    "score_embedding": 0.52875,
    "total_score": 0.55125,
    "x": 15.354949951171875,
    "y": 4.105257034301758,
    "cluster_id": 22
  },
  {
    "feature_id": 450,
    "explanation_index": 0,
    "text": "Names of people, often surnames, and sometimes words related to medical or scientific terms.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8203182419141134,
    "similarity_var": 0.001033670809707448,
    "score_fuzz": 0.69,
    "score_detection": 0.73,
    "score_embedding": 0.5983999999999999,
    "total_score": 0.6728,
    "x": 7.301656246185303,
    "y": -0.6396140456199646,
    "cluster_id": -1
  },
  {
    "feature_id": 450,
    "explanation_index": 1,
    "text": "Named entities, particularly proper nouns like personal names and technical terms, are often activated in context, with attention focusing on the full or partial form of the name, especially when it appears in a sequence or near punctuation.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8203182419141134,
    "similarity_var": 0.001033670809707448,
    "score_fuzz": 0.59,
    "score_detection": 0.33,
    "score_embedding": 0.514375,
    "total_score": 0.47812499999999997,
    "x": 6.846012592315674,
    "y": -0.8718573451042175,
    "cluster_id": 84
  },
  {
    "feature_id": 450,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8203182419141134,
    "similarity_var": 0.001033670809707448,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.605,
    "total_score": 0.535,
    "x": -7.924350261688232,
    "y": 9.13586711883545,
    "cluster_id": 52
  },
  {
    "feature_id": 451,
    "explanation_index": 0,
    "text": "Abbreviations, names of diseases, medical conditions, treatments, and organizations, often in the context of scientific or medical research.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8870614369710287,
    "similarity_var": 2.5785101855370205e-05,
    "score_fuzz": 0.69,
    "score_detection": 0.48,
    "score_embedding": 0.3648,
    "total_score": 0.5115999999999999,
    "x": 7.3549628257751465,
    "y": 1.3877930641174316,
    "cluster_id": 25
  },
  {
    "feature_id": 451,
    "explanation_index": 1,
    "text": "Partial or truncated proper nouns, acronyms, or medical terms often appear in scientific text with internal tokenization, where the model activates on fragments of compound terms, especially at the boundaries of abbreviations, gene names, disease names, or journal references.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8870614369710287,
    "similarity_var": 2.5785101855370205e-05,
    "score_fuzz": 0.7,
    "score_detection": 0.56,
    "score_embedding": 0.32125000000000004,
    "total_score": 0.5270833333333333,
    "x": 7.583308696746826,
    "y": 2.7669291496276855,
    "cluster_id": -1
  },
  {
    "feature_id": 451,
    "explanation_index": 2,
    "text": "The highlighted tokens are domain\u2011specific named entities\u2014medical terms, drug names, disease names, and abbreviations\u2014often multi\u2011word phrases or capitalized abbreviations that the model treats as key features.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8870614369710287,
    "similarity_var": 2.5785101855370205e-05,
    "score_fuzz": 0.575,
    "score_detection": 0.425,
    "score_embedding": 0.424375,
    "total_score": 0.47479166666666667,
    "x": 13.721258163452148,
    "y": 4.473050117492676,
    "cluster_id": -1
  },
  {
    "feature_id": 452,
    "explanation_index": 0,
    "text": "Numerical digits embedded within text, often used to represent quantities, measurements, or codes.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8883878389994303,
    "similarity_var": 0.00030335120100804456,
    "score_fuzz": 1.0,
    "score_detection": 0.88,
    "score_embedding": 0.45840000000000003,
    "total_score": 0.7794666666666666,
    "x": 6.97623348236084,
    "y": 8.76911449432373,
    "cluster_id": 29
  },
  {
    "feature_id": 452,
    "explanation_index": 1,
    "text": "The digit \\\"6\\\" appears frequently in numerical contexts, often as part of multi-digit numbers, dates, or measurements, and is sometimes associated with specific formatting patterns like decimals or ranges. Other digits like \\\"2\\\", \\\"8\\\", and \\\"0\\\" also appear in similar numerical contexts, but \\\"6\\\" stands out as a recurring activation point in various numeric sequences.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8883878389994303,
    "similarity_var": 0.00030335120100804456,
    "score_fuzz": 0.84,
    "score_detection": 0.83,
    "score_embedding": 0.46124999999999994,
    "total_score": 0.7104166666666666,
    "x": 7.488548278808594,
    "y": 8.443511962890625,
    "cluster_id": 29
  },
  {
    "feature_id": 452,
    "explanation_index": 2,
    "text": "The highlighted tokens are numeric digits that appear within numeric values in the text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8883878389994303,
    "similarity_var": 0.00030335120100804456,
    "score_fuzz": 0.975,
    "score_detection": 0.8,
    "score_embedding": 0.286875,
    "total_score": 0.6872916666666665,
    "x": 13.201176643371582,
    "y": 5.916408061981201,
    "cluster_id": 30
  },
  {
    "feature_id": 453,
    "explanation_index": 0,
    "text": "Possessive pronouns and possessive forms of nouns, often used to indicate ownership or association.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9225174983342489,
    "similarity_var": 4.1415941922985494e-05,
    "score_fuzz": 0.93,
    "score_detection": 0.64,
    "score_embedding": 0.6576,
    "total_score": 0.7425333333333333,
    "x": 12.046159744262695,
    "y": 1.1099934577941895,
    "cluster_id": 28
  },
  {
    "feature_id": 453,
    "explanation_index": 1,
    "text": "Possessive pronouns (his, her, their, your, our, my) frequently appear in contexts involving personal attribution, ownership, or reference to individuals' actions, thoughts, or possessions, often preceding or following descriptive clauses or narrative details.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9225174983342489,
    "similarity_var": 4.1415941922985494e-05,
    "score_fuzz": 0.96,
    "score_detection": 0.78,
    "score_embedding": 0.711875,
    "total_score": 0.8172916666666667,
    "x": 12.063573837280273,
    "y": 1.1146327257156372,
    "cluster_id": 28
  },
  {
    "feature_id": 453,
    "explanation_index": 2,
    "text": "The highlighted tokens are possessive pronouns indicating ownership or relationship, often preceded by a space.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9225174983342489,
    "similarity_var": 4.1415941922985494e-05,
    "score_fuzz": 0.975,
    "score_detection": 0.5,
    "score_embedding": 0.638125,
    "total_score": 0.7043750000000001,
    "x": 13.93062686920166,
    "y": 3.845271110534668,
    "cluster_id": -1
  },
  {
    "feature_id": 454,
    "explanation_index": 0,
    "text": "Verbs or nouns related to exerting influence, control, or pressure, often in a strong or forceful manner.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8457714716593424,
    "similarity_var": 0.002041990639659572,
    "score_fuzz": 0.82,
    "score_detection": 0.7,
    "score_embedding": 0.5724,
    "total_score": 0.6974666666666667,
    "x": 10.71267032623291,
    "y": -0.8108529448509216,
    "cluster_id": 14
  },
  {
    "feature_id": 454,
    "explanation_index": 1,
    "text": "The word \\\"force\\\" and its variants (e.g., forced, forces, enforcing) are frequently activated in contexts involving physical or abstract influence, control, or pressure, often in technical, legal, or scientific domains.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8457714716593424,
    "similarity_var": 0.002041990639659572,
    "score_fuzz": 0.75,
    "score_detection": 0.74,
    "score_embedding": 0.489375,
    "total_score": 0.6597916666666667,
    "x": 9.42780876159668,
    "y": 0.9549404978752136,
    "cluster_id": -1
  },
  {
    "feature_id": 454,
    "explanation_index": 2,
    "text": "The highlighted tokens are content words\u2014nouns, adjectives, or verbs\u2014that carry semantic weight and are not function words, serving as key terms that convey the main idea of the text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8457714716593424,
    "similarity_var": 0.002041990639659572,
    "score_fuzz": 0.6,
    "score_detection": 0.35,
    "score_embedding": 0.325625,
    "total_score": 0.42520833333333335,
    "x": 15.359012603759766,
    "y": 3.999027967453003,
    "cluster_id": 22
  },
  {
    "feature_id": 455,
    "explanation_index": 0,
    "text": "Punctuation marks and special characters, often used to denote separation, continuation, or formatting in text, such as semicolons, commas, colons, parentheses, and slashes.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.836064875125885,
    "similarity_var": 0.005416202338397606,
    "score_fuzz": 0.74,
    "score_detection": 0.52,
    "score_embedding": 0.39120000000000005,
    "total_score": 0.5504,
    "x": 8.434581756591797,
    "y": 6.996040344238281,
    "cluster_id": 37
  },
  {
    "feature_id": 455,
    "explanation_index": 1,
    "text": "Punctuation and special symbols such as commas, semicolons, parentheses, and slashes are frequently activated when marking syntactic boundaries, formatting, or separating elements in structured text.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.836064875125885,
    "similarity_var": 0.005416202338397606,
    "score_fuzz": 0.7578947368421053,
    "score_detection": 0.55,
    "score_embedding": 0.3225,
    "total_score": 0.5434649122807017,
    "x": 9.169093132019043,
    "y": 6.842392444610596,
    "cluster_id": -1
  },
  {
    "feature_id": 455,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.836064875125885,
    "similarity_var": 0.005416202338397606,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.36249999999999993,
    "total_score": 0.4541666666666666,
    "x": -7.922080039978027,
    "y": 9.138141632080078,
    "cluster_id": 52
  },
  {
    "feature_id": 456,
    "explanation_index": 0,
    "text": "Nouns, adjectives, and adverbs often function as important tokens, typically representing objects, concepts, or ideas, and are frequently used to convey specific information or context.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8064458171526591,
    "similarity_var": 0.000869447073458534,
    "score_fuzz": 0.59,
    "score_detection": 0.42,
    "score_embedding": 0.7512000000000001,
    "total_score": 0.5870666666666667,
    "x": 10.650225639343262,
    "y": 4.473715305328369,
    "cluster_id": 47
  },
  {
    "feature_id": 456,
    "explanation_index": 1,
    "text": "Common multi-word phrases or compound nouns that function as specific locations, entities, or technical terms, often appearing in contextually precise or named references.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8064458171526591,
    "similarity_var": 0.000869447073458534,
    "score_fuzz": 0.54,
    "score_detection": 0.4,
    "score_embedding": 0.635,
    "total_score": 0.525,
    "x": 8.989343643188477,
    "y": -0.05293237417936325,
    "cluster_id": 83
  },
  {
    "feature_id": 456,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8064458171526591,
    "similarity_var": 0.000869447073458534,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.5862499999999999,
    "total_score": 0.5287499999999999,
    "x": -7.893251419067383,
    "y": 9.167407989501953,
    "cluster_id": 52
  },
  {
    "feature_id": 457,
    "explanation_index": 0,
    "text": "Numerical digits embedded within text, often as part of a larger numerical value or identifier.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8999963998794556,
    "similarity_var": 8.044693501811177e-05,
    "score_fuzz": 0.68,
    "score_detection": 0.44,
    "score_embedding": 0.5764,
    "total_score": 0.5654666666666667,
    "x": 6.996264934539795,
    "y": 8.732112884521484,
    "cluster_id": 29
  },
  {
    "feature_id": 457,
    "explanation_index": 1,
    "text": "Individual digits in numerical sequences, particularly those forming part of dates, measurements, or identifiers, with higher activation values when they appear in contextually significant positions such as years, decimal points, or large numbers.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8999963998794556,
    "similarity_var": 8.044693501811177e-05,
    "score_fuzz": 0.77,
    "score_detection": 0.43,
    "score_embedding": 0.8325,
    "total_score": 0.6774999999999999,
    "x": 7.317330360412598,
    "y": 8.585325241088867,
    "cluster_id": 29
  },
  {
    "feature_id": 457,
    "explanation_index": 2,
    "text": "The highlighted tokens are single characters that belong to numeric literals or short alphanumeric identifiers, typically digits within numbers or short codes.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8999963998794556,
    "similarity_var": 8.044693501811177e-05,
    "score_fuzz": 0.675,
    "score_detection": 0.425,
    "score_embedding": 0.819375,
    "total_score": 0.6397916666666666,
    "x": 13.278314590454102,
    "y": 5.949501037597656,
    "cluster_id": 30
  },
  {
    "feature_id": 458,
    "explanation_index": 0,
    "text": "Verbs or verb phrases that convey the idea of fulfilling or satisfying a requirement, need, or expectation, often in a context of provision, accommodation, or customization.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8966139356295267,
    "similarity_var": 4.874059578775637e-05,
    "score_fuzz": 0.75,
    "score_detection": 0.66,
    "score_embedding": 0.6436,
    "total_score": 0.6845333333333334,
    "x": 10.689457893371582,
    "y": -0.4827980697154999,
    "cluster_id": 85
  },
  {
    "feature_id": 458,
    "explanation_index": 1,
    "text": "Common patterns include the use of comparative or functional verbs like \\\"meet\\\" and \\\"accommodate\\\" followed by possessive or abstract nouns such as \\\"needs,\\\" \\\"preferences,\\\" or \\\"requirements,\\\" often in contexts of service, design, or personalization. Additionally, partial word activations (e.g., \\\"er\\\", \\\"s\\\", \\\"rol\\\", \\\"ge\\\") suggest that models attend to morphological and lexical fragments, particularly in compound or technical terms. The frequent presence of \\\"your\\\" and possessive markers indicates a focus on personalized or user-centered language.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8966139356295267,
    "similarity_var": 4.874059578775637e-05,
    "score_fuzz": 0.7368421052631579,
    "score_detection": 0.7473684210526316,
    "score_embedding": 0.535625,
    "total_score": 0.6732785087719299,
    "x": 11.21500015258789,
    "y": 1.1141105890274048,
    "cluster_id": -1
  },
  {
    "feature_id": 458,
    "explanation_index": 2,
    "text": "The highlighted words are the core lexical items of common collocations that express actions or states\u2014verbs such as \u201cmeet,\u201d nouns like \u201cneeds\u201d or \u201caccommodate,\u201d and comparative adjectives\u2014often forming idiomatic or functional phrases.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8966139356295267,
    "similarity_var": 4.874059578775637e-05,
    "score_fuzz": 0.775,
    "score_detection": 0.775,
    "score_embedding": 0.59125,
    "total_score": 0.7137500000000001,
    "x": 16.702739715576172,
    "y": 3.6157517433166504,
    "cluster_id": 20
  },
  {
    "feature_id": 459,
    "explanation_index": 0,
    "text": "Various symbols, punctuation, and short words or phrases that serve as delimiters, operators, or conjunctions in different contexts, including programming, mathematics, and formal writing.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8544972737630209,
    "similarity_var": 0.0002561849618377071,
    "score_fuzz": 0.39,
    "score_detection": 0.34,
    "score_embedding": 0.6504000000000001,
    "total_score": 0.46013333333333334,
    "x": 9.931629180908203,
    "y": 6.83494758605957,
    "cluster_id": 69
  },
  {
    "feature_id": 459,
    "explanation_index": 1,
    "text": "Empty or whitespace-filled tokens, punctuation, and special symbols often serve as structural or syntactic markers in text, particularly in code, mathematical notation, or formatted documents, with activations indicating their role in parsing or formatting.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8544972737630209,
    "similarity_var": 0.0002561849618377071,
    "score_fuzz": 0.37,
    "score_detection": 0.31,
    "score_embedding": 0.514375,
    "total_score": 0.398125,
    "x": 11.159339904785156,
    "y": 7.075608253479004,
    "cluster_id": -1
  },
  {
    "feature_id": 459,
    "explanation_index": 2,
    "text": "The highlighted words are the core lexical elements that carry the main semantic content of a phrase\u2014typically nouns, adjectives, or key verbs, and occasionally punctuation that signals structure.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8544972737630209,
    "similarity_var": 0.0002561849618377071,
    "score_fuzz": 0.575,
    "score_detection": 0.775,
    "score_embedding": 0.525625,
    "total_score": 0.6252083333333334,
    "x": 16.652536392211914,
    "y": 3.6325125694274902,
    "cluster_id": 20
  },
  {
    "feature_id": 460,
    "explanation_index": 0,
    "text": "Prefixes or suffixes of words, often indicating a relationship or a characteristic, and sometimes part of proper nouns or abbreviations.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.866952915986379,
    "similarity_var": 0.00015224696054458618,
    "score_fuzz": 0.78,
    "score_detection": 0.72,
    "score_embedding": 0.8204,
    "total_score": 0.7734666666666667,
    "x": 8.273457527160645,
    "y": 2.174999475479126,
    "cluster_id": 44
  },
  {
    "feature_id": 460,
    "explanation_index": 1,
    "text": "Partial or truncated proper nouns, abbreviations, or technical terms often appear with lowercase or fragmented spelling, typically preceding or following a contextually significant word or symbol.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.866952915986379,
    "similarity_var": 0.00015224696054458618,
    "score_fuzz": 0.7684210526315789,
    "score_detection": 0.6736842105263158,
    "score_embedding": 0.86875,
    "total_score": 0.7702850877192983,
    "x": 7.417010307312012,
    "y": 2.7795259952545166,
    "cluster_id": -1
  },
  {
    "feature_id": 460,
    "explanation_index": 2,
    "text": "The model highlights subword fragments that are part of larger identifiers or words, often at the start or end, indicating sensitivity to morphological or code token boundaries.\\\" Also mention that many tokens are prefixes like \\\"NS\\\", \\\"ns\\\", \\\"Ins\\\", \\\"ens\\\", \\\"ensuring\\\", \\\"ensure\\\", \\\"insured\\\", \\\"insurance\\\", \\\"inscribed\\\", \\\"insulin\\\", \\\"ins\\\", \\\"NSLog\\\", \\\"namespace\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", \\\"NS\\\", ",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.866952915986379,
    "similarity_var": 0.00015224696054458618,
    "score_fuzz": 0.8,
    "score_detection": 0.775,
    "score_embedding": 0.9125,
    "total_score": 0.8291666666666667,
    "x": 14.851184844970703,
    "y": 5.1030120849609375,
    "cluster_id": 77
  },
  {
    "feature_id": 461,
    "explanation_index": 0,
    "text": "A suffix or a part of a word that is often used in Japanese text, sometimes indicating a grammatical function or a word ending.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8162901798884074,
    "similarity_var": 0.0010739516371087473,
    "score_fuzz": 0.5,
    "score_detection": 0.3,
    "score_embedding": 0.38759999999999994,
    "total_score": 0.39586666666666664,
    "x": 8.381621360778809,
    "y": 2.225163221359253,
    "cluster_id": 44
  },
  {
    "feature_id": 461,
    "explanation_index": 1,
    "text": "Morphological suffixes and compound words indicating possession, state, or action, often appearing in context of abstract concepts, emotions, or grammatical constructions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8162901798884074,
    "similarity_var": 0.0010739516371087473,
    "score_fuzz": 0.64,
    "score_detection": 0.59,
    "score_embedding": 0.5275,
    "total_score": 0.5858333333333333,
    "x": 8.638166427612305,
    "y": 2.3846170902252197,
    "cluster_id": 66
  },
  {
    "feature_id": 461,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8162901798884074,
    "similarity_var": 0.0010739516371087473,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.5231250000000001,
    "total_score": 0.5077083333333333,
    "x": -7.928886413574219,
    "y": 9.131400108337402,
    "cluster_id": 52
  },
  {
    "feature_id": 462,
    "explanation_index": 0,
    "text": "Proper nouns, names of people, organizations, and locations, as well as words that initiate or conclude a quotation, or indicate a transition in thought or action.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8570423523585001,
    "similarity_var": 0.0013436171360731288,
    "score_fuzz": 0.47,
    "score_detection": 0.5,
    "score_embedding": 0.37439999999999996,
    "total_score": 0.4481333333333333,
    "x": 7.418441295623779,
    "y": -0.8708946704864502,
    "cluster_id": 16
  },
  {
    "feature_id": 462,
    "explanation_index": 1,
    "text": "Common noun phrases and proper nouns that denote specific entities, locations, or people, often appearing in contextually significant or referential positions within sentences.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8570423523585001,
    "similarity_var": 0.0013436171360731288,
    "score_fuzz": 0.54,
    "score_detection": 0.46,
    "score_embedding": 0.438125,
    "total_score": 0.47937499999999994,
    "x": 8.840532302856445,
    "y": -0.379117876291275,
    "cluster_id": -1
  },
  {
    "feature_id": 462,
    "explanation_index": 2,
    "text": "Important tokens are usually the first word or key noun in a phrase that carries a distinct semantic role\u2014often a named entity, idiom, or core concept\u2014serving as the anchor for that phrase\u2019s meaning.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8570423523585001,
    "similarity_var": 0.0013436171360731288,
    "score_fuzz": 0.575,
    "score_detection": 0.55,
    "score_embedding": 0.34312499999999996,
    "total_score": 0.48937499999999995,
    "x": 11.471785545349121,
    "y": 4.659193515777588,
    "cluster_id": 78
  },
  {
    "feature_id": 463,
    "explanation_index": 0,
    "text": "Numerical values, often representing years, quantities, or codes, embedded within text.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9062117139498392,
    "similarity_var": 5.1174506785242916e-05,
    "score_fuzz": 0.78,
    "score_detection": 0.62,
    "score_embedding": 0.2108,
    "total_score": 0.5369333333333333,
    "x": 6.9315643310546875,
    "y": 8.762478828430176,
    "cluster_id": 29
  },
  {
    "feature_id": 463,
    "explanation_index": 1,
    "text": "Single-digit numbers (0\u20139) frequently appear in contextual positions such as dates, identifiers, numerical thresholds, or sequential references, often indicating version numbers, years, or labeled components.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9062117139498392,
    "similarity_var": 5.1174506785242916e-05,
    "score_fuzz": 0.79,
    "score_detection": 0.6,
    "score_embedding": 0.31312500000000004,
    "total_score": 0.5677083333333334,
    "x": 7.325275421142578,
    "y": 8.594344139099121,
    "cluster_id": 29
  },
  {
    "feature_id": 463,
    "explanation_index": 2,
    "text": "The highlighted tokens are numeric identifiers embedded in file names, URLs, dates, or code, often representing placeholders or version numbers.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9062117139498392,
    "similarity_var": 5.1174506785242916e-05,
    "score_fuzz": 0.7,
    "score_detection": 0.6,
    "score_embedding": 0.30375,
    "total_score": 0.5345833333333333,
    "x": 13.31917953491211,
    "y": 5.960253715515137,
    "cluster_id": 30
  },
  {
    "feature_id": 464,
    "explanation_index": 0,
    "text": "Technical terms and concepts related to computing, networking, and digital technology, often referring to the internet, web, and online platforms.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8187210162480673,
    "similarity_var": 0.003769628667047047,
    "score_fuzz": 0.8,
    "score_detection": 0.6,
    "score_embedding": 0.6856,
    "total_score": 0.6951999999999999,
    "x": 7.453376293182373,
    "y": 1.0931981801986694,
    "cluster_id": 25
  },
  {
    "feature_id": 464,
    "explanation_index": 1,
    "text": "The text latents frequently involve technological or digital infrastructure terms, particularly those related to online connectivity, networks, and digital services, with strong activation on specific substrings like \\\"internet\\\", \\\"web\\\", \\\"online\\\", \\\"Wi-Fi\\\", \\\"IP\\\", \\\"Ethernet\\\", and \\\"cyberspace\\\", often appearing in contexts related to digital access, communication, or networked systems.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8187210162480673,
    "similarity_var": 0.003769628667047047,
    "score_fuzz": 0.83,
    "score_detection": 0.75,
    "score_embedding": 0.66375,
    "total_score": 0.7479166666666667,
    "x": 9.587136268615723,
    "y": 3.2296366691589355,
    "cluster_id": -1
  },
  {
    "feature_id": 464,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8187210162480673,
    "similarity_var": 0.003769628667047047,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.6675000000000001,
    "total_score": 0.5558333333333333,
    "x": -7.920953273773193,
    "y": 9.1393404006958,
    "cluster_id": 52
  },
  {
    "feature_id": 465,
    "explanation_index": 0,
    "text": "Various tokens including nouns, adjectives, adverbs, and conjunctions, often representing objects, concepts, or relationships, and sometimes indicating a transition or connection between ideas.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8845287561416626,
    "similarity_var": 0.00024461611388204574,
    "score_fuzz": 0.73,
    "score_detection": 0.73,
    "score_embedding": 0.364,
    "total_score": 0.608,
    "x": 10.58458137512207,
    "y": 4.536287307739258,
    "cluster_id": 47
  },
  {
    "feature_id": 465,
    "explanation_index": 1,
    "text": "Commonly activated tokens include standalone words or multi-word phrases that function as key semantic units, often representing objects, locations, abstract concepts, or grammatical constructs like comparatives, possessives, or conjunctions, with higher activation values typically associated with content words (nouns, adjectives, verbs) and lower values with function words or punctuation.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8845287561416626,
    "similarity_var": 0.00024461611388204574,
    "score_fuzz": 0.77,
    "score_detection": 0.82,
    "score_embedding": 0.41875,
    "total_score": 0.6695833333333333,
    "x": 10.16784381866455,
    "y": 3.5234014987945557,
    "cluster_id": 41
  },
  {
    "feature_id": 465,
    "explanation_index": 2,
    "text": "The highlighted tokens are consistently short, high\u2011frequency function words or morphological markers that serve as connectors or modifiers within common collocations or idiomatic phrases, often appearing in contiguous sequences and playing a key role in the overall meaning.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8845287561416626,
    "similarity_var": 0.00024461611388204574,
    "score_fuzz": 0.675,
    "score_detection": 0.775,
    "score_embedding": 0.40687500000000004,
    "total_score": 0.6189583333333334,
    "x": 13.94189739227295,
    "y": 3.9697115421295166,
    "cluster_id": 42
  },
  {
    "feature_id": 467,
    "explanation_index": 0,
    "text": "Symbols, units, and abbreviations used in scientific notation, often representing chemical elements, physical quantities, or mathematical operations.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8789540330568949,
    "similarity_var": 0.001128438395180669,
    "score_fuzz": 0.57,
    "score_detection": 0.7,
    "score_embedding": 0.2672,
    "total_score": 0.5124,
    "x": 9.157508850097656,
    "y": 8.172063827514648,
    "cluster_id": 74
  },
  {
    "feature_id": 467,
    "explanation_index": 1,
    "text": "Chemical and scientific notation involving numerical values, units, subscripts, superscripts, and special symbols, often with precise formatting and contextual significance.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8789540330568949,
    "similarity_var": 0.001128438395180669,
    "score_fuzz": 0.51,
    "score_detection": 0.71,
    "score_embedding": 0.24875,
    "total_score": 0.4895833333333333,
    "x": 9.113612174987793,
    "y": 8.126230239868164,
    "cluster_id": 74
  },
  {
    "feature_id": 467,
    "explanation_index": 2,
    "text": "The highlighted tokens consistently correspond to fragments of chemical names, numeric values, and measurement units\u2014often split across delimiters\u2014showing that the model focuses on chemical substructures and quantitative descriptors.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8789540330568949,
    "similarity_var": 0.001128438395180669,
    "score_fuzz": 0.45,
    "score_detection": 0.525,
    "score_embedding": 0.30625,
    "total_score": 0.4270833333333333,
    "x": 8.165099143981934,
    "y": 3.1782517433166504,
    "cluster_id": 76
  },
  {
    "feature_id": 468,
    "explanation_index": 0,
    "text": "Special characters, punctuation, and short words or abbreviations often used in technical or formal writing, such as mathematical or programming notation, and sometimes nouns or words in specific contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8613935510317484,
    "similarity_var": 8.332456492452265e-05,
    "score_fuzz": 0.28,
    "score_detection": 0.43,
    "score_embedding": 0.3268,
    "total_score": 0.34559999999999996,
    "x": 8.93917179107666,
    "y": 7.567790985107422,
    "cluster_id": 68
  },
  {
    "feature_id": 468,
    "explanation_index": 1,
    "text": "The presence of delimiters or placeholder tokens (like <<>> or <<>>), often surrounding text fragments, punctuation, or symbols, indicating structural or syntactic placeholders in code, formatting, or markup, with activations primarily on single characters, symbols, or short sequences that serve as markers or separators.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8613935510317484,
    "similarity_var": 8.332456492452265e-05,
    "score_fuzz": 0.45,
    "score_detection": 0.31,
    "score_embedding": 0.298125,
    "total_score": 0.35270833333333335,
    "x": 9.9489164352417,
    "y": 6.846676349639893,
    "cluster_id": 69
  },
  {
    "feature_id": 468,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core content words or symbols that carry the main semantic or functional weight in each snippet\u2014whether they are key nouns, verbs, adjectives, technical terms, numbers, or punctuation\u2014often forming meaningful phrases or code identifiers that define the central idea or operation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8613935510317484,
    "similarity_var": 8.332456492452265e-05,
    "score_fuzz": 0.3,
    "score_detection": 0.4,
    "score_embedding": 0.34125,
    "total_score": 0.34708333333333335,
    "x": 15.025259971618652,
    "y": 4.40972900390625,
    "cluster_id": 72
  },
  {
    "feature_id": 471,
    "explanation_index": 0,
    "text": "Punctuation marks and digits, often used in citations, references, and numerical data.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8277782996495565,
    "similarity_var": 0.0018825079915442999,
    "score_fuzz": 0.38,
    "score_detection": 0.49,
    "score_embedding": 0.09040000000000001,
    "total_score": 0.3201333333333333,
    "x": 8.285711288452148,
    "y": 7.4054365158081055,
    "cluster_id": -1
  },
  {
    "feature_id": 471,
    "explanation_index": 1,
    "text": "Individual digits, particularly '8', frequently appear in numerical data, references, timestamps, and formatting contexts, often as part of identifiers, measurements, or sequence numbers.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8277782996495565,
    "similarity_var": 0.0018825079915442999,
    "score_fuzz": 0.52,
    "score_detection": 0.47,
    "score_embedding": 0.260625,
    "total_score": 0.41687499999999994,
    "x": 7.239889621734619,
    "y": 8.650211334228516,
    "cluster_id": 29
  },
  {
    "feature_id": 471,
    "explanation_index": 2,
    "text": "The highlighted tokens always form a contiguous, semantically coherent unit\u2014typically a noun phrase, a numeric expression, or a short idiomatic clause\u2014so the model treats the entire block as a single important entity.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8277782996495565,
    "similarity_var": 0.0018825079915442999,
    "score_fuzz": 0.675,
    "score_detection": 0.625,
    "score_embedding": 0.15125000000000002,
    "total_score": 0.48375000000000007,
    "x": 15.161848068237305,
    "y": 4.714751720428467,
    "cluster_id": 55
  },
  {
    "feature_id": 472,
    "explanation_index": 0,
    "text": "Possessive pronouns, articles, and other function words, often used to indicate ownership or association, and sometimes preceding a quotation or a proper noun.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8741176327069601,
    "similarity_var": 0.00024711119272622127,
    "score_fuzz": 0.68,
    "score_detection": 0.38,
    "score_embedding": 0.41759999999999997,
    "total_score": 0.4925333333333333,
    "x": 11.985748291015625,
    "y": 1.0734935998916626,
    "cluster_id": 28
  },
  {
    "feature_id": 472,
    "explanation_index": 1,
    "text": "Possessive pronouns like \\\"his\\\", \\\"their\\\", \\\"your\\\" and demonstratives like \\\"this\\\", \\\"that\\\" are frequently activated when referring to previously mentioned entities, often in contexts involving personal attribution, possession, or contextual reference.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8741176327069601,
    "similarity_var": 0.00024711119272622127,
    "score_fuzz": 0.7,
    "score_detection": 0.47,
    "score_embedding": 0.396875,
    "total_score": 0.5222916666666667,
    "x": 12.075241088867188,
    "y": 1.1203129291534424,
    "cluster_id": 28
  },
  {
    "feature_id": 472,
    "explanation_index": 2,
    "text": "The highlighted tokens are short, high\u2011frequency function words\u2014pronouns, determiners, prepositions, conjunctions, or small nouns\u2014that signal grammatical relationships such as possession, reference, or clause linkage. They are crucial for structuring the sentence and connecting ideas.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8741176327069601,
    "similarity_var": 0.00024711119272622127,
    "score_fuzz": 0.6,
    "score_detection": 0.425,
    "score_embedding": 0.369375,
    "total_score": 0.46479166666666666,
    "x": 13.503671646118164,
    "y": 3.253174066543579,
    "cluster_id": 35
  },
  {
    "feature_id": 473,
    "explanation_index": 0,
    "text": "Units of measurement, physical quantities, and environmental conditions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8794393738110861,
    "similarity_var": 0.0007586596278304431,
    "score_fuzz": 0.67,
    "score_detection": 0.57,
    "score_embedding": 0.5051999999999999,
    "total_score": 0.5817333333333333,
    "x": 7.825511932373047,
    "y": 1.0090714693069458,
    "cluster_id": -1
  },
  {
    "feature_id": 473,
    "explanation_index": 1,
    "text": "Nouns and noun phrases related to environmental or physical conditions, often describing measurable phenomena such as temperature, weather, rainfall, and seasonal or spatial variations.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8794393738110861,
    "similarity_var": 0.0007586596278304431,
    "score_fuzz": 0.63,
    "score_detection": 0.53,
    "score_embedding": 0.47625,
    "total_score": 0.5454166666666668,
    "x": 8.228782653808594,
    "y": 0.38083162903785706,
    "cluster_id": 12
  },
  {
    "feature_id": 473,
    "explanation_index": 2,
    "text": "The highlighted tokens are core domain terms and quantitative markers\u2014such as environmental variables, measurements, and units\u2014that signal the main informational content of scientific or technical text, often forming part of multi\u2011word phrases that convey key concepts.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8794393738110861,
    "similarity_var": 0.0007586596278304431,
    "score_fuzz": 0.65,
    "score_detection": 0.475,
    "score_embedding": 0.429375,
    "total_score": 0.5181250000000001,
    "x": 13.680908203125,
    "y": 4.688709735870361,
    "cluster_id": -1
  },
  {
    "feature_id": 474,
    "explanation_index": 0,
    "text": "Code blocks and syntax elements, often denoting the end of a statement, block, or function.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.902269184589386,
    "similarity_var": 1.1354851582249617e-05,
    "score_fuzz": 0.77,
    "score_detection": 0.56,
    "score_embedding": 0.4508,
    "total_score": 0.5936,
    "x": 11.137784957885742,
    "y": 8.102792739868164,
    "cluster_id": -1
  },
  {
    "feature_id": 474,
    "explanation_index": 1,
    "text": "Patterns in code structure involving newline characters and balanced delimiters, often indicating syntactic boundaries or formatting in programming or markup languages.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.902269184589386,
    "similarity_var": 1.1354851582249617e-05,
    "score_fuzz": 0.73,
    "score_detection": 0.53,
    "score_embedding": 0.326875,
    "total_score": 0.5289583333333333,
    "x": 10.368988037109375,
    "y": 7.110797882080078,
    "cluster_id": 86
  },
  {
    "feature_id": 474,
    "explanation_index": 2,
    "text": "The highlighted tokens are structural syntax elements\u2014whitespace, newlines, braces, parentheses, semicolons, and other delimiters\u2014that define the boundaries and organization of code blocks.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.902269184589386,
    "similarity_var": 1.1354851582249617e-05,
    "score_fuzz": 0.8,
    "score_detection": 0.55,
    "score_embedding": 0.38750000000000007,
    "total_score": 0.5791666666666667,
    "x": 13.721853256225586,
    "y": 6.4863972663879395,
    "cluster_id": 8
  },
  {
    "feature_id": 476,
    "explanation_index": 0,
    "text": "Prepositions, particularly \\\"in\\\" and \\\"into\\\", often used to indicate location or position within a physical space.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9294689893722534,
    "similarity_var": 0.0002906543223015016,
    "score_fuzz": 0.91,
    "score_detection": 0.78,
    "score_embedding": 0.4176,
    "total_score": 0.7025333333333333,
    "x": 12.36469554901123,
    "y": -0.64703369140625,
    "cluster_id": 63
  },
  {
    "feature_id": 476,
    "explanation_index": 1,
    "text": "Prepositions \\\"in\\\" and \\\"into\\\" frequently appear in spatial or situational contexts, often indicating location, containment, or movement into a place or state, with \\\"in\\\" being more common and often paired with nouns denoting enclosed or defined spaces.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9294689893722534,
    "similarity_var": 0.0002906543223015016,
    "score_fuzz": 0.9157894736842105,
    "score_detection": 0.76,
    "score_embedding": 0.36375,
    "total_score": 0.6798464912280702,
    "x": 12.410233497619629,
    "y": -0.6370939612388611,
    "cluster_id": 63
  },
  {
    "feature_id": 476,
    "explanation_index": 2,
    "text": "The token \u201cin\u201d (and its variant \u201cinside\u201d) functions as a preposition indicating location or inclusion, frequently appearing as a separate word preceded by a space.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9294689893722534,
    "similarity_var": 0.0002906543223015016,
    "score_fuzz": 1.0,
    "score_detection": 0.95,
    "score_embedding": 0.39875000000000005,
    "total_score": 0.7829166666666666,
    "x": 12.419062614440918,
    "y": -0.6327248215675354,
    "cluster_id": 63
  },
  {
    "feature_id": 477,
    "explanation_index": 0,
    "text": "Punctuation marks, often periods, that end sentences or clauses.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8781620264053345,
    "similarity_var": 0.0007423851256215622,
    "score_fuzz": 0.93,
    "score_detection": 0.56,
    "score_embedding": 0.6848,
    "total_score": 0.7249333333333334,
    "x": 7.9825944900512695,
    "y": 6.652731895446777,
    "cluster_id": -1
  },
  {
    "feature_id": 477,
    "explanation_index": 1,
    "text": "The period (\\\".\\\") is frequently activated in contexts involving punctuation boundaries, especially at the end of sentences, clauses, or after closing brackets, quotation marks, or mathematical expressions, often signaling syntactic or structural completion.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8781620264053345,
    "similarity_var": 0.0007423851256215622,
    "score_fuzz": 0.87,
    "score_detection": 0.5,
    "score_embedding": 0.6743750000000001,
    "total_score": 0.6814583333333334,
    "x": 8.171573638916016,
    "y": 6.952577114105225,
    "cluster_id": -1
  },
  {
    "feature_id": 477,
    "explanation_index": 2,
    "text": "The highlighted tokens are almost always punctuation marks or very short words that appear at the ends of phrases or sentences, suggesting the model is picking up on boundary and structural cues rather than substantive lexical content.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8781620264053345,
    "similarity_var": 0.0007423851256215622,
    "score_fuzz": 0.65,
    "score_detection": 0.5,
    "score_embedding": 0.66375,
    "total_score": 0.6045833333333333,
    "x": 14.099306106567383,
    "y": 5.064289093017578,
    "cluster_id": -1
  },
  {
    "feature_id": 478,
    "explanation_index": 0,
    "text": "Words related to nationality, international relations, education, and global movement.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8516151309013367,
    "similarity_var": 0.00019942141472265953,
    "score_fuzz": 0.65,
    "score_detection": 0.47,
    "score_embedding": 0.5056,
    "total_score": 0.5418666666666667,
    "x": 7.557906150817871,
    "y": -0.8215115070343018,
    "cluster_id": 16
  },
  {
    "feature_id": 478,
    "explanation_index": 1,
    "text": "Commonly activated tokens include words related to geographical or demographic categories (e.g., \\\"expatriates\\\", \\\"emigrants\\\", \\\"international\\\", \\\"overseas\\\"), often appearing in contexts involving movement, identity, or affiliation, with frequent use of compound terms and prepositional phrases like \\\"in\\\", \\\"from\\\", \\\"to\\\", and \\\"and\\\" as connectors.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8516151309013367,
    "similarity_var": 0.00019942141472265953,
    "score_fuzz": 0.66,
    "score_detection": 0.46,
    "score_embedding": 0.54375,
    "total_score": 0.5545833333333333,
    "x": 10.294090270996094,
    "y": 3.230961561203003,
    "cluster_id": 50
  },
  {
    "feature_id": 478,
    "explanation_index": 2,
    "text": "the pattern: The examples show tokens that are part of words like \\\"expatriate\\\", \\\"international\\\", \\\"students\\\", \\\"expatriates\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\", \\\"expatriate\\\".",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8516151309013367,
    "similarity_var": 0.00019942141472265953,
    "score_fuzz": 0.75,
    "score_detection": 0.65,
    "score_embedding": 0.63375,
    "total_score": 0.6779166666666666,
    "x": 11.043463706970215,
    "y": 3.5687623023986816,
    "cluster_id": -1
  },
  {
    "feature_id": 479,
    "explanation_index": 0,
    "text": "Proper nouns, names of people, places, organizations, and titles, as well as common nouns representing objects, concepts, and ideas, often used to provide context or convey specific information.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8816481630007426,
    "similarity_var": 8.984248652015797e-05,
    "score_fuzz": 0.5894736842105263,
    "score_detection": 0.56,
    "score_embedding": 0.41,
    "total_score": 0.5198245614035087,
    "x": 7.508565902709961,
    "y": -0.8872923851013184,
    "cluster_id": 16
  },
  {
    "feature_id": 479,
    "explanation_index": 1,
    "text": "The presence of named entities, proper nouns, or specific identifiers (such as names, locations, brands, dates, or titles) that are contextually significant, often appearing in proximity to punctuation or within quoted or highlighted text.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8816481630007426,
    "similarity_var": 8.984248652015797e-05,
    "score_fuzz": 0.56,
    "score_detection": 0.6,
    "score_embedding": 0.401875,
    "total_score": 0.520625,
    "x": 6.8658127784729,
    "y": -0.8400519490242004,
    "cluster_id": 84
  },
  {
    "feature_id": 479,
    "explanation_index": 2,
    "text": "The pattern seems to be that the important tokens are often nouns or phrases that are part of a larger context, sometimes with punctuation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8816481630007426,
    "similarity_var": 8.984248652015797e-05,
    "score_fuzz": 0.425,
    "score_detection": 0.4,
    "score_embedding": 0.37687500000000007,
    "total_score": 0.400625,
    "x": 11.399771690368652,
    "y": 4.426327228546143,
    "cluster_id": 3
  },
  {
    "feature_id": 480,
    "explanation_index": 0,
    "text": "Numerical values, often representing dates, times, quantities, or identifiers, embedded within text.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8712607820828756,
    "similarity_var": 8.057930190198528e-05,
    "score_fuzz": 0.82,
    "score_detection": 0.51,
    "score_embedding": 0.2708,
    "total_score": 0.5336,
    "x": 6.926703929901123,
    "y": 8.831621170043945,
    "cluster_id": 29
  },
  {
    "feature_id": 480,
    "explanation_index": 1,
    "text": "Numbers and digits are frequently highlighted when they appear in sequences, especially in contexts involving time, counts, measurements, or identifiers, often indicating quantitative or structural significance.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8712607820828756,
    "similarity_var": 8.057930190198528e-05,
    "score_fuzz": 0.9,
    "score_detection": 0.59,
    "score_embedding": 0.25,
    "total_score": 0.58,
    "x": 7.313200950622559,
    "y": 8.571066856384277,
    "cluster_id": 29
  },
  {
    "feature_id": 480,
    "explanation_index": 2,
    "text": "The highlighted tokens are usually short, single\u2011word elements\u2014often nouns, numbers, or time markers\u2014that act as the core identifiers or quantitative anchors within a phrase or context.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8712607820828756,
    "similarity_var": 8.057930190198528e-05,
    "score_fuzz": 0.925,
    "score_detection": 0.7,
    "score_embedding": 0.19874999999999998,
    "total_score": 0.6079166666666667,
    "x": 14.465591430664062,
    "y": 4.15244197845459,
    "cluster_id": -1
  },
  {
    "feature_id": 481,
    "explanation_index": 0,
    "text": "Words expressing respect, gratitude, or recognition, often in formal or professional contexts, including nouns and adjectives describing honor, praise, or esteem.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8957594831784567,
    "similarity_var": 0.0005495075557280731,
    "score_fuzz": 0.75,
    "score_detection": 0.67,
    "score_embedding": 0.5856,
    "total_score": 0.6685333333333333,
    "x": 8.97059440612793,
    "y": 1.1637321710586548,
    "cluster_id": 45
  },
  {
    "feature_id": 481,
    "explanation_index": 1,
    "text": "Words related to recognition, evaluation, or social value\u2014such as honor, respect, appreciation, gratitude, and distinction\u2014are frequently activated in contexts involving praise, acknowledgment, or moral judgment.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8957594831784567,
    "similarity_var": 0.0005495075557280731,
    "score_fuzz": 0.77,
    "score_detection": 0.66,
    "score_embedding": 0.533125,
    "total_score": 0.654375,
    "x": 9.077387809753418,
    "y": 1.2423416376113892,
    "cluster_id": 45
  },
  {
    "feature_id": 481,
    "explanation_index": 2,
    "text": "The highlighted tokens are usually nouns or adjectives that convey honor, respect, or formal status, appearing in academic or official contexts and typically preceded by a space.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8957594831784567,
    "similarity_var": 0.0005495075557280731,
    "score_fuzz": 0.65,
    "score_detection": 0.575,
    "score_embedding": 0.598125,
    "total_score": 0.6077083333333334,
    "x": 14.638307571411133,
    "y": 3.993807792663574,
    "cluster_id": 11
  },
  {
    "feature_id": 483,
    "explanation_index": 0,
    "text": "Tokens often represent nouns, names, or words that are part of a larger phrase or sentence, sometimes denoting a specific object, location, or concept, and can be found in various contexts such as scientific, technical, or everyday language.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8506430387496948,
    "similarity_var": 0.0002624597787317384,
    "score_fuzz": 0.55,
    "score_detection": 0.42,
    "score_embedding": 0.4672,
    "total_score": 0.4790666666666667,
    "x": 10.263418197631836,
    "y": 4.437970161437988,
    "cluster_id": 1
  },
  {
    "feature_id": 483,
    "explanation_index": 1,
    "text": "Common patterns include abbreviations, technical terms, proper nouns, and compound words often appearing in scientific, technical, or formal contexts, with frequent use of suffixes like \\\"er\\\", \\\"ing\\\", \\\"ed\\\", and \\\"re\\\" in morphological variations, and recurring tokens such as \\\"record\\\", \\\"results\\\", \\\"release\\\", \\\"range\\\", \\\"reservoir\\\", \\\"refurbished\\\", \\\"replaced\\\", \\\"recovered\\\", \\\"recreated\\\", \\\"retreated\\\", \\\"replaced\\\", \\\"received\\\", \\\"reporters\\\", \\\"around\\\", \\\"roles\\\", \\\"research\\\", \\\"region\\\", \\\"Russia\\\", \\\"recent\\\", \\\"rectangular\\\", \\\"recess\\\", \\\"resonance\\\", \\\"frequency\\\", \\\"RCE\\\", \\\"RPD\\\", \\\"rs\\\", \\\"Arg\\\", \\\"Rydberg\\\", \\\"ravel\\\", \\\"rm\\\", \\\"uf\\\", \\\"roa\\\", \\\"esta\\\", \\\"urant\\\", \\\"Request\\\", \\\"res\\\", \\\"disrupt\\\", \\\"result\\\", \\\"replace\\\", \\\"refurbished\\\", \\\"recovered\\\", \\\"recreated\\\", \\\"retreated\\\", \\\"replaced\\\", \\\"received\\\", \\\"reporters\\\", \\\"around\\\", \\\"roles\\\", \\\"research\\\", \\\"region\\\", \\\"Russia\\\", \\\"recent\\\", \\\"rectangular\\\", \\\"recess\\\", \\\"resonance\\\", \\\"frequency\\\", \\\"RCE\\\", \\\"RPD\\\", \\\"rs\\\", \\\"Arg\\\", \\\"Rydberg\\\", \\\"ravel\\\", \\\"rm\\\", \\\"uf\\\", \\\"roa\\\", \\\"esta\\\", \\\"urant\\\", \\\"Request\\\", \\\"res\\\", \\\"disrupt\\\", \\\"result\\\", \\\"replace\\\", \\\"refurbished\\\", \\\"recovered\\\", \\\"recreated\\\", \\\"retreated\\\", \\\"replaced\\\", \\\"received\\\", \\\"reporters\\\", \\\"around\\\", \\\"roles\\\", \\\"research\\\", \\\"region\\\", \\\"Russia\\\", \\\"recent\\\", \\\"rectangular\\\", \\\"recess\\\", \\\"resonance\\\", \\\"frequency\\\", \\\"RCE\\\", \\\"RPD\\\", \\\"rs\\\", \\\"Arg\\\", \\\"Rydberg\\\", \\\"ravel\\\", \\\"rm\\\", \\\"uf\\\", \\\"roa\\\", \\\"esta\\\", \\\"urant\\\", \\\"Request\\\", \\\"res\\\", \\\"disrupt\\\", \\\"result\\\", \\\"replace\\\", \\\"refurbished\\\", \\\"recovered\\\", \\\"recreated\\\", \\\"retreated\\\", \\\"replaced\\\", \\\"received\\\", \\\"reporters\\\", \\\"around\\\", \\\"roles\\\", \\\"research\\\", \\\"region\\\", \\\"Russia\\\", \\\"recent\\\", \\\"rectangular\\\", \\\"recess\\\", \\\"resonance\\\", \\\"frequency\\\", \\\"RCE",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8506430387496948,
    "similarity_var": 0.0002624597787317384,
    "score_fuzz": 0.56,
    "score_detection": 0.23,
    "score_embedding": 0.36750000000000005,
    "total_score": 0.3858333333333334,
    "x": 9.271492004394531,
    "y": 2.9989819526672363,
    "cluster_id": -1
  },
  {
    "feature_id": 483,
    "explanation_index": 2,
    "text": "The marked spans are the content\u2011rich tokens or phrases that carry the bulk of a sentence\u2019s meaning\u2014idiomatic expressions, comparative adjectives, nouns or noun phrases that name objects, places, or entities, and technical or domain\u2011specific terms. They are usually content words (nouns, adjectives, or multi\u2011word units) rather than function words, and they receive high activation scores because they are key to understanding the text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8506430387496948,
    "similarity_var": 0.0002624597787317384,
    "score_fuzz": 0.725,
    "score_detection": 0.375,
    "score_embedding": 0.35625,
    "total_score": 0.48541666666666666,
    "x": 15.576057434082031,
    "y": 4.2455902099609375,
    "cluster_id": -1
  },
  {
    "feature_id": 484,
    "explanation_index": 0,
    "text": "Units of measurement, quantities, and various nouns representing objects, concepts, or entities, often denoting a specific type, amount, or category.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9063607454299927,
    "similarity_var": 0.00025545762557281176,
    "score_fuzz": 0.74,
    "score_detection": 0.63,
    "score_embedding": 0.3896,
    "total_score": 0.5865333333333334,
    "x": 7.914982795715332,
    "y": 0.895661473274231,
    "cluster_id": -1
  },
  {
    "feature_id": 484,
    "explanation_index": 1,
    "text": "Nouns denoting measurable quantities, categories, or physical entities, often appearing in scientific, technical, or descriptive contexts, with high activation values when part of a specific unit, category, or structural element.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9063607454299927,
    "similarity_var": 0.00025545762557281176,
    "score_fuzz": 0.78,
    "score_detection": 0.73,
    "score_embedding": 0.45749999999999996,
    "total_score": 0.6558333333333334,
    "x": 8.111926078796387,
    "y": 0.707438588142395,
    "cluster_id": -1
  },
  {
    "feature_id": 484,
    "explanation_index": 2,
    "text": "The highlighted tokens are typically nouns or noun phrases that denote specific entities, categories, or objects, often serving as key terms in technical or descriptive contexts.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9063607454299927,
    "similarity_var": 0.00025545762557281176,
    "score_fuzz": 0.75,
    "score_detection": 0.575,
    "score_embedding": 0.315625,
    "total_score": 0.546875,
    "x": 14.551797866821289,
    "y": 4.005443572998047,
    "cluster_id": 11
  },
  {
    "feature_id": 485,
    "explanation_index": 0,
    "text": "Abbreviations and technical terms in specialized fields, particularly in electronics, physics, and telecommunications.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8997329870859782,
    "similarity_var": 0.0004142527365292242,
    "score_fuzz": 0.74,
    "score_detection": 0.43,
    "score_embedding": 0.6324,
    "total_score": 0.6008,
    "x": 7.608346462249756,
    "y": 1.423538327217102,
    "cluster_id": -1
  },
  {
    "feature_id": 485,
    "explanation_index": 1,
    "text": "Abbreviations and technical terms in scientific and engineering contexts, often composed of capitalized letters or hyphenated components, frequently appearing in sequences related to technology, physics, and communication systems.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8997329870859782,
    "similarity_var": 0.0004142527365292242,
    "score_fuzz": 0.69,
    "score_detection": 0.46,
    "score_embedding": 0.753125,
    "total_score": 0.634375,
    "x": 7.595916748046875,
    "y": 1.6884021759033203,
    "cluster_id": -1
  },
  {
    "feature_id": 485,
    "explanation_index": 2,
    "text": "The highlighted tokens are domain\u2011specific technical terms or abbreviations that serve as the core content words in each sentence.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8997329870859782,
    "similarity_var": 0.0004142527365292242,
    "score_fuzz": 0.475,
    "score_detection": 0.35,
    "score_embedding": 0.589375,
    "total_score": 0.4714583333333333,
    "x": 13.810132026672363,
    "y": 4.629966735839844,
    "cluster_id": -1
  },
  {
    "feature_id": 486,
    "explanation_index": 0,
    "text": "Geographic locations, proper nouns, and specific names of institutions, organizations, and individuals.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8869718909263611,
    "similarity_var": 8.201244350184804e-05,
    "score_fuzz": 0.62,
    "score_detection": 0.35,
    "score_embedding": 0.608,
    "total_score": 0.5259999999999999,
    "x": 7.41197395324707,
    "y": -0.9610841870307922,
    "cluster_id": 16
  },
  {
    "feature_id": 486,
    "explanation_index": 1,
    "text": "Proper nouns, particularly place names and institutional names, are frequently activated when they appear in context, often accompanied by punctuation or adjacent tokens that help identify their boundaries.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8869718909263611,
    "similarity_var": 8.201244350184804e-05,
    "score_fuzz": 0.62,
    "score_detection": 0.34,
    "score_embedding": 0.5843750000000001,
    "total_score": 0.5147916666666666,
    "x": 7.066718101501465,
    "y": -1.0952478647232056,
    "cluster_id": 40
  },
  {
    "feature_id": 486,
    "explanation_index": 2,
    "text": "The highlighted tokens are primarily proper nouns and entity names\u2014places, institutions, and technical terms\u2014often capitalized and sometimes part of multi\u2011word phrases; occasionally short suffixes such as \u201cer\u201d are flagged when they complete a comparative adjective.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8869718909263611,
    "similarity_var": 8.201244350184804e-05,
    "score_fuzz": 0.675,
    "score_detection": 0.5,
    "score_embedding": 0.66,
    "total_score": 0.6116666666666667,
    "x": 14.473649024963379,
    "y": 4.000775337219238,
    "cluster_id": 11
  },
  {
    "feature_id": 487,
    "explanation_index": 0,
    "text": "Direct address or second-person pronouns, often used in dialogue or informal writing, and sometimes preceding or following punctuation marks.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9180163343747457,
    "similarity_var": 0.00015423595711736327,
    "score_fuzz": 0.71,
    "score_detection": 0.51,
    "score_embedding": 0.3328,
    "total_score": 0.5176,
    "x": 11.711087226867676,
    "y": 1.33119535446167,
    "cluster_id": 71
  },
  {
    "feature_id": 487,
    "explanation_index": 1,
    "text": "Pronouns such as \\\"you\\\", \\\"your\\\", \\\"you're\\\", and \\\"you\\\" in contexts involving direct address, self-reference, or conditional statements, often signaling personal engagement, questioning, or emotional emphasis.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9180163343747457,
    "similarity_var": 0.00015423595711736327,
    "score_fuzz": 0.66,
    "score_detection": 0.54,
    "score_embedding": 0.464375,
    "total_score": 0.5547916666666667,
    "x": 11.720636367797852,
    "y": 1.375712513923645,
    "cluster_id": 71
  },
  {
    "feature_id": 487,
    "explanation_index": 2,
    "text": "The highlighted tokens are mainly second\u2011person pronouns and possessives (e.g., \u201cyou\u201d, \u201cyour\u201d) that signal direct address or dialogue, along with punctuation marks that delimit speech.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9180163343747457,
    "similarity_var": 0.00015423595711736327,
    "score_fuzz": 0.6,
    "score_detection": 0.55,
    "score_embedding": 0.41500000000000004,
    "total_score": 0.5216666666666666,
    "x": 13.81964111328125,
    "y": 5.205580234527588,
    "cluster_id": -1
  },
  {
    "feature_id": 488,
    "explanation_index": 0,
    "text": "Various scientific and technical terms, including names of plants, biological processes, and chemical compounds, as well as programming-related terms and symbols.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8548149267832438,
    "similarity_var": 0.0005105566055010829,
    "score_fuzz": 0.4421052631578947,
    "score_detection": 0.39,
    "score_embedding": 0.49839999999999995,
    "total_score": 0.4435017543859649,
    "x": 7.276632785797119,
    "y": 1.2039616107940674,
    "cluster_id": 25
  },
  {
    "feature_id": 488,
    "explanation_index": 1,
    "text": "Fragments of compound words or scientific terms, often derived from Latin or Greek roots, where the activation focuses on partial morphemes that contribute to the meaning of the full term.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8548149267832438,
    "similarity_var": 0.0005105566055010829,
    "score_fuzz": 0.49,
    "score_detection": 0.28,
    "score_embedding": 0.464375,
    "total_score": 0.4114583333333333,
    "x": 7.27811336517334,
    "y": 2.3833370208740234,
    "cluster_id": -1
  },
  {
    "feature_id": 488,
    "explanation_index": 2,
    "text": "The examples reveal that the model\u2019s activations focus on sub\u2011word fragments\u2014prefixes, suffixes, or internal pieces of longer words\u2014rather than on whole words. These fragments often come from domain\u2011specific terminology and are repeated across different contexts, indicating that the model relies on a sub\u2011word tokenization scheme (e.g., BPE or WordPiece) to represent and process rare or complex lexical items.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8548149267832438,
    "similarity_var": 0.0005105566055010829,
    "score_fuzz": 0.4,
    "score_detection": 0.3,
    "score_embedding": 0.44125000000000003,
    "total_score": 0.3804166666666666,
    "x": 8.10757064819336,
    "y": 3.2493062019348145,
    "cluster_id": 76
  },
  {
    "feature_id": 489,
    "explanation_index": 0,
    "text": "Nouns representing various concepts, including music, performance, news, magic, furniture, money, jewelry, and other objects or ideas, often in contexts where they are being highlighted or emphasized.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8691748380661011,
    "similarity_var": 0.0003586606803291185,
    "score_fuzz": 0.64,
    "score_detection": 0.29,
    "score_embedding": 0.512,
    "total_score": 0.48066666666666663,
    "x": 8.4858980178833,
    "y": 0.10029835253953934,
    "cluster_id": 24
  },
  {
    "feature_id": 489,
    "explanation_index": 1,
    "text": "The word \\\"music\\\" and related terms (e.g., \\\"tune\\\", \\\"rhythm\\\", \\\"orchestra\\\", \\\"musical\\\") are frequently activated in contexts involving sound, performance, entertainment, or artistic expression, often indicating a central theme or focus in the described setting or activity.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8691748380661011,
    "similarity_var": 0.0003586606803291185,
    "score_fuzz": 0.67,
    "score_detection": 0.57,
    "score_embedding": 0.421875,
    "total_score": 0.5539583333333333,
    "x": 8.750024795532227,
    "y": 0.19980037212371826,
    "cluster_id": -1
  },
  {
    "feature_id": 489,
    "explanation_index": 2,
    "text": "The pattern: The important tokens are nouns or noun phrases that refer to categories of content: music, musical, tune, orchestra, musical, etc.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8691748380661011,
    "similarity_var": 0.0003586606803291185,
    "score_fuzz": 0.625,
    "score_detection": 0.375,
    "score_embedding": 0.478125,
    "total_score": 0.4927083333333333,
    "x": 11.40622615814209,
    "y": 4.459451675415039,
    "cluster_id": 3
  },
  {
    "feature_id": 490,
    "explanation_index": 0,
    "text": "Verbs of movement or action, often involving the relocation of objects or people, sometimes with a sense of accompaniment or causation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9420262177785238,
    "similarity_var": 1.8999098847258563e-05,
    "score_fuzz": 0.77,
    "score_detection": 0.49,
    "score_embedding": 0.6199999999999999,
    "total_score": 0.6266666666666666,
    "x": 10.89179801940918,
    "y": -0.9870401620864868,
    "cluster_id": -1
  },
  {
    "feature_id": 490,
    "explanation_index": 1,
    "text": "Verbs related to movement or transfer of people, objects, or abstract concepts, often followed by directional or locative complements, with high activation on the verb and its direct object or destination.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9420262177785238,
    "similarity_var": 1.8999098847258563e-05,
    "score_fuzz": 0.79,
    "score_detection": 0.49,
    "score_embedding": 0.734375,
    "total_score": 0.6714583333333334,
    "x": 10.980721473693848,
    "y": -1.0314935445785522,
    "cluster_id": -1
  },
  {
    "feature_id": 490,
    "explanation_index": 2,
    "text": "The highlighted tokens are verbs that describe movement or transfer, often paired with prepositions indicating direction or accompaniment.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9420262177785238,
    "similarity_var": 1.8999098847258563e-05,
    "score_fuzz": 0.775,
    "score_detection": 0.4,
    "score_embedding": 0.665,
    "total_score": 0.6133333333333334,
    "x": 14.454605102539062,
    "y": 3.377741813659668,
    "cluster_id": -1
  },
  {
    "feature_id": 491,
    "explanation_index": 0,
    "text": "Tokens often represent proper nouns, technical terms, or common words in various contexts, including scientific, geographical, and everyday language.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8598592480023702,
    "similarity_var": 0.0007161951863502561,
    "score_fuzz": 0.69,
    "score_detection": 0.66,
    "score_embedding": 0.3188,
    "total_score": 0.5562666666666667,
    "x": 10.244063377380371,
    "y": 4.321993350982666,
    "cluster_id": 1
  },
  {
    "feature_id": 491,
    "explanation_index": 1,
    "text": "Partial or fragmented words, often at the end of a token, that are part of compound terms, proper names, or technical vocabulary, with activation patterns suggesting recognition of morphological or lexical fragments.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8598592480023702,
    "similarity_var": 0.0007161951863502561,
    "score_fuzz": 0.32,
    "score_detection": 0.3,
    "score_embedding": 0.39062500000000006,
    "total_score": 0.33687500000000004,
    "x": 7.077808856964111,
    "y": 2.82318115234375,
    "cluster_id": 15
  },
  {
    "feature_id": 491,
    "explanation_index": 2,
    "text": "The model\u2019s activations consistently target subword fragments that belong to larger words, often capturing prefixes or suffixes, indicating that the latent representation is sensitive to morphological subunits rather than whole words.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8598592480023702,
    "similarity_var": 0.0007161951863502561,
    "score_fuzz": 0.45,
    "score_detection": 0.4,
    "score_embedding": 0.41625,
    "total_score": 0.42208333333333337,
    "x": 8.021185874938965,
    "y": 3.256819725036621,
    "cluster_id": 76
  },
  {
    "feature_id": 493,
    "explanation_index": 0,
    "text": "Names of sports, leisure activities, and related nouns, often in the context of tourism, events, or establishments.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8251421054204305,
    "similarity_var": 0.0017042956282967085,
    "score_fuzz": 0.8,
    "score_detection": 0.8,
    "score_embedding": 0.4752,
    "total_score": 0.6917333333333334,
    "x": 8.164041519165039,
    "y": -0.4410240352153778,
    "cluster_id": -1
  },
  {
    "feature_id": 493,
    "explanation_index": 1,
    "text": "The word \\\"golf\\\" frequently appears in contexts related to sports, venues, equipment, or events, often as part of compound terms like \\\"golf course,\\\" \\\"golf cart,\\\" or \\\"golf club,\\\" and is typically associated with recreational or competitive activities.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8251421054204305,
    "similarity_var": 0.0017042956282967085,
    "score_fuzz": 0.67,
    "score_detection": 0.67,
    "score_embedding": 0.7943749999999999,
    "total_score": 0.7114583333333333,
    "x": 8.19288444519043,
    "y": -0.35193732380867004,
    "cluster_id": -1
  },
  {
    "feature_id": 493,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8251421054204305,
    "similarity_var": 0.0017042956282967085,
    "score_fuzz": 0.525,
    "score_detection": 0.5,
    "score_embedding": 0.6318750000000001,
    "total_score": 0.5522916666666666,
    "x": -5.949594974517822,
    "y": 15.959253311157227,
    "cluster_id": 10
  },
  {
    "feature_id": 494,
    "explanation_index": 0,
    "text": "Function words and articles, as well as nouns representing organizations, companies, and individuals, often serving to introduce or connect clauses, and sometimes indicating possession or association.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8197419842084249,
    "similarity_var": 0.0008573088390883124,
    "score_fuzz": 0.47,
    "score_detection": 0.46,
    "score_embedding": 0.4072,
    "total_score": 0.4457333333333333,
    "x": 10.7012300491333,
    "y": 1.1663060188293457,
    "cluster_id": 26
  },
  {
    "feature_id": 494,
    "explanation_index": 1,
    "text": "Common function words and phrases such as \\\"to\\\", \\\"and\\\", \\\"that\\\", \\\"is\\\", \\\"from\\\", \\\"it\\\", \\\"they\\\", \\\"we\\\", \\\"she\\\", \\\"you\\\", \\\"er\\\", \\\"the\\\", \\\"a\\\", \\\"in\\\", \\\"on\\\", \\\"of\\\", \\\"with\\\", \\\"for\\\", \\\"as\\\", \\\"by\\\", \\\"at\\\", \\\"about\\\", \\\"into\\\", \\\"out\\\", \\\"up\\\", \\\"down\\\", \\\"over\\\", \\\"under\\\", \\\"between\\\", \\\"among\\\", \\\"through\\\", \\\"during\\\", \\\"before\\\", \\\"after\\\", \\\"since\\\", \\\"until\\\", \\\"while\\\", \\\"when\\\", \\\"where\\\", \\\"why\\\", \\\"how\\\", \\\"what\\\", \\\"who\\\", \\\"whom\\\", \\\"whose\\\", \\\"which\\\", \\\"whether\\\", \\\"if\\\", \\\"unless\\\", \\\"although\\\", \\\"though\\\", \\\"even though\\\", \\\"despite\\\", \\\"in spite of\\\", \\\"regardless of\\\", \\\"instead of\\\", \\\"rather than\\\", \\\"due to\\\", \\\"because of\\\", \\\"owing to\\\", \\\"thanks to\\\", \\\"in order to\\\", \\\"so that\\\", \\\"in case\\\", \\\"provided that\\\", \\\"as long as\\\", \\\"as soon as\\\", \\\"once\\\", \\\"after\\\", \\\"before\\\", \\\"until\\\", \\\"while\\\", \\\"since\\\", \\\"when\\\", \\\"where\\\", \\\"why\\\", \\\"how\\\", \\\"what\\\", \\\"who\\\", \\\"whom\\\", \\\"whose\\\", \\\"which\\\", \\\"whether\\\", \\\"if\\\", \\\"unless\\\", \\\"although\\\", \\\"though\\\", \\\"even though\\\", \\\"despite\\\", \\\"in spite of\\\", \\\"regardless of\\\", \\\"instead of\\\", \\\"rather than\\\", \\\"due to\\\", \\\"because of\\\", \\\"owing to\\\", \\\"thanks to\\\", \\\"in order to\\\", \\\"so that\\\", \\\"in case\\\", \\\"provided that\\\", \\\"as long as\\\", \\\"as soon as\\\", \\\"once\\\", \\\"after\\\", \\\"before\\\", \\\"until\\\", \\\"while\\\", \\\"since\\\", \\\"when\\\", \\\"where\\\", \\\"why\\\", \\\"how\\\", \\\"what\\\", \\\"who\\\", \\\"whom\\\", \\\"whose\\\", \\\"which\\\", \\\"whether\\\", \\\"if\\\", \\\"unless\\\", \\\"although\\\", \\\"though\\\", \\\"even though\\\", \\\"despite\\\", \\\"in spite of\\\", \\\"regardless of\\\", \\\"instead of\\\", \\\"rather than\\\", \\\"due to\\\", \\\"because of\\\", \\\"owing to\\\", \\\"thanks to\\\", \\\"in order to\\\", \\\"so that\\\", \\\"in case\\\", \\\"provided that\\\", \\\"as long as\\\", \\\"as soon as\\\", \\\"once\\\", \\\"after",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8197419842084249,
    "similarity_var": 0.0008573088390883124,
    "score_fuzz": 0.6,
    "score_detection": 0.52,
    "score_embedding": 0.438125,
    "total_score": 0.519375,
    "x": 11.059505462646484,
    "y": 3.211331844329834,
    "cluster_id": -1
  },
  {
    "feature_id": 494,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8197419842084249,
    "similarity_var": 0.0008573088390883124,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.3275,
    "total_score": 0.44250000000000006,
    "x": -5.8763532638549805,
    "y": 16.03244972229004,
    "cluster_id": 10
  },
  {
    "feature_id": 495,
    "explanation_index": 0,
    "text": "Prepositions indicating movement, transition, or relation, often used to connect clauses or phrases, and sometimes used to indicate time or manner.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8654473423957825,
    "similarity_var": 0.0027509515703130205,
    "score_fuzz": 0.75,
    "score_detection": 0.47,
    "score_embedding": 0.3476,
    "total_score": 0.5225333333333334,
    "x": 12.087600708007812,
    "y": -0.20783387124538422,
    "cluster_id": 39
  },
  {
    "feature_id": 495,
    "explanation_index": 1,
    "text": "Prepositions and conjunctions indicating direction, method, or contrast, often used in spatial, temporal, or causal relationships.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8654473423957825,
    "similarity_var": 0.0027509515703130205,
    "score_fuzz": 0.75,
    "score_detection": 0.46,
    "score_embedding": 0.26,
    "total_score": 0.49,
    "x": 12.031805992126465,
    "y": -0.2713913023471832,
    "cluster_id": 39
  },
  {
    "feature_id": 495,
    "explanation_index": 2,
    "text": "The highlighted tokens are typically short, function words or brief nouns that serve as the core of a phrase, indicating relationships, locations, or specific entities, and thus carry the main semantic load of the sentence.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8654473423957825,
    "similarity_var": 0.0027509515703130205,
    "score_fuzz": 0.75,
    "score_detection": 0.425,
    "score_embedding": 0.360625,
    "total_score": 0.511875,
    "x": 14.357393264770508,
    "y": 4.054172992706299,
    "cluster_id": -1
  },
  {
    "feature_id": 496,
    "explanation_index": 0,
    "text": "Technical terms and names of laboratory techniques, equipment, and materials, often used in scientific and medical contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9137208660443624,
    "similarity_var": 0.0002871692885746155,
    "score_fuzz": 0.69,
    "score_detection": 0.48,
    "score_embedding": 0.642,
    "total_score": 0.604,
    "x": 7.262332916259766,
    "y": 1.2009820938110352,
    "cluster_id": 25
  },
  {
    "feature_id": 496,
    "explanation_index": 1,
    "text": "Technical terms related to laboratory procedures, biochemical assays, and analytical methods, often involving specific instruments, reagents, or measurement techniques.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9137208660443624,
    "similarity_var": 0.0002871692885746155,
    "score_fuzz": 0.68,
    "score_detection": 0.55,
    "score_embedding": 0.775,
    "total_score": 0.6683333333333333,
    "x": 7.253641605377197,
    "y": 1.212015151977539,
    "cluster_id": 25
  },
  {
    "feature_id": 496,
    "explanation_index": 2,
    "text": "The highlighted tokens are domain\u2011specific terms that refer to laboratory procedures, instruments, and analytical steps, which recur across the examples.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9137208660443624,
    "similarity_var": 0.0002871692885746155,
    "score_fuzz": 0.8,
    "score_detection": 0.775,
    "score_embedding": 0.730625,
    "total_score": 0.7685416666666667,
    "x": 13.653337478637695,
    "y": 4.64900541305542,
    "cluster_id": -1
  },
  {
    "feature_id": 497,
    "explanation_index": 0,
    "text": "Verbs related to perception, understanding, or visualization, often used to express a point of view or to introduce a new idea.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9094129006067911,
    "similarity_var": 9.912426147767267e-05,
    "score_fuzz": 0.88,
    "score_detection": 0.74,
    "score_embedding": 0.2612,
    "total_score": 0.6270666666666668,
    "x": 10.311433792114258,
    "y": -1.287601113319397,
    "cluster_id": 23
  },
  {
    "feature_id": 497,
    "explanation_index": 1,
    "text": "Verbs related to perception or awareness, particularly \\\"see\\\", \\\"seen\\\", \\\"seeing\\\", \\\"saw\\\", and related forms, are frequently activated when describing observation, understanding, or recognition, often in contexts involving personal insight, visual perception, or acknowledgment of a situation.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9094129006067911,
    "similarity_var": 9.912426147767267e-05,
    "score_fuzz": 0.9,
    "score_detection": 0.86,
    "score_embedding": 0.181875,
    "total_score": 0.6472916666666667,
    "x": 10.338335037231445,
    "y": -1.3474136590957642,
    "cluster_id": 23
  },
  {
    "feature_id": 497,
    "explanation_index": 2,
    "text": "The highlighted tokens are all forms of the verb \u201csee\u201d (and occasionally \u201cVision\u201d), indicating a focus on observation or perception.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9094129006067911,
    "similarity_var": 9.912426147767267e-05,
    "score_fuzz": 0.925,
    "score_detection": 0.85,
    "score_embedding": 0.1125,
    "total_score": 0.6291666666666667,
    "x": 14.669062614440918,
    "y": 3.7024643421173096,
    "cluster_id": -1
  },
  {
    "feature_id": 499,
    "explanation_index": 0,
    "text": "Verbs or verb phrases indicating actions, states, or events that have occurred or will occur, often in relation to the subject's past or future experiences, and sometimes used in idiomatic expressions or to convey a sense of change or progression.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8701212406158447,
    "similarity_var": 0.00028777178013920474,
    "score_fuzz": 0.6842105263157895,
    "score_detection": 0.57,
    "score_embedding": 0.4964,
    "total_score": 0.5835368421052631,
    "x": 10.679536819458008,
    "y": -0.821081280708313,
    "cluster_id": 14
  },
  {
    "feature_id": 499,
    "explanation_index": 1,
    "text": "Common phrasal constructions involving temporal or modal expressions, often indicating past experiences, habitual actions, or hypothetical conditions, with high activation on function words like \\\"to\\\", \\\"never\\\", \\\"before\\\", \\\"ever\\\", \\\"up\\\", \\\"out\\\", and \\\"at\\\", and on key content words that complete idiomatic or grammatical structures.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8701212406158447,
    "similarity_var": 0.00028777178013920474,
    "score_fuzz": 0.78,
    "score_detection": 0.66,
    "score_embedding": 0.685625,
    "total_score": 0.7085416666666666,
    "x": 10.850008010864258,
    "y": 1.5475293397903442,
    "cluster_id": -1
  },
  {
    "feature_id": 499,
    "explanation_index": 2,
    "text": "The highlighted words are short function tokens that frequently appear in common collocations expressing time, experience, or direction (e.g., \u201cnever before,\u201d \u201cever before,\u201d \u201cto find,\u201d \u201cto return,\u201d \u201cto see\u201d). They serve as connectors that frame the surrounding content, indicating temporal or experiential context.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8701212406158447,
    "similarity_var": 0.00028777178013920474,
    "score_fuzz": 0.6,
    "score_detection": 0.625,
    "score_embedding": 0.648125,
    "total_score": 0.624375,
    "x": 13.812925338745117,
    "y": 3.9380104541778564,
    "cluster_id": 42
  },
  {
    "feature_id": 501,
    "explanation_index": 0,
    "text": "Words conveying bravery, fearlessness, and boldness, often describing actions, behaviors, or qualities of individuals.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9191675186157227,
    "similarity_var": 0.000367828660422731,
    "score_fuzz": 0.85,
    "score_detection": 0.69,
    "score_embedding": 0.7956,
    "total_score": 0.7785333333333333,
    "x": 9.26840877532959,
    "y": 1.1480904817581177,
    "cluster_id": -1
  },
  {
    "feature_id": 501,
    "explanation_index": 1,
    "text": "The text latents frequently involve words related to bravery, courage, and boldness, often appearing in contexts emphasizing moral or physical valor, with recurring morphological variants like \\\"-ous\\\", \\\"-ly\\\", \\\"-er\\\", and truncations of root words (e.g., \\\"bra\\\", \\\"bold\\\", \\\"dare\\\") that signal these traits.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9191675186157227,
    "similarity_var": 0.000367828660422731,
    "score_fuzz": 0.88,
    "score_detection": 0.76,
    "score_embedding": 0.649375,
    "total_score": 0.763125,
    "x": 9.896196365356445,
    "y": 0.8938954472541809,
    "cluster_id": -1
  },
  {
    "feature_id": 501,
    "explanation_index": 2,
    "text": "The highlighted fragments are parts of words that collectively signal traits of bravery, boldness, or daring\u2014synonyms such as courage, brave, bold, daring, and related terms.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9191675186157227,
    "similarity_var": 0.000367828660422731,
    "score_fuzz": 0.9,
    "score_detection": 0.675,
    "score_embedding": 0.7568750000000001,
    "total_score": 0.7772916666666667,
    "x": 15.784802436828613,
    "y": 7.393375396728516,
    "cluster_id": 19
  },
  {
    "feature_id": 503,
    "explanation_index": 0,
    "text": "Prefixes or words that are part of a compound word or phrase, often indicating a relationship, direction, or characteristic.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8680846293767294,
    "similarity_var": 0.0004996839267840237,
    "score_fuzz": 0.51,
    "score_detection": 0.43,
    "score_embedding": 0.2768,
    "total_score": 0.40559999999999996,
    "x": 8.240851402282715,
    "y": 2.1085903644561768,
    "cluster_id": 44
  },
  {
    "feature_id": 503,
    "explanation_index": 1,
    "text": "Commonly activated tokens include suffixes like \\\"er\\\", \\\"ing\\\", \\\"ly\\\", and \\\"able\\\", as well as function words like \\\"the\\\", \\\"to\\\", \\\"this\\\", \\\"that\\\", and \\\"what\\\", often appearing in comparative, descriptive, or explanatory contexts. Many activations cluster around compound or multi-syllabic words where partial segments (e.g., \\\"mis\\\", \\\"stere\\\", \\\"endos\\\", \\\"cination\\\") are individually significant, suggesting that morphological subunits of complex words are important for semantic interpretation. Additionally, common phrases like \\\"according to\\\", \\\"contrary to\\\", \\\"in the\\\", and \\\"this sort of\\\" frequently appear, indicating that functional and idiomatic expressions are key to contextual understanding.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8680846293767294,
    "similarity_var": 0.0004996839267840237,
    "score_fuzz": 0.62,
    "score_detection": 0.56,
    "score_embedding": 0.33999999999999997,
    "total_score": 0.5066666666666667,
    "x": 10.19581413269043,
    "y": 2.9918856620788574,
    "cluster_id": -1
  },
  {
    "feature_id": 503,
    "explanation_index": 2,
    "text": "The highlighted fragments are the core semantic units\u2014roots, suffixes, or whole words\u2014that carry the main meaning of a phrase or word, often appearing in idioms or common collocations, and are the most informative for the model\u2019s activation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8680846293767294,
    "similarity_var": 0.0004996839267840237,
    "score_fuzz": 0.75,
    "score_detection": 0.25,
    "score_embedding": 0.3725,
    "total_score": 0.4575,
    "x": 15.784887313842773,
    "y": 7.231645107269287,
    "cluster_id": -1
  },
  {
    "feature_id": 504,
    "explanation_index": 0,
    "text": "Specialized tokens often representing class names, function names, or variable names in programming languages, typically following camel case or underscore notation conventions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9040251970291138,
    "similarity_var": 0.0007638664498112272,
    "score_fuzz": 0.51,
    "score_detection": 0.53,
    "score_embedding": 0.62,
    "total_score": 0.5533333333333333,
    "x": 10.826417922973633,
    "y": 6.056346416473389,
    "cluster_id": 18
  },
  {
    "feature_id": 504,
    "explanation_index": 1,
    "text": "Tokens containing identifiers with embedded underscores, often representing class names, function names, or variable names in programming contexts, where the underscore is used to separate parts of a compound identifier.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9040251970291138,
    "similarity_var": 0.0007638664498112272,
    "score_fuzz": 0.6,
    "score_detection": 0.59,
    "score_embedding": 0.6006250000000001,
    "total_score": 0.5968749999999999,
    "x": 10.827518463134766,
    "y": 6.076103687286377,
    "cluster_id": 18
  },
  {
    "feature_id": 504,
    "explanation_index": 2,
    "text": "The highlighted fragments are meaningful substrings of code identifiers\u2014suffixes, prefixes, or internal parts\u2014that signal a class, method, or variable\u2019s role or type (e.g., \u201cImpl\u201d, \u201cError\u201d, \u201cRenderer\u201d, \u201cgetTime\u201d).",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9040251970291138,
    "similarity_var": 0.0007638664498112272,
    "score_fuzz": 0.65,
    "score_detection": 0.625,
    "score_embedding": 0.6,
    "total_score": 0.625,
    "x": 15.148253440856934,
    "y": 7.244283676147461,
    "cluster_id": -1
  },
  {
    "feature_id": 507,
    "explanation_index": 0,
    "text": "Punctuation marks and special characters, often used to denote code, formatting, or other non-text elements, as well as some common function words and articles.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8904234965642294,
    "similarity_var": 0.00013946029181571222,
    "score_fuzz": 0.45,
    "score_detection": 0.32,
    "score_embedding": 0.276,
    "total_score": 0.3486666666666667,
    "x": 8.641185760498047,
    "y": 7.183380126953125,
    "cluster_id": 4
  },
  {
    "feature_id": 507,
    "explanation_index": 1,
    "text": "Commonly activated tokens include punctuation, whitespace, and low-frequency words or symbols that often appear in syntactic or structural contexts, such as delimiters, formatting markers, or grammatical elements, with minimal semantic weight but high structural importance.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8904234965642294,
    "similarity_var": 0.00013946029181571222,
    "score_fuzz": 0.53,
    "score_detection": 0.37,
    "score_embedding": 0.415625,
    "total_score": 0.43854166666666666,
    "x": 10.19017219543457,
    "y": 3.542557954788208,
    "cluster_id": 41
  },
  {
    "feature_id": 507,
    "explanation_index": 2,
    "text": "The highlighted tokens are usually short, common function words that act as grammatical glue\u2014often the first word of a phrase or clause\u2014rather than content words.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8904234965642294,
    "similarity_var": 0.00013946029181571222,
    "score_fuzz": 0.5,
    "score_detection": 0.7,
    "score_embedding": 0.44062500000000004,
    "total_score": 0.546875,
    "x": 13.781487464904785,
    "y": 3.441277503967285,
    "cluster_id": 35
  },
  {
    "feature_id": 508,
    "explanation_index": 0,
    "text": "Nouns or adjectives representing medical or scientific terms, often related to anatomy, physiology, or pathology, and sometimes part of a larger phrase or concept.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9009170730908712,
    "similarity_var": 0.00023833753496739341,
    "score_fuzz": 0.57,
    "score_detection": 0.49,
    "score_embedding": 0.3572,
    "total_score": 0.4724,
    "x": 7.510706901550293,
    "y": 1.148410439491272,
    "cluster_id": 25
  },
  {
    "feature_id": 508,
    "explanation_index": 1,
    "text": "Fragmented medical terminology, often derived from compound or root words, where partial tokens (e.g., \\\"arth\\\", \\\"hip\\\", \\\"patho\\\", \\\"oste\\\") are activated due to their role in forming specialized anatomical, physiological, or pathological terms.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9009170730908712,
    "similarity_var": 0.00023833753496739341,
    "score_fuzz": 0.48,
    "score_detection": 0.47,
    "score_embedding": 0.38625,
    "total_score": 0.4454166666666666,
    "x": 7.611279487609863,
    "y": 2.4461052417755127,
    "cluster_id": -1
  },
  {
    "feature_id": 508,
    "explanation_index": 2,
    "text": "The highlighted fragments are sub\u2011word pieces that together form medical terms or common phrases; the activations indicate which pieces are most salient within each context.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9009170730908712,
    "similarity_var": 0.00023833753496739341,
    "score_fuzz": 0.35,
    "score_detection": 0.525,
    "score_embedding": 0.39249999999999996,
    "total_score": 0.42250000000000004,
    "x": 15.760416030883789,
    "y": 7.350094318389893,
    "cluster_id": 19
  },
  {
    "feature_id": 509,
    "explanation_index": 0,
    "text": "Geometric shapes and terms related to spatial relationships and mathematical concepts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8615451057751974,
    "similarity_var": 0.00021390451009592777,
    "score_fuzz": 0.65,
    "score_detection": 0.46,
    "score_embedding": 0.4556,
    "total_score": 0.5218666666666667,
    "x": 7.9104180335998535,
    "y": 0.27162057161331177,
    "cluster_id": -1
  },
  {
    "feature_id": 509,
    "explanation_index": 1,
    "text": "Fragments of geometric or mathematical terms, often derived from Greek roots, that appear in technical or scientific contexts, particularly in geometry, topology, and algorithmic descriptions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8615451057751974,
    "similarity_var": 0.00021390451009592777,
    "score_fuzz": 0.53,
    "score_detection": 0.31,
    "score_embedding": 0.37437499999999996,
    "total_score": 0.40479166666666666,
    "x": 7.3515706062316895,
    "y": 2.2814719676971436,
    "cluster_id": -1
  },
  {
    "feature_id": 509,
    "explanation_index": 2,
    "text": "The highlighted fragments are the core nouns or adjectives that make up technical or descriptive phrases\u2014often shape or mathematical terms, compound words, or key descriptors that carry the main semantic load of the sentence.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8615451057751974,
    "similarity_var": 0.00021390451009592777,
    "score_fuzz": 0.75,
    "score_detection": 0.55,
    "score_embedding": 0.416875,
    "total_score": 0.5722916666666666,
    "x": 15.810471534729004,
    "y": 7.337676525115967,
    "cluster_id": 19
  },
  {
    "feature_id": 511,
    "explanation_index": 0,
    "text": "Names of software, programming languages, technologies, and technical terms, often denoted as proper nouns or specific identifiers.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.900025208791097,
    "similarity_var": 4.799517552416749e-05,
    "score_fuzz": 0.69,
    "score_detection": 0.53,
    "score_embedding": 0.55,
    "total_score": 0.59,
    "x": 7.623885154724121,
    "y": -0.3131355345249176,
    "cluster_id": -1
  },
  {
    "feature_id": 511,
    "explanation_index": 1,
    "text": "Tokens containing technical or project-specific identifiers, often part of file paths, software versions, or code-related terms, frequently appear in programming or development contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.900025208791097,
    "similarity_var": 4.799517552416749e-05,
    "score_fuzz": 0.56,
    "score_detection": 0.55,
    "score_embedding": 0.669375,
    "total_score": 0.593125,
    "x": 10.870442390441895,
    "y": 6.137870788574219,
    "cluster_id": 18
  },
  {
    "feature_id": 511,
    "explanation_index": 2,
    "text": "The highlighted tokens are domain\u2011specific nouns, identifiers, or technical terms that serve as the semantic anchors in code, configuration, or documentation, often appearing as proper nouns, hyphenated names, or symbols.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.900025208791097,
    "similarity_var": 4.799517552416749e-05,
    "score_fuzz": 0.75,
    "score_detection": 0.625,
    "score_embedding": 0.6262500000000001,
    "total_score": 0.6670833333333334,
    "x": 13.863699913024902,
    "y": 4.620591640472412,
    "cluster_id": -1
  },
  {
    "feature_id": 512,
    "explanation_index": 0,
    "text": "Proper nouns, often referring to names of people, places, or nationalities.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8355742494265238,
    "similarity_var": 0.0027265525418024416,
    "score_fuzz": 0.81,
    "score_detection": 0.49,
    "score_embedding": 0.6199999999999999,
    "total_score": 0.64,
    "x": 7.413411617279053,
    "y": -0.9669461846351624,
    "cluster_id": 16
  },
  {
    "feature_id": 512,
    "explanation_index": 1,
    "text": "Proper nouns, particularly personal names and place names, are frequently activated in context, with higher activation when they appear in specific cultural, geographic, or institutional references.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8355742494265238,
    "similarity_var": 0.0027265525418024416,
    "score_fuzz": 0.72,
    "score_detection": 0.45,
    "score_embedding": 0.494375,
    "total_score": 0.5547916666666667,
    "x": 7.120941638946533,
    "y": -1.0837708711624146,
    "cluster_id": 40
  },
  {
    "feature_id": 512,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8355742494265238,
    "similarity_var": 0.0027265525418024416,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.634375,
    "total_score": 0.5447916666666667,
    "x": -7.903757572174072,
    "y": 9.156538963317871,
    "cluster_id": 52
  },
  {
    "feature_id": 514,
    "explanation_index": 0,
    "text": "Prepositions and articles often precede nouns, while adjectives often precede nouns they describe, and sometimes words that indicate a relationship or possession are used.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.851286768913269,
    "similarity_var": 2.2451254189093106e-05,
    "score_fuzz": 0.56,
    "score_detection": 0.45,
    "score_embedding": 0.32720000000000005,
    "total_score": 0.44573333333333337,
    "x": 13.000260353088379,
    "y": 0.2531445622444153,
    "cluster_id": 43
  },
  {
    "feature_id": 514,
    "explanation_index": 1,
    "text": "Commonly activated tokens include function words like \\\"of\\\", \\\"to\\\", \\\"for\\\", \\\"and\\\", \\\"the\\\", and \\\"s\\\", as well as adjectives and nouns that describe abstract or concrete attributes, often in compound or descriptive phrases, particularly in academic, cultural, or descriptive contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.851286768913269,
    "similarity_var": 2.2451254189093106e-05,
    "score_fuzz": 0.55,
    "score_detection": 0.44,
    "score_embedding": 0.260625,
    "total_score": 0.41687499999999994,
    "x": 10.257954597473145,
    "y": 3.213036298751831,
    "cluster_id": 50
  },
  {
    "feature_id": 514,
    "explanation_index": 2,
    "text": "The highlighted words are the core lexical elements of phrases\u2014usually nouns, adjectives, or prepositions\u2014that carry the main semantic content or form idiomatic collocations.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.851286768913269,
    "similarity_var": 2.2451254189093106e-05,
    "score_fuzz": 0.475,
    "score_detection": 0.2,
    "score_embedding": 0.2625,
    "total_score": 0.3125,
    "x": 16.69359016418457,
    "y": 3.677356243133545,
    "cluster_id": 20
  },
  {
    "feature_id": 515,
    "explanation_index": 0,
    "text": "Verbs and nouns related to construction, architecture, and infrastructure development, often describing the creation or expansion of buildings, facilities, and public spaces.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9005446831385294,
    "similarity_var": 0.0003247464475282729,
    "score_fuzz": 0.71,
    "score_detection": 0.69,
    "score_embedding": 0.6708,
    "total_score": 0.6902666666666666,
    "x": 10.315893173217773,
    "y": -0.6430467367172241,
    "cluster_id": -1
  },
  {
    "feature_id": 515,
    "explanation_index": 1,
    "text": "The token \\\"build\\\" and its inflected forms (e.g., \\\"building\\\", \\\"built\\\", \\\"build a\\\") are frequently activated when describing the construction or development of physical structures, often in contexts involving infrastructure, buildings, or urban planning.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9005446831385294,
    "similarity_var": 0.0003247464475282729,
    "score_fuzz": 0.64,
    "score_detection": 0.69,
    "score_embedding": 0.6400000000000001,
    "total_score": 0.6566666666666667,
    "x": 10.370553016662598,
    "y": 3.2014782428741455,
    "cluster_id": 50
  },
  {
    "feature_id": 515,
    "explanation_index": 2,
    "text": "The highlighted tokens cluster around construction\u2011related verbs and nouns\u2014especially \u201cbuild,\u201d \u201cbuilt,\u201d \u201cbuilding,\u201d and modifiers like \u201cnew\u201d\u2014and are frequently paired with determiners or prepositions (\u201cthe,\u201d \u201cof\u201d) that together form phrases describing a structure or location.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9005446831385294,
    "similarity_var": 0.0003247464475282729,
    "score_fuzz": 0.6571428571428571,
    "score_detection": 0.55,
    "score_embedding": 0.59125,
    "total_score": 0.5994642857142858,
    "x": 13.231690406799316,
    "y": 3.1060147285461426,
    "cluster_id": -1
  },
  {
    "feature_id": 516,
    "explanation_index": 0,
    "text": "Indentation or line breaks in code, often indicating the start or end of a block or function.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9016294876734415,
    "similarity_var": 4.822654764385308e-05,
    "score_fuzz": 0.74,
    "score_detection": 0.57,
    "score_embedding": 0.4272,
    "total_score": 0.5790666666666667,
    "x": 11.354681015014648,
    "y": 7.687068462371826,
    "cluster_id": 81
  },
  {
    "feature_id": 516,
    "explanation_index": 1,
    "text": "The newline character sequence (\\\"\\n\\\") is consistently activated in code formatting and structure, particularly around block delimiters, indentation, and syntactic boundaries in programming languages.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9016294876734415,
    "similarity_var": 4.822654764385308e-05,
    "score_fuzz": 0.74,
    "score_detection": 0.58,
    "score_embedding": 0.4306249999999999,
    "total_score": 0.5835416666666666,
    "x": 9.717315673828125,
    "y": 6.530299663543701,
    "cluster_id": 87
  },
  {
    "feature_id": 516,
    "explanation_index": 2,
    "text": "The key tokens are line\u2011break characters that delimit the code structure.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9016294876734415,
    "similarity_var": 4.822654764385308e-05,
    "score_fuzz": 0.675,
    "score_detection": 0.55,
    "score_embedding": 0.39499999999999996,
    "total_score": 0.54,
    "x": 13.632681846618652,
    "y": 6.468812465667725,
    "cluster_id": 8
  },
  {
    "feature_id": 517,
    "explanation_index": 0,
    "text": "Ordinal numbers, sequence indicators, and other terms denoting position or order, often used to specify a particular item or step in a series.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8011028369267782,
    "similarity_var": 0.00123852709229608,
    "score_fuzz": 0.9,
    "score_detection": 0.74,
    "score_embedding": 0.19240000000000002,
    "total_score": 0.6108000000000001,
    "x": 7.2548627853393555,
    "y": 8.66385269165039,
    "cluster_id": 29
  },
  {
    "feature_id": 517,
    "explanation_index": 1,
    "text": "The token \\\"first\\\" is frequently used to denote initial occurrence or sequence, often in contexts involving order, timing, or progression, and is typically activated in phrases indicating primacy or beginning.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8011028369267782,
    "similarity_var": 0.00123852709229608,
    "score_fuzz": 0.7,
    "score_detection": 0.74,
    "score_embedding": 0.37312500000000004,
    "total_score": 0.604375,
    "x": 9.419824600219727,
    "y": 6.3745269775390625,
    "cluster_id": -1
  },
  {
    "feature_id": 517,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8011028369267782,
    "similarity_var": 0.00123852709229608,
    "score_fuzz": 0.525,
    "score_detection": 0.5,
    "score_embedding": 0.08812500000000001,
    "total_score": 0.37104166666666666,
    "x": -7.963806629180908,
    "y": 9.096468925476074,
    "cluster_id": 52
  },
  {
    "feature_id": 518,
    "explanation_index": 0,
    "text": "Proper nouns, technical terms, and common nouns representing concepts, objects, or actions, often in formal or specialized contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8730722069740295,
    "similarity_var": 0.0005427568234802985,
    "score_fuzz": 0.64,
    "score_detection": 0.42,
    "score_embedding": 0.5336,
    "total_score": 0.5312,
    "x": 8.033225059509277,
    "y": -0.471732497215271,
    "cluster_id": -1
  },
  {
    "feature_id": 518,
    "explanation_index": 1,
    "text": "Tokens that are part of compound words, proper nouns, or technical terms, often appearing in contexts involving specific domains like science, technology, or formal writing, with higher activation values when they form meaningful units within a larger term or concept.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8730722069740295,
    "similarity_var": 0.0005427568234802985,
    "score_fuzz": 0.58,
    "score_detection": 0.42,
    "score_embedding": 0.47375,
    "total_score": 0.49124999999999996,
    "x": 10.1417818069458,
    "y": 4.1411638259887695,
    "cluster_id": -1
  },
  {
    "feature_id": 518,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core content words\u2014usually nouns, verbs, or key adjectives\u2014that form the semantic nucleus of a phrase or named entity, and thus carry the main meaning of the surrounding text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8730722069740295,
    "similarity_var": 0.0005427568234802985,
    "score_fuzz": 0.675,
    "score_detection": 0.325,
    "score_embedding": 0.5206250000000001,
    "total_score": 0.5068750000000001,
    "x": 15.44578742980957,
    "y": 4.019021034240723,
    "cluster_id": 22
  },
  {
    "feature_id": 520,
    "explanation_index": 0,
    "text": "A single character, often \\\"Q\\\", used as a variable or identifier in various contexts, including programming, mathematics, and scientific notation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8846565286318461,
    "similarity_var": 0.0004542302062454774,
    "score_fuzz": 0.7684210526315789,
    "score_detection": 0.53,
    "score_embedding": 0.3156,
    "total_score": 0.5380070175438596,
    "x": 9.026741027832031,
    "y": 7.519504547119141,
    "cluster_id": 68
  },
  {
    "feature_id": 520,
    "explanation_index": 1,
    "text": "The token \\\"Q\\\" and similar symbols (like \\\"q\\\", \\\"X\\\", \\\"Y\\\", \\\"PQ\\\", \\\"0\\\", \\\"/\\\") frequently appear in technical, programming, or mathematical contexts, often as placeholders, variable names, or syntax markers in code, equations, or configuration files. Their activation patterns suggest they are used to denote abstract or symbolic elements in structured text, particularly in code snippets, mathematical expressions, or system configurations.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8846565286318461,
    "similarity_var": 0.0004542302062454774,
    "score_fuzz": 0.68,
    "score_detection": 0.42,
    "score_embedding": 0.330625,
    "total_score": 0.476875,
    "x": 9.476125717163086,
    "y": 7.254725456237793,
    "cluster_id": -1
  },
  {
    "feature_id": 520,
    "explanation_index": 2,
    "text": "The highlighted items are short, non\u2011lexical symbols\u2014single letters or brief abbreviations\u2014that act as placeholders or variable names in code, equations, or technical prose, and thus carry high semantic weight in the surrounding context.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8846565286318461,
    "similarity_var": 0.0004542302062454774,
    "score_fuzz": 0.8571428571428571,
    "score_detection": 0.5,
    "score_embedding": 0.391875,
    "total_score": 0.5830059523809524,
    "x": 13.946843147277832,
    "y": 6.007621765136719,
    "cluster_id": -1
  },
  {
    "feature_id": 521,
    "explanation_index": 0,
    "text": "Double quotation marks often used to denote the start or end of a quotation, a code snippet, or a section of text.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8403228918711344,
    "similarity_var": 8.177237649281071e-06,
    "score_fuzz": 0.74,
    "score_detection": 0.65,
    "score_embedding": 0.402,
    "total_score": 0.5973333333333334,
    "x": 8.346126556396484,
    "y": 6.833816051483154,
    "cluster_id": 36
  },
  {
    "feature_id": 521,
    "explanation_index": 1,
    "text": "The newline character (\\\"\\n\\\") frequently appears in structured or formatted text, often separating logical blocks such as code, sections, or lines in documentation, and is highly activated in contexts involving syntax, formatting, or text segmentation.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8403228918711344,
    "similarity_var": 8.177237649281071e-06,
    "score_fuzz": 0.88,
    "score_detection": 0.72,
    "score_embedding": 0.36812500000000004,
    "total_score": 0.6560416666666667,
    "x": 9.771819114685059,
    "y": 6.590490341186523,
    "cluster_id": 87
  },
  {
    "feature_id": 521,
    "explanation_index": 2,
    "text": "The highlighted tokens are primarily non\u2011word characters that mark structural or formatting boundaries\u2014such as quotation marks, newlines, braces, punctuation, and whitespace\u2014rather than content words.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8403228918711344,
    "similarity_var": 8.177237649281071e-06,
    "score_fuzz": 0.9142857142857143,
    "score_detection": 0.575,
    "score_embedding": 0.41812499999999997,
    "total_score": 0.6358035714285714,
    "x": 13.934555053710938,
    "y": 5.31952428817749,
    "cluster_id": 62
  },
  {
    "feature_id": 522,
    "explanation_index": 0,
    "text": "Nouns representing concepts, quantities, or characteristics, often in a scientific or technical context.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8630047639211019,
    "similarity_var": 0.00408733869411135,
    "score_fuzz": 0.74,
    "score_detection": 0.42,
    "score_embedding": 0.3044,
    "total_score": 0.4881333333333333,
    "x": 8.031885147094727,
    "y": 0.5924198031425476,
    "cluster_id": -1
  },
  {
    "feature_id": 522,
    "explanation_index": 1,
    "text": "Nouns or noun phrases representing measurable quantities, abstract concepts, or technical terms commonly used in scientific, mathematical, or technical contexts, often appearing in comparative, analytical, or evaluative statements.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8630047639211019,
    "similarity_var": 0.00408733869411135,
    "score_fuzz": 0.69,
    "score_detection": 0.47,
    "score_embedding": 0.265625,
    "total_score": 0.4752083333333333,
    "x": 8.162694931030273,
    "y": 0.6146134734153748,
    "cluster_id": 12
  },
  {
    "feature_id": 522,
    "explanation_index": 2,
    "text": "The highlighted tokens are the most semantically salient words in each sentence\u2014usually nouns or adjectives that carry the core meaning or key content\u2014so the model activates them strongly.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8630047639211019,
    "similarity_var": 0.00408733869411135,
    "score_fuzz": 0.775,
    "score_detection": 0.625,
    "score_embedding": 0.37499999999999994,
    "total_score": 0.5916666666666667,
    "x": 15.097082138061523,
    "y": 4.542797565460205,
    "cluster_id": -1
  },
  {
    "feature_id": 524,
    "explanation_index": 0,
    "text": "Various tokens that appear to be significant in different contexts, including units of measurement, adjectives, nouns, and punctuation marks, often indicating a specific attribute, quantity, or relationship.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9004786213239034,
    "similarity_var": 0.0005389869504842042,
    "score_fuzz": 0.42,
    "score_detection": 0.18,
    "score_embedding": 0.4364,
    "total_score": 0.34546666666666664,
    "x": 10.652750015258789,
    "y": 4.362926483154297,
    "cluster_id": -1
  },
  {
    "feature_id": 524,
    "explanation_index": 1,
    "text": "Commonly activated tokens include comparative suffixes, punctuation marks, proper nouns, and descriptive adjectives, often appearing in contexts involving measurements, time, location, or qualitative attributes.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9004786213239034,
    "similarity_var": 0.0005389869504842042,
    "score_fuzz": 0.29,
    "score_detection": 0.2,
    "score_embedding": 0.41812499999999997,
    "total_score": 0.3027083333333333,
    "x": 10.163457870483398,
    "y": 3.588674783706665,
    "cluster_id": 41
  },
  {
    "feature_id": 524,
    "explanation_index": 2,
    "text": "The activations consistently target content words that serve as key descriptors or modifiers in phrases\u2014often nouns or adjectives\u2014and punctuation that signals clause boundaries, indicating the model\u2019s focus on semantically salient lexical items and structural markers.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9004786213239034,
    "similarity_var": 0.0005389869504842042,
    "score_fuzz": 0.65,
    "score_detection": 0.725,
    "score_embedding": 0.47937500000000005,
    "total_score": 0.618125,
    "x": 13.126338958740234,
    "y": 3.487297534942627,
    "cluster_id": -1
  },
  {
    "feature_id": 526,
    "explanation_index": 0,
    "text": "Verbs or verb phrases expressing ability, capability, or potential, often in the form of modal verbs or verb phrases with \\\"to\\\" or \\\"of\\\".",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.93008025487264,
    "similarity_var": 0.00031110569202357717,
    "score_fuzz": 0.91,
    "score_detection": 0.76,
    "score_embedding": 0.7604,
    "total_score": 0.8101333333333333,
    "x": 10.871724128723145,
    "y": -0.29326173663139343,
    "cluster_id": -1
  },
  {
    "feature_id": 526,
    "explanation_index": 1,
    "text": "The pattern involves modal or ability-related constructions using \\\"able to\\\", \\\"capable of\\\", \\\"can\\\", \\\"could\\\", \\\"unable to\\\", or \\\"to\\\" in contexts indicating potential, capacity, or permission, often preceding or following verbs that express action, function, or capability.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.93008025487264,
    "similarity_var": 0.00031110569202357717,
    "score_fuzz": 0.89,
    "score_detection": 0.84,
    "score_embedding": 0.8575,
    "total_score": 0.8624999999999999,
    "x": 10.986665725708008,
    "y": -0.08483608067035675,
    "cluster_id": -1
  },
  {
    "feature_id": 526,
    "explanation_index": 2,
    "text": "The highlighted tokens are small function words that form common modal or auxiliary verb phrases (e.g., \u201cable to\u201d, \u201ccapable of\u201d, \u201ccan\u201d, \u201calso\u201d, \u201caccurately\u201d, \u201cunable to\u201d, \u201cat\u201d, \u201ct\u201d, \u201call\u201d, \u201cfor\u201d, \u201ccould\u201d), indicating ability, possibility, or adverbial modification.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.93008025487264,
    "similarity_var": 0.00031110569202357717,
    "score_fuzz": 0.825,
    "score_detection": 0.875,
    "score_embedding": 0.8075,
    "total_score": 0.8358333333333333,
    "x": 14.131778717041016,
    "y": 3.541947841644287,
    "cluster_id": 0
  },
  {
    "feature_id": 527,
    "explanation_index": 0,
    "text": "Adjectives or adverbs describing something as level, even, or uniform, often in a physical or spatial sense, and sometimes used in idiomatic expressions or technical contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8524459600448608,
    "similarity_var": 0.0008671858773752206,
    "score_fuzz": 0.78,
    "score_detection": 0.72,
    "score_embedding": 0.6896,
    "total_score": 0.7298666666666667,
    "x": 8.943763732910156,
    "y": 1.3240641355514526,
    "cluster_id": 45
  },
  {
    "feature_id": 527,
    "explanation_index": 1,
    "text": "The word \\\"flat\\\" and its variants (e.g., \\\"flats\\\", \\\"flattening\\\", \\\"flatly\\\") frequently appear in contexts describing physical shape, spatial orientation, or metaphorical simplicity, often associated with surfaces, terrain, or directness of expression.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8524459600448608,
    "similarity_var": 0.0008671858773752206,
    "score_fuzz": 0.71,
    "score_detection": 0.7052631578947368,
    "score_embedding": 0.775625,
    "total_score": 0.7302960526315788,
    "x": 7.802709102630615,
    "y": 0.4041038155555725,
    "cluster_id": -1
  },
  {
    "feature_id": 527,
    "explanation_index": 2,
    "text": "The highlighted tokens are morphological variants of a single lexical root, appearing in different grammatical forms (noun, adjective, adverb, verb, etc.) and often in contexts that reflect the root meaning.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8524459600448608,
    "similarity_var": 0.0008671858773752206,
    "score_fuzz": 0.675,
    "score_detection": 0.725,
    "score_embedding": 0.5203125000000001,
    "total_score": 0.6401041666666667,
    "x": 14.98212718963623,
    "y": 4.087948799133301,
    "cluster_id": 22
  },
  {
    "feature_id": 528,
    "explanation_index": 0,
    "text": "Verbs or adjectives indicating thought processes, assumptions, or conclusions, often used in formal or academic writing to express reasoning, inference, or evaluation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8661636710166931,
    "similarity_var": 0.002241855847055755,
    "score_fuzz": 0.79,
    "score_detection": 0.64,
    "score_embedding": 0.5612,
    "total_score": 0.6637333333333334,
    "x": 10.327298164367676,
    "y": -0.8727660775184631,
    "cluster_id": 14
  },
  {
    "feature_id": 528,
    "explanation_index": 1,
    "text": "Words related to inference, assumption, or judgment, often used in speculative or analytical contexts, with a focus on cognitive or evaluative processes.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8661636710166931,
    "similarity_var": 0.002241855847055755,
    "score_fuzz": 0.81,
    "score_detection": 0.74,
    "score_embedding": 0.7068750000000001,
    "total_score": 0.7522916666666667,
    "x": 9.239021301269531,
    "y": 0.8784435391426086,
    "cluster_id": -1
  },
  {
    "feature_id": 528,
    "explanation_index": 2,
    "text": "The highlighted tokens are verbs or participles that express an action or state, often functioning as part of a clause or phrase, sometimes following a preposition.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8661636710166931,
    "similarity_var": 0.002241855847055755,
    "score_fuzz": 0.625,
    "score_detection": 0.375,
    "score_embedding": 0.326875,
    "total_score": 0.4422916666666667,
    "x": 14.520665168762207,
    "y": 3.364572286605835,
    "cluster_id": -1
  },
  {
    "feature_id": 529,
    "explanation_index": 0,
    "text": "Code snippets from various programming languages, including C, C++, and others, often containing function definitions, conditional statements, and variable declarations.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8591268658638,
    "similarity_var": 0.0006929471123934642,
    "score_fuzz": 0.52,
    "score_detection": 0.47,
    "score_embedding": 0.5843999999999999,
    "total_score": 0.5247999999999999,
    "x": 11.178723335266113,
    "y": 8.68449878692627,
    "cluster_id": 17
  },
  {
    "feature_id": 529,
    "explanation_index": 1,
    "text": "The token sequences often represent syntactic or structural elements in code, such as delimiters, keywords, and identifiers, with high activation on punctuation, braces, parentheses, and identifiers that denote code structure or control flow.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8591268658638,
    "similarity_var": 0.0006929471123934642,
    "score_fuzz": 0.46,
    "score_detection": 0.49,
    "score_embedding": 0.59125,
    "total_score": 0.51375,
    "x": 11.059707641601562,
    "y": 5.631159782409668,
    "cluster_id": 51
  },
  {
    "feature_id": 529,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core semantic units of each fragment\u2014idiomatic phrases in prose and key identifiers, operators, or literals in code\u2014often appearing as contiguous sequences that carry the main meaning of the sentence or statement.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8591268658638,
    "similarity_var": 0.0006929471123934642,
    "score_fuzz": 0.45,
    "score_detection": 0.5,
    "score_embedding": 0.6825,
    "total_score": 0.5441666666666666,
    "x": 15.086718559265137,
    "y": 4.654491424560547,
    "cluster_id": 55
  },
  {
    "feature_id": 530,
    "explanation_index": 0,
    "text": "Verbs that express a relationship, action, or state, often in formal or technical contexts, and tend to be used in a neutral or objective tone.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8883888721466064,
    "similarity_var": 0.0014457277450148354,
    "score_fuzz": 0.9,
    "score_detection": 0.47,
    "score_embedding": 0.5564000000000001,
    "total_score": 0.6421333333333333,
    "x": 10.57682991027832,
    "y": -0.777716338634491,
    "cluster_id": 14
  },
  {
    "feature_id": 530,
    "explanation_index": 1,
    "text": "Verbs and adjectives indicating a relationship, action, or state, often used in formal or technical contexts to describe processes, outcomes, or conditions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8883888721466064,
    "similarity_var": 0.0014457277450148354,
    "score_fuzz": 0.81,
    "score_detection": 0.45,
    "score_embedding": 0.475625,
    "total_score": 0.5785416666666666,
    "x": 10.606146812438965,
    "y": -0.6994292140007019,
    "cluster_id": 14
  },
  {
    "feature_id": 530,
    "explanation_index": 2,
    "text": "The highlighted tokens are verbs that serve as the core predicate of the clause, usually in past or present tense, and carry the main action or state of the sentence.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8883888721466064,
    "similarity_var": 0.0014457277450148354,
    "score_fuzz": 0.825,
    "score_detection": 0.825,
    "score_embedding": 0.6,
    "total_score": 0.75,
    "x": 14.626911163330078,
    "y": 3.363232374191284,
    "cluster_id": -1
  },
  {
    "feature_id": 531,
    "explanation_index": 0,
    "text": "Articles and prepositions, often used to introduce or connect phrases, clauses, or sentences, and sometimes used to indicate possession or relationship.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8642054001490275,
    "similarity_var": 0.00069269320072449,
    "score_fuzz": 0.6,
    "score_detection": 0.38,
    "score_embedding": 0.1288,
    "total_score": 0.3696,
    "x": 12.677536010742188,
    "y": 0.1821436583995819,
    "cluster_id": 57
  },
  {
    "feature_id": 531,
    "explanation_index": 1,
    "text": "The definite article \\\"the\\\" and related phrases like \\\"in the\\\", \\\"this\\\", \\\"above\\\", \\\"more\\\", and \\\"of\\\" are frequently activated in contextually specific, grammatically functional roles, often preceding or following key nouns, clauses, or technical terms, indicating their importance in structuring meaning and coherence in academic and descriptive text.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8642054001490275,
    "similarity_var": 0.00069269320072449,
    "score_fuzz": 0.7,
    "score_detection": 0.4,
    "score_embedding": 0.28375000000000006,
    "total_score": 0.46125,
    "x": 12.630467414855957,
    "y": 0.6649295687675476,
    "cluster_id": 34
  },
  {
    "feature_id": 531,
    "explanation_index": 2,
    "text": "The model consistently flags short, high\u2011frequency function words or key content words that anchor a phrase\u2014often appearing at the start of a clause or phrase\u2014indicating these tokens are crucial for the model\u2019s activation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8642054001490275,
    "similarity_var": 0.00069269320072449,
    "score_fuzz": 0.725,
    "score_detection": 0.45,
    "score_embedding": 0.22874999999999998,
    "total_score": 0.4679166666666667,
    "x": 12.975606918334961,
    "y": 3.332207441329956,
    "cluster_id": 82
  },
  {
    "feature_id": 532,
    "explanation_index": 0,
    "text": "Common nouns, proper nouns, and adjectives, often representing people, places, or objects, and sometimes indicating a transition or a state of being.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8701460162798563,
    "similarity_var": 0.00036410817828485485,
    "score_fuzz": 0.62,
    "score_detection": 0.4,
    "score_embedding": 0.73,
    "total_score": 0.5833333333333334,
    "x": 8.552937507629395,
    "y": -0.5011102557182312,
    "cluster_id": 79
  },
  {
    "feature_id": 532,
    "explanation_index": 1,
    "text": "Commonly activated tokens include proper nouns, common nouns, and function words that appear in contextually specific phrases, often related to people, places, time periods, or descriptive attributes, with a strong presence of compound terms and hyphenated words.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8701460162798563,
    "similarity_var": 0.00036410817828485485,
    "score_fuzz": 0.62,
    "score_detection": 0.54,
    "score_embedding": 0.74375,
    "total_score": 0.6345833333333334,
    "x": 10.171981811523438,
    "y": 3.629490375518799,
    "cluster_id": 41
  },
  {
    "feature_id": 532,
    "explanation_index": 2,
    "text": "The highlighted words consistently capture the central lexical element of a phrase that carries the sentence\u2019s main semantic load\u2014typically a noun, adjective, or key verb, occasionally a function word that anchors that phrase. These tokens are the ones the model flags as most informative for understanding the sentence.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8701460162798563,
    "similarity_var": 0.00036410817828485485,
    "score_fuzz": 0.525,
    "score_detection": 0.55,
    "score_embedding": 0.6637500000000001,
    "total_score": 0.5795833333333335,
    "x": 16.25107192993164,
    "y": 3.8021085262298584,
    "cluster_id": -1
  },
  {
    "feature_id": 533,
    "explanation_index": 0,
    "text": "Various programming-related terms and keywords, including import statements, function and method names, and other code elements.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8260185519854227,
    "similarity_var": 0.003193405959730771,
    "score_fuzz": 0.65,
    "score_detection": 0.61,
    "score_embedding": 0.4512,
    "total_score": 0.5704,
    "x": 10.480867385864258,
    "y": 8.611364364624023,
    "cluster_id": 80
  },
  {
    "feature_id": 533,
    "explanation_index": 1,
    "text": "Common tokens in technical and programming contexts, including file operations, code structure, and software functionality, often related to importing, exporting, and system interactions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8260185519854227,
    "similarity_var": 0.003193405959730771,
    "score_fuzz": 0.71,
    "score_detection": 0.67,
    "score_embedding": 0.53125,
    "total_score": 0.6370833333333333,
    "x": 10.942214012145996,
    "y": 6.084303855895996,
    "cluster_id": 18
  },
  {
    "feature_id": 533,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8260185519854227,
    "similarity_var": 0.003193405959730771,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.31500000000000006,
    "total_score": 0.4383333333333333,
    "x": -5.969435691833496,
    "y": 15.939513206481934,
    "cluster_id": 10
  },
  {
    "feature_id": 534,
    "explanation_index": 0,
    "text": "Various programming and markup language syntax elements, including symbols, operators, and tags, often used for formatting, control flow, and data representation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8853662808736166,
    "similarity_var": 0.00037843065644062155,
    "score_fuzz": 0.42,
    "score_detection": 0.42,
    "score_embedding": 0.26039999999999996,
    "total_score": 0.3668,
    "x": 10.439685821533203,
    "y": 8.162922859191895,
    "cluster_id": -1
  },
  {
    "feature_id": 534,
    "explanation_index": 1,
    "text": "Patterns involving punctuation, delimiters, and structural tokens in code or markup, often indicating syntax boundaries, formatting, or code structure.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8853662808736166,
    "similarity_var": 0.00037843065644062155,
    "score_fuzz": 0.48,
    "score_detection": 0.41,
    "score_embedding": 0.27375000000000005,
    "total_score": 0.38791666666666663,
    "x": 10.318533897399902,
    "y": 7.031822204589844,
    "cluster_id": 86
  },
  {
    "feature_id": 534,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core lexical items that carry the main semantic or syntactic role in a phrase or code fragment\u2014comparative endings, key nouns, or programming syntax elements such as keywords, punctuation, and identifiers.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8853662808736166,
    "similarity_var": 0.00037843065644062155,
    "score_fuzz": 0.45,
    "score_detection": 0.35,
    "score_embedding": 0.32062499999999994,
    "total_score": 0.37354166666666666,
    "x": 14.761861801147461,
    "y": 4.455442428588867,
    "cluster_id": -1
  },
  {
    "feature_id": 535,
    "explanation_index": 0,
    "text": "Punctuation and special characters, often used to denote code, formatting, or mathematical expressions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9103362361590067,
    "similarity_var": 0.00031212477663760616,
    "score_fuzz": 0.9,
    "score_detection": 0.97,
    "score_embedding": 0.9856,
    "total_score": 0.9518666666666666,
    "x": 8.668196678161621,
    "y": 7.358508110046387,
    "cluster_id": 4
  },
  {
    "feature_id": 535,
    "explanation_index": 1,
    "text": "Delimiters and special symbols (like << >>, [], {}, (), \\\"\\\", $, \\\\, |, ~, etc.) are used to mark structural or syntactic boundaries in text, often indicating code, mathematical expressions, citations, or formatting cues.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9103362361590067,
    "similarity_var": 0.00031212477663760616,
    "score_fuzz": 0.89,
    "score_detection": 0.9,
    "score_embedding": 0.945625,
    "total_score": 0.9118750000000001,
    "x": 9.688197135925293,
    "y": 6.991590976715088,
    "cluster_id": 21
  },
  {
    "feature_id": 535,
    "explanation_index": 2,
    "text": "Important tokens are typically short, non\u2011lexical symbols or identifiers that act as delimiters, punctuation, or code\u2011syntax elements, marking boundaries or special meaning in the text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9103362361590067,
    "similarity_var": 0.00031212477663760616,
    "score_fuzz": 0.775,
    "score_detection": 0.925,
    "score_embedding": 0.9237500000000001,
    "total_score": 0.8745833333333334,
    "x": 11.444486618041992,
    "y": 4.68912410736084,
    "cluster_id": 78
  },
  {
    "feature_id": 536,
    "explanation_index": 0,
    "text": "Nouns representing objects, locations, concepts, or ideas, often with a specific or technical meaning, and sometimes used in formal or descriptive contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.882061501344045,
    "similarity_var": 0.001157369838661598,
    "score_fuzz": 0.73,
    "score_detection": 0.68,
    "score_embedding": 0.8176,
    "total_score": 0.7425333333333334,
    "x": 8.113036155700684,
    "y": 0.2252574861049652,
    "cluster_id": 24
  },
  {
    "feature_id": 536,
    "explanation_index": 1,
    "text": "Nouns and adjectives denoting specific locations, abstract concepts, or unique entities, often used to convey precise meaning or context within a sentence.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.882061501344045,
    "similarity_var": 0.001157369838661598,
    "score_fuzz": 0.7263157894736842,
    "score_detection": 0.7894736842105263,
    "score_embedding": 0.779375,
    "total_score": 0.7650548245614036,
    "x": 8.389787673950195,
    "y": 0.25009024143218994,
    "cluster_id": 24
  },
  {
    "feature_id": 536,
    "explanation_index": 2,
    "text": "The highlighted tokens are the most semantically salient words in each sentence\u2014typically nouns or noun phrases, occasionally adjectives or adverbs\u2014that the model flags as key to the sentence\u2019s meaning, rather than function words.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.882061501344045,
    "similarity_var": 0.001157369838661598,
    "score_fuzz": 0.65,
    "score_detection": 0.675,
    "score_embedding": 0.74875,
    "total_score": 0.6912500000000001,
    "x": 15.17920970916748,
    "y": 4.322226524353027,
    "cluster_id": 72
  },
  {
    "feature_id": 538,
    "explanation_index": 0,
    "text": "Terms related to diseases, viruses, and medical conditions, often in the context of outbreaks, infections, and health crises.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8980074326197306,
    "similarity_var": 0.00025123685172524627,
    "score_fuzz": 0.84,
    "score_detection": 0.73,
    "score_embedding": 0.5736,
    "total_score": 0.7145333333333332,
    "x": 7.458056926727295,
    "y": 1.4380218982696533,
    "cluster_id": 25
  },
  {
    "feature_id": 538,
    "explanation_index": 1,
    "text": "Fragments of disease-related terms, particularly those involving viruses, infections, and medical conditions, often appear as partial tokens (e.g., \\\"vire\\\", \\\"spor\\\", \\\"malign\\\", \\\"missible\\\") that are contextually linked to broader biomedical concepts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8980074326197306,
    "similarity_var": 0.00025123685172524627,
    "score_fuzz": 0.8,
    "score_detection": 0.69,
    "score_embedding": 0.5525,
    "total_score": 0.6808333333333333,
    "x": 7.725718975067139,
    "y": 2.357564926147461,
    "cluster_id": -1
  },
  {
    "feature_id": 538,
    "explanation_index": 2,
    "text": "The highlighted tokens are those that belong to disease names or disease\u2011related phrases, often occurring with common articles or prepositions.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8980074326197306,
    "similarity_var": 0.00025123685172524627,
    "score_fuzz": 0.75,
    "score_detection": 0.675,
    "score_embedding": 0.45499999999999996,
    "total_score": 0.6266666666666666,
    "x": 13.854164123535156,
    "y": 4.026125907897949,
    "cluster_id": 42
  },
  {
    "feature_id": 539,
    "explanation_index": 0,
    "text": "Ellipses, often used to indicate a pause or omission in text, or to separate sections of a document.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9052555561065674,
    "similarity_var": 0.00018589726662080844,
    "score_fuzz": 0.71,
    "score_detection": 0.61,
    "score_embedding": 0.2352,
    "total_score": 0.5184,
    "x": 8.319538116455078,
    "y": 6.886256694793701,
    "cluster_id": 36
  },
  {
    "feature_id": 539,
    "explanation_index": 1,
    "text": "The pattern involves the use of ellipsis markers (such as \\\"...\\\" or \\\" . . .\\\") or similar punctuation sequences to indicate a pause, omission, or trailing thought, often appearing before or after quoted or emphasized text.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9052555561065674,
    "similarity_var": 0.00018589726662080844,
    "score_fuzz": 0.75,
    "score_detection": 0.67,
    "score_embedding": 0.194375,
    "total_score": 0.538125,
    "x": 9.81098747253418,
    "y": 6.622963905334473,
    "cluster_id": 87
  },
  {
    "feature_id": 539,
    "explanation_index": 2,
    "text": "The highlighted tokens are punctuation marks that signal sentence boundaries or pauses, such as periods, ellipses, question marks, and asterisks.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9052555561065674,
    "similarity_var": 0.00018589726662080844,
    "score_fuzz": 0.775,
    "score_detection": 0.625,
    "score_embedding": 0.213125,
    "total_score": 0.5377083333333333,
    "x": 13.850232124328613,
    "y": 5.2744364738464355,
    "cluster_id": 62
  },
  {
    "feature_id": 540,
    "explanation_index": 0,
    "text": "The verb \\\"make\\\" and its variations, often used in the context of creating, causing, or enabling something, and sometimes used in idiomatic expressions or in relation to objects or decisions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9063917199770609,
    "similarity_var": 0.00039357479989219095,
    "score_fuzz": 0.83,
    "score_detection": 0.8,
    "score_embedding": 0.5552,
    "total_score": 0.7284,
    "x": 11.214859008789062,
    "y": 2.2293543815612793,
    "cluster_id": -1
  },
  {
    "feature_id": 540,
    "explanation_index": 1,
    "text": "The verb \\\"make\\\" (and its inflected forms) is frequently used in contexts involving creation, causation, or enabling, often followed by a direct object or complement, and is highly activated when describing actions that result in a change or outcome.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9063917199770609,
    "similarity_var": 0.00039357479989219095,
    "score_fuzz": 0.86,
    "score_detection": 0.82,
    "score_embedding": 0.680625,
    "total_score": 0.7868749999999999,
    "x": 11.243780136108398,
    "y": 2.2415897846221924,
    "cluster_id": -1
  },
  {
    "feature_id": 540,
    "explanation_index": 2,
    "text": "The pattern: \\\"make\\\" and derivatives appear frequently.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9063917199770609,
    "similarity_var": 0.00039357479989219095,
    "score_fuzz": 0.85,
    "score_detection": 0.8,
    "score_embedding": 0.43687500000000007,
    "total_score": 0.695625,
    "x": 11.42518138885498,
    "y": 2.73437762260437,
    "cluster_id": -1
  },
  {
    "feature_id": 541,
    "explanation_index": 0,
    "text": "Adjectives or nouns indicating nationality, ethnicity, or geographical origin, often used to describe a person, place, or thing.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8916749954223633,
    "similarity_var": 0.0006108814684916789,
    "score_fuzz": 0.7,
    "score_detection": 0.42,
    "score_embedding": 0.424,
    "total_score": 0.5146666666666666,
    "x": 7.735169410705566,
    "y": -0.56892329454422,
    "cluster_id": 16
  },
  {
    "feature_id": 541,
    "explanation_index": 1,
    "text": "Proper nouns denoting nationalities, countries, or regions, often appearing in contexts involving identity, geography, or cultural references.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8916749954223633,
    "similarity_var": 0.0006108814684916789,
    "score_fuzz": 0.61,
    "score_detection": 0.34,
    "score_embedding": 0.32999999999999996,
    "total_score": 0.4266666666666666,
    "x": 7.470435619354248,
    "y": -0.887582004070282,
    "cluster_id": 16
  },
  {
    "feature_id": 541,
    "explanation_index": 2,
    "text": "Tokens that are nationality or ethnic adjectives (often capitalized and sometimes preceded by an article) are highlighted as important.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8916749954223633,
    "similarity_var": 0.0006108814684916789,
    "score_fuzz": 0.8,
    "score_detection": 0.5,
    "score_embedding": 0.585,
    "total_score": 0.6283333333333333,
    "x": 14.587594985961914,
    "y": 4.182619094848633,
    "cluster_id": -1
  },
  {
    "feature_id": 542,
    "explanation_index": 0,
    "text": "Javadoc-style comments used to document code, often including tags such as @param, @return, and @author.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9091740647951762,
    "similarity_var": 5.584092541808003e-05,
    "score_fuzz": 0.86,
    "score_detection": 0.88,
    "score_embedding": 0.34719999999999995,
    "total_score": 0.6957333333333334,
    "x": 10.743928909301758,
    "y": 7.393550395965576,
    "cluster_id": 7
  },
  {
    "feature_id": 542,
    "explanation_index": 1,
    "text": "The pattern involves documentation or metadata tags in code, typically starting with \\\"@\\\", \\\"@param\\\", \\\"@return\\\", \\\"@var\\\", \\\"@type\\\", \\\"@author\\\", \\\"@license\\\", \\\"@see\\\", \\\"@brief\\\", \\\"@ingroup\\\", \\\"@category\\\", \\\"@package\\\", \\\"@copyright\\\", \\\"@since\\\", \\\"@fileoverview\\\", \\\"@submodule\\\", \\\"@description\\\", \\\"@throws\\\", \\\"@var\\\", \\\"@method\\\", \\\"@note\\\", \\\"@example\\\", \\\"@deprecated\\\", \\\"@todo\\\", \\\"@link\\\", \\\"@since\\\", \\\"@version\\\", \\\"@example\\\", \\\"@internal\\\", \\\"@property\\\", \\\"@static\\\", \\\"@final\\\", \\\"@abstract\\\", \\\"@override\\\", \\\"@protected\\\", \\\"@public\\\", \\\"@private\\\", \\\"@interface\\\", \\\"@class\\\", \\\"@function\\\", \\\"@namespace\\\", \\\"@module\\\", \\\"@constructor\\\", \\\"@event\\\", \\\"@callback\\\", \\\"@example\\\", \\\"@todo\\\", \\\"@warning\\\", \\\"@note\\\", \\\"@deprecated\\\", \\\"@since\\\", \\\"@version\\\", \\\"@example\\\", \\\"@internal\\\", \\\"@property\\\", \\\"@static\\\", \\\"@final\\\", \\\"@abstract\\\", \\\"@override\\\", \\\"@protected\\\", \\\"@public\\\", \\\"@private\\\", \\\"@interface\\\", \\\"@class\\\", \\\"@function\\\", \\\"@namespace\\\", \\\"@module\\\", \\\"@constructor\\\", \\\"@event\\\", \\\"@callback\\\", \\\"@example\\\", \\\"@todo\\\", \\\"@warning\\\", \\\"@note\\\", \\\"@deprecated\\\", \\\"@since\\\", \\\"@version\\\", \\\"@example\\\", \\\"@internal\\\", \\\"@property\\\", \\\"@static\\\", \\\"@final\\\", \\\"@abstract\\\", \\\"@override\\\", \\\"@protected\\\", \\\"@public\\\", \\\"@private\\\", \\\"@interface\\\", \\\"@class\\\", \\\"@function\\\", \\\"@namespace\\\", \\\"@module\\\", \\\"@constructor\\\", \\\"@event\\\", \\\"@callback\\\", \\\"@example\\\", \\\"@todo\\\", \\\"@warning\\\", \\\"@note\\\", \\\"@deprecated\\\", \\\"@since\\\", \\\"@version\\\", \\\"@example\\\", \\\"@internal\\\", \\\"@property\\\", \\\"@static\\\", \\\"@final\\\", \\\"@abstract\\\", \\\"@override\\\", \\\"@protected\\\", \\\"@public\\\", \\\"@private\\\", \\\"@interface\\\", \\\"@class\\\", \\\"@function\\\", \\\"@namespace\\\", \\\"@module\\\", \\\"@constructor\\\", \\\"@event\\\", \\\"@callback\\\", \\\"@example\\\", \\\"@todo\\\", \\\"@warning\\\", \\\"@note\\\", \\\"@deprecated\\\", \\\"@since\\\", \\\"@version\\\", \\\"@example\\\", \\\"@internal\\\", \\\"@property\\\", \\\"@static\\\", \\\"@final\\\", \\\"@abstract\\\", \\\"@override\\\", \\\"@protected\\\", \\\"@public\\\", \\\"@private\\\", \\\"@interface\\\", \\\"@class\\\", \\\"@function\\\", \\\"@namespace\\\", \\\"@module\\\", \\\"@constructor\\\", \\\"@event\\\", \\\"@callback\\\", \\\"@example\\\", \\\"@todo\\\", \\\"@warning\\\", \\\"@note\\\", \\\"@deprecated\\\", \\\"@since\\\", \\\"@version\\\", \\\"@example\\\", \\\"@internal\\\", \\\"@property\\\", \\\"@static\\\", \\\"@final\\\", \\\"@abstract\\\", \\\"@override\\\", \\\"@protected\\\", \\\"@",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9091740647951762,
    "similarity_var": 5.584092541808003e-05,
    "score_fuzz": 0.85,
    "score_detection": 0.85,
    "score_embedding": 0.321875,
    "total_score": 0.6739583333333333,
    "x": 10.769330024719238,
    "y": 7.226731777191162,
    "cluster_id": -1
  },
  {
    "feature_id": 542,
    "explanation_index": 2,
    "text": "The highlighted tokens are code\u2011comment or method\u2011definition markers that annotate functions, classes, or parameters (e.g., @return, @param, @throws, @author, __init__, etc.).",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9091740647951762,
    "similarity_var": 5.584092541808003e-05,
    "score_fuzz": 0.975,
    "score_detection": 0.95,
    "score_embedding": 0.41000000000000003,
    "total_score": 0.7783333333333333,
    "x": 13.492624282836914,
    "y": 6.610419273376465,
    "cluster_id": -1
  },
  {
    "feature_id": 543,
    "explanation_index": 0,
    "text": "Various symbols and operators used in programming and mathematical contexts, including comparison operators, assignment operators, and symbols used to denote arrays, cases, and other programming constructs.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8885494867960612,
    "similarity_var": 0.0003671623194973803,
    "score_fuzz": 0.37,
    "score_detection": 0.26,
    "score_embedding": 0.3608,
    "total_score": 0.33026666666666665,
    "x": 9.655303001403809,
    "y": 8.207222938537598,
    "cluster_id": -1
  },
  {
    "feature_id": 543,
    "explanation_index": 1,
    "text": "Special symbols and operators such as \\\"==\\\" and \\\"\u2014\\\" are used to denote comparison, separation, or syntactic structure, often in code or formal notation.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8885494867960612,
    "similarity_var": 0.0003671623194973803,
    "score_fuzz": 0.44,
    "score_detection": 0.3,
    "score_embedding": 0.32437499999999997,
    "total_score": 0.35479166666666667,
    "x": 9.557352066040039,
    "y": 7.03971004486084,
    "cluster_id": 21
  },
  {
    "feature_id": 543,
    "explanation_index": 2,
    "text": "The highlighted tokens are short, high\u2011frequency function words or symbols that act as structural markers\u2014such as operators (==, ===), punctuation (\u2014, ;), or common linking words (was, been, case, equal, different). They typically appear at the boundaries of phrases or code constructs, signaling a change in context or a comparison.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8885494867960612,
    "similarity_var": 0.0003671623194973803,
    "score_fuzz": 0.675,
    "score_detection": 0.325,
    "score_embedding": 0.35,
    "total_score": 0.45,
    "x": 13.468502044677734,
    "y": 5.847430229187012,
    "cluster_id": -1
  },
  {
    "feature_id": 546,
    "explanation_index": 0,
    "text": "Abbreviations or acronyms often enclosed in parentheses, sometimes used to shorten names of organizations, technical terms, or concepts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8987069725990295,
    "similarity_var": 0.00035824438785662477,
    "score_fuzz": 0.7,
    "score_detection": 0.62,
    "score_embedding": 0.4048,
    "total_score": 0.5749333333333333,
    "x": 7.712646961212158,
    "y": 1.585654616355896,
    "cluster_id": -1
  },
  {
    "feature_id": 546,
    "explanation_index": 1,
    "text": "The pattern involves the use of parentheses containing abbreviations or acronyms, often immediately following a term or phrase, with the opening parenthesis frequently preceded by a space and the closing parenthesis often followed by a word or punctuation, indicating a defined or expanded form of a technical or formal term.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8987069725990295,
    "similarity_var": 0.00035824438785662477,
    "score_fuzz": 0.7684210526315789,
    "score_detection": 0.71,
    "score_embedding": 0.441875,
    "total_score": 0.6400986842105263,
    "x": 10.30001449584961,
    "y": 6.620567321777344,
    "cluster_id": -1
  },
  {
    "feature_id": 546,
    "explanation_index": 2,
    "text": "The pattern seems to be that the important tokens are often parentheses, abbreviations, acronyms, or punctuation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8987069725990295,
    "similarity_var": 0.00035824438785662477,
    "score_fuzz": 0.775,
    "score_detection": 0.625,
    "score_embedding": 0.5250000000000001,
    "total_score": 0.6416666666666667,
    "x": 11.33637523651123,
    "y": 4.3835015296936035,
    "cluster_id": 3
  },
  {
    "feature_id": 547,
    "explanation_index": 0,
    "text": "Various words and phrases, often with a neutral or formal tone, including nouns, adjectives, adverbs, and verbs, that appear to be part of a diverse set of texts, including articles, patents, and software documentation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8770472407341003,
    "similarity_var": 8.929690797524852e-05,
    "score_fuzz": 0.36,
    "score_detection": 0.36,
    "score_embedding": 0.2264,
    "total_score": 0.3154666666666666,
    "x": 9.314249992370605,
    "y": 0.09114474803209305,
    "cluster_id": -1
  },
  {
    "feature_id": 547,
    "explanation_index": 1,
    "text": "Commonly activated tokens include function words (e.g., \\\"the\\\", \\\"but\\\", \\\"and\\\"), suffixes forming comparative or abstract nouns (e.g., \\\"er\\\", \\\"ibility\\\", \\\"ness\\\"), and contextually significant nouns or phrases denoting locations, concepts, or technical terms, often appearing in compound or idiomatic expressions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8770472407341003,
    "similarity_var": 8.929690797524852e-05,
    "score_fuzz": 0.56,
    "score_detection": 0.35,
    "score_embedding": 0.23000000000000004,
    "total_score": 0.38000000000000006,
    "x": 10.187997817993164,
    "y": 3.2790844440460205,
    "cluster_id": 33
  },
  {
    "feature_id": 547,
    "explanation_index": 2,
    "text": "The highlighted fragments are subword pieces or whole words that combine to form the main lexical items of a sentence, often including common function words and domain\u2011specific terms that carry the core meaning.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8770472407341003,
    "similarity_var": 8.929690797524852e-05,
    "score_fuzz": 0.425,
    "score_detection": 0.3,
    "score_embedding": 0.1975,
    "total_score": 0.3075,
    "x": 15.764518737792969,
    "y": 7.353369235992432,
    "cluster_id": 19
  },
  {
    "feature_id": 548,
    "explanation_index": 0,
    "text": "Proper nouns, often representing names of people, places, organizations, or titles.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.828709602355957,
    "similarity_var": 0.00016846115705485923,
    "score_fuzz": 0.7,
    "score_detection": 0.51,
    "score_embedding": 0.8104,
    "total_score": 0.6734666666666667,
    "x": 7.425020217895508,
    "y": -0.9516468644142151,
    "cluster_id": 16
  },
  {
    "feature_id": 548,
    "explanation_index": 1,
    "text": "Partial or fragmented tokens, often representing parts of names, abbreviations, or technical terms, where the full form is implied or reconstructed from context.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.828709602355957,
    "similarity_var": 0.00016846115705485923,
    "score_fuzz": 0.63,
    "score_detection": 0.69,
    "score_embedding": 0.7175,
    "total_score": 0.6791666666666666,
    "x": 7.044839382171631,
    "y": 2.948488712310791,
    "cluster_id": 59
  },
  {
    "feature_id": 548,
    "explanation_index": 2,
    "text": "The model consistently flags sub\u2011word fragments that belong to larger lexical items\u2014especially suffixes or prefixes of proper nouns, technical terms, and multi\u2011word expressions\u2014showing that it relies on morphological cues rather than whole words.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.828709602355957,
    "similarity_var": 0.00016846115705485923,
    "score_fuzz": 0.6,
    "score_detection": 0.6,
    "score_embedding": 0.8406250000000001,
    "total_score": 0.6802083333333333,
    "x": 8.044901847839355,
    "y": 3.2415318489074707,
    "cluster_id": 76
  },
  {
    "feature_id": 549,
    "explanation_index": 0,
    "text": "Adverbs or adverbial phrases indicating time, such as \\\"now\\\", \\\"today\\\", \\\"finally\\\", and \\\"currently\\\", often used to introduce a new development or a change in situation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8609760403633118,
    "similarity_var": 0.0008095835843657065,
    "score_fuzz": 0.85,
    "score_detection": 0.85,
    "score_embedding": 0.7676,
    "total_score": 0.8225333333333333,
    "x": 11.44899845123291,
    "y": 3.6158244609832764,
    "cluster_id": -1
  },
  {
    "feature_id": 549,
    "explanation_index": 1,
    "text": "The word \\\"now\\\" frequently appears in contexts indicating a shift in time or current state, often signaling a transition from past to present or emphasizing immediacy, particularly in statements about availability, change, or ongoing relevance.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8609760403633118,
    "similarity_var": 0.0008095835843657065,
    "score_fuzz": 0.84,
    "score_detection": 0.82,
    "score_embedding": 0.619375,
    "total_score": 0.7597916666666666,
    "x": 11.501816749572754,
    "y": 3.6746983528137207,
    "cluster_id": -1
  },
  {
    "feature_id": 549,
    "explanation_index": 2,
    "text": "The pattern seems to be that the special words are often \\\"now\\\" or \\\"now\\\" with variations, or \\\"now\\\" preceded by capital letter.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8609760403633118,
    "similarity_var": 0.0008095835843657065,
    "score_fuzz": 0.775,
    "score_detection": 0.8,
    "score_embedding": 0.44875000000000004,
    "total_score": 0.6745833333333334,
    "x": 11.506631851196289,
    "y": 3.8870060443878174,
    "cluster_id": -1
  },
  {
    "feature_id": 550,
    "explanation_index": 0,
    "text": "Various programming-related terms, including class names, method names, and keywords, often used in the context of caching, memory management, and data structures.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9265257517496744,
    "similarity_var": 0.00013430619787947585,
    "score_fuzz": 0.66,
    "score_detection": 0.51,
    "score_embedding": 0.6796,
    "total_score": 0.6165333333333333,
    "x": 10.411545753479004,
    "y": 8.639053344726562,
    "cluster_id": 80
  },
  {
    "feature_id": 550,
    "explanation_index": 1,
    "text": "Tokens related to caching mechanisms, data storage, or memory management in code, often appearing as identifiers, method names, or configuration keys, with frequent use of compound terms like \\\"cache\\\", \\\"cacheKey\\\", \\\"cached\\\", \\\"cacheService\\\", and similar patterns involving prefixes, suffixes, or camelCase naming.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9265257517496744,
    "similarity_var": 0.00013430619787947585,
    "score_fuzz": 0.66,
    "score_detection": 0.64,
    "score_embedding": 0.62625,
    "total_score": 0.6420833333333333,
    "x": 10.970184326171875,
    "y": 6.102328777313232,
    "cluster_id": 18
  },
  {
    "feature_id": 550,
    "explanation_index": 2,
    "text": "The highlighted tokens are identifiers or keywords that signal a caching concept\u2014such as \u201cCache\u201d, \u201ccache\u201d, \u201ccache:\u201d, \u201cCacheKey\u201d, \u201ccacheGroups\u201d, \u201ccacheObserver\u201d, \u201ccacheService\u201d, etc.\u2014used throughout code to refer to cache objects, cache settings, or cache\u2011related operations.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9265257517496744,
    "similarity_var": 0.00013430619787947585,
    "score_fuzz": 0.75,
    "score_detection": 0.625,
    "score_embedding": 0.623125,
    "total_score": 0.6660416666666666,
    "x": 13.628267288208008,
    "y": 6.218251705169678,
    "cluster_id": -1
  },
  {
    "feature_id": 551,
    "explanation_index": 0,
    "text": "A line break or paragraph separation often denoted by a newline character.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8804598848025004,
    "similarity_var": 0.0004376163968665815,
    "score_fuzz": 0.83,
    "score_detection": 0.71,
    "score_embedding": 0.5032,
    "total_score": 0.6810666666666667,
    "x": 9.877266883850098,
    "y": 6.677789688110352,
    "cluster_id": -1
  },
  {
    "feature_id": 551,
    "explanation_index": 1,
    "text": "Frequent use of newline characters and structural tokens in code, documentation, and formatted text, often signaling syntactic boundaries, section breaks, or formatting markers.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8804598848025004,
    "similarity_var": 0.0004376163968665815,
    "score_fuzz": 0.82,
    "score_detection": 0.67,
    "score_embedding": 0.4475,
    "total_score": 0.6458333333333334,
    "x": 10.166358947753906,
    "y": 6.814576148986816,
    "cluster_id": 88
  },
  {
    "feature_id": 551,
    "explanation_index": 2,
    "text": "The highlighted tokens are usually structural markers that separate or emphasize content\u2014line breaks, punctuation, or key words that signal a transition or boundary.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8804598848025004,
    "similarity_var": 0.0004376163968665815,
    "score_fuzz": 0.8,
    "score_detection": 0.725,
    "score_embedding": 0.364375,
    "total_score": 0.6297916666666666,
    "x": 13.956668853759766,
    "y": 5.274086952209473,
    "cluster_id": 62
  },
  {
    "feature_id": 552,
    "explanation_index": 0,
    "text": "Indentation and line breaks in source code, often indicating the start or end of a block or function.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9047864079475403,
    "similarity_var": 8.993494825186114e-05,
    "score_fuzz": 0.61,
    "score_detection": 0.49,
    "score_embedding": 0.5883999999999999,
    "total_score": 0.5628000000000001,
    "x": 11.346054077148438,
    "y": 7.706031322479248,
    "cluster_id": 81
  },
  {
    "feature_id": 552,
    "explanation_index": 1,
    "text": "Patterns in code syntax and structure, particularly around line breaks, indentation, and token placement in programming language constructs such as braces, parentheses, and control flow statements.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9047864079475403,
    "similarity_var": 8.993494825186114e-05,
    "score_fuzz": 0.4,
    "score_detection": 0.4,
    "score_embedding": 0.31875,
    "total_score": 0.3729166666666666,
    "x": 10.664443016052246,
    "y": 7.482102870941162,
    "cluster_id": 7
  },
  {
    "feature_id": 552,
    "explanation_index": 2,
    "text": "The highlighted tokens are typically the first identifier or symbol after a newline or indentation in code, often marking the start of a function call, variable declaration, or control structure.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9047864079475403,
    "similarity_var": 8.993494825186114e-05,
    "score_fuzz": 0.525,
    "score_detection": 0.5,
    "score_embedding": 0.50375,
    "total_score": 0.5095833333333334,
    "x": 13.76733112335205,
    "y": 6.380795001983643,
    "cluster_id": -1
  },
  {
    "feature_id": 553,
    "explanation_index": 0,
    "text": "Titles of books, series, chapters, and other written works, often including subtitles, authors, and publication information.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.836910625298818,
    "similarity_var": 0.0009161277366263538,
    "score_fuzz": 0.5263157894736842,
    "score_detection": 0.52,
    "score_embedding": 0.4144,
    "total_score": 0.48690526315789473,
    "x": 9.351729393005371,
    "y": 0.4387313425540924,
    "cluster_id": -1
  },
  {
    "feature_id": 553,
    "explanation_index": 1,
    "text": "Common patterns include proper nouns, titles, and compound terms, often involving book, series, or fictional work names, with frequent use of underscores, hyphens, and capitalization to denote titles or special terms.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.836910625298818,
    "similarity_var": 0.0009161277366263538,
    "score_fuzz": 0.54,
    "score_detection": 0.49,
    "score_embedding": 0.46312500000000006,
    "total_score": 0.49770833333333336,
    "x": 9.36983585357666,
    "y": 0.33942240476608276,
    "cluster_id": -1
  },
  {
    "feature_id": 553,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core lexical elements that compose named entities, titles, or key phrases, often split by tokenization, and they carry the main semantic content of the surrounding text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.836910625298818,
    "similarity_var": 0.0009161277366263538,
    "score_fuzz": 0.575,
    "score_detection": 0.475,
    "score_embedding": 0.5225,
    "total_score": 0.5241666666666666,
    "x": 15.019291877746582,
    "y": 4.395949840545654,
    "cluster_id": 72
  },
  {
    "feature_id": 554,
    "explanation_index": 0,
    "text": "Proper nouns, often representing names of people, places, or organizations, and sometimes words related to family, inheritance, or genetics.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8598113059997559,
    "similarity_var": 0.00043419813069315677,
    "score_fuzz": 0.5,
    "score_detection": 0.43,
    "score_embedding": 0.6976,
    "total_score": 0.5425333333333333,
    "x": 7.485630512237549,
    "y": -0.867634117603302,
    "cluster_id": 16
  },
  {
    "feature_id": 554,
    "explanation_index": 1,
    "text": "Fragments of compound words or multi-word terms, often related to family, inheritance, or technical/medical concepts, where the activation is distributed across partial or split tokens, particularly at morpheme boundaries or within hyphenated/compound structures.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8598113059997559,
    "similarity_var": 0.00043419813069315677,
    "score_fuzz": 0.62,
    "score_detection": 0.64,
    "score_embedding": 0.830625,
    "total_score": 0.696875,
    "x": 7.046085834503174,
    "y": 2.5306644439697266,
    "cluster_id": 2
  },
  {
    "feature_id": 554,
    "explanation_index": 2,
    "text": "The highlighted fragments are typically short, high\u2011frequency words or meaningful morphemes that appear at word boundaries\u2014often function words, common nouns, or parts of proper names\u2014so the model flags them as salient.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8598113059997559,
    "similarity_var": 0.00043419813069315677,
    "score_fuzz": 0.425,
    "score_detection": 0.45,
    "score_embedding": 0.6975,
    "total_score": 0.5241666666666667,
    "x": 15.66006088256836,
    "y": 7.028904914855957,
    "cluster_id": 19
  },
  {
    "feature_id": 555,
    "explanation_index": 0,
    "text": "Verbs of communication, often in the form of dialogue or reported speech, typically involving a subject and a recipient.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8651685118675232,
    "similarity_var": 0.003117696165453765,
    "score_fuzz": 0.86,
    "score_detection": 0.71,
    "score_embedding": 0.5479999999999999,
    "total_score": 0.706,
    "x": 10.496620178222656,
    "y": -0.7892611026763916,
    "cluster_id": 14
  },
  {
    "feature_id": 555,
    "explanation_index": 1,
    "text": "Verbs of speech or communication (e.g., said, told, told, added, yelled, says, stating) frequently co-occur with pronouns or nouns indicating the recipient or subject of the statement, often signaling direct or indirect dialogue.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8651685118675232,
    "similarity_var": 0.003117696165453765,
    "score_fuzz": 0.91,
    "score_detection": 0.83,
    "score_embedding": 0.55625,
    "total_score": 0.7654166666666667,
    "x": 10.35186767578125,
    "y": -0.760516881942749,
    "cluster_id": 14
  },
  {
    "feature_id": 555,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8651685118675232,
    "similarity_var": 0.003117696165453765,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.458125,
    "total_score": 0.48604166666666665,
    "x": -7.925278663635254,
    "y": 9.135034561157227,
    "cluster_id": 52
  },
  {
    "feature_id": 556,
    "explanation_index": 0,
    "text": "Preprocessor directives, import statements, and keywords in programming languages, often used for including files, defining constants, importing modules, and specifying conditions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9282381733258566,
    "similarity_var": 4.918713001305579e-05,
    "score_fuzz": 0.53,
    "score_detection": 0.41,
    "score_embedding": 0.6287999999999999,
    "total_score": 0.5229333333333334,
    "x": 10.612090110778809,
    "y": 8.501505851745605,
    "cluster_id": 48
  },
  {
    "feature_id": 556,
    "explanation_index": 1,
    "text": "Keywords and identifiers commonly used in programming languages and configuration files, particularly those related to file inclusion, conditional compilation, and code structure.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9282381733258566,
    "similarity_var": 4.918713001305579e-05,
    "score_fuzz": 0.41,
    "score_detection": 0.39,
    "score_embedding": 0.55,
    "total_score": 0.45,
    "x": 10.532705307006836,
    "y": 8.590558052062988,
    "cluster_id": 80
  },
  {
    "feature_id": 556,
    "explanation_index": 2,
    "text": "The highlighted words are language\u2011specific directives or keywords that govern inclusion, compilation, or filtering of code or resources across multiple programming languages.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9282381733258566,
    "similarity_var": 4.918713001305579e-05,
    "score_fuzz": 0.575,
    "score_detection": 0.5,
    "score_embedding": 0.6206250000000001,
    "total_score": 0.5652083333333334,
    "x": 14.165117263793945,
    "y": 6.590302467346191,
    "cluster_id": -1
  },
  {
    "feature_id": 557,
    "explanation_index": 0,
    "text": "Nouns or adjectives representing a positive or desirable outcome, advantage, or quality, often related to economics, utility, or usefulness.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9262241919835409,
    "similarity_var": 0.0007938588465405714,
    "score_fuzz": 0.86,
    "score_detection": 0.82,
    "score_embedding": 0.616,
    "total_score": 0.7653333333333333,
    "x": 8.783035278320312,
    "y": 1.1717748641967773,
    "cluster_id": 90
  },
  {
    "feature_id": 557,
    "explanation_index": 1,
    "text": "Nouns and adjectives denoting positive outcomes, advantages, or beneficial effects, often associated with abstract concepts like profit, benefit, utility, or advantage, frequently appearing in evaluative or analytical contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9262241919835409,
    "similarity_var": 0.0007938588465405714,
    "score_fuzz": 0.9,
    "score_detection": 0.82,
    "score_embedding": 0.6575000000000001,
    "total_score": 0.7925,
    "x": 8.415420532226562,
    "y": 0.8590083718299866,
    "cluster_id": 54
  },
  {
    "feature_id": 557,
    "explanation_index": 2,
    "text": "The highlighted words are nouns or adjectives that form benefit\u2011or\u2011advantage phrases, often preceded by prepositions such as \u201cof\u201d, \u201cto\u201d, or \u201cfor\u201d.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9262241919835409,
    "similarity_var": 0.0007938588465405714,
    "score_fuzz": 0.925,
    "score_detection": 0.8,
    "score_embedding": 0.56,
    "total_score": 0.7616666666666667,
    "x": 16.70833396911621,
    "y": 3.6330618858337402,
    "cluster_id": 20
  },
  {
    "feature_id": 558,
    "explanation_index": 0,
    "text": "Facial expressions, particularly smiling, often used to convey emotions, friendliness, or approachability in social interactions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8970709045728048,
    "similarity_var": 0.00034561426293638274,
    "score_fuzz": 0.93,
    "score_detection": 0.86,
    "score_embedding": 0.8012,
    "total_score": 0.8637333333333334,
    "x": 10.194692611694336,
    "y": -0.28525158762931824,
    "cluster_id": -1
  },
  {
    "feature_id": 558,
    "explanation_index": 1,
    "text": "Facial expressions such as smiling, grinning, or frowning are used to convey emotional states, often in response to social or narrative context, with \\\"smile\\\" and its variants being the most frequent and contextually significant.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8970709045728048,
    "similarity_var": 0.00034561426293638274,
    "score_fuzz": 0.96,
    "score_detection": 0.9,
    "score_embedding": 0.9050000000000001,
    "total_score": 0.9216666666666667,
    "x": 10.179737091064453,
    "y": -0.2537288963794708,
    "cluster_id": -1
  },
  {
    "feature_id": 558,
    "explanation_index": 2,
    "text": "The passages repeatedly feature variations of the word \u201csmile\u201d (smiled, smiles, smiling, grin, grinning, etc.) used to describe characters\u2019 facial expressions or emotional reactions, often in dialogue or narrative descriptions.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8970709045728048,
    "similarity_var": 0.00034561426293638274,
    "score_fuzz": 0.85,
    "score_detection": 0.875,
    "score_embedding": 0.87125,
    "total_score": 0.8654166666666666,
    "x": 10.175223350524902,
    "y": -0.23971140384674072,
    "cluster_id": -1
  },
  {
    "feature_id": 559,
    "explanation_index": 0,
    "text": "French words or phrases, often used in formal or literary contexts, and sometimes used to add a touch of elegance or sophistication to the text.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8314815362294515,
    "similarity_var": 0.00043118848058851554,
    "score_fuzz": 0.79,
    "score_detection": 0.74,
    "score_embedding": 0.7043999999999999,
    "total_score": 0.7448,
    "x": 10.508078575134277,
    "y": 1.0488189458847046,
    "cluster_id": -1
  },
  {
    "feature_id": 559,
    "explanation_index": 1,
    "text": "Fragments of words or phrases that are part of compound terms, proper nouns, or technical expressions, often appearing in incomplete or partially tokenized form, with high activation on morphological or orthographic boundaries.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8314815362294515,
    "similarity_var": 0.00043118848058851554,
    "score_fuzz": 0.34,
    "score_detection": 0.43,
    "score_embedding": 0.49875,
    "total_score": 0.42291666666666666,
    "x": 6.963222026824951,
    "y": 2.6842503547668457,
    "cluster_id": 2
  },
  {
    "feature_id": 559,
    "explanation_index": 2,
    "text": "The highlighted fragments consistently capture the core lexical content of a phrase or word\u2014whether a noun phrase, idiomatic expression, or a morphological fragment\u2014providing the main semantic load of the surrounding text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8314815362294515,
    "similarity_var": 0.00043118848058851554,
    "score_fuzz": 0.575,
    "score_detection": 0.45,
    "score_embedding": 0.628125,
    "total_score": 0.5510416666666667,
    "x": 15.833829879760742,
    "y": 7.427642345428467,
    "cluster_id": 19
  },
  {
    "feature_id": 560,
    "explanation_index": 0,
    "text": "Verbs and prepositions that connect clauses or phrases, often indicating a relationship of action, possession, or inclusion, and sometimes used in formal or technical writing.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8549335996309916,
    "similarity_var": 0.0002433847568054956,
    "score_fuzz": 0.58,
    "score_detection": 0.52,
    "score_embedding": 0.47559999999999997,
    "total_score": 0.5252,
    "x": 11.886332511901855,
    "y": -0.11608662456274033,
    "cluster_id": -1
  },
  {
    "feature_id": 560,
    "explanation_index": 1,
    "text": "Commonly activated tokens include function words (e.g., \\\"the\\\", \\\"to\\\", \\\"and\\\", \\\"of\\\", \\\"with\\\", \\\"who\\\", \\\"as\\\", \\\"be\\\", \\\"is\\\", \\\"was\\\", \\\"use\\\", \\\"include\\\", \\\"mainly\\\", \\\"than\\\", \\\"from\\\", \\\"for\\\", \\\"in\\\", \\\"on\\\", \\\"by\\\", \\\"at\\\", \\\"out\\\", \\\"up\\\", \\\"over\\\", \\\"under\\\", \\\"into\\\", \\\"through\\\", \\\"between\\\", \\\"among\\\", \\\"before\\\", \\\"after\\\", \\\"during\\\", \\\"since\\\", \\\"until\\\", \\\"unless\\\", \\\"although\\\", \\\"because\\\", \\\"if\\\", \\\"when\\\", \\\"while\\\", \\\"where\\\", \\\"why\\\", \\\"how\\\", \\\"what\\\", \\\"which\\\", \\\"who\\\", \\\"whom\\\", \\\"whose\\\", \\\"that\\\", \\\"this\\\", \\\"these\\\", \\\"those\\\", \\\"here\\\", \\\"there\\\", \\\"now\\\", \\\"then\\\", \\\"soon\\\", \\\"later\\\", \\\"already\\\", \\\"yet\\\", \\\"still\\\", \\\"just\\\", \\\"even\\\", \\\"only\\\", \\\"also\\\", \\\"too\\\", \\\"either\\\", \\\"neither\\\", \\\"both\\\", \\\"all\\\", \\\"some\\\", \\\"any\\\", \\\"none\\\", \\\"every\\\", \\\"each\\\", \\\"many\\\", \\\"much\\\", \\\"more\\\", \\\"most\\\", \\\"less\\\", \\\"least\\\", \\\"few\\\", \\\"fewer\\\", \\\"least\\\", \\\"little\\\", \\\"less\\\", \\\"least\\\", \\\"other\\\", \\\"another\\\", \\\"same\\\", \\\"different\\\", \\\"such\\\", \\\"so\\\", \\\"very\\\", \\\"too\\\", \\\"quite\\\", \\\"rather\\\", \\\"fairly\\\", \\\"really\\\", \\\"truly\\\", \\\"actually\\\", \\\"especially\\\", \\\"particularly\\\", \\\"specifically\\\", \\\"especially\\\", \\\"particularly\\\", \\\"specifically\\\", \\\"especially\\\", \\\"particularly\\\", \\\"specifically\\\", \\\"especially\\\", \\\"particularly\\\", \\\"specifically\\\", \\\"especially\\\", \\\"particularly\\\", \\\"specifically\\\", \\\"especially\\\", \\\"particularly\\\", \\\"specifically\\\", \\\"especially\\\", \\\"particularly\\\", \\\"specifically\\\", \\\"especially\\\", \\\"particularly\\\", \\\"specifically\\\", \\\"especially\\\", \\\"particularly\\\", \\\"specifically\\\", \\\"especially\\\", \\\"particularly\\\", \\\"specifically\\\", \\\"especially\\\", \\\"particularly\\\", \\\"specifically\\\", \\\"especially\\\", \\\"particularly\\\", \\\"specifically\\\", \\\"especially\\\", \\\"particularly\\\", \\\"specifically\\\", \\\"especially\\\", \\\"particularly\\\", \\\"specifically\\\", \\\"especially\\\", \\\"particularly\\\", \\\"specifically\\\", \\\"especially\\\", \\\"particularly\\\", \\\"specifically\\\", \\\"especially\\\", \\\"particularly\\\", \\\"specifically\\\", \\\"especially\\\", \\\"particularly\\\", \\\"specific",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8549335996309916,
    "similarity_var": 0.0002433847568054956,
    "score_fuzz": 0.5,
    "score_detection": 0.44,
    "score_embedding": 0.559375,
    "total_score": 0.49979166666666663,
    "x": 10.957782745361328,
    "y": 3.3442468643188477,
    "cluster_id": 27
  },
  {
    "feature_id": 560,
    "explanation_index": 2,
    "text": "The highlighted tokens are consistently short, high\u2011frequency words that act as connectors or belong to common collocations, indicating that the model focuses on these words to capture contextual and semantic relationships.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8549335996309916,
    "similarity_var": 0.0002433847568054956,
    "score_fuzz": 0.45,
    "score_detection": 0.4,
    "score_embedding": 0.480625,
    "total_score": 0.4435416666666667,
    "x": 13.777715682983398,
    "y": 4.052330017089844,
    "cluster_id": 42
  },
  {
    "feature_id": 561,
    "explanation_index": 0,
    "text": "A whitespace character or a newline preceding a conditional statement or function definition.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8860715826352438,
    "similarity_var": 0.00040703357921343135,
    "score_fuzz": 0.69,
    "score_detection": 0.58,
    "score_embedding": 0.856,
    "total_score": 0.7086666666666667,
    "x": 11.230045318603516,
    "y": 7.288856029510498,
    "cluster_id": -1
  },
  {
    "feature_id": 561,
    "explanation_index": 1,
    "text": "The newline character (\\\"\\\\n\\\") frequently appears before or after code blocks, conditional statements, and function definitions, often serving as structural separators in source code.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8860715826352438,
    "similarity_var": 0.00040703357921343135,
    "score_fuzz": 0.68,
    "score_detection": 0.55,
    "score_embedding": 0.7206250000000001,
    "total_score": 0.6502083333333334,
    "x": 9.730586051940918,
    "y": 6.541117191314697,
    "cluster_id": 87
  },
  {
    "feature_id": 561,
    "explanation_index": 2,
    "text": "The highlighted tokens are the structural delimiters and whitespace that define code layout\u2014line breaks, indentation, braces, parentheses, semicolons, and other punctuation that mark block boundaries and control flow.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8860715826352438,
    "similarity_var": 0.00040703357921343135,
    "score_fuzz": 0.55,
    "score_detection": 0.55,
    "score_embedding": 0.7737499999999999,
    "total_score": 0.6245833333333334,
    "x": 13.67541217803955,
    "y": 6.478686809539795,
    "cluster_id": 8
  },
  {
    "feature_id": 562,
    "explanation_index": 0,
    "text": "Prepositions, articles, and conjunctions, often in combination with nouns or other parts of speech, that provide context and structure to sentences.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8679831027984619,
    "similarity_var": 0.0001452717221350023,
    "score_fuzz": 0.7052631578947368,
    "score_detection": 0.7894736842105263,
    "score_embedding": 0.5272000000000001,
    "total_score": 0.673978947368421,
    "x": 12.513530731201172,
    "y": 0.09306895732879639,
    "cluster_id": -1
  },
  {
    "feature_id": 562,
    "explanation_index": 1,
    "text": "The model attends to sequences of tokens that form meaningful linguistic units such as proper nouns, technical terms, idiomatic expressions, or syntactic structures, often involving compound words, punctuation, or specific grammatical patterns like prepositional phrases and comparative suffixes.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8679831027984619,
    "similarity_var": 0.0001452717221350023,
    "score_fuzz": 0.72,
    "score_detection": 0.84,
    "score_embedding": 0.46125000000000005,
    "total_score": 0.6737500000000001,
    "x": 8.295368194580078,
    "y": 3.2704267501831055,
    "cluster_id": -1
  },
  {
    "feature_id": 562,
    "explanation_index": 2,
    "text": "Important tokens are usually nouns, adjectives, or prepositions that belong to a phrase conveying a concrete idea\u2014often a location, object, or comparative form\u2014and they frequently appear as part of a noun or prepositional phrase.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8679831027984619,
    "similarity_var": 0.0001452717221350023,
    "score_fuzz": 0.625,
    "score_detection": 0.8,
    "score_embedding": 0.5331250000000001,
    "total_score": 0.6527083333333333,
    "x": 11.426338195800781,
    "y": 4.663717269897461,
    "cluster_id": 78
  },
  {
    "feature_id": 563,
    "explanation_index": 0,
    "text": "Code snippets in various programming languages, often containing method calls, variable assignments, and conditional statements, with a focus on syntax and structure.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8852014541625977,
    "similarity_var": 0.00017747039700803194,
    "score_fuzz": 0.49,
    "score_detection": 0.47,
    "score_embedding": 0.48,
    "total_score": 0.48,
    "x": 11.164113998413086,
    "y": 8.664064407348633,
    "cluster_id": 17
  },
  {
    "feature_id": 563,
    "explanation_index": 1,
    "text": "Repeated use of delimiters enclosing identifiers or code elements, often surrounding variable names, method calls, or structural tokens in programming syntax, with high activation on the enclosed tokens and surrounding whitespace or punctuation.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8852014541625977,
    "similarity_var": 0.00017747039700803194,
    "score_fuzz": 0.5,
    "score_detection": 0.48,
    "score_embedding": 0.499375,
    "total_score": 0.49312500000000004,
    "x": 10.17293643951416,
    "y": 7.1715474128723145,
    "cluster_id": -1
  },
  {
    "feature_id": 563,
    "explanation_index": 2,
    "text": "The highlighted tokens are identifiers or keywords that play a key role in the code\u2019s logic\u2014function names, variable names, class names, or control\u2011flow keywords\u2014often followed by syntax such as parentheses, dots, or braces that signals their use. The activation scores indicate how central each token is to the surrounding code.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8852014541625977,
    "similarity_var": 0.00017747039700803194,
    "score_fuzz": 0.55,
    "score_detection": 0.475,
    "score_embedding": 0.379375,
    "total_score": 0.46812499999999996,
    "x": 13.818387031555176,
    "y": 6.618141174316406,
    "cluster_id": 8
  },
  {
    "feature_id": 564,
    "explanation_index": 0,
    "text": "Non-ASCII characters, often representing letters with diacritical marks, used in various languages.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8214123447736105,
    "similarity_var": 0.003910174630164755,
    "score_fuzz": 0.86,
    "score_detection": 0.84,
    "score_embedding": 0.2516,
    "total_score": 0.6505333333333333,
    "x": 8.736101150512695,
    "y": 7.28815221786499,
    "cluster_id": 4
  },
  {
    "feature_id": 564,
    "explanation_index": 1,
    "text": "Subword tokens representing diacritical marks or special characters in multilingual text, often part of proper nouns, names, or linguistic variants.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8214123447736105,
    "similarity_var": 0.003910174630164755,
    "score_fuzz": 0.8,
    "score_detection": 0.82,
    "score_embedding": 0.243125,
    "total_score": 0.6210416666666667,
    "x": 14.87944507598877,
    "y": 5.205077648162842,
    "cluster_id": 77
  },
  {
    "feature_id": 564,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8214123447736105,
    "similarity_var": 0.003910174630164755,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.31875,
    "total_score": 0.4395833333333334,
    "x": -7.899331569671631,
    "y": 9.160955429077148,
    "cluster_id": 52
  },
  {
    "feature_id": 565,
    "explanation_index": 0,
    "text": "A token that is often used to denote a shift or a change in the text, such as a greater-than or less-than symbol, a left or right arrow, or an asterisk, and is frequently used in programming languages, mathematical expressions, and citations.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8768154184023539,
    "similarity_var": 0.0006785899509659366,
    "score_fuzz": 0.53,
    "score_detection": 0.44,
    "score_embedding": 0.5456,
    "total_score": 0.5052,
    "x": 10.665759086608887,
    "y": 5.819941520690918,
    "cluster_id": 18
  },
  {
    "feature_id": 565,
    "explanation_index": 1,
    "text": "Patterns in the text involve structural or syntactic elements such as line breaks, punctuation, and formatting markers (e.g., newlines, parentheses, brackets, and special symbols) that often appear in code, markup, or formatted documents, with activations concentrated on delimiters, whitespace, and structural tokens.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8768154184023539,
    "similarity_var": 0.0006785899509659366,
    "score_fuzz": 0.44,
    "score_detection": 0.42,
    "score_embedding": 0.595,
    "total_score": 0.48500000000000004,
    "x": 10.246519088745117,
    "y": 6.8093767166137695,
    "cluster_id": 88
  },
  {
    "feature_id": 565,
    "explanation_index": 2,
    "text": "The highlighted tokens are primarily structural delimiters\u2014punctuation, brackets, and whitespace\u2014that mark boundaries or key positions in the text or code.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8768154184023539,
    "similarity_var": 0.0006785899509659366,
    "score_fuzz": 0.55,
    "score_detection": 0.4,
    "score_embedding": 0.559375,
    "total_score": 0.5031249999999999,
    "x": 13.71427059173584,
    "y": 5.7891106605529785,
    "cluster_id": -1
  },
  {
    "feature_id": 566,
    "explanation_index": 0,
    "text": "Special characters and numbers often used in mathematical expressions, citations, and technical notation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8991308410962423,
    "similarity_var": 0.00029575172335525067,
    "score_fuzz": 0.97,
    "score_detection": 0.96,
    "score_embedding": 0.8888,
    "total_score": 0.9396,
    "x": 8.917301177978516,
    "y": 7.903962135314941,
    "cluster_id": -1
  },
  {
    "feature_id": 566,
    "explanation_index": 1,
    "text": "Single digits and punctuation symbols frequently appear in numerical, mathematical, or technical contexts, often within sequences involving numbers, equations, or formatting markers.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8991308410962423,
    "similarity_var": 0.00029575172335525067,
    "score_fuzz": 0.93,
    "score_detection": 0.91,
    "score_embedding": 0.940625,
    "total_score": 0.926875,
    "x": 7.59335470199585,
    "y": 8.36925220489502,
    "cluster_id": 29
  },
  {
    "feature_id": 566,
    "explanation_index": 2,
    "text": "The highlighted tokens are consistently short, non\u2011lexical elements\u2014digits, punctuation, or single\u2011character symbols\u2014that appear within numeric literals, code fragments, or mathematical expressions, rather than ordinary words.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8991308410962423,
    "similarity_var": 0.00029575172335525067,
    "score_fuzz": 0.925,
    "score_detection": 0.9,
    "score_embedding": 0.95,
    "total_score": 0.9250000000000002,
    "x": 13.293737411499023,
    "y": 5.918578147888184,
    "cluster_id": 30
  },
  {
    "feature_id": 567,
    "explanation_index": 0,
    "text": "LaTeX mathematical expressions and equations, often including labels and alignment environments.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9269137779871622,
    "similarity_var": 0.0001482334830890232,
    "score_fuzz": 0.58,
    "score_detection": 0.49,
    "score_embedding": 0.666,
    "total_score": 0.5786666666666666,
    "x": 9.770247459411621,
    "y": 8.206221580505371,
    "cluster_id": -1
  },
  {
    "feature_id": 567,
    "explanation_index": 1,
    "text": "Mathematical expressions in LaTeX format, particularly those involving environments like aligned, cases, equation, and array, often preceded or followed by delimiters such as $$, \\\\begin{, \\\\end, or \\\\label, with frequent use of special symbols and structural tokens like {, }, $, and \\\\.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9269137779871622,
    "similarity_var": 0.0001482334830890232,
    "score_fuzz": 0.67,
    "score_detection": 0.51,
    "score_embedding": 0.6593749999999999,
    "total_score": 0.613125,
    "x": 9.688153266906738,
    "y": 8.083229064941406,
    "cluster_id": -1
  },
  {
    "feature_id": 567,
    "explanation_index": 2,
    "text": "LaTeX syntax elements that delimit math mode, environments, and labeling commands.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9269137779871622,
    "similarity_var": 0.0001482334830890232,
    "score_fuzz": 0.75,
    "score_detection": 0.55,
    "score_embedding": 0.684375,
    "total_score": 0.6614583333333334,
    "x": 10.03319263458252,
    "y": 8.05886173248291,
    "cluster_id": -1
  },
  {
    "feature_id": 568,
    "explanation_index": 0,
    "text": "Numerical values, often representing quantities, measurements, or identifiers, and sometimes used in mathematical expressions or as part of a larger code.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8983032902081808,
    "similarity_var": 0.00021954391897654408,
    "score_fuzz": 0.56,
    "score_detection": 0.45,
    "score_embedding": 0.35760000000000003,
    "total_score": 0.45586666666666664,
    "x": 6.824654579162598,
    "y": 8.811370849609375,
    "cluster_id": 29
  },
  {
    "feature_id": 568,
    "explanation_index": 1,
    "text": "Individual digits and symbols in numerical sequences, mathematical expressions, or technical identifiers, often appearing in contexts involving equations, codes, timestamps, or scientific notation.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8983032902081808,
    "similarity_var": 0.00021954391897654408,
    "score_fuzz": 0.58,
    "score_detection": 0.45,
    "score_embedding": 0.318125,
    "total_score": 0.449375,
    "x": 7.340188026428223,
    "y": 8.567729949951172,
    "cluster_id": 29
  },
  {
    "feature_id": 568,
    "explanation_index": 2,
    "text": "The highlighted tokens are usually short numeric or symbolic fragments that act as identifiers, indices, or delimiters in code, mathematical expressions, or reference strings.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8983032902081808,
    "similarity_var": 0.00021954391897654408,
    "score_fuzz": 0.675,
    "score_detection": 0.375,
    "score_embedding": 0.38125,
    "total_score": 0.4770833333333333,
    "x": 13.427122116088867,
    "y": 5.954745769500732,
    "cluster_id": 30
  },
  {
    "feature_id": 569,
    "explanation_index": 0,
    "text": "Nouns representing concepts, objects, or abstract ideas that are often related to human activities, characteristics, or conditions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8984038233757019,
    "similarity_var": 0.00039619777519088,
    "score_fuzz": 0.87,
    "score_detection": 0.42,
    "score_embedding": 0.5128,
    "total_score": 0.6009333333333333,
    "x": 8.2583589553833,
    "y": 0.22056539356708527,
    "cluster_id": 24
  },
  {
    "feature_id": 569,
    "explanation_index": 1,
    "text": "Nouns denoting abstract or physical entities that are central to the context, often related to biological, medical, social, or psychological concepts, with high activation values indicating their importance in conveying meaning.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8984038233757019,
    "similarity_var": 0.00039619777519088,
    "score_fuzz": 0.93,
    "score_detection": 0.69,
    "score_embedding": 0.5243749999999999,
    "total_score": 0.7147916666666667,
    "x": 8.156707763671875,
    "y": 0.40213891863822937,
    "cluster_id": 12
  },
  {
    "feature_id": 569,
    "explanation_index": 2,
    "text": "The highlighted tokens are nouns or noun phrases that carry the core semantic content of the sentence, typically serving as the subject or object, and are the focus of activation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8984038233757019,
    "similarity_var": 0.00039619777519088,
    "score_fuzz": 0.8571428571428571,
    "score_detection": 0.45,
    "score_embedding": 0.48124999999999996,
    "total_score": 0.5961309523809524,
    "x": 14.823256492614746,
    "y": 3.733246326446533,
    "cluster_id": -1
  },
  {
    "feature_id": 570,
    "explanation_index": 0,
    "text": "Various tokens including numbers, symbols, and words that appear to be part of a larger text, often denoting specific entities, quantities, or concepts, and sometimes serving as references or citations.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8423354427019755,
    "similarity_var": 0.00015564270233959913,
    "score_fuzz": 0.56,
    "score_detection": 0.52,
    "score_embedding": 0.5164,
    "total_score": 0.5321333333333333,
    "x": 10.250054359436035,
    "y": 5.012092590332031,
    "cluster_id": -1
  },
  {
    "feature_id": 570,
    "explanation_index": 1,
    "text": "The presence of specific lexical items related to biological, genetic, or scientific terminology, often in the context of plant breeding, genetic modification, or experimental procedures, with frequent use of comparative, descriptive, or technical phrasing.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8423354427019755,
    "similarity_var": 0.00015564270233959913,
    "score_fuzz": 0.59,
    "score_detection": 0.6,
    "score_embedding": 0.4425,
    "total_score": 0.5441666666666666,
    "x": 7.40728759765625,
    "y": 1.173223614692688,
    "cluster_id": 25
  },
  {
    "feature_id": 570,
    "explanation_index": 2,
    "text": "Important tokens are usually content words that form idiomatic or noun phrases, often flanked by function words that link them, and occasionally include comparative suffixes.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8423354427019755,
    "similarity_var": 0.00015564270233959913,
    "score_fuzz": 0.475,
    "score_detection": 0.4,
    "score_embedding": 0.39437500000000003,
    "total_score": 0.42312500000000003,
    "x": 11.485060691833496,
    "y": 4.641841888427734,
    "cluster_id": 78
  },
  {
    "feature_id": 571,
    "explanation_index": 0,
    "text": "Technical terms and abbreviations in scientific and academic contexts, often related to physics, astronomy, and chemistry.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8989435434341431,
    "similarity_var": 1.0353142587386325e-05,
    "score_fuzz": 0.72,
    "score_detection": 0.6,
    "score_embedding": 0.1848,
    "total_score": 0.5015999999999999,
    "x": 7.412632465362549,
    "y": 1.2384639978408813,
    "cluster_id": 25
  },
  {
    "feature_id": 571,
    "explanation_index": 1,
    "text": "Compound scientific terms formed by concatenation of root words, often representing specialized concepts in physics, chemistry, or astronomy, with high activation on individual morphemes that together form a technical term.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8989435434341431,
    "similarity_var": 1.0353142587386325e-05,
    "score_fuzz": 0.75,
    "score_detection": 0.82,
    "score_embedding": 0.271875,
    "total_score": 0.6139583333333333,
    "x": 7.437560081481934,
    "y": 2.2319939136505127,
    "cluster_id": -1
  },
  {
    "feature_id": 571,
    "explanation_index": 2,
    "text": "The highlighted tokens are domain\u2011specific scientific terms or fragments of multi\u2011word technical phrases, typically nouns or adjectives that appear in research contexts across fields such as astrophysics, climate science, and chemistry.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8989435434341431,
    "similarity_var": 1.0353142587386325e-05,
    "score_fuzz": 0.9428571428571428,
    "score_detection": 0.7714285714285715,
    "score_embedding": 0.2625,
    "total_score": 0.6589285714285714,
    "x": 13.684114456176758,
    "y": 4.626736640930176,
    "cluster_id": -1
  },
  {
    "feature_id": 572,
    "explanation_index": 0,
    "text": "Common nouns and adjectives, often representing objects, concepts, or ideas, and sometimes indicating a location, status, or relationship.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8844375610351562,
    "similarity_var": 0.001008719131696978,
    "score_fuzz": 0.78,
    "score_detection": 0.96,
    "score_embedding": 0.4608,
    "total_score": 0.7336,
    "x": 8.554883003234863,
    "y": -0.46552008390426636,
    "cluster_id": 79
  },
  {
    "feature_id": 572,
    "explanation_index": 1,
    "text": "Common nouns and adjectives denoting physical locations, abstract states, or tangible entities, often appearing in contexts involving spatial, temporal, or conceptual boundaries.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8844375610351562,
    "similarity_var": 0.001008719131696978,
    "score_fuzz": 0.7,
    "score_detection": 0.87,
    "score_embedding": 0.4525,
    "total_score": 0.6741666666666667,
    "x": 8.519033432006836,
    "y": -0.047658588737249374,
    "cluster_id": -1
  },
  {
    "feature_id": 572,
    "explanation_index": 2,
    "text": "The pattern might be that important tokens are nouns, adjectives, or phrases that are part of a larger phrase.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8844375610351562,
    "similarity_var": 0.001008719131696978,
    "score_fuzz": 0.7,
    "score_detection": 0.85,
    "score_embedding": 0.260625,
    "total_score": 0.6035416666666666,
    "x": 11.32933235168457,
    "y": 4.461321830749512,
    "cluster_id": 3
  },
  {
    "feature_id": 573,
    "explanation_index": 0,
    "text": "Words related to family relationships, possession, or connection, often used to describe kinship or association.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8849705457687378,
    "similarity_var": 0.000637527693643373,
    "score_fuzz": 0.76,
    "score_detection": 0.61,
    "score_embedding": 0.5864,
    "total_score": 0.6521333333333333,
    "x": 8.126057624816895,
    "y": -0.1505708396434784,
    "cluster_id": -1
  },
  {
    "feature_id": 573,
    "explanation_index": 1,
    "text": "The word \\\"and\\\" frequently appears in lists or comparisons, often connecting nouns or noun phrases, particularly in contexts involving groups, relationships, or categories such as people, family members, or entities. It is commonly used to link items in a series, especially when describing social groups, familial relationships, or inclusive categories.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8849705457687378,
    "similarity_var": 0.000637527693643373,
    "score_fuzz": 0.64,
    "score_detection": 0.66,
    "score_embedding": 0.426875,
    "total_score": 0.575625,
    "x": 11.719315528869629,
    "y": 2.16888165473938,
    "cluster_id": 38
  },
  {
    "feature_id": 573,
    "explanation_index": 2,
    "text": "The highlighted tokens are family\u2011related terms and modifiers that signal relationships or family units, often appearing with words like \u201crun,\u201d \u201cmember,\u201d \u201cof,\u201d or \u201cand.\u201d",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8849705457687378,
    "similarity_var": 0.000637527693643373,
    "score_fuzz": 0.7,
    "score_detection": 0.575,
    "score_embedding": 0.525,
    "total_score": 0.6,
    "x": 13.94736099243164,
    "y": 4.1090617179870605,
    "cluster_id": 42
  },
  {
    "feature_id": 574,
    "explanation_index": 0,
    "text": "Verbs or words related to expressions of strong emotions, particularly sadness, grief, or pain, often describing a person's reaction to a situation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8481216430664062,
    "similarity_var": 0.0016103303820666308,
    "score_fuzz": 0.8,
    "score_detection": 0.78,
    "score_embedding": 0.8543999999999999,
    "total_score": 0.8114666666666667,
    "x": 10.31189250946045,
    "y": -0.471009761095047,
    "cluster_id": -1
  },
  {
    "feature_id": 574,
    "explanation_index": 1,
    "text": "The root morphemes \\\"cry\\\", \\\"tear\\\", \\\"sob\\\", and \\\"wail\\\" are associated with emotional expression, particularly sadness or distress, often appearing in contexts involving intense feelings, physical reactions like crying or blurred vision, or metaphorical extensions of emotional states.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8481216430664062,
    "similarity_var": 0.0016103303820666308,
    "score_fuzz": 0.73,
    "score_detection": 0.8,
    "score_embedding": 0.8443750000000001,
    "total_score": 0.7914583333333334,
    "x": 10.165468215942383,
    "y": -0.1846580058336258,
    "cluster_id": -1
  },
  {
    "feature_id": 574,
    "explanation_index": 2,
    "text": "The model consistently flags short substrings that belong to emotionally charged or action\u2011oriented words, often appearing as incomplete fragments of larger terms.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8481216430664062,
    "similarity_var": 0.0016103303820666308,
    "score_fuzz": 0.7428571428571429,
    "score_detection": 0.75,
    "score_embedding": 0.5318750000000001,
    "total_score": 0.6749107142857144,
    "x": 8.075175285339355,
    "y": 3.2184383869171143,
    "cluster_id": 76
  },
  {
    "feature_id": 575,
    "explanation_index": 0,
    "text": "Verbs and adverbs related to making statements or promises under oath, or testifying in a formal setting, often in a legal context.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9004866480827332,
    "similarity_var": 0.00017065905584227417,
    "score_fuzz": 0.73,
    "score_detection": 0.72,
    "score_embedding": 0.838,
    "total_score": 0.7626666666666666,
    "x": 10.638707160949707,
    "y": -0.5091315507888794,
    "cluster_id": 85
  },
  {
    "feature_id": 575,
    "explanation_index": 1,
    "text": "The word \\\"swear\\\" and its variants (e.g., \\\"sworn\\\", \\\"swearing\\\") are frequently activated in contexts involving oaths, promises, or assertions of truth, often in legal, formal, or emotionally charged statements.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9004866480827332,
    "similarity_var": 0.00017065905584227417,
    "score_fuzz": 0.64,
    "score_detection": 0.65,
    "score_embedding": 0.9362499999999999,
    "total_score": 0.7420833333333333,
    "x": 10.49422836303711,
    "y": 0.026153553277254105,
    "cluster_id": -1
  },
  {
    "feature_id": 575,
    "explanation_index": 2,
    "text": "The highlighted tokens are typically short, often legal or oath\u2011related verbs or function words that appear in declarative statements about oaths, testimony, or legal actions.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9004866480827332,
    "similarity_var": 0.00017065905584227417,
    "score_fuzz": 0.75,
    "score_detection": 0.65,
    "score_embedding": 0.886875,
    "total_score": 0.7622916666666666,
    "x": 13.832002639770508,
    "y": 3.302794933319092,
    "cluster_id": 35
  },
  {
    "feature_id": 576,
    "explanation_index": 0,
    "text": "Words related to sports, particularly American football, baseball, and other competitive activities, often referring to actions, objects, or scoring elements within the games.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8322889606157938,
    "similarity_var": 0.0009675535523483192,
    "score_fuzz": 0.51,
    "score_detection": 0.28,
    "score_embedding": 0.4404,
    "total_score": 0.4101333333333333,
    "x": 8.2691650390625,
    "y": -0.3060283362865448,
    "cluster_id": -1
  },
  {
    "feature_id": 576,
    "explanation_index": 1,
    "text": "Common suffixes or compound words ending in -er, -ing, -ed, or -ing/-ed combinations that denote actions, states, or roles, often related to sports, physical actions, or abstract concepts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8322889606157938,
    "similarity_var": 0.0009675535523483192,
    "score_fuzz": 0.55,
    "score_detection": 0.35,
    "score_embedding": 0.47625,
    "total_score": 0.45875,
    "x": 8.526216506958008,
    "y": 2.2603259086608887,
    "cluster_id": 66
  },
  {
    "feature_id": 576,
    "explanation_index": 2,
    "text": "The highlighted tokens are the semantic anchors of each clause\u2014nouns, noun phrases, or key verbs that form idiomatic or collocational units, often indicating objects, actions, or comparative states, and they carry the main meaning or sentiment of the sentence.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8322889606157938,
    "similarity_var": 0.0009675535523483192,
    "score_fuzz": 0.65,
    "score_detection": 0.475,
    "score_embedding": 0.5587500000000001,
    "total_score": 0.56125,
    "x": 14.894062995910645,
    "y": 3.639803171157837,
    "cluster_id": -1
  },
  {
    "feature_id": 577,
    "explanation_index": 0,
    "text": "Tokens that are part of author names, citations, or references in various contexts, including academic papers, code comments, and online articles.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8767459591229757,
    "similarity_var": 0.00037247809100509553,
    "score_fuzz": 0.8105263157894737,
    "score_detection": 0.84,
    "score_embedding": 0.38680000000000003,
    "total_score": 0.6791087719298247,
    "x": 10.062036514282227,
    "y": 4.830315113067627,
    "cluster_id": -1
  },
  {
    "feature_id": 577,
    "explanation_index": 1,
    "text": "Named entities, particularly proper nouns such as people, places, or organizations, often appear in contexts involving citations, attributions, or metadata, and are frequently associated with punctuation or formatting markers like parentheses, brackets, or special symbols.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8767459591229757,
    "similarity_var": 0.00037247809100509553,
    "score_fuzz": 0.84,
    "score_detection": 0.88,
    "score_embedding": 0.48500000000000004,
    "total_score": 0.735,
    "x": 6.8749895095825195,
    "y": -0.8166530728340149,
    "cluster_id": 84
  },
  {
    "feature_id": 577,
    "explanation_index": 2,
    "text": "The highlighted segments are the core semantic units of each sentence\u2014typically nouns or noun phrases that name a concrete object, place, or concept, often preceded by an article or preposition, and occasionally code\u2011style markers such as \u201c@\u201d or \u201c*\u201d that signal annotations or directives.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8767459591229757,
    "similarity_var": 0.00037247809100509553,
    "score_fuzz": 0.225,
    "score_detection": 0.525,
    "score_embedding": 0.34375,
    "total_score": 0.3645833333333333,
    "x": 15.582895278930664,
    "y": 6.878023624420166,
    "cluster_id": -1
  },
  {
    "feature_id": 578,
    "explanation_index": 0,
    "text": "Adverbs and adjectives that express possibility, potential, or extent, often used in formal or technical writing to convey nuanced information or to hedge statements.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8291995922724406,
    "similarity_var": 0.002002190240397618,
    "score_fuzz": 0.7,
    "score_detection": 0.51,
    "score_embedding": 0.48719999999999997,
    "total_score": 0.5657333333333333,
    "x": 9.346339225769043,
    "y": 1.5467675924301147,
    "cluster_id": 89
  },
  {
    "feature_id": 578,
    "explanation_index": 1,
    "text": "Words related to possibility, likelihood, or uncertainty (e.g., potential, possibly, presumably, allegedly, potentially, possibly, presumably) often appear in contexts involving speculation, hypotheticals, or cautious claims.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8291995922724406,
    "similarity_var": 0.002002190240397618,
    "score_fuzz": 0.66,
    "score_detection": 0.64,
    "score_embedding": 0.566875,
    "total_score": 0.6222916666666667,
    "x": 9.252511978149414,
    "y": 1.0704330205917358,
    "cluster_id": -1
  },
  {
    "feature_id": 578,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8291995922724406,
    "similarity_var": 0.002002190240397618,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.3762500000000001,
    "total_score": 0.45875000000000005,
    "x": -7.864960670471191,
    "y": 9.195340156555176,
    "cluster_id": 52
  },
  {
    "feature_id": 579,
    "explanation_index": 0,
    "text": "Punctuation marks and conjunctions used to connect clauses, phrases, or sentences in formal or legal writing, often introducing or separating quotes, citations, or explanations.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8939530253410339,
    "similarity_var": 7.681712469557549e-05,
    "score_fuzz": 0.81,
    "score_detection": 0.5,
    "score_embedding": 0.5484,
    "total_score": 0.6194666666666667,
    "x": 7.923192501068115,
    "y": 6.432061672210693,
    "cluster_id": 5
  },
  {
    "feature_id": 579,
    "explanation_index": 1,
    "text": "The word \\\"that\\\" frequently appears in conditional or explanatory clauses, often introducing a legal or logical justification, while punctuation like commas and periods mark syntactic boundaries in formal legal text.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8939530253410339,
    "similarity_var": 7.681712469557549e-05,
    "score_fuzz": 0.71,
    "score_detection": 0.64,
    "score_embedding": 0.5806250000000001,
    "total_score": 0.6435416666666667,
    "x": 8.525339126586914,
    "y": 6.3479485511779785,
    "cluster_id": -1
  },
  {
    "feature_id": 579,
    "explanation_index": 2,
    "text": "The highlighted tokens are the grammatical glue of the text\u2014function words and punctuation that link clauses, signal relationships, and structure the legal prose.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8939530253410339,
    "similarity_var": 7.681712469557549e-05,
    "score_fuzz": 0.725,
    "score_detection": 0.525,
    "score_embedding": 0.564375,
    "total_score": 0.6047916666666667,
    "x": 13.709861755371094,
    "y": 3.3468940258026123,
    "cluster_id": 35
  },
  {
    "feature_id": 581,
    "explanation_index": 0,
    "text": "Punctuation marks, mathematical symbols, and special characters, often used in formal or technical writing, such as academic papers, patents, and mathematical equations.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8566872477531433,
    "similarity_var": 0.002175730992180528,
    "score_fuzz": 0.33,
    "score_detection": 0.22,
    "score_embedding": 0.27759999999999996,
    "total_score": 0.27586666666666665,
    "x": 8.515046119689941,
    "y": 7.30632209777832,
    "cluster_id": 4
  },
  {
    "feature_id": 581,
    "explanation_index": 1,
    "text": "The presence of technical, mathematical, or formal notation elements, including subscripts, superscripts, special symbols, and structured syntax, often associated with scientific, mathematical, or technical writing.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8566872477531433,
    "similarity_var": 0.002175730992180528,
    "score_fuzz": 0.22,
    "score_detection": 0.18,
    "score_embedding": 0.344375,
    "total_score": 0.248125,
    "x": 9.249434471130371,
    "y": 7.977266788482666,
    "cluster_id": -1
  },
  {
    "feature_id": 581,
    "explanation_index": 2,
    "text": "The highlighted tokens are contiguous, high\u2011impact units\u2014idioms, suffixes, container nouns, or formal symbols\u2014that the model treats as key semantic or syntactic building blocks.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8566872477531433,
    "similarity_var": 0.002175730992180528,
    "score_fuzz": 0.325,
    "score_detection": 0.35,
    "score_embedding": 0.511875,
    "total_score": 0.39562500000000006,
    "x": 15.099181175231934,
    "y": 4.768269062042236,
    "cluster_id": 55
  },
  {
    "feature_id": 582,
    "explanation_index": 0,
    "text": "Common nouns and pronouns, often referring to objects, concepts, or entities being examined, investigated, or discussed in a formal or technical context.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8640383879343668,
    "similarity_var": 0.0004187568441535758,
    "score_fuzz": 0.62,
    "score_detection": 0.42,
    "score_embedding": 0.41800000000000004,
    "total_score": 0.48600000000000004,
    "x": 8.600975036621094,
    "y": -0.09919101744890213,
    "cluster_id": -1
  },
  {
    "feature_id": 582,
    "explanation_index": 1,
    "text": "Commonly activated tokens include pronouns referring to previously mentioned entities, prepositions indicating spatial or logical relationships, and nouns denoting abstract or concrete objects, often in contexts involving review, evaluation, or reference to prior information.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8640383879343668,
    "similarity_var": 0.0004187568441535758,
    "score_fuzz": 0.58,
    "score_detection": 0.48,
    "score_embedding": 0.41187500000000005,
    "total_score": 0.49062500000000003,
    "x": 10.324710845947266,
    "y": 3.704533338546753,
    "cluster_id": -1
  },
  {
    "feature_id": 582,
    "explanation_index": 2,
    "text": "The tokens are often common words: \\\"it\\\", \\\"the\\\", \\\"to\\\", \\\"for\\\", \\\"in\\\", \\\"at\\\", \\\"by\\\", \\\"and\\\", \\\"with\\\", \\\"of\\\", \\\"on\\\", \\\"is\\\", \\\"was\\\", \\\"are\\\", \\\"be\\\", \\\"have\\\", \\\"has\\\", \\\"had\\\", \\\"were\\\", \\\"will\\\", \\\"would\\\", \\\"can\\\", \\\"could\\\", \\\"should\\\", \\\"would\\\", \\\"might\\\", \\\"must\\\", \\\"shall\\\", \\\"do\\\", \\\"does\\\", \\\"did\\\", \\\"done\\\", \\\"doing\\\", \\\"doing\\\", etc.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8640383879343668,
    "similarity_var": 0.0004187568441535758,
    "score_fuzz": 0.475,
    "score_detection": 0.5,
    "score_embedding": 0.22187500000000002,
    "total_score": 0.3989583333333333,
    "x": 11.007369041442871,
    "y": 3.3672244548797607,
    "cluster_id": 27
  },
  {
    "feature_id": 584,
    "explanation_index": 0,
    "text": "Various programming language syntax elements, including function calls, variable declarations, control structures, and HTML tags.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9048012097676595,
    "similarity_var": 0.00027678360938033895,
    "score_fuzz": 0.62,
    "score_detection": 0.55,
    "score_embedding": 0.5267999999999999,
    "total_score": 0.5656,
    "x": 10.662799835205078,
    "y": 8.353714942932129,
    "cluster_id": 48
  },
  {
    "feature_id": 584,
    "explanation_index": 1,
    "text": "Delimiters and structural tokens in code or markup, often used to denote syntax elements, code blocks, or formatting boundaries, with frequent activation of identifiers, punctuation, and keyword tokens.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9048012097676595,
    "similarity_var": 0.00027678360938033895,
    "score_fuzz": 0.51,
    "score_detection": 0.62,
    "score_embedding": 0.55125,
    "total_score": 0.5604166666666667,
    "x": 10.1848783493042,
    "y": 7.047828674316406,
    "cluster_id": -1
  },
  {
    "feature_id": 584,
    "explanation_index": 2,
    "text": "The highlighted tokens are code elements that carry syntactic or semantic weight in programming contexts\u2014function names, variable identifiers, operators, and punctuation\u2014often appearing within code fragments.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9048012097676595,
    "similarity_var": 0.00027678360938033895,
    "score_fuzz": 0.5,
    "score_detection": 0.475,
    "score_embedding": 0.525625,
    "total_score": 0.5002083333333333,
    "x": 13.927553176879883,
    "y": 6.574413299560547,
    "cluster_id": 8
  },
  {
    "feature_id": 586,
    "explanation_index": 0,
    "text": "The word \\\"who\\\" is used as a relative pronoun to introduce a clause describing a person or people, often indicating that they have a particular characteristic or have performed a specific action.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9532967607180277,
    "similarity_var": 7.85434499077395e-05,
    "score_fuzz": 0.9,
    "score_detection": 0.93,
    "score_embedding": 0.6012,
    "total_score": 0.8104,
    "x": 11.699952125549316,
    "y": 1.4894670248031616,
    "cluster_id": 71
  },
  {
    "feature_id": 586,
    "explanation_index": 1,
    "text": "The pronoun \\\"who\\\" is used to introduce a relative clause that provides additional information about a person or group previously mentioned, often indicating a specific individual or entity with a defined role or characteristic.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9532967607180277,
    "similarity_var": 7.85434499077395e-05,
    "score_fuzz": 0.91,
    "score_detection": 0.93,
    "score_embedding": 0.6706249999999999,
    "total_score": 0.836875,
    "x": 11.655011177062988,
    "y": 1.5052562952041626,
    "cluster_id": -1
  },
  {
    "feature_id": 586,
    "explanation_index": 2,
    "text": "The pattern: \\\"who\\\" is used as a relative pronoun.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9532967607180277,
    "similarity_var": 7.85434499077395e-05,
    "score_fuzz": 0.925,
    "score_detection": 0.95,
    "score_embedding": 0.648125,
    "total_score": 0.8410416666666666,
    "x": 11.70269775390625,
    "y": 1.5402541160583496,
    "cluster_id": -1
  },
  {
    "feature_id": 587,
    "explanation_index": 0,
    "text": "Code snippets from various programming languages, often including function calls, variable assignments, and control structures, with a focus on syntax and structure.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9008239308993021,
    "similarity_var": 0.0002690840641206035,
    "score_fuzz": 0.72,
    "score_detection": 0.73,
    "score_embedding": 0.4004,
    "total_score": 0.6168,
    "x": 11.221400260925293,
    "y": 8.72519302368164,
    "cluster_id": 17
  },
  {
    "feature_id": 587,
    "explanation_index": 1,
    "text": "Patterns involving code syntax, including identifiers, operators, and structural tokens, often associated with programming language constructs and comments.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9008239308993021,
    "similarity_var": 0.0002690840641206035,
    "score_fuzz": 0.64,
    "score_detection": 0.67,
    "score_embedding": 0.313125,
    "total_score": 0.5410416666666666,
    "x": 10.702897071838379,
    "y": 7.404508113861084,
    "cluster_id": 7
  },
  {
    "feature_id": 587,
    "explanation_index": 2,
    "text": "The highlighted tokens are code fragments that together form syntactically meaningful units\u2014identifiers, keywords, operators, and punctuation\u2014often appearing as contiguous sequences that represent a single expression or statement.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9008239308993021,
    "similarity_var": 0.0002690840641206035,
    "score_fuzz": 0.35,
    "score_detection": 0.55,
    "score_embedding": 0.205625,
    "total_score": 0.3685416666666667,
    "x": 14.041584968566895,
    "y": 6.217185020446777,
    "cluster_id": -1
  },
  {
    "feature_id": 590,
    "explanation_index": 0,
    "text": "A wide range of programming languages and code snippets, often with a focus on syntax and structure, including indentation, brackets, and semicolons.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8686927358309428,
    "similarity_var": 0.00034084734342896026,
    "score_fuzz": 0.54,
    "score_detection": 0.62,
    "score_embedding": 0.3744,
    "total_score": 0.5114666666666667,
    "x": 11.213211059570312,
    "y": 8.727428436279297,
    "cluster_id": 17
  },
  {
    "feature_id": 590,
    "explanation_index": 1,
    "text": "Patterns involving punctuation, brackets, and special symbols used in code syntax, often indicating structure, control flow, or formatting, with high activation on tokens that mark boundaries or syntactic elements.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8686927358309428,
    "similarity_var": 0.00034084734342896026,
    "score_fuzz": 0.45,
    "score_detection": 0.53,
    "score_embedding": 0.31625000000000003,
    "total_score": 0.4320833333333334,
    "x": 10.400958061218262,
    "y": 7.185781955718994,
    "cluster_id": 86
  },
  {
    "feature_id": 590,
    "explanation_index": 2,
    "text": "The highlighted tokens are always short, contiguous units that together form a meaningful phrase or code fragment\u2014whether an idiomatic expression, a comparative ending, a noun phrase, a keyword, a variable name, or a placeholder. They serve as the core element of the surrounding context, appearing in natural\u2011language sentences or programming snippets, and are typically bounded by whitespace or punctuation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8686927358309428,
    "similarity_var": 0.00034084734342896026,
    "score_fuzz": 0.4,
    "score_detection": 0.5,
    "score_embedding": 0.38187499999999996,
    "total_score": 0.4272916666666666,
    "x": 14.923317909240723,
    "y": 4.669009208679199,
    "cluster_id": -1
  },
  {
    "feature_id": 591,
    "explanation_index": 0,
    "text": "Various programming-related syntax elements, including file paths, class and function names, and code snippets in different programming languages.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8933167060216268,
    "similarity_var": 0.00023080473218881374,
    "score_fuzz": 0.37,
    "score_detection": 0.36,
    "score_embedding": 0.34439999999999993,
    "total_score": 0.35813333333333325,
    "x": 10.64455795288086,
    "y": 8.38186264038086,
    "cluster_id": 48
  },
  {
    "feature_id": 591,
    "explanation_index": 1,
    "text": "Frequent use of forward slashes, dots, and angle brackets in code syntax, often associated with file paths, HTML/XML tags, or programming language constructs.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8933167060216268,
    "similarity_var": 0.00023080473218881374,
    "score_fuzz": 0.45,
    "score_detection": 0.42,
    "score_embedding": 0.464375,
    "total_score": 0.4447916666666667,
    "x": 10.44458293914795,
    "y": 7.73450231552124,
    "cluster_id": -1
  },
  {
    "feature_id": 591,
    "explanation_index": 2,
    "text": "The highlighted tokens are structural markers in code and markup\u2014tags, file extensions, operators, path separators, and language keywords\u2014that delineate syntax and context.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8933167060216268,
    "similarity_var": 0.00023080473218881374,
    "score_fuzz": 0.425,
    "score_detection": 0.375,
    "score_embedding": 0.5337500000000001,
    "total_score": 0.4445833333333334,
    "x": 13.841358184814453,
    "y": 6.2807722091674805,
    "cluster_id": -1
  },
  {
    "feature_id": 592,
    "explanation_index": 0,
    "text": "Nouns, noun phrases, or words that are part of a compound word, often representing objects, concepts, or actions, and sometimes indicating a relationship or a characteristic.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8912005225817362,
    "similarity_var": 0.0002475181965672214,
    "score_fuzz": 0.75,
    "score_detection": 0.46,
    "score_embedding": 0.18840000000000004,
    "total_score": 0.46613333333333334,
    "x": 8.544110298156738,
    "y": 0.10153352469205856,
    "cluster_id": 24
  },
  {
    "feature_id": 592,
    "explanation_index": 1,
    "text": "Compound nouns or multi-word terms where the first part is a modifier and the second part is a core noun, often representing a specific concept, location, or technical term, with the second word typically carrying higher activation importance.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8912005225817362,
    "similarity_var": 0.0002475181965672214,
    "score_fuzz": 0.73,
    "score_detection": 0.53,
    "score_embedding": 0.23562500000000003,
    "total_score": 0.49854166666666666,
    "x": 8.692996978759766,
    "y": 0.43804627656936646,
    "cluster_id": -1
  },
  {
    "feature_id": 592,
    "explanation_index": 2,
    "text": "The highlighted tokens are usually the core nouns or noun phrases that carry the main semantic content of the surrounding phrase, often representing objects, concepts, or entities, and occasionally key adjectives or prepositions that form idiomatic expressions.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8912005225817362,
    "similarity_var": 0.0002475181965672214,
    "score_fuzz": 0.7,
    "score_detection": 0.575,
    "score_embedding": 0.273125,
    "total_score": 0.5160416666666666,
    "x": 15.062859535217285,
    "y": 3.885181188583374,
    "cluster_id": 22
  },
  {
    "feature_id": 594,
    "explanation_index": 0,
    "text": "Numerical values, often representing quantities, measurements, or statistical data, frequently appearing in scientific, mathematical, or technical contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8831561406453451,
    "similarity_var": 6.718878056075382e-05,
    "score_fuzz": 0.96,
    "score_detection": 0.88,
    "score_embedding": 0.6735999999999999,
    "total_score": 0.8378666666666666,
    "x": 6.808372974395752,
    "y": 8.798059463500977,
    "cluster_id": 29
  },
  {
    "feature_id": 594,
    "explanation_index": 1,
    "text": "The digit \\\"1\\\" frequently appears in numerical contexts, particularly in sequences involving measurements, percentages, or mathematical expressions, often as part of a larger number or in positions where it contributes to a significant digit in a value.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8831561406453451,
    "similarity_var": 6.718878056075382e-05,
    "score_fuzz": 0.75,
    "score_detection": 0.89,
    "score_embedding": 0.6212500000000002,
    "total_score": 0.7537500000000001,
    "x": 7.526801109313965,
    "y": 8.400867462158203,
    "cluster_id": 29
  },
  {
    "feature_id": 594,
    "explanation_index": 2,
    "text": "The highlighted tokens are numeric values or placeholders that appear in a wide range of contexts\u2014percentages, ranges, measurements, and numeric identifiers\u2014indicating that the model focuses on numeric information within the text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8831561406453451,
    "similarity_var": 6.718878056075382e-05,
    "score_fuzz": 0.925,
    "score_detection": 0.825,
    "score_embedding": 0.5806250000000001,
    "total_score": 0.776875,
    "x": 13.217757225036621,
    "y": 5.8551344871521,
    "cluster_id": 30
  },
  {
    "feature_id": 596,
    "explanation_index": 0,
    "text": "Prepositions and conjunctions, often used to indicate time, duration, or continuation, and sometimes preceding or following a comma or period.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8378869692484537,
    "similarity_var": 0.0027218117079483607,
    "score_fuzz": 0.72,
    "score_detection": 0.54,
    "score_embedding": 0.6768000000000001,
    "total_score": 0.6456000000000001,
    "x": 12.136123657226562,
    "y": 0.00564449280500412,
    "cluster_id": 9
  },
  {
    "feature_id": 596,
    "explanation_index": 1,
    "text": "Common temporal or spatial phrases involving time durations, locations, or sequential relationships, often containing prepositions or conjunctions that link clauses or specify context.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8378869692484537,
    "similarity_var": 0.0027218117079483607,
    "score_fuzz": 0.62,
    "score_detection": 0.67,
    "score_embedding": 0.525625,
    "total_score": 0.6052083333333333,
    "x": 12.107537269592285,
    "y": -0.1595568060874939,
    "cluster_id": 9
  },
  {
    "feature_id": 596,
    "explanation_index": 2,
    "text": "the patterns.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8378869692484537,
    "similarity_var": 0.0027218117079483607,
    "score_fuzz": 0.575,
    "score_detection": 0.275,
    "score_embedding": 0.5393749999999999,
    "total_score": 0.46312499999999995,
    "x": 5.139211654663086,
    "y": 9.968585968017578,
    "cluster_id": 58
  },
  {
    "feature_id": 597,
    "explanation_index": 0,
    "text": "Various nouns and words that appear to be significant in the context of the surrounding text, including proper nouns, common nouns, and words that indicate relationships or actions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8282077511151632,
    "similarity_var": 0.0010957425032395286,
    "score_fuzz": 0.61,
    "score_detection": 0.37,
    "score_embedding": 0.11239999999999999,
    "total_score": 0.36413333333333336,
    "x": 8.535906791687012,
    "y": -0.36321431398391724,
    "cluster_id": -1
  },
  {
    "feature_id": 597,
    "explanation_index": 1,
    "text": "Fragments of words or compound terms, often part of larger lexical units, where the activation is concentrated on partial or morphologically derived components, particularly in contexts involving technical, proper, or compound nouns.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8282077511151632,
    "similarity_var": 0.0010957425032395286,
    "score_fuzz": 0.48,
    "score_detection": 0.43,
    "score_embedding": 0.145625,
    "total_score": 0.351875,
    "x": 7.110503196716309,
    "y": 2.442643642425537,
    "cluster_id": 2
  },
  {
    "feature_id": 597,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8282077511151632,
    "similarity_var": 0.0010957425032395286,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.133125,
    "total_score": 0.3777083333333333,
    "x": -6.008086681365967,
    "y": 15.900917053222656,
    "cluster_id": 10
  },
  {
    "feature_id": 598,
    "explanation_index": 0,
    "text": "Prepositions, conjunctions, and articles, often used in phrases or idiomatic expressions, and sometimes used to introduce clauses or quotes.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.867872436841329,
    "similarity_var": 0.00025205041649753766,
    "score_fuzz": 0.78,
    "score_detection": 0.42,
    "score_embedding": 0.24,
    "total_score": 0.48,
    "x": 12.263033866882324,
    "y": 0.11842141300439835,
    "cluster_id": -1
  },
  {
    "feature_id": 598,
    "explanation_index": 1,
    "text": "The word \\\"as\\\" frequently appears in contexts involving comparisons, definitions, or qualifications, often introducing a clause that explains or modifies the preceding statement. It is commonly used in formal or technical writing to denote equivalence, manner, or condition.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.867872436841329,
    "similarity_var": 0.00025205041649753766,
    "score_fuzz": 0.86,
    "score_detection": 0.84,
    "score_embedding": 0.159375,
    "total_score": 0.6197916666666666,
    "x": 11.711915969848633,
    "y": 2.6427271366119385,
    "cluster_id": 49
  },
  {
    "feature_id": 598,
    "explanation_index": 2,
    "text": "The token \u201cas\u201d is a high\u2011frequency function word that appears in many contexts\u2014often as a conjunction or preposition, sometimes capitalized, and frequently in legal or code phrases such as \u201cAS\u202fIS\u201d.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.867872436841329,
    "similarity_var": 0.00025205041649753766,
    "score_fuzz": 0.825,
    "score_detection": 0.725,
    "score_embedding": 0.131875,
    "total_score": 0.5606249999999999,
    "x": 11.719367980957031,
    "y": 2.711589813232422,
    "cluster_id": 49
  },
  {
    "feature_id": 599,
    "explanation_index": 0,
    "text": "Definite articles, possessive pronouns, and indefinite articles often precede nouns in formal or technical writing, particularly in contexts such as scientific or academic texts, official documents, and descriptive passages.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8667462865511576,
    "similarity_var": 0.0005835972726049792,
    "score_fuzz": 0.85,
    "score_detection": 0.38,
    "score_embedding": 0.3228,
    "total_score": 0.5176,
    "x": 12.876219749450684,
    "y": 0.5098035931587219,
    "cluster_id": 34
  },
  {
    "feature_id": 599,
    "explanation_index": 1,
    "text": "The definite article \\\"the\\\" frequently appears in contexts involving specific, previously mentioned, or uniquely identifiable entities, often preceding nouns that denote abstract concepts, technical components, geographical features, or established systems.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8667462865511576,
    "similarity_var": 0.0005835972726049792,
    "score_fuzz": 0.72,
    "score_detection": 0.61,
    "score_embedding": 0.44625,
    "total_score": 0.5920833333333334,
    "x": 12.68212604522705,
    "y": 0.7195313572883606,
    "cluster_id": 34
  },
  {
    "feature_id": 599,
    "explanation_index": 2,
    "text": "The highlighted tokens are function words\u2014articles, determiners, pronouns\u2014that serve grammatical roles in the sentence.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8667462865511576,
    "similarity_var": 0.0005835972726049792,
    "score_fuzz": 0.85,
    "score_detection": 0.775,
    "score_embedding": 0.42125,
    "total_score": 0.6820833333333334,
    "x": 13.486865043640137,
    "y": 3.238929033279419,
    "cluster_id": 35
  },
  {
    "feature_id": 600,
    "explanation_index": 0,
    "text": "Various parts of speech, including nouns, pronouns, adjectives, and adverbs, often functioning as subjects, objects, or modifiers in sentences, sometimes introducing or following quotations or clauses.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8514881730079651,
    "similarity_var": 0.0003631451222953312,
    "score_fuzz": 0.57,
    "score_detection": 0.49,
    "score_embedding": 0.434,
    "total_score": 0.498,
    "x": 9.518464088439941,
    "y": -0.06144135817885399,
    "cluster_id": -1
  },
  {
    "feature_id": 600,
    "explanation_index": 1,
    "text": "Pronouns and nouns referring to people, places, or entities in contextually specific roles, often following or preceding descriptive or relational phrases.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8514881730079651,
    "similarity_var": 0.0003631451222953312,
    "score_fuzz": 0.69,
    "score_detection": 0.34,
    "score_embedding": 0.325,
    "total_score": 0.45166666666666666,
    "x": 11.683686256408691,
    "y": 1.0489072799682617,
    "cluster_id": 64
  },
  {
    "feature_id": 600,
    "explanation_index": 2,
    "text": "The activations consistently target small, high\u2011frequency function words\u2014pronouns, prepositions, articles, and conjunctions\u2014that appear at clause or phrase boundaries, indicating that the model focuses on syntactic glue rather than on content words.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8514881730079651,
    "similarity_var": 0.0003631451222953312,
    "score_fuzz": 0.4,
    "score_detection": 0.425,
    "score_embedding": 0.39812499999999995,
    "total_score": 0.40770833333333334,
    "x": 13.020064353942871,
    "y": 3.304915189743042,
    "cluster_id": 82
  },
  {
    "feature_id": 601,
    "explanation_index": 0,
    "text": "Tokens related to regulation, regularity, and registration, often in formal or technical contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8438515067100525,
    "similarity_var": 5.0192598301634916e-05,
    "score_fuzz": 0.7157894736842105,
    "score_detection": 0.7,
    "score_embedding": 0.5752,
    "total_score": 0.6636631578947368,
    "x": 10.331913948059082,
    "y": 4.279087066650391,
    "cluster_id": 1
  },
  {
    "feature_id": 601,
    "explanation_index": 1,
    "text": "Partial or truncated words, often stemming from abbreviations, technical terms, or morphological fragments, that are contextually meaningful and frequently appear in scientific, technical, or formal writing.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8438515067100525,
    "similarity_var": 5.0192598301634916e-05,
    "score_fuzz": 0.46,
    "score_detection": 0.75,
    "score_embedding": 0.608125,
    "total_score": 0.6060416666666667,
    "x": 7.3570733070373535,
    "y": 2.8614308834075928,
    "cluster_id": 15
  },
  {
    "feature_id": 601,
    "explanation_index": 2,
    "text": "The pattern might be that the activations highlight substrings that are part of larger words, often prefixes like \\\"reg\\\", \\\"re\\\", \\\"regu\\\", \\\"regi\\\", \\\"regul\\\", \\\"regul\\\".",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8438515067100525,
    "similarity_var": 5.0192598301634916e-05,
    "score_fuzz": 0.8,
    "score_detection": 0.775,
    "score_embedding": 0.5768749999999999,
    "total_score": 0.7172916666666667,
    "x": 11.478132247924805,
    "y": 4.049186706542969,
    "cluster_id": -1
  },
  {
    "feature_id": 602,
    "explanation_index": 0,
    "text": "Adjectives and nouns describing size, magnitude, or importance, often used to emphasize or compare something.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8870843648910522,
    "similarity_var": 0.0010745501814710678,
    "score_fuzz": 0.65,
    "score_detection": 0.48,
    "score_embedding": 0.7036,
    "total_score": 0.6112,
    "x": 8.917862892150879,
    "y": 1.280856966972351,
    "cluster_id": 45
  },
  {
    "feature_id": 602,
    "explanation_index": 1,
    "text": "Superlative or comparative adjectives (e.g., big, large, great, major, vast, long, high, deep, huge, small, little, much, little, store, bit) often used to emphasize degree, size, or importance, frequently appearing in contexts involving scale, magnitude, or comparison.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8870843648910522,
    "similarity_var": 0.0010745501814710678,
    "score_fuzz": 0.71,
    "score_detection": 0.52,
    "score_embedding": 0.6968749999999999,
    "total_score": 0.6422916666666666,
    "x": 9.713879585266113,
    "y": 2.024524211883545,
    "cluster_id": -1
  },
  {
    "feature_id": 602,
    "explanation_index": 2,
    "text": "The highlighted terms are modifiers\u2014adjectives or nouns\u2014that supply descriptive detail (size, importance, location) to the noun they accompany, appearing in both prose and code contexts.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8870843648910522,
    "similarity_var": 0.0010745501814710678,
    "score_fuzz": 0.6285714285714286,
    "score_detection": 0.3,
    "score_embedding": 0.566875,
    "total_score": 0.4984821428571429,
    "x": 16.730390548706055,
    "y": 3.608482599258423,
    "cluster_id": 20
  },
  {
    "feature_id": 603,
    "explanation_index": 0,
    "text": "Mathematical and scientific notation, including symbols, equations, and formatting, often used in academic or technical contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8543616930643717,
    "similarity_var": 0.0012886734495375484,
    "score_fuzz": 0.56,
    "score_detection": 0.51,
    "score_embedding": 0.596,
    "total_score": 0.5553333333333333,
    "x": 9.209436416625977,
    "y": 8.222686767578125,
    "cluster_id": 74
  },
  {
    "feature_id": 603,
    "explanation_index": 1,
    "text": "The token sequences often involve mathematical expressions, symbolic notation, or technical terminology, with activations frequently occurring at punctuation, operators, subscripts, superscripts, or specific structural markers in equations and formal notation.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8543616930643717,
    "similarity_var": 0.0012886734495375484,
    "score_fuzz": 0.56,
    "score_detection": 0.62,
    "score_embedding": 0.46062500000000006,
    "total_score": 0.5468750000000001,
    "x": 10.969822883605957,
    "y": 5.43998384475708,
    "cluster_id": 51
  },
  {
    "feature_id": 603,
    "explanation_index": 2,
    "text": "The highlighted tokens consistently represent the essential lexical or symbolic components that form idiomatic phrases, comparative endings, key nouns, or functional symbols, serving as the core units that drive the meaning or operation of the surrounding text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8543616930643717,
    "similarity_var": 0.0012886734495375484,
    "score_fuzz": 0.675,
    "score_detection": 0.525,
    "score_embedding": 0.4325,
    "total_score": 0.5441666666666668,
    "x": 14.939159393310547,
    "y": 4.302894592285156,
    "cluster_id": -1
  },
  {
    "feature_id": 604,
    "explanation_index": 0,
    "text": "Nouns representing academic or scientific activities, such as research, studies, analysis, experiments, and evaluations, often in formal or technical contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9362991452217102,
    "similarity_var": 0.0002807552778492095,
    "score_fuzz": 0.87,
    "score_detection": 0.58,
    "score_embedding": 0.7332,
    "total_score": 0.7277333333333332,
    "x": 7.778247356414795,
    "y": 0.5344060659408569,
    "cluster_id": -1
  },
  {
    "feature_id": 604,
    "explanation_index": 1,
    "text": "Nouns denoting research-related activities or outcomes, such as study, analysis, research, experiment, and evaluation, often appear in academic or scientific contexts and are frequently associated with methodological or investigative processes.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9362991452217102,
    "similarity_var": 0.0002807552778492095,
    "score_fuzz": 0.89,
    "score_detection": 0.62,
    "score_embedding": 0.654375,
    "total_score": 0.7214583333333334,
    "x": 7.630162715911865,
    "y": 0.635554313659668,
    "cluster_id": -1
  },
  {
    "feature_id": 604,
    "explanation_index": 2,
    "text": "The highlighted words are nouns that signal a research or analytic activity\u2014terms such as study, analysis, survey, research, experiment, simulation, work, review, computation, processing, determination, check, test, evaluation, or investigation. These tokens mark the core content of a scientific or technical passage.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9362991452217102,
    "similarity_var": 0.0002807552778492095,
    "score_fuzz": 0.85,
    "score_detection": 0.7,
    "score_embedding": 0.755625,
    "total_score": 0.7685416666666667,
    "x": 7.575493335723877,
    "y": 0.5925351977348328,
    "cluster_id": -1
  },
  {
    "feature_id": 605,
    "explanation_index": 0,
    "text": "Type declarations and variable type specifiers in programming languages.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8980840047200521,
    "similarity_var": 0.0007665973836886844,
    "score_fuzz": 0.78,
    "score_detection": 0.69,
    "score_embedding": 0.48519999999999996,
    "total_score": 0.6517333333333334,
    "x": 10.661336898803711,
    "y": 8.431669235229492,
    "cluster_id": 48
  },
  {
    "feature_id": 605,
    "explanation_index": 1,
    "text": "Keywords and identifiers in programming languages that denote data types, variable declarations, or structural components, often appearing in contexts involving type definitions, variable declarations, or function signatures.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8980840047200521,
    "similarity_var": 0.0007665973836886844,
    "score_fuzz": 0.75,
    "score_detection": 0.5,
    "score_embedding": 0.62875,
    "total_score": 0.6262500000000001,
    "x": 10.488200187683105,
    "y": 8.55788516998291,
    "cluster_id": 80
  },
  {
    "feature_id": 605,
    "explanation_index": 2,
    "text": "The highlighted tokens are programming\u2011language keywords, type names, and identifiers that function as syntactic elements within code snippets.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8980840047200521,
    "similarity_var": 0.0007665973836886844,
    "score_fuzz": 0.825,
    "score_detection": 0.5,
    "score_embedding": 0.6525,
    "total_score": 0.6591666666666667,
    "x": 13.899255752563477,
    "y": 6.605011940002441,
    "cluster_id": 8
  },
  {
    "feature_id": 606,
    "explanation_index": 0,
    "text": "Verbs in the passive voice, often describing an action or state that has been done to the subject, frequently in a formal or objective tone.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8886375228563944,
    "similarity_var": 0.0008246805524699932,
    "score_fuzz": 0.88,
    "score_detection": 0.37,
    "score_embedding": 0.396,
    "total_score": 0.5486666666666666,
    "x": 10.53819751739502,
    "y": -0.803090512752533,
    "cluster_id": 14
  },
  {
    "feature_id": 606,
    "explanation_index": 1,
    "text": "Past-tense passive-voice verbs indicating an action done to a subject, often involving treatment, state change, or external influence.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8886375228563944,
    "similarity_var": 0.0008246805524699932,
    "score_fuzz": 0.93,
    "score_detection": 0.44,
    "score_embedding": 0.3587499999999999,
    "total_score": 0.57625,
    "x": 10.605449676513672,
    "y": -0.7859698534011841,
    "cluster_id": 14
  },
  {
    "feature_id": 606,
    "explanation_index": 2,
    "text": "The text is dominated by past\u2011participle verbs\u2014mostly ending in\u202f\u2011ed or\u202f\u2011en\u2014that function as adjectives or nouns to describe actions, states, or conditions.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8886375228563944,
    "similarity_var": 0.0008246805524699932,
    "score_fuzz": 0.875,
    "score_detection": 0.425,
    "score_embedding": 0.511875,
    "total_score": 0.6039583333333334,
    "x": 10.176772117614746,
    "y": -0.5788952112197876,
    "cluster_id": -1
  },
  {
    "feature_id": 607,
    "explanation_index": 0,
    "text": "Commas separating dates, often in the format of day, month, and year, or year only, and sometimes used in other numerical contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8812204798062643,
    "similarity_var": 1.939817762853914e-05,
    "score_fuzz": 0.68,
    "score_detection": 0.63,
    "score_embedding": 0.2636,
    "total_score": 0.5245333333333334,
    "x": 8.044743537902832,
    "y": 6.53524923324585,
    "cluster_id": 5
  },
  {
    "feature_id": 607,
    "explanation_index": 1,
    "text": "The digit sequences \\\"20\\\" followed by one or two digits, often part of a date format, with or without separators like commas or spaces, are consistently activated in contexts involving calendar dates.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8812204798062643,
    "similarity_var": 1.939817762853914e-05,
    "score_fuzz": 0.56,
    "score_detection": 0.56,
    "score_embedding": 0.30625,
    "total_score": 0.47541666666666665,
    "x": 7.523606777191162,
    "y": 8.410734176635742,
    "cluster_id": 29
  },
  {
    "feature_id": 607,
    "explanation_index": 2,
    "text": "The highlighted tokens are components of dates and date ranges\u2014month names, day numbers, year numbers, ordinal suffixes, and surrounding punctuation such as commas, hyphens, and parentheses.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8812204798062643,
    "similarity_var": 1.939817762853914e-05,
    "score_fuzz": 0.6,
    "score_detection": 0.6,
    "score_embedding": 0.32562500000000005,
    "total_score": 0.5085416666666667,
    "x": 13.275952339172363,
    "y": 5.809854984283447,
    "cluster_id": 30
  },
  {
    "feature_id": 608,
    "explanation_index": 0,
    "text": "Code snippets in various programming languages, including C, C++, and assembly, with a focus on variable declarations, function calls, and control structures.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8185753226280212,
    "similarity_var": 0.0017414482865945047,
    "score_fuzz": 0.53,
    "score_detection": 0.59,
    "score_embedding": 0.6232,
    "total_score": 0.5810666666666667,
    "x": 11.227876663208008,
    "y": 8.73945140838623,
    "cluster_id": 17
  },
  {
    "feature_id": 608,
    "explanation_index": 1,
    "text": "The token \\\"er\\\" appears in comparative forms of adjectives, often in contexts involving size, degree, or intensity, and is frequently associated with grammatical structure indicating comparison.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8185753226280212,
    "similarity_var": 0.0017414482865945047,
    "score_fuzz": 0.5,
    "score_detection": 0.49,
    "score_embedding": 0.50125,
    "total_score": 0.4970833333333333,
    "x": 11.843544006347656,
    "y": 3.4167118072509766,
    "cluster_id": 60
  },
  {
    "feature_id": 608,
    "explanation_index": 2,
    "text": "The highlighted tokens are the syntactic and semantic building blocks that drive program behavior\u2014keywords, identifiers, operators, literals, and punctuation that form control\u2011flow constructs, function calls, assignments, and declarations.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8185753226280212,
    "similarity_var": 0.0017414482865945047,
    "score_fuzz": 0.525,
    "score_detection": 0.6,
    "score_embedding": 0.5475000000000001,
    "total_score": 0.5575,
    "x": 13.68708324432373,
    "y": 6.7820539474487305,
    "cluster_id": 8
  },
  {
    "feature_id": 609,
    "explanation_index": 0,
    "text": "Official documents, laws, and formal terminology, often denoted by capitalized words or abbreviations, and typically used in formal or technical contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9269167184829712,
    "similarity_var": 6.397161683224795e-05,
    "score_fuzz": 0.78,
    "score_detection": 0.42,
    "score_embedding": 0.4456,
    "total_score": 0.5485333333333333,
    "x": 7.766147613525391,
    "y": 1.73467218875885,
    "cluster_id": -1
  },
  {
    "feature_id": 609,
    "explanation_index": 1,
    "text": "Common legal or formal terminology referring to official documents, statutes, codes, acts, rules, or regulations, often appearing in legal, regulatory, or technical contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9269167184829712,
    "similarity_var": 6.397161683224795e-05,
    "score_fuzz": 0.83,
    "score_detection": 0.44,
    "score_embedding": 0.5449999999999999,
    "total_score": 0.605,
    "x": 8.987502098083496,
    "y": 4.274945259094238,
    "cluster_id": -1
  },
  {
    "feature_id": 609,
    "explanation_index": 2,
    "text": "The highlighted tokens are legal or technical terms that denote formal documents or regulatory elements, often capitalized and used in citations, indicating the text\u2019s focus on legal/technical references.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9269167184829712,
    "similarity_var": 6.397161683224795e-05,
    "score_fuzz": 0.85,
    "score_detection": 0.425,
    "score_embedding": 0.519375,
    "total_score": 0.598125,
    "x": 9.212254524230957,
    "y": 4.494376182556152,
    "cluster_id": -1
  },
  {
    "feature_id": 611,
    "explanation_index": 0,
    "text": "Initials or parts of surnames in citations and references.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9103067517280579,
    "similarity_var": 5.2675260086232356e-05,
    "score_fuzz": 0.79,
    "score_detection": 0.86,
    "score_embedding": 0.6692,
    "total_score": 0.7730666666666667,
    "x": 7.07127046585083,
    "y": -0.47204461693763733,
    "cluster_id": -1
  },
  {
    "feature_id": 611,
    "explanation_index": 1,
    "text": "Partial or truncated names, often surnames, where the model activates on fragments of names that are part of academic or technical references, typically appearing in citations, author names, or bibliographic entries.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9103067517280579,
    "similarity_var": 5.2675260086232356e-05,
    "score_fuzz": 0.94,
    "score_detection": 0.86,
    "score_embedding": 0.714375,
    "total_score": 0.8381249999999999,
    "x": 7.2739787101745605,
    "y": 2.7545783519744873,
    "cluster_id": 15
  },
  {
    "feature_id": 611,
    "explanation_index": 2,
    "text": "The highlighted fragments are consistently parts of author names or citation markers\u2014short, often capitalized or accented tokens that appear in academic references.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9103067517280579,
    "similarity_var": 5.2675260086232356e-05,
    "score_fuzz": 0.85,
    "score_detection": 0.75,
    "score_embedding": 0.635,
    "total_score": 0.7450000000000001,
    "x": 15.437638282775879,
    "y": 7.191553115844727,
    "cluster_id": 56
  },
  {
    "feature_id": 612,
    "explanation_index": 0,
    "text": "Proper nouns, geographical locations, and common nouns representing places, destinations, or establishments, often related to tourism or travel.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9048858483632406,
    "similarity_var": 0.00017773944131802306,
    "score_fuzz": 0.52,
    "score_detection": 0.32,
    "score_embedding": 0.25880000000000003,
    "total_score": 0.36626666666666674,
    "x": 7.397594928741455,
    "y": -0.9985165596008301,
    "cluster_id": 16
  },
  {
    "feature_id": 612,
    "explanation_index": 1,
    "text": "Proper nouns and place names, often capitalized or part of compound terms, are frequently highlighted in context, especially when referring to geographic locations, tourist sites, or branded entities.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9048858483632406,
    "similarity_var": 0.00017773944131802306,
    "score_fuzz": 0.4,
    "score_detection": 0.3,
    "score_embedding": 0.24125000000000002,
    "total_score": 0.31375,
    "x": 7.074902534484863,
    "y": -1.1011589765548706,
    "cluster_id": 40
  },
  {
    "feature_id": 612,
    "explanation_index": 2,
    "text": "The highlighted tokens are nouns that form part of a phrase describing a place or service, often in a tourism context, and frequently appear with an article or preposition. They can be proper nouns or generic nouns such as \u201cTourist\u201d, \u201cHotel\u201d, \u201cResort\u201d, \u201cTour\u201d, \u201cInformation\u201d, \u201cVisit\u201d, \u201cVacation\u201d, \u201cHoliday\u201d, \u201cTours\u201d, and they often appear in multi\u2011word phrases like \u201cTourist Information\u201d or \u201cHotel\u201d.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9048858483632406,
    "similarity_var": 0.00017773944131802306,
    "score_fuzz": 0.55,
    "score_detection": 0.4,
    "score_embedding": 0.296875,
    "total_score": 0.4156250000000001,
    "x": 14.507022857666016,
    "y": 3.8485958576202393,
    "cluster_id": 11
  },
  {
    "feature_id": 615,
    "explanation_index": 0,
    "text": "Nouns representing various concepts, objects, and entities, often denoting specific things, places, organizations, or ideas.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8962334593137106,
    "similarity_var": 0.00038323809014270986,
    "score_fuzz": 0.57,
    "score_detection": 0.35,
    "score_embedding": 0.7208,
    "total_score": 0.5469333333333334,
    "x": 8.117676734924316,
    "y": 0.059852421283721924,
    "cluster_id": -1
  },
  {
    "feature_id": 615,
    "explanation_index": 1,
    "text": "Nouns or noun phrases representing specific locations, objects, or abstract concepts, often part of compound terms or proper names, with high activation values indicating their semantic centrality in context.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8962334593137106,
    "similarity_var": 0.00038323809014270986,
    "score_fuzz": 0.42,
    "score_detection": 0.26,
    "score_embedding": 0.708125,
    "total_score": 0.46270833333333333,
    "x": 8.761655807495117,
    "y": -0.03837527334690094,
    "cluster_id": -1
  },
  {
    "feature_id": 615,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core semantic units\u2014typically nouns or noun phrases\u2014that carry the main meaning of the sentence.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8962334593137106,
    "similarity_var": 0.00038323809014270986,
    "score_fuzz": 0.775,
    "score_detection": 0.25,
    "score_embedding": 0.7962500000000001,
    "total_score": 0.6070833333333333,
    "x": 15.421761512756348,
    "y": 4.409418106079102,
    "cluster_id": 31
  },
  {
    "feature_id": 616,
    "explanation_index": 0,
    "text": "Nouns representing physical boundaries, edges, or surfaces, as well as words related to spatial relationships and geographical features.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8888573249181112,
    "similarity_var": 0.0005600452646142963,
    "score_fuzz": 0.8,
    "score_detection": 0.72,
    "score_embedding": 0.25880000000000003,
    "total_score": 0.5929333333333333,
    "x": 8.037630081176758,
    "y": 0.21463808417320251,
    "cluster_id": 24
  },
  {
    "feature_id": 616,
    "explanation_index": 1,
    "text": "Common noun phrases denoting physical locations, boundaries, or structural components, often used in technical or descriptive contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8888573249181112,
    "similarity_var": 0.0005600452646142963,
    "score_fuzz": 0.78,
    "score_detection": 0.75,
    "score_embedding": 0.25312500000000004,
    "total_score": 0.594375,
    "x": 8.762532234191895,
    "y": -0.033111512660980225,
    "cluster_id": -1
  },
  {
    "feature_id": 616,
    "explanation_index": 2,
    "text": "The highlighted words are domain\u2011specific nouns or technical terms that act as key descriptors of spatial, structural, or functional elements within their surrounding context.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8888573249181112,
    "similarity_var": 0.0005600452646142963,
    "score_fuzz": 0.625,
    "score_detection": 0.625,
    "score_embedding": 0.30375,
    "total_score": 0.5179166666666667,
    "x": 16.710777282714844,
    "y": 3.678687334060669,
    "cluster_id": 20
  },
  {
    "feature_id": 617,
    "explanation_index": 0,
    "text": "Tokens representing programming syntax elements, including operators, keywords, and symbols, often used in C++ and other programming languages.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8929696877797445,
    "similarity_var": 0.000118059566691247,
    "score_fuzz": 0.53,
    "score_detection": 0.8,
    "score_embedding": 0.2984,
    "total_score": 0.5428000000000001,
    "x": 10.871891021728516,
    "y": 5.979013919830322,
    "cluster_id": 18
  },
  {
    "feature_id": 617,
    "explanation_index": 1,
    "text": "Patterns in code include identifiers with underscores and numeric suffixes, template syntax with angle brackets, and symbolic tokens representing programming constructs or constants.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8929696877797445,
    "similarity_var": 0.000118059566691247,
    "score_fuzz": 0.54,
    "score_detection": 0.69,
    "score_embedding": 0.36000000000000004,
    "total_score": 0.53,
    "x": 10.777881622314453,
    "y": 7.292688846588135,
    "cluster_id": 7
  },
  {
    "feature_id": 617,
    "explanation_index": 2,
    "text": "The highlighted fragments are code identifiers and syntactic elements that define behavior\u2014function names, macros, template parameters, constants, and operators\u2014often split across tokens, indicating the model is focusing on the structural components of code that drive execution.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8929696877797445,
    "similarity_var": 0.000118059566691247,
    "score_fuzz": 0.45,
    "score_detection": 0.675,
    "score_embedding": 0.33687500000000004,
    "total_score": 0.4872916666666667,
    "x": 15.075263023376465,
    "y": 7.231965065002441,
    "cluster_id": -1
  },
  {
    "feature_id": 618,
    "explanation_index": 0,
    "text": "Nouns representing objects, concepts, or entities, often in a technical, scientific, or formal context.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8912246028582255,
    "similarity_var": 0.0007155710833244041,
    "score_fuzz": 0.79,
    "score_detection": 0.51,
    "score_embedding": 0.5704,
    "total_score": 0.6234666666666667,
    "x": 8.11172866821289,
    "y": 0.3437352180480957,
    "cluster_id": 12
  },
  {
    "feature_id": 618,
    "explanation_index": 1,
    "text": "Nouns denoting specific physical, technical, or conceptual entities, often part of compound terms or domain-specific terminology, with high activation values indicating their importance in context.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8912246028582255,
    "similarity_var": 0.0007155710833244041,
    "score_fuzz": 0.7,
    "score_detection": 0.46,
    "score_embedding": 0.5525,
    "total_score": 0.5708333333333333,
    "x": 8.22286605834961,
    "y": 0.448280394077301,
    "cluster_id": 12
  },
  {
    "feature_id": 618,
    "explanation_index": 2,
    "text": "The highlighted tokens consistently represent the semantic core of each passage\u2014content words, especially nouns or noun phrases, often domain\u2011specific or key terms, that carry the main meaning of the sentence or phrase.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8912246028582255,
    "similarity_var": 0.0007155710833244041,
    "score_fuzz": 0.925,
    "score_detection": 0.625,
    "score_embedding": 0.6656249999999999,
    "total_score": 0.7385416666666668,
    "x": 15.411595344543457,
    "y": 4.011528491973877,
    "cluster_id": 22
  },
  {
    "feature_id": 619,
    "explanation_index": 0,
    "text": "Abbreviations, codes, and symbols often used in technical, scientific, and programming contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8737106323242188,
    "similarity_var": 0.0012266731947742453,
    "score_fuzz": 0.84,
    "score_detection": 0.87,
    "score_embedding": 0.6832,
    "total_score": 0.7977333333333334,
    "x": 9.235260963439941,
    "y": 7.816818714141846,
    "cluster_id": -1
  },
  {
    "feature_id": 619,
    "explanation_index": 1,
    "text": "Patterns in the text involve sequences of uppercase letters and digits enclosed in delimiters, often representing abbreviations, codes, identifiers, or technical labels in scientific, technical, or programming contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8737106323242188,
    "similarity_var": 0.0012266731947742453,
    "score_fuzz": 0.73,
    "score_detection": 0.73,
    "score_embedding": 0.77375,
    "total_score": 0.7445833333333334,
    "x": 10.336673736572266,
    "y": 6.800334930419922,
    "cluster_id": 88
  },
  {
    "feature_id": 619,
    "explanation_index": 2,
    "text": "The highlighted fragments are short alphanumeric substrings that occur at word or identifier boundaries across varied domains, suggesting a pattern of selecting minimal, high\u2011frequency or boundary\u2011anchored tokens as salient features.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8737106323242188,
    "similarity_var": 0.0012266731947742453,
    "score_fuzz": 0.9,
    "score_detection": 0.85,
    "score_embedding": 0.731875,
    "total_score": 0.8272916666666666,
    "x": 15.424736976623535,
    "y": 7.236264705657959,
    "cluster_id": 56
  },
  {
    "feature_id": 620,
    "explanation_index": 0,
    "text": "Prefixes or partial words of various lengths, often from proper nouns or technical terms, and sometimes from common words.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8968318502108256,
    "similarity_var": 0.00015720955912554597,
    "score_fuzz": 0.65,
    "score_detection": 0.42,
    "score_embedding": 0.5352,
    "total_score": 0.5350666666666667,
    "x": 8.096259117126465,
    "y": 2.254753589630127,
    "cluster_id": -1
  },
  {
    "feature_id": 620,
    "explanation_index": 1,
    "text": "Partial word fragments at the start of tokens, often representing names, places, or technical terms, with varying activation levels depending on context and familiarity.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8968318502108256,
    "similarity_var": 0.00015720955912554597,
    "score_fuzz": 0.63,
    "score_detection": 0.38,
    "score_embedding": 0.486875,
    "total_score": 0.49895833333333334,
    "x": 7.0639872550964355,
    "y": 2.9574949741363525,
    "cluster_id": 59
  },
  {
    "feature_id": 620,
    "explanation_index": 2,
    "text": "The model\u2019s activations are triggered by sub\u2011word fragments that appear inside larger words\u2014often proper nouns or technical terms\u2014indicating that the network relies on sub\u2011word tokenization and that these partial tokens carry semantic or syntactic weight.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8968318502108256,
    "similarity_var": 0.00015720955912554597,
    "score_fuzz": 0.85,
    "score_detection": 0.375,
    "score_embedding": 0.42874999999999996,
    "total_score": 0.55125,
    "x": 8.177373886108398,
    "y": 3.2990670204162598,
    "cluster_id": 76
  },
  {
    "feature_id": 621,
    "explanation_index": 0,
    "text": "Numerical values, often in a specific format or context, such as monetary amounts, measurements, or indices, and sometimes accompanied by a unit or symbol.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8842191100120544,
    "similarity_var": 0.0004797624660165904,
    "score_fuzz": 0.71,
    "score_detection": 0.58,
    "score_embedding": 0.4808,
    "total_score": 0.5902666666666666,
    "x": 6.823395252227783,
    "y": 8.773905754089355,
    "cluster_id": 29
  },
  {
    "feature_id": 621,
    "explanation_index": 1,
    "text": "Numeric digits and symbols in contexts involving mathematical expressions, code syntax, or formatted data, often appearing in sequences with surrounding punctuation or special characters.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8842191100120544,
    "similarity_var": 0.0004797624660165904,
    "score_fuzz": 0.54,
    "score_detection": 0.37,
    "score_embedding": 0.49,
    "total_score": 0.4666666666666666,
    "x": 7.670654296875,
    "y": 8.32020378112793,
    "cluster_id": 29
  },
  {
    "feature_id": 621,
    "explanation_index": 2,
    "text": "The highlighted fragments are short numeric or symbolic pieces that form the core of code or mathematical expressions; they are typically single characters or brief sequences that are essential to the syntax or semantics of the surrounding text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8842191100120544,
    "similarity_var": 0.0004797624660165904,
    "score_fuzz": 0.425,
    "score_detection": 0.325,
    "score_embedding": 0.3625,
    "total_score": 0.37083333333333335,
    "x": 15.32955265045166,
    "y": 7.330940246582031,
    "cluster_id": 56
  },
  {
    "feature_id": 622,
    "explanation_index": 0,
    "text": "Adjectives and adverbs describing preferences, opinions, or qualities, often indicating a positive or favorable sentiment.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9036332964897156,
    "similarity_var": 0.0002838351413056254,
    "score_fuzz": 0.69,
    "score_detection": 0.33,
    "score_embedding": 0.2928,
    "total_score": 0.4376,
    "x": 9.033524513244629,
    "y": 1.300953984260559,
    "cluster_id": 45
  },
  {
    "feature_id": 622,
    "explanation_index": 1,
    "text": "Words denoting preference, quality, or desirability, often used in evaluative or comparative contexts, with high activation values when expressing subjective judgment or positive attributes.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9036332964897156,
    "similarity_var": 0.0002838351413056254,
    "score_fuzz": 0.73,
    "score_detection": 0.38,
    "score_embedding": 0.573125,
    "total_score": 0.5610416666666667,
    "x": 9.041695594787598,
    "y": 1.3062466382980347,
    "cluster_id": 45
  },
  {
    "feature_id": 622,
    "explanation_index": 2,
    "text": "The highlighted tokens are usually adjectives or nouns that express preference, evaluation, or relational meaning, often used as modifiers or descriptors in contexts of comparison, choice, or description.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9036332964897156,
    "similarity_var": 0.0002838351413056254,
    "score_fuzz": 0.875,
    "score_detection": 0.35,
    "score_embedding": 0.578125,
    "total_score": 0.6010416666666667,
    "x": 14.730328559875488,
    "y": 4.039935111999512,
    "cluster_id": 11
  },
  {
    "feature_id": 623,
    "explanation_index": 0,
    "text": "Punctuation marks used to separate items, indicate pauses, or set off information in a variety of contexts, including citations, lists, and mathematical expressions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9089876015981039,
    "similarity_var": 0.00021309560448498939,
    "score_fuzz": 0.65,
    "score_detection": 0.5,
    "score_embedding": 0.4292,
    "total_score": 0.5264,
    "x": 8.093658447265625,
    "y": 6.711890697479248,
    "cluster_id": 36
  },
  {
    "feature_id": 623,
    "explanation_index": 1,
    "text": "Punctuation and special symbols such as parentheses, commas, semicolons, dashes, and brackets are frequently used to delimit structured information, annotations, citations, or formatting elements in text.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9089876015981039,
    "similarity_var": 0.00021309560448498939,
    "score_fuzz": 0.64,
    "score_detection": 0.53,
    "score_embedding": 0.395,
    "total_score": 0.5216666666666666,
    "x": 9.358602523803711,
    "y": 6.892392158508301,
    "cluster_id": -1
  },
  {
    "feature_id": 623,
    "explanation_index": 2,
    "text": "The highlighted tokens are punctuation and structural delimiters\u2014dashes, parentheses, commas, semicolons, brackets, and similar marks\u2014that signal boundaries, groupings, or parenthetical information in the text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9089876015981039,
    "similarity_var": 0.00021309560448498939,
    "score_fuzz": 0.775,
    "score_detection": 0.45,
    "score_embedding": 0.33875,
    "total_score": 0.5212500000000001,
    "x": 13.742243766784668,
    "y": 5.5538177490234375,
    "cluster_id": -1
  },
  {
    "feature_id": 624,
    "explanation_index": 0,
    "text": "Tokens that are part of a larger word or phrase, often indicating a suffix or a word that is being modified, and sometimes being part of a proper noun.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8705171545346578,
    "similarity_var": 0.000156999869520607,
    "score_fuzz": 0.41,
    "score_detection": 0.62,
    "score_embedding": 0.0832,
    "total_score": 0.37106666666666666,
    "x": 10.234332084655762,
    "y": 4.377468585968018,
    "cluster_id": 1
  },
  {
    "feature_id": 624,
    "explanation_index": 1,
    "text": "Fragments of words or phrases that are part of compound terms, proper nouns, or technical expressions, often appearing at the edge of tokens or within structured text, with high activation on partial or adjacent components.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8705171545346578,
    "similarity_var": 0.000156999869520607,
    "score_fuzz": 0.26,
    "score_detection": 0.62,
    "score_embedding": 0.015625000000000003,
    "total_score": 0.29854166666666665,
    "x": 7.009167194366455,
    "y": 2.646881580352783,
    "cluster_id": 2
  },
  {
    "feature_id": 624,
    "explanation_index": 2,
    "text": "The highlighted tokens are almost always the initial word of a multi\u2011word unit that carries a distinct meaning\u2014such as an idiom, a noun phrase, or a technical term. These words, which are often nouns, adjectives, or prepositions, function as the head of that phrase and signal the start of a semantically important segment.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8705171545346578,
    "similarity_var": 0.000156999869520607,
    "score_fuzz": 0.825,
    "score_detection": 0.875,
    "score_embedding": 0.031875,
    "total_score": 0.5772916666666666,
    "x": 15.224411010742188,
    "y": 4.004949569702148,
    "cluster_id": 22
  },
  {
    "feature_id": 625,
    "explanation_index": 0,
    "text": "Adjectives or adverbs describing physical properties, materials, or intensifying qualities of objects or concepts, often used to emphasize or specify characteristics.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.89298943678538,
    "similarity_var": 6.211319730040386e-05,
    "score_fuzz": 0.7,
    "score_detection": 0.47,
    "score_embedding": 0.5952,
    "total_score": 0.5883999999999999,
    "x": 8.80806827545166,
    "y": 1.173015832901001,
    "cluster_id": 90
  },
  {
    "feature_id": 625,
    "explanation_index": 1,
    "text": "Commonly activated tokens are suffixes or root forms of adjectives and nouns that describe physical or structural properties, often related to durability, design, or technical characteristics, with frequent emphasis on comparative or qualitative descriptors.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.89298943678538,
    "similarity_var": 6.211319730040386e-05,
    "score_fuzz": 0.79,
    "score_detection": 0.63,
    "score_embedding": 0.5375000000000001,
    "total_score": 0.6525,
    "x": 10.150620460510254,
    "y": 3.699880838394165,
    "cluster_id": 41
  },
  {
    "feature_id": 625,
    "explanation_index": 2,
    "text": "The highlighted words are the semantic core of descriptive phrases that convey key attributes of an object or concept; they are usually adjectives or nouns (sometimes multi\u2011word) that define quality, size, or function.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.89298943678538,
    "similarity_var": 6.211319730040386e-05,
    "score_fuzz": 0.625,
    "score_detection": 0.4,
    "score_embedding": 0.46249999999999997,
    "total_score": 0.4958333333333333,
    "x": 16.726245880126953,
    "y": 3.663771867752075,
    "cluster_id": 20
  },
  {
    "feature_id": 627,
    "explanation_index": 0,
    "text": "Prepositions and words that describe location, direction, or relation to other objects or concepts, often indicating a spatial or contextual relationship.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8317122658093771,
    "similarity_var": 0.00037593231932536096,
    "score_fuzz": 0.48,
    "score_detection": 0.52,
    "score_embedding": 0.1824,
    "total_score": 0.3941333333333333,
    "x": 12.030682563781738,
    "y": -0.33674782514572144,
    "cluster_id": 39
  },
  {
    "feature_id": 627,
    "explanation_index": 1,
    "text": "Common multi-word phrases or compound terms where the final part of a word is split across tokens, often indicating a technical or descriptive term with a specific context.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8317122658093771,
    "similarity_var": 0.00037593231932536096,
    "score_fuzz": 0.45,
    "score_detection": 0.42,
    "score_embedding": 0.11125000000000002,
    "total_score": 0.32708333333333334,
    "x": 9.067988395690918,
    "y": 0.11141300201416016,
    "cluster_id": -1
  },
  {
    "feature_id": 627,
    "explanation_index": 2,
    "text": "The highlighted fragments are the core lexical pieces\u2014often stems or key components\u2014of longer words or multi\u2011word expressions that carry the main semantic content.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8317122658093771,
    "similarity_var": 0.00037593231932536096,
    "score_fuzz": 0.7,
    "score_detection": 0.55,
    "score_embedding": 0.12187500000000001,
    "total_score": 0.45729166666666665,
    "x": 15.834210395812988,
    "y": 7.4025163650512695,
    "cluster_id": 19
  },
  {
    "feature_id": 628,
    "explanation_index": 0,
    "text": "Tokens that are part of a larger code or mathematical expression, often including symbols, variables, and keywords, or words that are part of a formal or technical text.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8784680962562561,
    "similarity_var": 0.0014673975727059012,
    "score_fuzz": 0.73,
    "score_detection": 0.79,
    "score_embedding": 0.7856000000000001,
    "total_score": 0.7685333333333334,
    "x": 10.621119499206543,
    "y": 5.76702356338501,
    "cluster_id": 18
  },
  {
    "feature_id": 628,
    "explanation_index": 1,
    "text": "Fragments of technical, mathematical, or structured text containing symbols, identifiers, or code-like elements, often with embedded variables, formatting markers, or domain-specific notation.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8784680962562561,
    "similarity_var": 0.0014673975727059012,
    "score_fuzz": 0.73,
    "score_detection": 0.77,
    "score_embedding": 0.7918749999999999,
    "total_score": 0.7639583333333334,
    "x": 10.02286434173584,
    "y": 6.310415744781494,
    "cluster_id": -1
  },
  {
    "feature_id": 628,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core semantic units\u2014main nouns, key adjectives, or essential identifiers\u2014that carry the primary meaning or function in each snippet.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8784680962562561,
    "similarity_var": 0.0014673975727059012,
    "score_fuzz": 0.45,
    "score_detection": 0.45,
    "score_embedding": 0.779375,
    "total_score": 0.5597916666666667,
    "x": 15.370478630065918,
    "y": 4.527159214019775,
    "cluster_id": 31
  },
  {
    "feature_id": 629,
    "explanation_index": 0,
    "text": "Words and phrases related to certainty, confidence, and assurance, often used to convey a sense of guarantee, reliability, or conviction.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8494834303855896,
    "similarity_var": 0.0053309463318764,
    "score_fuzz": 0.76,
    "score_detection": 0.66,
    "score_embedding": 0.546,
    "total_score": 0.6553333333333333,
    "x": 9.285531997680664,
    "y": 1.1124776601791382,
    "cluster_id": -1
  },
  {
    "feature_id": 629,
    "explanation_index": 1,
    "text": "Words related to certainty, confidence, or assurance, often used to express conviction, reliability, or inevitability, with a focus on modal or evaluative language indicating high confidence in a statement or outcome.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8494834303855896,
    "similarity_var": 0.0053309463318764,
    "score_fuzz": 0.74,
    "score_detection": 0.67,
    "score_embedding": 0.6375,
    "total_score": 0.6825000000000001,
    "x": 9.262550354003906,
    "y": 1.127934455871582,
    "cluster_id": -1
  },
  {
    "feature_id": 629,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8494834303855896,
    "similarity_var": 0.0053309463318764,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.5325,
    "total_score": 0.5108333333333334,
    "x": -7.893780708312988,
    "y": 9.166647911071777,
    "cluster_id": 52
  },
  {
    "feature_id": 630,
    "explanation_index": 0,
    "text": "Partial words, often prefixes or suffixes, of various nouns, particularly those related to biology, medicine, and food.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8652642766634623,
    "similarity_var": 0.00024755775524059546,
    "score_fuzz": 0.74,
    "score_detection": 0.64,
    "score_embedding": 0.49679999999999996,
    "total_score": 0.6255999999999999,
    "x": 7.46685791015625,
    "y": 2.6198363304138184,
    "cluster_id": -1
  },
  {
    "feature_id": 630,
    "explanation_index": 1,
    "text": "Partial word fragments at the end of tokens, often representing the beginning of a longer word, with high activation values when the full word is contextually relevant.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8652642766634623,
    "similarity_var": 0.00024755775524059546,
    "score_fuzz": 0.67,
    "score_detection": 0.65,
    "score_embedding": 0.40031249999999996,
    "total_score": 0.5734374999999999,
    "x": 7.108892440795898,
    "y": 3.0174789428710938,
    "cluster_id": 59
  },
  {
    "feature_id": 630,
    "explanation_index": 2,
    "text": "The highlighted pieces are the sub\u2011word or whole\u2011word units that carry the core meaning of a phrase or word\u2014often the start or end of a lexical item, or a whole noun or idiom. They are the fragments that the model treats as the key building blocks for the semantic or syntactic pattern in the text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8652642766634623,
    "similarity_var": 0.00024755775524059546,
    "score_fuzz": 0.625,
    "score_detection": 0.425,
    "score_embedding": 0.34031249999999996,
    "total_score": 0.4634375,
    "x": 15.839064598083496,
    "y": 7.343301773071289,
    "cluster_id": 19
  },
  {
    "feature_id": 631,
    "explanation_index": 0,
    "text": "Common nouns representing abstract concepts, objects, or ideas, often in a formal or technical context.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8837393720944723,
    "similarity_var": 0.00030751921905963146,
    "score_fuzz": 0.64,
    "score_detection": 0.41,
    "score_embedding": 0.4576,
    "total_score": 0.5025333333333334,
    "x": 8.3159818649292,
    "y": 0.10109925270080566,
    "cluster_id": 24
  },
  {
    "feature_id": 631,
    "explanation_index": 1,
    "text": "Nouns representing abstract or concrete entities that are central to the context, often appearing in phrases related to processes, states, or specific domains like law, science, or personal experience.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8837393720944723,
    "similarity_var": 0.00030751921905963146,
    "score_fuzz": 0.66,
    "score_detection": 0.43,
    "score_embedding": 0.460625,
    "total_score": 0.5168750000000001,
    "x": 8.198638916015625,
    "y": 0.252482533454895,
    "cluster_id": 24
  },
  {
    "feature_id": 631,
    "explanation_index": 2,
    "text": "The highlighted tokens are consistently nouns or noun phrases that carry the core semantic content of each sentence, functioning as the main subject, object, or key descriptive element that anchors the meaning.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8837393720944723,
    "similarity_var": 0.00030751921905963146,
    "score_fuzz": 0.725,
    "score_detection": 0.275,
    "score_embedding": 0.491875,
    "total_score": 0.4972916666666667,
    "x": 15.04110336303711,
    "y": 3.7262511253356934,
    "cluster_id": -1
  },
  {
    "feature_id": 632,
    "explanation_index": 0,
    "text": "Proper nouns, often representing names of places, organizations, or people, typically of Scandinavian origin.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8410640954971313,
    "similarity_var": 0.0012487240398044719,
    "score_fuzz": 0.8315789473684211,
    "score_detection": 0.84,
    "score_embedding": 0.44200000000000006,
    "total_score": 0.7045263157894737,
    "x": 7.44166374206543,
    "y": -0.932835042476654,
    "cluster_id": 16
  },
  {
    "feature_id": 632,
    "explanation_index": 1,
    "text": "Fragments of proper nouns, particularly geographical names, personal names, and institutional names, often appearing with partial or split spelling, commonly in contexts involving scientific, geographical, or technical terminology.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8410640954971313,
    "similarity_var": 0.0012487240398044719,
    "score_fuzz": 0.76,
    "score_detection": 0.75,
    "score_embedding": 0.15875000000000006,
    "total_score": 0.55625,
    "x": 6.958549499511719,
    "y": 2.5472257137298584,
    "cluster_id": 2
  },
  {
    "feature_id": 632,
    "explanation_index": 2,
    "text": "The highlighted segments are consistently sub\u2011word fragments\u2014often the suffixes or prefixes of words\u2014rather than complete words. These fragments can be single letters or short sequences, sometimes with a leading space, and they appear at token boundaries where a word is split. The activation values indicate that the model treats each fragment as a distinct unit that contributes to the overall representation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8410640954971313,
    "similarity_var": 0.0012487240398044719,
    "score_fuzz": 0.4,
    "score_detection": 0.6,
    "score_embedding": 0.14375000000000002,
    "total_score": 0.38125000000000003,
    "x": 15.036504745483398,
    "y": 5.524880409240723,
    "cluster_id": -1
  },
  {
    "feature_id": 633,
    "explanation_index": 0,
    "text": "Words related to financial support, fundraising, or provision of resources, often in the context of organizations, projects, or initiatives.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8195085128148397,
    "similarity_var": 0.002335178204154273,
    "score_fuzz": 0.75,
    "score_detection": 0.66,
    "score_embedding": 0.7627999999999999,
    "total_score": 0.7242666666666667,
    "x": 10.482893943786621,
    "y": 0.09216655790805817,
    "cluster_id": -1
  },
  {
    "feature_id": 633,
    "explanation_index": 1,
    "text": "The suffix \\\"-ing\\\" is frequently used in verbs and participles, often indicating ongoing or continuous action, and is commonly found in contexts involving processes, states, or descriptions of activity.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8195085128148397,
    "similarity_var": 0.002335178204154273,
    "score_fuzz": 0.54,
    "score_detection": 0.61,
    "score_embedding": 0.7756249999999999,
    "total_score": 0.6418749999999999,
    "x": 8.547518730163574,
    "y": 2.294553279876709,
    "cluster_id": 66
  },
  {
    "feature_id": 633,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core lexical items that carry the main semantic content of the sentence, often nouns or stems of nouns/verbs that form the central theme (e.g., funding, support, campaign, sustain).",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8195085128148397,
    "similarity_var": 0.002335178204154273,
    "score_fuzz": 0.6857142857142857,
    "score_detection": 0.475,
    "score_embedding": 0.71125,
    "total_score": 0.6239880952380953,
    "x": 15.12141227722168,
    "y": 3.9531517028808594,
    "cluster_id": 22
  },
  {
    "feature_id": 634,
    "explanation_index": 0,
    "text": "Tokens often represent words that are part of proper nouns, technical terms, or words with specialized meanings, sometimes being part of a larger phrase or name.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8723981181780497,
    "similarity_var": 0.00012277437113618185,
    "score_fuzz": 0.48,
    "score_detection": 0.39,
    "score_embedding": 0.6148,
    "total_score": 0.4949333333333333,
    "x": 10.171396255493164,
    "y": 4.388697624206543,
    "cluster_id": 1
  },
  {
    "feature_id": 634,
    "explanation_index": 1,
    "text": "Partial word fragments at the start of tokens, often representing the beginning of a longer word, particularly in compound or proper nouns, with varying activation levels depending on context and length.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8723981181780497,
    "similarity_var": 0.00012277437113618185,
    "score_fuzz": 0.55,
    "score_detection": 0.36,
    "score_embedding": 0.559375,
    "total_score": 0.4897916666666666,
    "x": 7.095211505889893,
    "y": 2.9428870677948,
    "cluster_id": 59
  },
  {
    "feature_id": 634,
    "explanation_index": 2,
    "text": "The tokens are often prefixes of words: \\\"peti\\\", \\\"pe\\\", \\\"pep\\\", \\\"pem\\\", \\\"peach\\\", \\\"Pet\\\", \\\"petition\\\", \\\"pen\\\", \\\"penit\\\", \\\"peak\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\", \\\"pe\\\".",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8723981181780497,
    "similarity_var": 0.00012277437113618185,
    "score_fuzz": 0.7,
    "score_detection": 0.7,
    "score_embedding": 0.750625,
    "total_score": 0.7168749999999999,
    "x": 11.002214431762695,
    "y": 3.3633038997650146,
    "cluster_id": 27
  },
  {
    "feature_id": 635,
    "explanation_index": 0,
    "text": "Adjectives and adverbs expressing evaluation or assessment, often indicating something is optimal, desirable, or of high quality.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.905704915523529,
    "similarity_var": 0.0005943707869775494,
    "score_fuzz": 0.85,
    "score_detection": 0.57,
    "score_embedding": 0.6944,
    "total_score": 0.7048,
    "x": 9.049161911010742,
    "y": 1.3411072492599487,
    "cluster_id": 45
  },
  {
    "feature_id": 635,
    "explanation_index": 1,
    "text": "Adjectives and noun phrases expressing high quality or superiority, often used in evaluative or comparative contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.905704915523529,
    "similarity_var": 0.0005943707869775494,
    "score_fuzz": 0.76,
    "score_detection": 0.46,
    "score_embedding": 0.5075,
    "total_score": 0.5758333333333333,
    "x": 9.049728393554688,
    "y": 1.3229038715362549,
    "cluster_id": 45
  },
  {
    "feature_id": 635,
    "explanation_index": 2,
    "text": "The highlighted words are key terms that form evaluative or locational phrases\u2014typically positive adjectives or nouns that modify a noun or express a way, idea, or place.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.905704915523529,
    "similarity_var": 0.0005943707869775494,
    "score_fuzz": 0.725,
    "score_detection": 0.3,
    "score_embedding": 0.486875,
    "total_score": 0.5039583333333333,
    "x": 16.7180233001709,
    "y": 3.639293909072876,
    "cluster_id": 20
  },
  {
    "feature_id": 636,
    "explanation_index": 0,
    "text": "Years or centuries in numerical format, often in the context of citations, references, or historical events.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8687846859296163,
    "similarity_var": 0.0007691724262228503,
    "score_fuzz": 0.9,
    "score_detection": 0.84,
    "score_embedding": 0.49479999999999996,
    "total_score": 0.7449333333333333,
    "x": 7.121978282928467,
    "y": 8.716752052307129,
    "cluster_id": 29
  },
  {
    "feature_id": 636,
    "explanation_index": 1,
    "text": "The digit \\\"9\\\" frequently appears in historical dates, legal citations, and numerical references, often as part of a year or sequential identifier.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8687846859296163,
    "similarity_var": 0.0007691724262228503,
    "score_fuzz": 0.88,
    "score_detection": 0.77,
    "score_embedding": 0.6325,
    "total_score": 0.7608333333333333,
    "x": 7.400640487670898,
    "y": 8.530962944030762,
    "cluster_id": 29
  },
  {
    "feature_id": 636,
    "explanation_index": 2,
    "text": "The highlighted tokens are four\u2011digit year numbers; the activations correspond to the individual digits within those years.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8687846859296163,
    "similarity_var": 0.0007691724262228503,
    "score_fuzz": 0.675,
    "score_detection": 0.8,
    "score_embedding": 0.355,
    "total_score": 0.61,
    "x": 13.139008522033691,
    "y": 5.893944263458252,
    "cluster_id": 30
  },
  {
    "feature_id": 637,
    "explanation_index": 0,
    "text": "Tokens that are nouns, adjectives, or adverbs, often with formal or technical connotations, and sometimes indicating a deviation from the norm or an exception to a rule.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8513155976931254,
    "similarity_var": 0.003398323290583328,
    "score_fuzz": 0.83,
    "score_detection": 0.7894736842105263,
    "score_embedding": 0.4776,
    "total_score": 0.6990245614035088,
    "x": 10.185663223266602,
    "y": 4.25111198425293,
    "cluster_id": 1
  },
  {
    "feature_id": 637,
    "explanation_index": 1,
    "text": "Commonly activated tokens include words denoting legal or technical exceptions, violations, or conditions (e.g., \\\"except\\\", \\\"unless\\\", \\\"violation\\\", \\\"exemption\\\"), as well as adjectives describing rarity, abnormality, or exclusivity, often in formal or analytical contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8513155976931254,
    "similarity_var": 0.003398323290583328,
    "score_fuzz": 0.71,
    "score_detection": 0.64,
    "score_embedding": 0.48750000000000004,
    "total_score": 0.6125,
    "x": 10.092019081115723,
    "y": 3.5325348377227783,
    "cluster_id": 41
  },
  {
    "feature_id": 637,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8513155976931254,
    "similarity_var": 0.003398323290583328,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.24,
    "total_score": 0.41333333333333333,
    "x": -7.902677059173584,
    "y": 9.157695770263672,
    "cluster_id": 52
  },
  {
    "feature_id": 638,
    "explanation_index": 0,
    "text": "Various tokens including nouns, adjectives, adverbs, and prepositions, often indicating a relationship or connection between entities, actions, or ideas, and sometimes denoting a specific context or domain.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8582433064778646,
    "similarity_var": 0.00019515032378889275,
    "score_fuzz": 0.51,
    "score_detection": 0.46,
    "score_embedding": 0.4835999999999999,
    "total_score": 0.48453333333333326,
    "x": 10.569838523864746,
    "y": 4.480508804321289,
    "cluster_id": 47
  },
  {
    "feature_id": 638,
    "explanation_index": 1,
    "text": "Fragments of text containing specific identifiers, technical terms, or symbolic notation, often related to scientific, mathematical, or programming contexts, with emphasis on precise formatting, special characters, and structured syntax.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8582433064778646,
    "similarity_var": 0.00019515032378889275,
    "score_fuzz": 0.59,
    "score_detection": 0.63,
    "score_embedding": 0.635,
    "total_score": 0.6183333333333333,
    "x": 9.917435646057129,
    "y": 6.369222164154053,
    "cluster_id": -1
  },
  {
    "feature_id": 638,
    "explanation_index": 2,
    "text": "The highlighted tokens consistently capture the core lexical units that carry the main meaning of each sentence\u2014typically nouns, noun phrases, or key verb/adjective fragments, sometimes forming idiomatic or technical multi\u2011word expressions, and occasionally short morphological pieces. These contiguous units are the most semantically salient elements of the text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8582433064778646,
    "similarity_var": 0.00019515032378889275,
    "score_fuzz": 0.425,
    "score_detection": 0.475,
    "score_embedding": 0.6487499999999999,
    "total_score": 0.51625,
    "x": 15.349984169006348,
    "y": 4.467698097229004,
    "cluster_id": 31
  },
  {
    "feature_id": 639,
    "explanation_index": 0,
    "text": "Suffixes or words that are appended to other words, often indicating a relationship or modification, and sometimes used in technical or specialized contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8023823300997416,
    "similarity_var": 0.0012227204708739551,
    "score_fuzz": 0.6,
    "score_detection": 0.59,
    "score_embedding": 0.7712,
    "total_score": 0.6537333333333333,
    "x": 8.424782752990723,
    "y": 2.211430311203003,
    "cluster_id": 44
  },
  {
    "feature_id": 639,
    "explanation_index": 1,
    "text": "The pattern involves tokens that are part of compound identifiers, often in technical or code-like contexts, where segments are concatenated with underscores to form meaningful terms, and the most activated tokens are typically the final components of such compound words.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8023823300997416,
    "similarity_var": 0.0012227204708739551,
    "score_fuzz": 0.52,
    "score_detection": 0.29,
    "score_embedding": 0.7025000000000001,
    "total_score": 0.5041666666666668,
    "x": 11.03189468383789,
    "y": 4.723998069763184,
    "cluster_id": -1
  },
  {
    "feature_id": 639,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8023823300997416,
    "similarity_var": 0.0012227204708739551,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.52625,
    "total_score": 0.50875,
    "x": -5.870680809020996,
    "y": 16.0382022857666,
    "cluster_id": 10
  },
  {
    "feature_id": 640,
    "explanation_index": 0,
    "text": "Articles, prepositions, and conjunctions, often used to connect words or phrases in technical and scientific contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8556918303171793,
    "similarity_var": 0.00026855590378794934,
    "score_fuzz": 0.72,
    "score_detection": 0.88,
    "score_embedding": 0.37560000000000004,
    "total_score": 0.6585333333333333,
    "x": 12.650202751159668,
    "y": 0.16009286046028137,
    "cluster_id": 57
  },
  {
    "feature_id": 640,
    "explanation_index": 1,
    "text": "Fragments of technical or scientific terms, often derived from compound words or abbreviations, where partial tokens (like \\\"el\\\", \\\"sub\\\", \\\"hat\\\", \\\"M\\\", \\\"fiber\\\") are activated due to their role in forming precise domain-specific terminology.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8556918303171793,
    "similarity_var": 0.00026855590378794934,
    "score_fuzz": 0.36,
    "score_detection": 0.64,
    "score_embedding": 0.31375,
    "total_score": 0.4379166666666667,
    "x": 9.472606658935547,
    "y": 3.2321226596832275,
    "cluster_id": -1
  },
  {
    "feature_id": 640,
    "explanation_index": 2,
    "text": "The highlighted fragments are the core lexical items that form meaningful phrases\u2014usually contiguous sequences of nouns, adjectives, prepositions, or punctuation\u2014that carry the main content of the sentence.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8556918303171793,
    "similarity_var": 0.00026855590378794934,
    "score_fuzz": 0.85,
    "score_detection": 0.85,
    "score_embedding": 0.15437500000000004,
    "total_score": 0.618125,
    "x": 15.81662654876709,
    "y": 7.3985915184021,
    "cluster_id": 19
  },
  {
    "feature_id": 641,
    "explanation_index": 0,
    "text": "Interrogative words or phrases often initiating a question, and nouns representing concepts, events, or actions, sometimes in idiomatic expressions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8492985169092814,
    "similarity_var": 0.000673572622617592,
    "score_fuzz": 0.65,
    "score_detection": 0.66,
    "score_embedding": 0.6844,
    "total_score": 0.6648000000000001,
    "x": 11.174242973327637,
    "y": 1.6610867977142334,
    "cluster_id": -1
  },
  {
    "feature_id": 641,
    "explanation_index": 1,
    "text": "The word \\\"what\\\" frequently appears in contexts involving uncertainty, inquiry, or explanation, often introducing a clause that specifies an unknown or emphasized outcome, idea, or event.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8492985169092814,
    "similarity_var": 0.000673572622617592,
    "score_fuzz": 0.64,
    "score_detection": 0.66,
    "score_embedding": 0.784375,
    "total_score": 0.6947916666666667,
    "x": 11.22335433959961,
    "y": 1.9929790496826172,
    "cluster_id": 70
  },
  {
    "feature_id": 641,
    "explanation_index": 2,
    "text": "The tokens are often common words like \\\"what\\\", \\\"thing\\\", \\\"to\\\", \\\"what\\\", \\\"thing\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\", \\\"what\\\".",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8492985169092814,
    "similarity_var": 0.000673572622617592,
    "score_fuzz": 0.675,
    "score_detection": 0.8,
    "score_embedding": 0.8143750000000001,
    "total_score": 0.763125,
    "x": 11.000335693359375,
    "y": 3.373565435409546,
    "cluster_id": 27
  },
  {
    "feature_id": 642,
    "explanation_index": 0,
    "text": "Punctuation and special characters, often used to denote mathematical or programming syntax, or to indicate a specific formatting or emphasis in text.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8538128137588501,
    "similarity_var": 0.0002615915075594444,
    "score_fuzz": 0.34,
    "score_detection": 0.4,
    "score_embedding": 0.2192,
    "total_score": 0.31973333333333337,
    "x": 8.640463829040527,
    "y": 7.271213531494141,
    "cluster_id": 4
  },
  {
    "feature_id": 642,
    "explanation_index": 1,
    "text": "Common patterns include the use of comparative or superlative forms, technical or domain-specific terminology, and structural markers in code or mathematical notation, often involving suffixes like \\\"er\\\", \\\"max\\\", \\\"min\\\", or symbols like \\\">\\\", \\\":\\\", and \\\"\u00b1\\\", with frequent emphasis on precision, measurement, or logical structure.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8538128137588501,
    "similarity_var": 0.0002615915075594444,
    "score_fuzz": 0.38,
    "score_detection": 0.46,
    "score_embedding": 0.245625,
    "total_score": 0.361875,
    "x": 10.112397193908691,
    "y": 6.677704811096191,
    "cluster_id": -1
  },
  {
    "feature_id": 642,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core content words or technical keywords that carry the main meaning of each phrase or code fragment. They are typically nouns, adjectives, or programming terms that serve as the subject, object, or key concept, and they are often surrounded by punctuation or whitespace that marks the boundaries of the phrase.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8538128137588501,
    "similarity_var": 0.0002615915075594444,
    "score_fuzz": 0.65,
    "score_detection": 0.5,
    "score_embedding": 0.30625,
    "total_score": 0.4854166666666666,
    "x": 14.909961700439453,
    "y": 4.1721415519714355,
    "cluster_id": -1
  },
  {
    "feature_id": 643,
    "explanation_index": 0,
    "text": "A digit, usually \\\"1\\\" or \\\"2\\\", that is part of a year or date in a text.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8922410607337952,
    "similarity_var": 5.9448358904035103e-05,
    "score_fuzz": 0.91,
    "score_detection": 0.8,
    "score_embedding": 0.4308,
    "total_score": 0.7136,
    "x": 7.419812202453613,
    "y": 8.513017654418945,
    "cluster_id": 29
  },
  {
    "feature_id": 643,
    "explanation_index": 1,
    "text": "The digit \\\"2\\\" frequently appears in numerical sequences representing years, particularly in the context of dates and temporal references, often preceding or following other digits to form four-digit year identifiers.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8922410607337952,
    "similarity_var": 5.9448358904035103e-05,
    "score_fuzz": 0.71,
    "score_detection": 0.74,
    "score_embedding": 0.291875,
    "total_score": 0.580625,
    "x": 7.444876194000244,
    "y": 8.482292175292969,
    "cluster_id": 29
  },
  {
    "feature_id": 643,
    "explanation_index": 2,
    "text": "The model consistently flags numeric tokens that form part of dates or years, especially the digits 1 and 2, as important.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8922410607337952,
    "similarity_var": 5.9448358904035103e-05,
    "score_fuzz": 0.8,
    "score_detection": 0.75,
    "score_embedding": 0.24375,
    "total_score": 0.5979166666666667,
    "x": 7.457480430603027,
    "y": 8.515539169311523,
    "cluster_id": 29
  },
  {
    "feature_id": 644,
    "explanation_index": 0,
    "text": "Verbs and verb phrases indicating planning, consideration, or contemplation of future actions or ideas.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.943200925985972,
    "similarity_var": 0.00014461664531574393,
    "score_fuzz": 0.88,
    "score_detection": 0.81,
    "score_embedding": 0.7804,
    "total_score": 0.8234666666666666,
    "x": 10.789416313171387,
    "y": -0.7104260325431824,
    "cluster_id": -1
  },
  {
    "feature_id": 644,
    "explanation_index": 1,
    "text": "Verbs related to planning, considering, or intending, often followed by prepositions like \\\"on,\\\" \\\"to,\\\" \\\"about,\\\" or \\\"of,\\\" and frequently used in contexts involving future actions, decisions, or evaluations.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.943200925985972,
    "similarity_var": 0.00014461664531574393,
    "score_fuzz": 0.89,
    "score_detection": 0.79,
    "score_embedding": 0.82625,
    "total_score": 0.8354166666666667,
    "x": 11.152070045471191,
    "y": -0.562598466873169,
    "cluster_id": -1
  },
  {
    "feature_id": 644,
    "explanation_index": 2,
    "text": "The highlighted fragments are verbs or verb phrases that signal intent, planning, or consideration\u2014often followed by a preposition such as \u201con,\u201d \u201cto,\u201d \u201cinto,\u201d or \u201cabout.\u201d These patterns mark future\u2011oriented actions or deliberations in the surrounding text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.943200925985972,
    "similarity_var": 0.00014461664531574393,
    "score_fuzz": 0.8,
    "score_detection": 0.725,
    "score_embedding": 0.728125,
    "total_score": 0.7510416666666666,
    "x": 15.78389835357666,
    "y": 7.37723445892334,
    "cluster_id": 19
  },
  {
    "feature_id": 646,
    "explanation_index": 0,
    "text": "Partial words or word roots, often from scientific or technical contexts, including biological, chemical, and anatomical terms.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9016061226526896,
    "similarity_var": 0.0010612488184409902,
    "score_fuzz": 0.51,
    "score_detection": 0.22,
    "score_embedding": 0.36279999999999996,
    "total_score": 0.3642666666666667,
    "x": 7.339510440826416,
    "y": 2.4889862537384033,
    "cluster_id": -1
  },
  {
    "feature_id": 646,
    "explanation_index": 1,
    "text": "Partial word fragments at the end of tokens, often representing roots or stems of scientific, biological, or technical terms, frequently appearing in contexts involving taxonomy, anatomy, or scientific nomenclature.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9016061226526896,
    "similarity_var": 0.0010612488184409902,
    "score_fuzz": 0.56,
    "score_detection": 0.26,
    "score_embedding": 0.37249999999999994,
    "total_score": 0.39749999999999996,
    "x": 7.275402069091797,
    "y": 2.758467674255371,
    "cluster_id": 15
  },
  {
    "feature_id": 646,
    "explanation_index": 2,
    "text": "The highlighted fragments are sub\u2011word pieces that correspond to meaningful lexical roots or stems inside larger words, often appearing at word boundaries, indicating that the model is focusing on morphological subunits rather than whole words.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9016061226526896,
    "similarity_var": 0.0010612488184409902,
    "score_fuzz": 0.65,
    "score_detection": 0.15,
    "score_embedding": 0.33999999999999997,
    "total_score": 0.38000000000000006,
    "x": 15.674609184265137,
    "y": 7.088521480560303,
    "cluster_id": 19
  },
  {
    "feature_id": 647,
    "explanation_index": 0,
    "text": "Interrogative words or phrases, conjunctions, and prepositions that introduce a reason, explanation, or condition, often used in a causal or explanatory context.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8702551126480103,
    "similarity_var": 0.0009485049549790384,
    "score_fuzz": 0.81,
    "score_detection": 0.69,
    "score_embedding": 0.49200000000000005,
    "total_score": 0.664,
    "x": 11.230199813842773,
    "y": 1.506921648979187,
    "cluster_id": -1
  },
  {
    "feature_id": 647,
    "explanation_index": 1,
    "text": "The word \\\"why\\\" frequently appears in contexts questioning causality or justification, often introducing a rationale or explanation, and is typically associated with introspection, reasoning, or logical inquiry.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8702551126480103,
    "similarity_var": 0.0009485049549790384,
    "score_fuzz": 0.66,
    "score_detection": 0.72,
    "score_embedding": 0.561875,
    "total_score": 0.6472916666666667,
    "x": 11.281454086303711,
    "y": 1.8912607431411743,
    "cluster_id": 70
  },
  {
    "feature_id": 647,
    "explanation_index": 2,
    "text": "The highlighted tokens are short, high\u2011frequency function words that act as discourse markers or question words (e.g., \u201cwhy,\u201d \u201cbecause,\u201d \u201clong,\u201d \u201cwhile,\u201d \u201chow,\u201d \u201cdefine\u201d). They signal shifts in topic, clarification, or emphasis, and the model treats them as key cues for understanding or generating the surrounding text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8702551126480103,
    "similarity_var": 0.0009485049549790384,
    "score_fuzz": 0.8,
    "score_detection": 0.8,
    "score_embedding": 0.27625,
    "total_score": 0.6254166666666667,
    "x": 14.194717407226562,
    "y": 4.806461334228516,
    "cluster_id": -1
  },
  {
    "feature_id": 648,
    "explanation_index": 0,
    "text": "The token immediately preceding a return statement in a programming context.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8702602585156759,
    "similarity_var": 0.0006733262539795091,
    "score_fuzz": 0.71,
    "score_detection": 0.73,
    "score_embedding": 0.754,
    "total_score": 0.7313333333333333,
    "x": 10.962113380432129,
    "y": 5.95867919921875,
    "cluster_id": 18
  },
  {
    "feature_id": 648,
    "explanation_index": 1,
    "text": "Terminal punctuation and closing braces in code syntax, often appearing at the end of blocks or statements, with high activation on closing symbols like \\\"}\\\", \\\";\\\", and newline sequences.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8702602585156759,
    "similarity_var": 0.0006733262539795091,
    "score_fuzz": 0.82,
    "score_detection": 0.76,
    "score_embedding": 0.728125,
    "total_score": 0.769375,
    "x": 9.51597785949707,
    "y": 6.654832363128662,
    "cluster_id": 61
  },
  {
    "feature_id": 648,
    "explanation_index": 2,
    "text": "The highlighted tokens are punctuation and control\u2011flow keywords that mark the boundaries of statements or blocks in code, such as semicolons, braces, parentheses, and return statements.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8702602585156759,
    "similarity_var": 0.0006733262539795091,
    "score_fuzz": 0.75,
    "score_detection": 0.5,
    "score_embedding": 0.7418750000000001,
    "total_score": 0.6639583333333333,
    "x": 13.561342239379883,
    "y": 6.383260250091553,
    "cluster_id": 8
  },
  {
    "feature_id": 650,
    "explanation_index": 0,
    "text": "Backslashes used as escape characters in various programming languages and markup formats.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.875745971997579,
    "similarity_var": 0.00022934542271555195,
    "score_fuzz": 0.78,
    "score_detection": 0.54,
    "score_embedding": 0.5980000000000001,
    "total_score": 0.6393333333333334,
    "x": 9.435500144958496,
    "y": 7.475337028503418,
    "cluster_id": -1
  },
  {
    "feature_id": 650,
    "explanation_index": 1,
    "text": "The token sequence \\\"<<\\\" followed by a closing \\\">>\\\" appears in various contexts, often surrounding structural or formatting markers in code, markup, or mathematical expressions, typically indicating a placeholder, delimiter, or syntactic construct.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.875745971997579,
    "similarity_var": 0.00022934542271555195,
    "score_fuzz": 0.57,
    "score_detection": 0.64,
    "score_embedding": 0.733125,
    "total_score": 0.6477083333333333,
    "x": 9.5303955078125,
    "y": 6.575310707092285,
    "cluster_id": 61
  },
  {
    "feature_id": 650,
    "explanation_index": 2,
    "text": "The highlighted tokens are non\u2011word characters that serve as delimiters or escape symbols in programming, markup, or mathematical notation.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.875745971997579,
    "similarity_var": 0.00022934542271555195,
    "score_fuzz": 0.6,
    "score_detection": 0.475,
    "score_embedding": 0.7618750000000001,
    "total_score": 0.6122916666666667,
    "x": 13.371894836425781,
    "y": 5.997198104858398,
    "cluster_id": 30
  },
  {
    "feature_id": 651,
    "explanation_index": 0,
    "text": "Adverbs, conjunctions, and other function words that provide additional information, contrast, or connection between clauses or phrases, often indicating degree, manner, time, or exception.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8921558658281962,
    "similarity_var": 0.0003068077212170629,
    "score_fuzz": 0.79,
    "score_detection": 0.67,
    "score_embedding": 0.1768,
    "total_score": 0.5456,
    "x": 9.587675094604492,
    "y": 1.5167121887207031,
    "cluster_id": -1
  },
  {
    "feature_id": 651,
    "explanation_index": 1,
    "text": "Commonly used adverbial or conjunctive phrases that introduce contrast, addition, degree, or emphasis, often appearing in evaluative or conditional contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8921558658281962,
    "similarity_var": 0.0003068077212170629,
    "score_fuzz": 0.85,
    "score_detection": 0.58,
    "score_embedding": 0.166875,
    "total_score": 0.5322916666666666,
    "x": 9.539003372192383,
    "y": 1.5432286262512207,
    "cluster_id": -1
  },
  {
    "feature_id": 651,
    "explanation_index": 2,
    "text": "The highlighted tokens are common function words\u2014conjunctions, prepositions, adverbs, determiners, and other high\u2011frequency grammatical connectors\u2014that the model treats as key for structuring sentences, linking clauses, and indicating comparison or modification.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8921558658281962,
    "similarity_var": 0.0003068077212170629,
    "score_fuzz": 0.775,
    "score_detection": 0.5,
    "score_embedding": 0.11625,
    "total_score": 0.46374999999999994,
    "x": 13.432207107543945,
    "y": 3.235525131225586,
    "cluster_id": 35
  },
  {
    "feature_id": 652,
    "explanation_index": 0,
    "text": "Adverbs or adjectives that convey a sense of clarity, explicitness, or obviousness, often used to emphasize or highlight a point, and sometimes used in formal or technical writing.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.914615253607432,
    "similarity_var": 6.637421861041856e-05,
    "score_fuzz": 0.82,
    "score_detection": 0.71,
    "score_embedding": 0.33039999999999997,
    "total_score": 0.6201333333333333,
    "x": 9.375510215759277,
    "y": 1.5836838483810425,
    "cluster_id": 89
  },
  {
    "feature_id": 652,
    "explanation_index": 1,
    "text": "Adjectives and adverbs derived from root words, often indicating degree, clarity, or emphasis, with high activation values when used to modify or strengthen a claim, description, or perception.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.914615253607432,
    "similarity_var": 6.637421861041856e-05,
    "score_fuzz": 0.9,
    "score_detection": 0.76,
    "score_embedding": 0.12312500000000001,
    "total_score": 0.594375,
    "x": 9.196564674377441,
    "y": 1.5409661531448364,
    "cluster_id": -1
  },
  {
    "feature_id": 652,
    "explanation_index": 2,
    "text": "The highlighted words are primarily adjectives or adverbs that modify preceding nouns or verbs, often conveying degree, clarity, or emphasis in the sentence.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.914615253607432,
    "similarity_var": 6.637421861041856e-05,
    "score_fuzz": 0.95,
    "score_detection": 0.775,
    "score_embedding": 0.16562500000000002,
    "total_score": 0.6302083333333334,
    "x": 16.741825103759766,
    "y": 3.5755128860473633,
    "cluster_id": 20
  },
  {
    "feature_id": 653,
    "explanation_index": 0,
    "text": "Punctuation marks and special characters, often used to denote mathematical operations, comparisons, or to separate items in a list, as well as some nouns and adjectives.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8563015262285868,
    "similarity_var": 0.0006427158534860508,
    "score_fuzz": 0.64,
    "score_detection": 0.75,
    "score_embedding": 0.7432000000000001,
    "total_score": 0.7110666666666668,
    "x": 8.277852058410645,
    "y": 7.120552062988281,
    "cluster_id": 37
  },
  {
    "feature_id": 653,
    "explanation_index": 1,
    "text": "The token sequences often represent morphological suffixes, punctuation, numerical or symbolic elements, or parts of technical notation, with activations concentrated on specific sub-words or symbols that carry structural or semantic significance in context.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8563015262285868,
    "similarity_var": 0.0006427158534860508,
    "score_fuzz": 0.67,
    "score_detection": 0.75,
    "score_embedding": 0.7325,
    "total_score": 0.7174999999999999,
    "x": 10.96824836730957,
    "y": 5.269177436828613,
    "cluster_id": -1
  },
  {
    "feature_id": 653,
    "explanation_index": 2,
    "text": "The highlighted tokens consistently comprise the core lexical or punctuation elements that form a meaningful phrase or expression\u2014often a noun, verb, adjective, or idiom\u2014that the model treats as crucial for interpreting or generating the surrounding text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8563015262285868,
    "similarity_var": 0.0006427158534860508,
    "score_fuzz": 0.25,
    "score_detection": 0.275,
    "score_embedding": 0.7306250000000001,
    "total_score": 0.41854166666666676,
    "x": 15.169349670410156,
    "y": 4.266418933868408,
    "cluster_id": 91
  },
  {
    "feature_id": 654,
    "explanation_index": 0,
    "text": "Punctuation marks and digits, often used in citations, references, and numerical data, and sometimes used in text to represent titles, names, or labels.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8375351627667745,
    "similarity_var": 0.0007573590349644457,
    "score_fuzz": 0.75,
    "score_detection": 0.59,
    "score_embedding": 0.852,
    "total_score": 0.7306666666666666,
    "x": 8.27270793914795,
    "y": 7.297202110290527,
    "cluster_id": -1
  },
  {
    "feature_id": 654,
    "explanation_index": 1,
    "text": "The token \\\"2\\\" is frequently activated in contexts involving numerical sequences, dates, or identifiers, often appearing in proximity to punctuation or other digits, suggesting its role as a digit in numerical expressions or labels.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8375351627667745,
    "similarity_var": 0.0007573590349644457,
    "score_fuzz": 0.68,
    "score_detection": 0.57,
    "score_embedding": 0.810625,
    "total_score": 0.686875,
    "x": 7.594052314758301,
    "y": 8.300748825073242,
    "cluster_id": 29
  },
  {
    "feature_id": 654,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core content words that carry the main semantic load of a phrase or clause, often nouns, adjectives, or numbers, and they tend to delineate the boundaries of a meaningful unit.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8375351627667745,
    "similarity_var": 0.0007573590349644457,
    "score_fuzz": 0.7,
    "score_detection": 0.5,
    "score_embedding": 0.7825000000000001,
    "total_score": 0.6608333333333333,
    "x": 15.276494026184082,
    "y": 4.102797031402588,
    "cluster_id": 22
  },
  {
    "feature_id": 655,
    "explanation_index": 0,
    "text": "Punctuation marks, often used to indicate possession, quotation, or abbreviation, and sometimes used in technical contexts such as coding or data representation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8860393365224203,
    "similarity_var": 0.0002557143529039586,
    "score_fuzz": 0.51,
    "score_detection": 0.33,
    "score_embedding": 0.3572,
    "total_score": 0.3990666666666667,
    "x": 8.222018241882324,
    "y": 6.833688735961914,
    "cluster_id": 36
  },
  {
    "feature_id": 655,
    "explanation_index": 1,
    "text": "Common patterns include punctuation marks (like periods, apostrophes, and quotation marks), numerical digits, and partial word fragments (especially at word boundaries) that are often part of technical, syntactic, or formatting structures in text.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8860393365224203,
    "similarity_var": 0.0002557143529039586,
    "score_fuzz": 0.53,
    "score_detection": 0.31,
    "score_embedding": 0.305625,
    "total_score": 0.381875,
    "x": 10.066190719604492,
    "y": 6.722801685333252,
    "cluster_id": -1
  },
  {
    "feature_id": 655,
    "explanation_index": 2,
    "text": "The highlighted fragments are typically short suffixes, punctuation, or whole nouns that mark grammatical boundaries or carry key semantic content, such as comparative endings, contractions, sentence delimiters, and object names.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8860393365224203,
    "similarity_var": 0.0002557143529039586,
    "score_fuzz": 0.45,
    "score_detection": 0.65,
    "score_embedding": 0.391875,
    "total_score": 0.4972916666666667,
    "x": 15.634519577026367,
    "y": 7.155854225158691,
    "cluster_id": 19
  },
  {
    "feature_id": 656,
    "explanation_index": 0,
    "text": "Various programming language syntax elements, including function calls, variable declarations, and mathematical operations.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8895498315493265,
    "similarity_var": 0.00018136996379385865,
    "score_fuzz": 0.9,
    "score_detection": 1.0,
    "score_embedding": 0.9332,
    "total_score": 0.9443999999999999,
    "x": 10.643945693969727,
    "y": 8.32036018371582,
    "cluster_id": 48
  },
  {
    "feature_id": 656,
    "explanation_index": 1,
    "text": "The token sequences often involve syntactic or structural markers in code or mathematical expressions, such as function calls, type annotations, control flow keywords, or mathematical operators, with high activation on specific tokens that denote syntax boundaries, data types, or logical constructs.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8895498315493265,
    "similarity_var": 0.00018136996379385865,
    "score_fuzz": 0.91,
    "score_detection": 0.99,
    "score_embedding": 0.5025,
    "total_score": 0.8008333333333333,
    "x": 11.019818305969238,
    "y": 5.519557952880859,
    "cluster_id": 51
  },
  {
    "feature_id": 656,
    "explanation_index": 2,
    "text": "The highlighted tokens are the syntactically significant parts of code\u2014keywords, identifiers, operators, and punctuation\u2014that together form meaningful code fragments.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8895498315493265,
    "similarity_var": 0.00018136996379385865,
    "score_fuzz": 0.85,
    "score_detection": 0.9,
    "score_embedding": 0.6306250000000001,
    "total_score": 0.7935416666666667,
    "x": 13.95012092590332,
    "y": 6.548332214355469,
    "cluster_id": 8
  },
  {
    "feature_id": 657,
    "explanation_index": 0,
    "text": "Mathematical notation and symbols, often used in equations and formulas, including various fonts and styles to represent different types of variables and constants.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8943027456601461,
    "similarity_var": 0.0004874141281005803,
    "score_fuzz": 0.69,
    "score_detection": 0.57,
    "score_embedding": 0.5588000000000001,
    "total_score": 0.6062666666666666,
    "x": 9.280139923095703,
    "y": 8.309619903564453,
    "cluster_id": 74
  },
  {
    "feature_id": 657,
    "explanation_index": 1,
    "text": "Mathematical notation tokens representing special symbols, operators, or formatting commands in LaTeX, often used to denote mathematical constructs such as hats, bars, tildes, bold, mathcal, mathbb, and other typographical variants.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8943027456601461,
    "similarity_var": 0.0004874141281005803,
    "score_fuzz": 0.8,
    "score_detection": 0.68,
    "score_embedding": 0.52625,
    "total_score": 0.6687500000000001,
    "x": 9.49378490447998,
    "y": 8.189306259155273,
    "cluster_id": -1
  },
  {
    "feature_id": 657,
    "explanation_index": 2,
    "text": "The highlighted tokens are LaTeX commands or math symbols that appear within mathematical expressions.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8943027456601461,
    "similarity_var": 0.0004874141281005803,
    "score_fuzz": 0.675,
    "score_detection": 0.5,
    "score_embedding": 0.566875,
    "total_score": 0.5806250000000001,
    "x": 13.237967491149902,
    "y": 6.023157596588135,
    "cluster_id": 30
  },
  {
    "feature_id": 658,
    "explanation_index": 0,
    "text": "Proper nouns, names of places, organizations, and specific titles, often denoting geographical locations, institutions, or individuals.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8816817800203959,
    "similarity_var": 0.0011370266970524136,
    "score_fuzz": 0.49,
    "score_detection": 0.3,
    "score_embedding": 0.42439999999999994,
    "total_score": 0.4048,
    "x": 7.408446311950684,
    "y": -0.9710080623626709,
    "cluster_id": 16
  },
  {
    "feature_id": 658,
    "explanation_index": 1,
    "text": "Fragmented or partially encoded proper nouns, often representing names, locations, or technical terms, where individual subtokens are activated due to their role in forming a larger identifier.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8816817800203959,
    "similarity_var": 0.0011370266970524136,
    "score_fuzz": 0.41,
    "score_detection": 0.36,
    "score_embedding": 0.526875,
    "total_score": 0.4322916666666667,
    "x": 6.998209476470947,
    "y": 2.9052529335021973,
    "cluster_id": 59
  },
  {
    "feature_id": 658,
    "explanation_index": 2,
    "text": "The highlighted tokens are sub\u2011word fragments that belong to larger words or multi\u2011word expressions\u2014often with a leading space or punctuation\u2014showing that the model is focusing on parts of proper nouns, brand names, or phrases rather than complete words.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8816817800203959,
    "similarity_var": 0.0011370266970524136,
    "score_fuzz": 0.375,
    "score_detection": 0.425,
    "score_embedding": 0.556875,
    "total_score": 0.4522916666666667,
    "x": 14.806350708007812,
    "y": 4.97528076171875,
    "cluster_id": -1
  },
  {
    "feature_id": 660,
    "explanation_index": 0,
    "text": "Adjectives and nouns representing social concepts, academic fields, and demographic characteristics, often used in formal or technical contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8539297779401144,
    "similarity_var": 0.001239312470328318,
    "score_fuzz": 0.87,
    "score_detection": 0.87,
    "score_embedding": 0.17920000000000003,
    "total_score": 0.6397333333333334,
    "x": 8.276716232299805,
    "y": 0.6656652688980103,
    "cluster_id": 12
  },
  {
    "feature_id": 660,
    "explanation_index": 1,
    "text": "Compound terms formed by combining two or more root words with hyphens or spaces, often used in academic or technical contexts to describe social, economic, or demographic categories.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8539297779401144,
    "similarity_var": 0.001239312470328318,
    "score_fuzz": 0.75,
    "score_detection": 0.76,
    "score_embedding": 0.24874999999999997,
    "total_score": 0.58625,
    "x": 8.148633003234863,
    "y": 1.597569227218628,
    "cluster_id": -1
  },
  {
    "feature_id": 660,
    "explanation_index": 2,
    "text": "The model\u2019s activations consistently target tokens that belong to domain\u2011specific multi\u2011word expressions\u2014especially hyphenated or compound nouns\u2014because these phrases carry the key semantic content needed for the task.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8539297779401144,
    "similarity_var": 0.001239312470328318,
    "score_fuzz": 0.65,
    "score_detection": 0.725,
    "score_embedding": 0.06812499999999999,
    "total_score": 0.48104166666666665,
    "x": 8.360994338989258,
    "y": 3.384986639022827,
    "cluster_id": -1
  },
  {
    "feature_id": 661,
    "explanation_index": 0,
    "text": "Tokens related to generation, genes, and general concepts, often appearing in scientific, technical, or formal contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8153010408083597,
    "similarity_var": 0.0017809877580587691,
    "score_fuzz": 0.76,
    "score_detection": 0.76,
    "score_embedding": 0.8432000000000001,
    "total_score": 0.7877333333333333,
    "x": 10.421257019042969,
    "y": 4.355740547180176,
    "cluster_id": -1
  },
  {
    "feature_id": 661,
    "explanation_index": 1,
    "text": "Fragments of words, often derived from root forms of technical or scientific terms, that are part of compound or morphologically complex words, particularly in domains like genetics, engineering, and chemistry.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8153010408083597,
    "similarity_var": 0.0017809877580587691,
    "score_fuzz": 0.69,
    "score_detection": 0.74,
    "score_embedding": 0.8200000000000001,
    "total_score": 0.75,
    "x": 7.295399188995361,
    "y": 2.365593194961548,
    "cluster_id": -1
  },
  {
    "feature_id": 661,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8153010408083597,
    "similarity_var": 0.0017809877580587691,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.80125,
    "total_score": 0.6004166666666667,
    "x": -7.893919467926025,
    "y": 9.166420936584473,
    "cluster_id": 52
  },
  {
    "feature_id": 662,
    "explanation_index": 0,
    "text": "Specialized terms and keywords in programming languages, often denoting specific concepts, data types, or functions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8969487547874451,
    "similarity_var": 0.00030222579839526514,
    "score_fuzz": 0.58,
    "score_detection": 0.49,
    "score_embedding": 0.6292,
    "total_score": 0.5663999999999999,
    "x": 10.43964672088623,
    "y": 8.631454467773438,
    "cluster_id": 80
  },
  {
    "feature_id": 662,
    "explanation_index": 1,
    "text": "Sequences of capitalized or camelCase identifiers, often representing namespaces, types, or modules in programming code, with frequent use of separators like dots, underscores, or angle brackets.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8969487547874451,
    "similarity_var": 0.00030222579839526514,
    "score_fuzz": 0.63,
    "score_detection": 0.49,
    "score_embedding": 0.625,
    "total_score": 0.5816666666666667,
    "x": 10.963791847229004,
    "y": 6.286098480224609,
    "cluster_id": -1
  },
  {
    "feature_id": 662,
    "explanation_index": 2,
    "text": "The highlighted fragments are programming\u2011language identifiers, keywords, or library names that carry semantic weight in code snippets. They appear as class, function, namespace, or constant names, often prefixed by a namespace or module, and are not ordinary natural\u2011language words.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8969487547874451,
    "similarity_var": 0.00030222579839526514,
    "score_fuzz": 0.5,
    "score_detection": 0.525,
    "score_embedding": 0.644375,
    "total_score": 0.5564583333333334,
    "x": 15.117284774780273,
    "y": 7.256086349487305,
    "cluster_id": -1
  },
  {
    "feature_id": 663,
    "explanation_index": 0,
    "text": "Terms related to psychology, mental health, and neurological conditions, often describing abnormal or altered states of mind.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.888807475566864,
    "similarity_var": 0.001329217859636837,
    "score_fuzz": 0.82,
    "score_detection": 0.76,
    "score_embedding": 0.8004,
    "total_score": 0.7934666666666667,
    "x": 7.481130599975586,
    "y": 1.3939526081085205,
    "cluster_id": 25
  },
  {
    "feature_id": 663,
    "explanation_index": 1,
    "text": "Fragments of psychiatric or psychological terms, often incomplete or partially activated, that are contextually linked to mental health, behavior, or neurological conditions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.888807475566864,
    "similarity_var": 0.001329217859636837,
    "score_fuzz": 0.87,
    "score_detection": 0.75,
    "score_embedding": 0.7974999999999999,
    "total_score": 0.8058333333333333,
    "x": 7.063417434692383,
    "y": 2.4913923740386963,
    "cluster_id": 2
  },
  {
    "feature_id": 663,
    "explanation_index": 2,
    "text": "The activations highlight partial word fragments that are prefixes of longer terms, many of which are mental\u2011health or drug\u2011related, indicating the model\u2019s sensitivity to word stems rather than complete words.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.888807475566864,
    "similarity_var": 0.001329217859636837,
    "score_fuzz": 0.825,
    "score_detection": 0.775,
    "score_embedding": 0.8175,
    "total_score": 0.8058333333333333,
    "x": 7.930125713348389,
    "y": 3.2606492042541504,
    "cluster_id": 76
  },
  {
    "feature_id": 664,
    "explanation_index": 0,
    "text": "Verbs and verb contractions used in informal expressions, often in the form of a phrase or a sentence fragment, typically indicating a casual tone or a conversational style.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8560704986254374,
    "similarity_var": 0.00031835268430866235,
    "score_fuzz": 0.6,
    "score_detection": 0.4,
    "score_embedding": 0.5748000000000001,
    "total_score": 0.5249333333333334,
    "x": 10.47041130065918,
    "y": -0.3968554735183716,
    "cluster_id": -1
  },
  {
    "feature_id": 664,
    "explanation_index": 1,
    "text": "The token \\\"s\\\" is frequently activated in contractions of \\\"is\\\" or \\\"has\\\", and \\\"is\\\", \\\"was\\\", \\\"be\\\", and \\\"that\\\" are commonly activated in clauses that establish identity, state, or equivalence, often in explanatory or definitional contexts.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8560704986254374,
    "similarity_var": 0.00031835268430866235,
    "score_fuzz": 0.84,
    "score_detection": 0.57,
    "score_embedding": 0.6487499999999999,
    "total_score": 0.6862499999999999,
    "x": 10.98411750793457,
    "y": 2.502967596054077,
    "cluster_id": -1
  },
  {
    "feature_id": 664,
    "explanation_index": 2,
    "text": "The activations consistently flag short, high\u2011frequency function words\u2014especially verbs and particles that form contractions or common phrases\u2014as key tokens, rather than content words.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8560704986254374,
    "similarity_var": 0.00031835268430866235,
    "score_fuzz": 0.675,
    "score_detection": 0.4,
    "score_embedding": 0.5962500000000001,
    "total_score": 0.5570833333333334,
    "x": 12.989144325256348,
    "y": 3.3181610107421875,
    "cluster_id": 82
  },
  {
    "feature_id": 666,
    "explanation_index": 0,
    "text": "Prepositions indicating relationships such as possession, agency, or direction, often used in formal or written contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9070259928703308,
    "similarity_var": 0.00030979591179895277,
    "score_fuzz": 0.81,
    "score_detection": 0.36,
    "score_embedding": 0.3476000000000001,
    "total_score": 0.5058666666666667,
    "x": 12.061529159545898,
    "y": -0.31565797328948975,
    "cluster_id": 39
  },
  {
    "feature_id": 666,
    "explanation_index": 1,
    "text": "Prepositions such as \\\"to\\\", \\\"of\\\", \\\"by\\\", \\\"for\\\", \\\"with\\\", and \\\"in\\\" frequently appear in contexts involving relationships of direction, possession, agency, or location, often preceding or following key nouns in syntactic constructions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9070259928703308,
    "similarity_var": 0.00030979591179895277,
    "score_fuzz": 0.83,
    "score_detection": 0.5,
    "score_embedding": 0.41625,
    "total_score": 0.5820833333333334,
    "x": 12.4107666015625,
    "y": -0.5702223777770996,
    "cluster_id": 63
  },
  {
    "feature_id": 666,
    "explanation_index": 2,
    "text": "The highlighted tokens are short prepositions or articles that serve as grammatical connectors, linking nouns, phrases, or clauses and indicating relationships such as possession, direction, or association.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9070259928703308,
    "similarity_var": 0.00030979591179895277,
    "score_fuzz": 0.775,
    "score_detection": 0.35,
    "score_embedding": 0.353125,
    "total_score": 0.4927083333333333,
    "x": 14.140900611877441,
    "y": 3.577653408050537,
    "cluster_id": 0
  },
  {
    "feature_id": 667,
    "explanation_index": 0,
    "text": "Prefixes or suffixes of words, often indicating direction, movement, or change, and sometimes used in verb conjugation or noun formation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8878045280774435,
    "similarity_var": 2.364463764652985e-05,
    "score_fuzz": 0.68,
    "score_detection": 0.56,
    "score_embedding": 0.514,
    "total_score": 0.5846666666666668,
    "x": 8.360861778259277,
    "y": 2.1676676273345947,
    "cluster_id": 44
  },
  {
    "feature_id": 667,
    "explanation_index": 1,
    "text": "Common morphological suffixes and prefixes in multi-language text, often appearing in compound words or word stems, with high activation values indicating their role in semantic or grammatical structure.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8878045280774435,
    "similarity_var": 2.364463764652985e-05,
    "score_fuzz": 0.6105263157894737,
    "score_detection": 0.43,
    "score_embedding": 0.454375,
    "total_score": 0.49830043859649126,
    "x": 8.474637031555176,
    "y": 2.5971157550811768,
    "cluster_id": -1
  },
  {
    "feature_id": 667,
    "explanation_index": 2,
    "text": "The patterns: The important tokens are often word fragments that are part of larger words, often suffixes or prefixes that indicate grammatical or semantic roles.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8878045280774435,
    "similarity_var": 2.364463764652985e-05,
    "score_fuzz": 0.625,
    "score_detection": 0.5,
    "score_embedding": 0.46562499999999996,
    "total_score": 0.5302083333333333,
    "x": 11.409496307373047,
    "y": 4.4311394691467285,
    "cluster_id": 3
  },
  {
    "feature_id": 669,
    "explanation_index": 0,
    "text": "Nouns, verbs, and adjectives that are often part of a larger phrase or sentence, sometimes indicating a specific concept, object, or action, and occasionally being part of a technical or specialized term.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8895801703135172,
    "similarity_var": 0.0002925000643882767,
    "score_fuzz": 0.76,
    "score_detection": 0.63,
    "score_embedding": 0.36,
    "total_score": 0.5833333333333334,
    "x": 8.948534965515137,
    "y": -0.07412800192832947,
    "cluster_id": 83
  },
  {
    "feature_id": 669,
    "explanation_index": 1,
    "text": "Common noun phrases and compound terms, often representing specific concepts, locations, or technical entities, with high activation values on key content words.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8895801703135172,
    "similarity_var": 0.0002925000643882767,
    "score_fuzz": 0.69,
    "score_detection": 0.52,
    "score_embedding": 0.316875,
    "total_score": 0.5089583333333333,
    "x": 8.941880226135254,
    "y": -0.09287472069263458,
    "cluster_id": 83
  },
  {
    "feature_id": 669,
    "explanation_index": 2,
    "text": "The tokens are various words, often nouns, adjectives, etc.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8895801703135172,
    "similarity_var": 0.0002925000643882767,
    "score_fuzz": 0.7,
    "score_detection": 0.65,
    "score_embedding": 0.27375,
    "total_score": 0.54125,
    "x": 10.215250015258789,
    "y": 4.3590803146362305,
    "cluster_id": 1
  },
  {
    "feature_id": 670,
    "explanation_index": 0,
    "text": "Prepositions and conjunctions, often used to connect clauses or phrases, and sometimes preceding or following nouns or verbs.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8667089343070984,
    "similarity_var": 0.0002455880745510323,
    "score_fuzz": 0.46,
    "score_detection": 0.41,
    "score_embedding": 0.48879999999999996,
    "total_score": 0.45293333333333335,
    "x": 12.071179389953613,
    "y": -0.017702095210552216,
    "cluster_id": 9
  },
  {
    "feature_id": 670,
    "explanation_index": 1,
    "text": "Common linguistic patterns involving prepositions, possessives, and compound terms, often indicating relationships, attributes, or technical descriptions in context.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8667089343070984,
    "similarity_var": 0.0002455880745510323,
    "score_fuzz": 0.45,
    "score_detection": 0.37,
    "score_embedding": 0.46687500000000004,
    "total_score": 0.4289583333333334,
    "x": 9.899579048156738,
    "y": 0.43728071451187134,
    "cluster_id": -1
  },
  {
    "feature_id": 670,
    "explanation_index": 2,
    "text": "The highlighted words are typically nouns or adjectives that belong to a larger phrase or technical term, often appearing with surrounding punctuation or as part of a proper\u2011noun phrase.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8667089343070984,
    "similarity_var": 0.0002455880745510323,
    "score_fuzz": 0.5,
    "score_detection": 0.55,
    "score_embedding": 0.48187500000000005,
    "total_score": 0.510625,
    "x": 16.713342666625977,
    "y": 3.616525888442993,
    "cluster_id": 20
  },
  {
    "feature_id": 671,
    "explanation_index": 0,
    "text": "The term \\\"service\\\" often refers to an intangible product or action provided by a person, organization, or system, sometimes in a professional or official capacity.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8186429142951965,
    "similarity_var": 0.0014081068479351682,
    "score_fuzz": 0.81,
    "score_detection": 0.8,
    "score_embedding": 0.6432,
    "total_score": 0.7510666666666667,
    "x": 10.294651985168457,
    "y": 0.4087873101234436,
    "cluster_id": -1
  },
  {
    "feature_id": 671,
    "explanation_index": 1,
    "text": "The word \\\"service\\\" and its variants (e.g., served, serving, servant, services) frequently appear in contexts involving utility, support, or institutional functions, often related to infrastructure, employment, or organizational roles.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8186429142951965,
    "similarity_var": 0.0014081068479351682,
    "score_fuzz": 0.9,
    "score_detection": 0.9,
    "score_embedding": 0.569375,
    "total_score": 0.7897916666666666,
    "x": 10.457762718200684,
    "y": 0.49520379304885864,
    "cluster_id": -1
  },
  {
    "feature_id": 671,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8186429142951965,
    "similarity_var": 0.0014081068479351682,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.158125,
    "total_score": 0.38604166666666667,
    "x": -7.929648399353027,
    "y": 9.130735397338867,
    "cluster_id": 52
  },
  {
    "feature_id": 673,
    "explanation_index": 0,
    "text": "Names, labels, and identifiers of various entities, including people, places, objects, and concepts, often used to specify or reference them uniquely.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8864790002504984,
    "similarity_var": 0.0002155174044189165,
    "score_fuzz": 0.52,
    "score_detection": 0.47,
    "score_embedding": 0.49160000000000004,
    "total_score": 0.4938666666666667,
    "x": 7.25462007522583,
    "y": -0.7120171785354614,
    "cluster_id": -1
  },
  {
    "feature_id": 673,
    "explanation_index": 1,
    "text": "The token \\\"name\\\" frequently appears in contexts involving identification, labeling, or referencing entities, often in proximity to possessive forms, quotation marks, or structured data fields, and is commonly associated with proper nouns, identifiers, or descriptive labels.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8864790002504984,
    "similarity_var": 0.0002155174044189165,
    "score_fuzz": 0.65,
    "score_detection": 0.63,
    "score_embedding": 0.503125,
    "total_score": 0.594375,
    "x": 10.617040634155273,
    "y": 3.607381820678711,
    "cluster_id": -1
  },
  {
    "feature_id": 673,
    "explanation_index": 2,
    "text": "The highlighted tokens are typically short, high\u2011frequency words that function as connectors or identifiers\u2014most often \u201cname\u201d and its variants, along with prepositions and articles such as \u201cto,\u201d \u201cthe,\u201d \u201cof,\u201d \u201cand,\u201d and \u201cfor.\u201d These words usually appear in code\u2011style or naming contexts, forming phrases that point to a variable, attribute, or proper noun.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8864790002504984,
    "similarity_var": 0.0002155174044189165,
    "score_fuzz": 0.4,
    "score_detection": 0.425,
    "score_embedding": 0.45125000000000004,
    "total_score": 0.4254166666666667,
    "x": 13.804927825927734,
    "y": 4.050561904907227,
    "cluster_id": 42
  },
  {
    "feature_id": 674,
    "explanation_index": 0,
    "text": "Tokens that are part of a code or programming syntax, often including symbols, keywords, and variable names.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8867412010828654,
    "similarity_var": 7.988295199920812e-05,
    "score_fuzz": 0.21052631578947367,
    "score_detection": 0.16,
    "score_embedding": 0.33359999999999995,
    "total_score": 0.23470877192982456,
    "x": 10.833854675292969,
    "y": 6.023160457611084,
    "cluster_id": 18
  },
  {
    "feature_id": 674,
    "explanation_index": 1,
    "text": "Fragments of structured or formatted text, including code, mathematical expressions, markup, citations, and technical notation, often containing isolated tokens or partial words that are part of larger syntactic or semantic constructs.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8867412010828654,
    "similarity_var": 7.988295199920812e-05,
    "score_fuzz": 0.38,
    "score_detection": 0.31,
    "score_embedding": 0.520625,
    "total_score": 0.40354166666666663,
    "x": 10.053247451782227,
    "y": 6.25803804397583,
    "cluster_id": -1
  },
  {
    "feature_id": 674,
    "explanation_index": 2,
    "text": "The highlighted fragments are arbitrary tokens inside delimiters, ranging from words and numbers to punctuation and code, and each token is treated as important regardless of its semantic content.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8867412010828654,
    "similarity_var": 7.988295199920812e-05,
    "score_fuzz": 0.35,
    "score_detection": 0.375,
    "score_embedding": 0.5325,
    "total_score": 0.41916666666666663,
    "x": 14.938455581665039,
    "y": 7.0900044441223145,
    "cluster_id": -1
  },
  {
    "feature_id": 675,
    "explanation_index": 0,
    "text": "Proper nouns, names of people, places, organizations, and titles, as well as words related to music, film, and art.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8124277591705322,
    "similarity_var": 0.00011105070231801999,
    "score_fuzz": 0.75,
    "score_detection": 0.8,
    "score_embedding": 0.6807999999999998,
    "total_score": 0.7435999999999999,
    "x": 7.5572123527526855,
    "y": -0.8594586849212646,
    "cluster_id": 16
  },
  {
    "feature_id": 675,
    "explanation_index": 1,
    "text": "The token \\\"er\\\" is often part of a comparative adjective, and the context frequently involves descriptions of size, degree, or intensity.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8124277591705322,
    "similarity_var": 0.00011105070231801999,
    "score_fuzz": 0.48,
    "score_detection": 0.43,
    "score_embedding": 0.28625,
    "total_score": 0.39875,
    "x": 11.85491943359375,
    "y": 3.3815131187438965,
    "cluster_id": 60
  },
  {
    "feature_id": 675,
    "explanation_index": 2,
    "text": "The highlighted tokens are always parts of semantically cohesive units\u2014idiomatic phrases, fixed expressions, or named entities\u2014whose internal tokens vary in importance, as shown by the activation scores.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8124277591705322,
    "similarity_var": 0.00011105070231801999,
    "score_fuzz": 0.625,
    "score_detection": 0.475,
    "score_embedding": 0.22625,
    "total_score": 0.4420833333333334,
    "x": 15.387809753417969,
    "y": 4.535708904266357,
    "cluster_id": 31
  },
  {
    "feature_id": 676,
    "explanation_index": 0,
    "text": "The token \\\"for\\\" is often used to indicate a duration or period of time, typically in phrases that express how long something has been happening, will happen, or has existed.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.933703084786733,
    "similarity_var": 0.00010651504970206182,
    "score_fuzz": 0.91,
    "score_detection": 0.91,
    "score_embedding": 0.6244000000000001,
    "total_score": 0.8148,
    "x": 11.742517471313477,
    "y": 0.2053556591272354,
    "cluster_id": -1
  },
  {
    "feature_id": 676,
    "explanation_index": 1,
    "text": "The preposition \\\"for\\\" is used to indicate duration of time, often preceding a time period or interval.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.933703084786733,
    "similarity_var": 0.00010651504970206182,
    "score_fuzz": 0.98,
    "score_detection": 0.93,
    "score_embedding": 0.7000000000000001,
    "total_score": 0.8700000000000001,
    "x": 11.778361320495605,
    "y": 0.13127698004245758,
    "cluster_id": -1
  },
  {
    "feature_id": 676,
    "explanation_index": 2,
    "text": "The highlighted token is the preposition \u201cfor,\u201d which frequently signals a duration or purpose in the surrounding phrase.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.933703084786733,
    "similarity_var": 0.00010651504970206182,
    "score_fuzz": 0.9428571428571428,
    "score_detection": 0.875,
    "score_embedding": 0.5825,
    "total_score": 0.8001190476190475,
    "x": 14.067511558532715,
    "y": 3.7034106254577637,
    "cluster_id": 67
  },
  {
    "feature_id": 677,
    "explanation_index": 0,
    "text": "Adjectives describing objects, materials, or concepts, often with a sense of intensity, quality, or property, and sometimes used in technical or formal contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9101359446843466,
    "similarity_var": 8.361783006291842e-05,
    "score_fuzz": 0.74,
    "score_detection": 0.58,
    "score_embedding": 0.276,
    "total_score": 0.5319999999999999,
    "x": 8.743041038513184,
    "y": 1.133283257484436,
    "cluster_id": 90
  },
  {
    "feature_id": 677,
    "explanation_index": 1,
    "text": "Adjectives and noun phrases describing physical or abstract qualities, often used to emphasize characteristics like size, condition, or intensity, with frequent use of suffixes like -ed, -ly, or -ing, and occasional presence of technical or domain-specific terms.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9101359446843466,
    "similarity_var": 8.361783006291842e-05,
    "score_fuzz": 0.73,
    "score_detection": 0.67,
    "score_embedding": 0.28375,
    "total_score": 0.5612499999999999,
    "x": 8.83434009552002,
    "y": 1.2257179021835327,
    "cluster_id": 90
  },
  {
    "feature_id": 677,
    "explanation_index": 2,
    "text": "The highlighted tokens are largely adjectives or descriptive terms that function as modifiers in noun phrases, often appearing in technical or descriptive prose.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9101359446843466,
    "similarity_var": 8.361783006291842e-05,
    "score_fuzz": 0.725,
    "score_detection": 0.725,
    "score_embedding": 0.310625,
    "total_score": 0.5868749999999999,
    "x": 14.982763290405273,
    "y": 3.9953503608703613,
    "cluster_id": 22
  },
  {
    "feature_id": 678,
    "explanation_index": 0,
    "text": "Truncated words or words with missing letters, often due to typos, abbreviations, or formatting issues.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8697752753893534,
    "similarity_var": 0.0008483473516736556,
    "score_fuzz": 0.59,
    "score_detection": 0.52,
    "score_embedding": 0.57,
    "total_score": 0.5599999999999999,
    "x": 7.378396511077881,
    "y": 2.9264075756073,
    "cluster_id": 15
  },
  {
    "feature_id": 678,
    "explanation_index": 1,
    "text": "Fragments of words or morphemes that appear at the end of tokens, often due to incomplete or corrupted text, with activations concentrated on partial suffixes or root forms.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8697752753893534,
    "similarity_var": 0.0008483473516736556,
    "score_fuzz": 0.6,
    "score_detection": 0.53,
    "score_embedding": 0.55625,
    "total_score": 0.5620833333333333,
    "x": 7.134171485900879,
    "y": 2.9763853549957275,
    "cluster_id": 59
  },
  {
    "feature_id": 678,
    "explanation_index": 2,
    "text": "The salient units are short character sequences that correspond to word fragments\u2014especially suffixes or prefixes\u2014rather than full words, capturing morphological information for subword tokenization.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8697752753893534,
    "similarity_var": 0.0008483473516736556,
    "score_fuzz": 0.5,
    "score_detection": 0.275,
    "score_embedding": 0.6056250000000001,
    "total_score": 0.4602083333333334,
    "x": 14.860671043395996,
    "y": 5.101399898529053,
    "cluster_id": 77
  },
  {
    "feature_id": 679,
    "explanation_index": 0,
    "text": "Punctuation marks and common function words, often used in programming and technical contexts, as well as nouns and proper nouns, especially those related to technology, locations, and names.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8837095896402994,
    "similarity_var": 0.0005980746292672102,
    "score_fuzz": 0.48,
    "score_detection": 0.36,
    "score_embedding": 0.40199999999999997,
    "total_score": 0.414,
    "x": 7.767687797546387,
    "y": 6.663055896759033,
    "cluster_id": 32
  },
  {
    "feature_id": 679,
    "explanation_index": 1,
    "text": "Fragments of words or identifiers that appear within delimiters, often representing technical terms, variable names, or proper nouns, with high activation values indicating their importance in context.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8837095896402994,
    "similarity_var": 0.0005980746292672102,
    "score_fuzz": 0.6,
    "score_detection": 0.47,
    "score_embedding": 0.56625,
    "total_score": 0.5454166666666667,
    "x": 7.047110557556152,
    "y": 2.8443105220794678,
    "cluster_id": 59
  },
  {
    "feature_id": 679,
    "explanation_index": 2,
    "text": "The highlighted fragments are short, often two\u2011to\u2011four\u2011character tokens that appear as independent words or code identifiers, usually preceded by a space or punctuation. They tend to be the core lexical units of a phrase or a programming construct, and their presence signals a key element in the surrounding text.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8837095896402994,
    "similarity_var": 0.0005980746292672102,
    "score_fuzz": 0.45,
    "score_detection": 0.5,
    "score_embedding": 0.581875,
    "total_score": 0.510625,
    "x": 15.248892784118652,
    "y": 7.225741863250732,
    "cluster_id": 56
  },
  {
    "feature_id": 680,
    "explanation_index": 0,
    "text": "Indentation spaces in code, often used to denote block-level structure.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9386340777079264,
    "similarity_var": 0.00018025078338802637,
    "score_fuzz": 0.84,
    "score_detection": 0.65,
    "score_embedding": 0.4732,
    "total_score": 0.6544,
    "x": 11.365768432617188,
    "y": 7.721565246582031,
    "cluster_id": 81
  },
  {
    "feature_id": 680,
    "explanation_index": 1,
    "text": "Indentation spaces or tabs used to visually structure code blocks, often aligning with syntactic elements like loops, conditionals, or function bodies.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9386340777079264,
    "similarity_var": 0.00018025078338802637,
    "score_fuzz": 0.76,
    "score_detection": 0.58,
    "score_embedding": 0.46125,
    "total_score": 0.6004166666666666,
    "x": 11.382091522216797,
    "y": 7.7502031326293945,
    "cluster_id": 81
  },
  {
    "feature_id": 680,
    "explanation_index": 2,
    "text": "The highlighted tokens are sequences of whitespace that represent indentation levels in code, indicating block structure.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9386340777079264,
    "similarity_var": 0.00018025078338802637,
    "score_fuzz": 0.9,
    "score_detection": 0.55,
    "score_embedding": 0.46625000000000005,
    "total_score": 0.63875,
    "x": 13.575586318969727,
    "y": 6.423651218414307,
    "cluster_id": 8
  },
  {
    "feature_id": 682,
    "explanation_index": 0,
    "text": "Proper nouns, titles, and specific names of entities, such as organizations, locations, books, and publications.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8629657427469889,
    "similarity_var": 0.0003261309805332581,
    "score_fuzz": 0.75,
    "score_detection": 0.67,
    "score_embedding": 0.5764,
    "total_score": 0.6654666666666667,
    "x": 7.494315147399902,
    "y": -0.9009591341018677,
    "cluster_id": 16
  },
  {
    "feature_id": 682,
    "explanation_index": 1,
    "text": "Common patterns include proper nouns, brand names, and technical terms, often appearing in contexts involving titles, locations, products, or specialized domains, with frequent use of punctuation and formatting markers around them.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8629657427469889,
    "similarity_var": 0.0003261309805332581,
    "score_fuzz": 0.6,
    "score_detection": 0.53,
    "score_embedding": 0.413125,
    "total_score": 0.5143749999999999,
    "x": 9.467358589172363,
    "y": 0.3383174538612366,
    "cluster_id": -1
  },
  {
    "feature_id": 682,
    "explanation_index": 2,
    "text": "The pattern might be that the highlighted tokens are nouns or proper nouns, or maybe tokens that are capitalized or have special characters.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8629657427469889,
    "similarity_var": 0.0003261309805332581,
    "score_fuzz": 0.575,
    "score_detection": 0.525,
    "score_embedding": 0.46375,
    "total_score": 0.5212500000000001,
    "x": 13.814676284790039,
    "y": 4.674068450927734,
    "cluster_id": -1
  },
  {
    "feature_id": 683,
    "explanation_index": 0,
    "text": "First-person pronouns, auxiliary verbs, and other short function words often used in informal writing and speech, such as in blogs, reviews, and social media posts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8383617401123047,
    "similarity_var": 0.00039518112752290335,
    "score_fuzz": 0.62,
    "score_detection": 0.58,
    "score_embedding": 0.6312,
    "total_score": 0.6103999999999999,
    "x": 11.470803260803223,
    "y": 0.9754032492637634,
    "cluster_id": -1
  },
  {
    "feature_id": 683,
    "explanation_index": 1,
    "text": "Pronouns such as \\\"I\\\", \\\"you\\\", \\\"we\\\", and \\\"they\\\" frequently appear in personal narratives and direct address, often signaling subjective experience or engagement with the reader.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8383617401123047,
    "similarity_var": 0.00039518112752290335,
    "score_fuzz": 0.72,
    "score_detection": 0.62,
    "score_embedding": 0.731875,
    "total_score": 0.6906249999999999,
    "x": 11.699702262878418,
    "y": 1.4028396606445312,
    "cluster_id": 71
  },
  {
    "feature_id": 683,
    "explanation_index": 2,
    "text": "The highlighted tokens are typically short, high\u2011frequency function words or common suffixes that appear at clause boundaries or after punctuation, indicating grammatical or discourse structure.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8383617401123047,
    "similarity_var": 0.00039518112752290335,
    "score_fuzz": 0.525,
    "score_detection": 0.5,
    "score_embedding": 0.6843750000000001,
    "total_score": 0.5697916666666667,
    "x": 13.814844131469727,
    "y": 3.567732095718384,
    "cluster_id": -1
  },
  {
    "feature_id": 684,
    "explanation_index": 0,
    "text": "Various programming language syntax elements, including keywords, data types, function calls, and variable declarations.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9192825754483541,
    "similarity_var": 0.0001727935852815992,
    "score_fuzz": 0.42,
    "score_detection": 0.35,
    "score_embedding": 0.6323999999999999,
    "total_score": 0.46746666666666664,
    "x": 10.649262428283691,
    "y": 8.40809440612793,
    "cluster_id": 48
  },
  {
    "feature_id": 684,
    "explanation_index": 1,
    "text": "The presence of code-specific syntax elements such as identifiers, operators, and keywords in programming contexts, often surrounded by delimiters or appearing in structured code patterns.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9192825754483541,
    "similarity_var": 0.0001727935852815992,
    "score_fuzz": 0.44,
    "score_detection": 0.37,
    "score_embedding": 0.73,
    "total_score": 0.5133333333333333,
    "x": 10.594348907470703,
    "y": 7.556023120880127,
    "cluster_id": -1
  },
  {
    "feature_id": 684,
    "explanation_index": 2,
    "text": "The highlighted tokens are syntactic elements of programming code\u2014keywords, identifiers, operators, and literals\u2014that are crucial for the structure and meaning of the code snippets.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9192825754483541,
    "similarity_var": 0.0001727935852815992,
    "score_fuzz": 0.4,
    "score_detection": 0.425,
    "score_embedding": 0.77125,
    "total_score": 0.5320833333333334,
    "x": 13.837127685546875,
    "y": 6.673951625823975,
    "cluster_id": 8
  },
  {
    "feature_id": 685,
    "explanation_index": 0,
    "text": "Adverbs and adjectives indicating degree, proximity, or manner, often used to modify or intensify the meaning of a verb, adjective, or another adverb.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9148866931597391,
    "similarity_var": 0.0002039063266236793,
    "score_fuzz": 0.96,
    "score_detection": 0.47,
    "score_embedding": 0.5591999999999999,
    "total_score": 0.6630666666666666,
    "x": 9.275230407714844,
    "y": 1.557692050933838,
    "cluster_id": 89
  },
  {
    "feature_id": 685,
    "explanation_index": 1,
    "text": "Intensifiers and approximators such as \\\"almost\\\", \\\"nearly\\\", \\\"barely\\\", \\\"hardly\\\", \\\"practically\\\", \\\"quasi-\\\", \\\"basically\\\", \\\"effectively\\\", \\\"essentially\\\", \\\"virtually\\\", and \\\"absolutely\\\" are used to convey degrees of approximation, limitation, or emphasis, often modifying the certainty, extent, or intensity of a statement.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9148866931597391,
    "similarity_var": 0.0002039063266236793,
    "score_fuzz": 0.95,
    "score_detection": 0.89,
    "score_embedding": 0.56375,
    "total_score": 0.8012499999999999,
    "x": 11.809585571289062,
    "y": 3.39743709564209,
    "cluster_id": 60
  },
  {
    "feature_id": 685,
    "explanation_index": 2,
    "text": "The highlighted tokens are adverbs of degree or approximation (e.g., \u201calmost,\u201d \u201cnearly,\u201d \u201cvirtually,\u201d \u201cbarely,\u201d \u201chardly,\u201d \u201cmuch,\u201d \u201cbasically,\u201d \u201cpractically,\u201d \u201cquite,\u201d \u201cessentially,\u201d \u201ceffectively,\u201d \u201cabsolutely\u201d). They typically precede a noun or adjective phrase to indicate closeness to a state, a level of intensity, or a subtle emphasis, thereby adding nuance to the description.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9148866931597391,
    "similarity_var": 0.0002039063266236793,
    "score_fuzz": 0.975,
    "score_detection": 0.825,
    "score_embedding": 0.55625,
    "total_score": 0.7854166666666665,
    "x": 14.972103118896484,
    "y": 4.093458652496338,
    "cluster_id": 22
  },
  {
    "feature_id": 687,
    "explanation_index": 0,
    "text": "Words related to weight, difficulty, or responsibility, often describing a challenge or obligation.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9244307478268942,
    "similarity_var": 0.00010786742973402219,
    "score_fuzz": 0.71,
    "score_detection": 0.58,
    "score_embedding": 0.8436,
    "total_score": 0.7111999999999999,
    "x": 10.282840728759766,
    "y": 0.45788338780403137,
    "cluster_id": -1
  },
  {
    "feature_id": 687,
    "explanation_index": 1,
    "text": "The text latents frequently involve words related to physical or emotional strain, responsibility, or difficulty, often appearing in contexts discussing pressure, effort, or burden, with a recurring emphasis on abstract or tangible loads, demands, or challenges.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9244307478268942,
    "similarity_var": 0.00010786742973402219,
    "score_fuzz": 0.77,
    "score_detection": 0.58,
    "score_embedding": 0.841875,
    "total_score": 0.730625,
    "x": 10.257311820983887,
    "y": 0.6151012778282166,
    "cluster_id": -1
  },
  {
    "feature_id": 687,
    "explanation_index": 2,
    "text": "The highlighted tokens are nouns or verbs that express a burden, load, or responsibility\u2014often modified by adjectives such as \u201cheavy,\u201d \u201cwork,\u201d or \u201cpressure\u201d\u2014and they appear in contexts that convey effort, difficulty, or duty.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9244307478268942,
    "similarity_var": 0.00010786742973402219,
    "score_fuzz": 0.7,
    "score_detection": 0.625,
    "score_embedding": 0.8987499999999999,
    "total_score": 0.74125,
    "x": 15.349682807922363,
    "y": 4.030735492706299,
    "cluster_id": 22
  },
  {
    "feature_id": 688,
    "explanation_index": 0,
    "text": "Proper nouns, often names of people, places, and organizations, and sometimes titles of artworks or other specific entities.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8486117521921793,
    "similarity_var": 0.00087689813290205,
    "score_fuzz": 0.64,
    "score_detection": 0.41,
    "score_embedding": 0.07320000000000002,
    "total_score": 0.3744,
    "x": 7.490757942199707,
    "y": -0.9344024062156677,
    "cluster_id": 16
  },
  {
    "feature_id": 688,
    "explanation_index": 1,
    "text": "Named entities, proper nouns, and specific geographical or institutional references are frequently highlighted, particularly when they appear in compound or abbreviated forms, often with partial tokenization or phonetic segmentation.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8486117521921793,
    "similarity_var": 0.00087689813290205,
    "score_fuzz": 0.47,
    "score_detection": 0.35,
    "score_embedding": 0.11750000000000002,
    "total_score": 0.3125,
    "x": 6.8376007080078125,
    "y": -0.8332805633544922,
    "cluster_id": 84
  },
  {
    "feature_id": 688,
    "explanation_index": 2,
    "text": "The highlighted fragments are the core lexical units of idiomatic or compositional expressions, often forming a contiguous sequence that carries the main semantic content, such as the noun in a container phrase, the comparative suffix, or the key words of an idiom.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8486117521921793,
    "similarity_var": 0.00087689813290205,
    "score_fuzz": 0.625,
    "score_detection": 0.65,
    "score_embedding": 0.19125000000000003,
    "total_score": 0.48875,
    "x": 15.784624099731445,
    "y": 7.375156402587891,
    "cluster_id": 19
  },
  {
    "feature_id": 689,
    "explanation_index": 0,
    "text": "First-person singular pronouns, other personal pronouns, and some adverbs or adjectives often used in informal writing or speech, typically marking a shift in tone or perspective.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8363482157389323,
    "similarity_var": 0.0025381983214087553,
    "score_fuzz": 0.73,
    "score_detection": 0.7,
    "score_embedding": 0.39239999999999997,
    "total_score": 0.6074666666666667,
    "x": 11.593887329101562,
    "y": 1.119326114654541,
    "cluster_id": 64
  },
  {
    "feature_id": 689,
    "explanation_index": 1,
    "text": "Pronouns and pronoun-like tokens (e.g., \\\"I\\\", \\\"we\\\", \\\"he\\\", \\\"she\\\", \\\"they\\\", \\\"you\\\", \\\"someone\\\", \\\"everyone\\\", \\\"anyone\\\", \\\"one\\\") frequently appear in contexts involving personal perspective, self-reference, or generalization, often signaling subjective viewpoints, inclusive or exclusive group references, or narrative voice.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8363482157389323,
    "similarity_var": 0.0025381983214087553,
    "score_fuzz": 0.73,
    "score_detection": 0.63,
    "score_embedding": 0.22125,
    "total_score": 0.5270833333333332,
    "x": 11.741418838500977,
    "y": 1.3879117965698242,
    "cluster_id": 71
  },
  {
    "feature_id": 689,
    "explanation_index": 2,
    "text": "the patterns in the examples.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8363482157389323,
    "similarity_var": 0.0025381983214087553,
    "score_fuzz": 0.5,
    "score_detection": 0.425,
    "score_embedding": 0.285625,
    "total_score": 0.4035416666666667,
    "x": 5.195289134979248,
    "y": 9.921859741210938,
    "cluster_id": 58
  },
  {
    "feature_id": 690,
    "explanation_index": 0,
    "text": "Commas used to separate clauses or items in a sentence, often indicating a pause in the text.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8879507581392924,
    "similarity_var": 0.0016499197525977,
    "score_fuzz": 0.92,
    "score_detection": 0.74,
    "score_embedding": 0.2368,
    "total_score": 0.6322666666666668,
    "x": 8.007132530212402,
    "y": 6.46025276184082,
    "cluster_id": 5
  },
  {
    "feature_id": 690,
    "explanation_index": 1,
    "text": "Commas and punctuation marks used to separate clauses, list items, or indicate pauses in narrative or descriptive text, often appearing before or after quoted material, parenthetical statements, or in sequences of related ideas.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8879507581392924,
    "similarity_var": 0.0016499197525977,
    "score_fuzz": 0.94,
    "score_detection": 0.75,
    "score_embedding": 0.14125000000000001,
    "total_score": 0.6104166666666667,
    "x": 7.951687335968018,
    "y": 6.405913352966309,
    "cluster_id": 5
  },
  {
    "feature_id": 690,
    "explanation_index": 2,
    "text": "The model identifies punctuation\u2014particularly commas\u2014as key tokens that influence its behavior.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8879507581392924,
    "similarity_var": 0.0016499197525977,
    "score_fuzz": 0.825,
    "score_detection": 0.4,
    "score_embedding": 0.17625000000000002,
    "total_score": 0.46708333333333335,
    "x": 13.341185569763184,
    "y": 5.316933631896973,
    "cluster_id": -1
  },
  {
    "feature_id": 691,
    "explanation_index": 0,
    "text": "Function words and prepositions, often used to indicate possession, direction, or relationship, and sometimes used to begin a clause or phrase.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8919655680656433,
    "similarity_var": 0.00041652767350086606,
    "score_fuzz": 0.64,
    "score_detection": 0.45,
    "score_embedding": 0.6352000000000001,
    "total_score": 0.5750666666666667,
    "x": 10.674261093139648,
    "y": 1.159375786781311,
    "cluster_id": 26
  },
  {
    "feature_id": 691,
    "explanation_index": 1,
    "text": "Common prepositions and possessive pronouns that connect clauses or modify nouns in syntactic dependencies, often appearing in contextually embedded phrases.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8919655680656433,
    "similarity_var": 0.00041652767350086606,
    "score_fuzz": 0.62,
    "score_detection": 0.41,
    "score_embedding": 0.71375,
    "total_score": 0.5812499999999999,
    "x": 12.176365852355957,
    "y": -0.0678071528673172,
    "cluster_id": 9
  },
  {
    "feature_id": 691,
    "explanation_index": 2,
    "text": "The highlighted tokens are mainly short, high\u2011frequency function words\u2014articles, prepositions, pronouns, and conjunctions\u2014that provide grammatical scaffolding and appear across many contexts and multi\u2011token sequences.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8919655680656433,
    "similarity_var": 0.00041652767350086606,
    "score_fuzz": 0.525,
    "score_detection": 0.475,
    "score_embedding": 0.7437499999999999,
    "total_score": 0.5812499999999999,
    "x": 13.44922924041748,
    "y": 3.241732120513916,
    "cluster_id": 35
  },
  {
    "feature_id": 692,
    "explanation_index": 0,
    "text": "Various tokens including nouns, adjectives, adverbs, and punctuation marks that appear to be part of a diverse set of texts, often marking the beginning or end of a quotation, a mathematical expression, or a code snippet, and sometimes indicating a transition or a connection between ideas.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8551160097122192,
    "similarity_var": 0.00018144736789575214,
    "score_fuzz": 0.37,
    "score_detection": 0.17,
    "score_embedding": 0.34320000000000006,
    "total_score": 0.29440000000000005,
    "x": 10.564099311828613,
    "y": 4.934855937957764,
    "cluster_id": -1
  },
  {
    "feature_id": 692,
    "explanation_index": 1,
    "text": "Common linguistic patterns involving multi-token phrases, proper nouns, or technical terms that are contextually significant, often appearing in structured or formal text, including idioms, scientific notation, compound words, and punctuation-heavy sequences.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8551160097122192,
    "similarity_var": 0.00018144736789575214,
    "score_fuzz": 0.4,
    "score_detection": 0.43,
    "score_embedding": 0.44562500000000005,
    "total_score": 0.4252083333333334,
    "x": 9.641395568847656,
    "y": 0.3934449255466461,
    "cluster_id": -1
  },
  {
    "feature_id": 692,
    "explanation_index": 2,
    "text": "The highlighted segments are contiguous words or symbols that form a semantically coherent unit\u2014usually a noun phrase or a single key term\u2014that the model identifies as most informative for the context.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8551160097122192,
    "similarity_var": 0.00018144736789575214,
    "score_fuzz": 0.575,
    "score_detection": 0.525,
    "score_embedding": 0.42437499999999995,
    "total_score": 0.508125,
    "x": 15.580025672912598,
    "y": 6.852118015289307,
    "cluster_id": -1
  },
  {
    "feature_id": 694,
    "explanation_index": 0,
    "text": "Geographic locations, often bodies of water such as lakes, seas, and rivers, as well as names of specific places and regions.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.897337277730306,
    "similarity_var": 0.0005007854469983246,
    "score_fuzz": 0.52,
    "score_detection": 0.38,
    "score_embedding": 0.32159999999999994,
    "total_score": 0.4072,
    "x": 7.28253698348999,
    "y": -1.1139178276062012,
    "cluster_id": -1
  },
  {
    "feature_id": 694,
    "explanation_index": 1,
    "text": "The token \\\"lake\\\" and its variants (e.g., \\\"Lak\\\", \\\"Lakes\\\", \\\"Lake District\\\") are frequently activated in contexts related to geographical locations, natural features, or place names, often associated with bodies of water in landscapes or travel-related descriptions.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.897337277730306,
    "similarity_var": 0.0005007854469983246,
    "score_fuzz": 0.6947368421052632,
    "score_detection": 0.6421052631578947,
    "score_embedding": 0.4975,
    "total_score": 0.6114473684210527,
    "x": 10.900687217712402,
    "y": 3.9824256896972656,
    "cluster_id": -1
  },
  {
    "feature_id": 694,
    "explanation_index": 2,
    "text": "the pattern: many tokens are \\\"Lake\\\" or \\\"lake\\\" or \\\"Lakes\\\" or \\\"Lake District\\\" etc.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.897337277730306,
    "similarity_var": 0.0005007854469983246,
    "score_fuzz": 0.7,
    "score_detection": 0.725,
    "score_embedding": 0.561875,
    "total_score": 0.6622916666666666,
    "x": 11.198904991149902,
    "y": 4.143309116363525,
    "cluster_id": -1
  },
  {
    "feature_id": 695,
    "explanation_index": 0,
    "text": "Abbreviations and units of measurement, often in scientific or technical contexts, and proper nouns, including names of people, places, and organizations.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8179447650909424,
    "similarity_var": 0.0023275456707262756,
    "score_fuzz": 0.53,
    "score_detection": 0.44,
    "score_embedding": 0.5268,
    "total_score": 0.4989333333333333,
    "x": 7.742855072021484,
    "y": 1.0768836736679077,
    "cluster_id": -1
  },
  {
    "feature_id": 695,
    "explanation_index": 1,
    "text": "The token \\\"mm\\\" and its variations (e.g., \\\"Mm\\\", \\\"mM\\\", \\\"MM\\\") frequently appear in contexts related to units of measurement (millimolar), abbreviations for \\\"massively multiplayer online\\\" in gaming, or as part of compound words and names, often in technical, scientific, or gaming-related text.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8179447650909424,
    "similarity_var": 0.0023275456707262756,
    "score_fuzz": 0.6,
    "score_detection": 0.64,
    "score_embedding": 0.5674999999999999,
    "total_score": 0.6024999999999999,
    "x": 10.074847221374512,
    "y": 4.304797172546387,
    "cluster_id": 1
  },
  {
    "feature_id": 695,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8179447650909424,
    "similarity_var": 0.0023275456707262756,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.47562499999999996,
    "total_score": 0.491875,
    "x": -7.942327976226807,
    "y": 9.118030548095703,
    "cluster_id": 52
  },
  {
    "feature_id": 696,
    "explanation_index": 0,
    "text": "Adjectives and nouns describing frequency, regulation, and commonality, often used to convey a sense of regularity, normalcy, or standardization.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.854295035203298,
    "similarity_var": 0.004527670665184126,
    "score_fuzz": 0.77,
    "score_detection": 0.66,
    "score_embedding": 0.49960000000000004,
    "total_score": 0.6432000000000001,
    "x": 8.695819854736328,
    "y": -0.4193843603134155,
    "cluster_id": -1
  },
  {
    "feature_id": 696,
    "explanation_index": 1,
    "text": "Common adjectives and nouns used to describe standard, typical, or expected conditions, often in contexts involving routine, normalcy, or baseline states.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.854295035203298,
    "similarity_var": 0.004527670665184126,
    "score_fuzz": 0.58,
    "score_detection": 0.46,
    "score_embedding": 0.45125,
    "total_score": 0.4970833333333333,
    "x": 8.621344566345215,
    "y": -0.5043448209762573,
    "cluster_id": 79
  },
  {
    "feature_id": 696,
    "explanation_index": 2,
    "text": "Explanation could not be parsed.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.854295035203298,
    "similarity_var": 0.004527670665184126,
    "score_fuzz": 0.5,
    "score_detection": 0.5,
    "score_embedding": 0.35875,
    "total_score": 0.4529166666666667,
    "x": -7.8735456466674805,
    "y": 9.186805725097656,
    "cluster_id": 52
  },
  {
    "feature_id": 697,
    "explanation_index": 0,
    "text": "Proper nouns, names of people, places, and organizations, as well as pronouns and common nouns in specific contexts.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8738678495089213,
    "similarity_var": 0.00017843370066906853,
    "score_fuzz": 0.7,
    "score_detection": 0.44,
    "score_embedding": 0.29000000000000004,
    "total_score": 0.4766666666666666,
    "x": 7.394032001495361,
    "y": -0.9796301126480103,
    "cluster_id": 16
  },
  {
    "feature_id": 697,
    "explanation_index": 1,
    "text": "Named entities, particularly proper nouns, are often split across token boundaries with high activation, especially when they appear in contexts involving people, places, organizations, or titles.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8738678495089213,
    "similarity_var": 0.00017843370066906853,
    "score_fuzz": 0.67,
    "score_detection": 0.46,
    "score_embedding": 0.26625,
    "total_score": 0.46541666666666676,
    "x": 6.773643970489502,
    "y": -0.8813555240631104,
    "cluster_id": 84
  },
  {
    "feature_id": 697,
    "explanation_index": 2,
    "text": "Tokens that are either whole words or fragments of words, often capitalized or starting with a capital letter, representing proper nouns, pronouns, or parts of compound words, are highlighted as important.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8738678495089213,
    "similarity_var": 0.00017843370066906853,
    "score_fuzz": 0.875,
    "score_detection": 0.375,
    "score_embedding": 0.26937500000000003,
    "total_score": 0.5064583333333333,
    "x": 14.552948951721191,
    "y": 4.246297359466553,
    "cluster_id": -1
  },
  {
    "feature_id": 698,
    "explanation_index": 0,
    "text": "Keywords and control structures in programming languages, including function definitions, conditional statements, loops, and data types.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.9150567253430685,
    "similarity_var": 6.992079158941857e-05,
    "score_fuzz": 0.5,
    "score_detection": 0.35,
    "score_embedding": 0.39039999999999997,
    "total_score": 0.41346666666666665,
    "x": 10.74262809753418,
    "y": 8.460247039794922,
    "cluster_id": 48
  },
  {
    "feature_id": 698,
    "explanation_index": 1,
    "text": "Keywords and identifiers in programming languages, SQL, and markup languages that denote control flow, data types, declarations, or structural elements, often appearing in syntactic contexts with specific formatting or casing.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.9150567253430685,
    "similarity_var": 6.992079158941857e-05,
    "score_fuzz": 0.49,
    "score_detection": 0.32,
    "score_embedding": 0.43937500000000007,
    "total_score": 0.4164583333333334,
    "x": 10.501083374023438,
    "y": 8.485757827758789,
    "cluster_id": 80
  },
  {
    "feature_id": 698,
    "explanation_index": 2,
    "text": "The highlighted tokens are programming language keywords or reserved words that signal control flow, data\u2011structure declarations, or language constructs across multiple languages.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.9150567253430685,
    "similarity_var": 6.992079158941857e-05,
    "score_fuzz": 0.725,
    "score_detection": 0.375,
    "score_embedding": 0.4156249999999999,
    "total_score": 0.5052083333333334,
    "x": 13.833746910095215,
    "y": 6.6977081298828125,
    "cluster_id": 8
  },
  {
    "feature_id": 699,
    "explanation_index": 0,
    "text": "Numerical values, often embedded within text, and sometimes used as part of a larger numerical expression or identifier.",
    "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "similarity_mean": 0.8529651562372843,
    "similarity_var": 0.00020587130127185875,
    "score_fuzz": 0.71,
    "score_detection": 0.58,
    "score_embedding": 0.8300000000000001,
    "total_score": 0.7066666666666667,
    "x": 6.8994059562683105,
    "y": 8.77837085723877,
    "cluster_id": 29
  },
  {
    "feature_id": 699,
    "explanation_index": 1,
    "text": "The digit '5' and the sequence 'th' frequently appear in ordinal numbers, often in contexts involving dates, centuries, or ranked positions, with high activation values indicating their importance in identifying numerical or ordinal patterns.",
    "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "similarity_mean": 0.8529651562372843,
    "similarity_var": 0.00020587130127185875,
    "score_fuzz": 0.52,
    "score_detection": 0.36,
    "score_embedding": 0.728125,
    "total_score": 0.5360416666666666,
    "x": 7.212209701538086,
    "y": 8.68683910369873,
    "cluster_id": 29
  },
  {
    "feature_id": 699,
    "explanation_index": 2,
    "text": "The highlighted tokens are the core lexical elements of idiomatic or figurative expressions, the comparative suffix \u201c\u2011er\u201d, or nouns that denote a container or location, often occurring adjacent to quotation marks or numeric contexts.",
    "llm_explainer": "openai/gpt-oss-20b",
    "similarity_mean": 0.8529651562372843,
    "similarity_var": 0.00020587130127185875,
    "score_fuzz": 0.575,
    "score_detection": 0.375,
    "score_embedding": 0.8256249999999999,
    "total_score": 0.5918749999999999,
    "x": 14.650747299194336,
    "y": 4.102586269378662,
    "cluster_id": 11
  }
]